{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "\n",
    "for i in range(6):\n",
    "    with open('..\\\\Collection\\\\D'+str(i+1)+'.txt', 'r', encoding='utf-8') as file:\n",
    "        documents.append(file.read())\n",
    "       \n",
    "\n",
    "print(len(documents))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Reformulation(QR) is a set of techniques used to transform a user’s original search query to a text that better aligns with the user’s intent and improves their search experience. Recently, zero-shot QR has been shown to be a promising approach due to its ability to exploit knowledge inherent in large language models. By taking inspiration from the success of ensemble prompting strategies which have benefited many tasks, we investigate if they can help improve query reformulation. In this context, we propose an ensemble based prompting technique, GenQREnsemble which leverages paraphrases of a zero-shot instruction to generate multiple sets of keywords ultimately improving retrieval performance. We further introduce its post-retrieval variant, GenQREnsembleRF to incorporate pseudo relevant feedback. On evaluations over four IR benchmarks, we find that GenQREnsemble generates better reformulations with relative nDCG@10 improvements up to 18% and MAP improvements upto 24% over the previous zero-shot state-of-art. On the MSMarco Passage Ranking task, GenQREnsembleRF shows relative gains of 5% MRR using pseudo-relevance feedback, and 9% nDCG@10 using relevant feedback documents.\n"
     ]
    }
   ],
   "source": [
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "termes_split= []\n",
    "\n",
    "for i in range(6):\n",
    "    termes_split.append(documents[i].split())\n",
    "   \n",
    "        \n",
    "print(len(termes_split))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Query', 'Reformulation(QR)', 'is', 'a', 'set', 'of', 'techniques', 'used', 'to', 'transform', 'a', 'user’s', 'original', 'search', 'query', 'to', 'a', 'text', 'that', 'better', 'aligns', 'with', 'the', 'user’s', 'intent', 'and', 'improves', 'their', 'search', 'experience.', 'Recently,', 'zero-shot', 'QR', 'has', 'been', 'shown', 'to', 'be', 'a', 'promising', 'approach', 'due', 'to', 'its', 'ability', 'to', 'exploit', 'knowledge', 'inherent', 'in', 'large', 'language', 'models.', 'By', 'taking', 'inspiration', 'from', 'the', 'success', 'of', 'ensemble', 'prompting', 'strategies', 'which', 'have', 'benefited', 'many', 'tasks,', 'we', 'investigate', 'if', 'they', 'can', 'help', 'improve', 'query', 'reformulation.', 'In', 'this', 'context,', 'we', 'propose', 'an', 'ensemble', 'based', 'prompting', 'technique,', 'GenQREnsemble', 'which', 'leverages', 'paraphrases', 'of', 'a', 'zero-shot', 'instruction', 'to', 'generate', 'multiple', 'sets', 'of', 'keywords', 'ultimately', 'improving', 'retrieval', 'performance.', 'We', 'further', 'introduce', 'its', 'post-retrieval', 'variant,', 'GenQREnsembleRF', 'to', 'incorporate', 'pseudo', 'relevant', 'feedback.', 'On', 'evaluations', 'over', 'four', 'IR', 'benchmarks,', 'we', 'find', 'that', 'GenQREnsemble', 'generates', 'better', 'reformulations', 'with', 'relative', 'nDCG@10', 'improvements', 'up', 'to', '18%', 'and', 'MAP', 'improvements', 'upto', '24%', 'over', 'the', 'previous', 'zero-shot', 'state-of-art.', 'On', 'the', 'MSMarco', 'Passage', 'Ranking', 'task,', 'GenQREnsembleRF', 'shows', 'relative', 'gains', 'of', '5%', 'MRR', 'using', 'pseudo-relevance', 'feedback,', 'and', '9%', 'nDCG@10', 'using', 'relevant', 'feedback', 'documents.']\n"
     ]
    }
   ],
   "source": [
    "print(termes_split[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ExpReg = nltk.RegexpTokenizer('(?:[A-Z]\\.)+|\\d+(?:\\.\\d+)?DA?|\\w+|\\.{3}') # \\d : équivalent à [0-9] \n",
    "termes_reg= []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(6):\n",
    "\n",
    "    termes_reg.append(ExpReg.tokenize(documents[i]) )\n",
    "        \n",
    "\n",
    "print(len(termes_reg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Query', 'Reformulation', 'QR', 'is', 'a', 'set', 'of', 'techniques', 'used', 'to', 'transform', 'a', 'user', 's', 'original', 'search', 'query', 'to', 'a', 'text', 'that', 'better', 'aligns', 'with', 'the', 'user', 's', 'intent', 'and', 'improves', 'their', 'search', 'experience', 'Recently', 'zero', 'shot', 'QR', 'has', 'been', 'shown', 'to', 'be', 'a', 'promising', 'approach', 'due', 'to', 'its', 'ability', 'to', 'exploit', 'knowledge', 'inherent', 'in', 'large', 'language', 'models', 'By', 'taking', 'inspiration', 'from', 'the', 'success', 'of', 'ensemble', 'prompting', 'strategies', 'which', 'have', 'benefited', 'many', 'tasks', 'we', 'investigate', 'if', 'they', 'can', 'help', 'improve', 'query', 'reformulation', 'In', 'this', 'context', 'we', 'propose', 'an', 'ensemble', 'based', 'prompting', 'technique', 'GenQREnsemble', 'which', 'leverages', 'paraphrases', 'of', 'a', 'zero', 'shot', 'instruction', 'to', 'generate', 'multiple', 'sets', 'of', 'keywords', 'ultimately', 'improving', 'retrieval', 'performance', 'We', 'further', 'introduce', 'its', 'post', 'retrieval', 'variant', 'GenQREnsembleRF', 'to', 'incorporate', 'pseudo', 'relevant', 'feedback', 'On', 'evaluations', 'over', 'four', 'IR', 'benchmarks', 'we', 'find', 'that', 'GenQREnsemble', 'generates', 'better', 'reformulations', 'with', 'relative', 'nDCG', '10', 'improvements', 'up', 'to', '18', 'and', 'MAP', 'improvements', 'upto', '24', 'over', 'the', 'previous', 'zero', 'shot', 'state', 'of', 'art', 'On', 'the', 'MSMarco', 'Passage', 'Ranking', 'task', 'GenQREnsembleRF', 'shows', 'relative', 'gains', 'of', '5', 'MRR', 'using', 'pseudo', 'relevance', 'feedback', 'and', '9', 'nDCG', '10', 'using', 'relevant', 'feedback', 'documents']\n",
      "['Ranking', 'documents', 'using', 'Large', 'Language', 'Models', 'LLMs', 'by', 'directly', 'feeding', 'the', 'query', 'and', 'candidate', 'documents', 'into', 'the', 'prompt', 'is', 'an', 'interesting', 'and', 'practical', 'problem', 'However', 'researchers', 'have', 'found', 'it', 'difficult', 'to', 'outperform', 'fine', 'tuned', 'baseline', 'rankers', 'on', 'benchmark', 'datasets', 'We', 'analyze', 'pointwise', 'and', 'listwise', 'ranking', 'prompts', 'used', 'by', 'existing', 'methods', 'and', 'argue', 'that', 'off', 'the', 'shelf', 'LLMs', 'do', 'not', 'fully', 'understand', 'these', 'challenging', 'ranking', 'formulations', 'In', 'this', 'paper', 'we', 'propose', 'to', 'significantly', 'reduce', 'the', 'burden', 'on', 'LLMs', 'by', 'using', 'a', 'new', 'technique', 'called', 'Pairwise', 'Ranking', 'Prompting', 'PRP', 'Our', 'results', 'are', 'the', 'first', 'in', 'the', 'literature', 'to', 'achieve', 'state', 'of', 'the', 'art', 'ranking', 'performance', 'on', 'standard', 'benchmarks', 'using', 'moderate', 'sized', 'open', 'sourced', 'LLMs', 'On', 'TREC', 'DL', '2019', 'and', '2020', 'PRP', 'based', 'on', 'the', 'Flan', 'UL2', 'model', 'with', '20B', 'parameters', 'performs', 'favorably', 'with', 'the', 'previous', 'best', 'approach', 'in', 'the', 'literature', 'which', 'is', 'based', 'on', 'the', 'blackbox', 'commercial', 'GPT', '4', 'that', 'has', '50x', 'estimated', 'model', 'size', 'while', 'outperforming', 'other', 'LLM', 'based', 'solutions', 'such', 'as', 'InstructGPT', 'which', 'has', '175B', 'parameters', 'by', 'over', '10', 'for', 'all', 'ranking', 'metrics', 'By', 'using', 'the', 'same', 'prompt', 'template', 'on', 'seven', 'BEIR', 'tasks', 'PRP', 'outperforms', 'supervised', 'baselines', 'and', 'outperforms', 'the', 'blackbox', 'commercial', 'ChatGPT', 'solution', 'by', '4', '2', 'and', 'pointwise', 'LLM', 'based', 'solutions', 'by', 'more', 'than', '10', 'on', 'average', 'NDCG', '10', 'Furthermore', 'we', 'propose', 'several', 'variants', 'of', 'PRP', 'to', 'improve', 'efficiency', 'and', 'show', 'that', 'it', 'is', 'possible', 'to', 'achieve', 'competitive', 'results', 'even', 'with', 'linear', 'complexity']\n",
      "['Large', 'language', 'models', 'LLM', 'have', 'manifested', 'unparalleled', 'modeling', 'capability', 'on', 'various', 'tasks', 'e', 'g', 'multi', 'step', 'reasoning', 'but', 'the', 'input', 'to', 'these', 'models', 'is', 'mostly', 'limited', 'to', 'plain', 'text', 'which', 'could', 'be', 'very', 'long', 'and', 'contain', 'noisy', 'information', 'Long', 'text', 'could', 'take', 'long', 'time', 'to', 'process', 'and', 'thus', 'may', 'not', 'be', 'efficient', 'enough', 'for', 'recommender', 'systems', 'that', 'require', 'immediate', 'response', 'In', 'LLM', 'based', 'recommendation', 'models', 'user', 'and', 'item', 'IDs', 'are', 'usually', 'filled', 'in', 'a', 'template', 'i', 'e', 'discrete', 'prompt', 'to', 'allow', 'the', 'models', 'to', 'understand', 'a', 'given', 'task', 'but', 'the', 'models', 'usually', 'need', 'extensive', 'fine', 'tuning', 'to', 'bridge', 'the', 'user', 'item', 'IDs', 'and', 'the', 'template', 'words', 'and', 'to', 'unleash', 'the', 'power', 'of', 'LLM', 'for', 'recommendation', 'To', 'address', 'the', 'problems', 'we', 'propose', 'to', 'distill', 'the', 'discrete', 'prompt', 'for', 'a', 'specific', 'task', 'to', 'a', 'set', 'of', 'continuous', 'prompt', 'vectors', 'so', 'as', 'to', 'bridge', 'IDs', 'and', 'words', 'and', 'to', 'reduce', 'the', 'inference', 'time', 'We', 'also', 'design', 'a', 'training', 'strategy', 'with', 'an', 'attempt', 'to', 'improve', 'the', 'efficiency', 'of', 'training', 'these', 'models', 'Experimental', 'results', 'on', 'three', 'real', 'world', 'datasets', 'demonstrate', 'the', 'effectiveness', 'of', 'our', 'PrOmpt', 'Distillation', 'POD', 'approach', 'on', 'both', 'sequential', 'recommendation', 'and', 'top', 'N', 'recommendation', 'tasks', 'Although', 'the', 'training', 'efficiency', 'can', 'be', 'significantly', 'improved', 'the', 'improvement', 'of', 'inference', 'efficiency', 'is', 'limited', 'This', 'finding', 'may', 'inspire', 'researchers', 'in', 'the', 'community', 'to', 'further', 'improve', 'the', 'inference', 'efficiency', 'of', 'LLM', 'based', 'recommendation', 'models']\n",
      "['Query', 'reformulation', 'is', 'a', 'well', 'known', 'problem', 'in', 'Information', 'Retrieval', 'IR', 'aimed', 'at', 'enhancing', 'single', 'search', 'successful', 'completion', 'rate', 'by', 'automatically', 'modifying', 'user', 's', 'input', 'query', 'Recent', 'methods', 'leverage', 'Large', 'Language', 'Models', 'LLMs', 'to', 'improve', 'query', 'reformulation', 'but', 'often', 'generate', 'limited', 'and', 'redundant', 'expansions', 'potentially', 'constraining', 'their', 'effectiveness', 'in', 'capturing', 'diverse', 'intents', 'In', 'this', 'paper', 'we', 'propose', 'GenCRF', 'a', 'Generative', 'Clustering', 'and', 'Reformulation', 'Framework', 'to', 'capture', 'diverse', 'intentions', 'adaptively', 'based', 'on', 'multiple', 'differentiated', 'well', 'generated', 'queries', 'in', 'the', 'retrieval', 'phase', 'for', 'the', 'first', 'time', 'GenCRF', 'leverages', 'LLMs', 'to', 'generate', 'variable', 'queries', 'from', 'the', 'initial', 'query', 'using', 'customized', 'prompts', 'then', 'clusters', 'them', 'into', 'groups', 'to', 'distinctly', 'represent', 'diverse', 'intents', 'Furthermore', 'the', 'framework', 'explores', 'to', 'combine', 'diverse', 'intents', 'query', 'with', 'innovative', 'weighted', 'aggregation', 'strategies', 'to', 'optimize', 'retrieval', 'performance', 'and', 'crucially', 'integrates', 'a', 'novel', 'Query', 'Evaluation', 'Rewarding', 'Model', 'QERM', 'to', 'refine', 'the', 'process', 'through', 'feedback', 'loops', 'Empirical', 'experiments', 'on', 'the', 'BEIR', 'benchmark', 'demonstrate', 'that', 'GenCRF', 'achieves', 'state', 'of', 'the', 'art', 'performance', 'surpassing', 'previous', 'query', 'reformulation', 'SOTAs', 'by', 'up', 'to', '12', 'on', 'nDCG', '10', 'These', 'techniques', 'can', 'be', 'adapted', 'to', 'various', 'LLMs', 'significantly', 'boosting', 'retriever', 'performance', 'and', 'advancing', 'the', 'field', 'of', 'Information', 'Retrieval']\n",
      "['Session', 'search', 'involves', 'a', 'series', 'of', 'interactive', 'queries', 'and', 'actions', 'to', 'fulfill', 'user', 's', 'complex', 'information', 'need', 'Current', 'strategies', 'typically', 'prioritize', 'sequential', 'modeling', 'for', 'deep', 'semantic', 'understanding', 'overlooking', 'the', 'graph', 'structure', 'in', 'interactions', 'While', 'some', 'approaches', 'focus', 'on', 'capturing', 'structural', 'information', 'they', 'use', 'a', 'generalized', 'representation', 'for', 'documents', 'neglecting', 'the', 'word', 'level', 'semantic', 'modeling', 'In', 'this', 'paper', 'we', 'propose', 'Symbolic', 'Graph', 'Ranker', 'SGR', 'which', 'aims', 'to', 'take', 'advantage', 'of', 'both', 'text', 'based', 'and', 'graph', 'based', 'approaches', 'by', 'leveraging', 'the', 'power', 'of', 'recent', 'Large', 'Language', 'Models', 'LLMs', 'Concretely', 'we', 'first', 'introduce', 'a', 'set', 'of', 'symbolic', 'grammar', 'rules', 'to', 'convert', 'session', 'graph', 'into', 'text', 'This', 'allows', 'integrating', 'session', 'history', 'interaction', 'process', 'and', 'task', 'instruction', 'seamlessly', 'as', 'inputs', 'for', 'the', 'LLM', 'Moreover', 'given', 'the', 'natural', 'discrepancy', 'between', 'LLMs', 'pre', 'trained', 'on', 'textual', 'corpora', 'and', 'the', 'symbolic', 'language', 'we', 'produce', 'using', 'our', 'graph', 'to', 'text', 'grammar', 'our', 'objective', 'is', 'to', 'enhance', 'LLMs', 'ability', 'to', 'capture', 'graph', 'structures', 'within', 'a', 'textual', 'format', 'To', 'achieve', 'this', 'we', 'introduce', 'a', 'set', 'of', 'self', 'supervised', 'symbolic', 'learning', 'tasks', 'including', 'link', 'prediction', 'node', 'content', 'generation', 'and', 'generative', 'contrastive', 'learning', 'to', 'enable', 'LLMs', 'to', 'capture', 'the', 'topological', 'information', 'from', 'coarse', 'grained', 'to', 'fine', 'grained', 'Experiment', 'results', 'and', 'comprehensive', 'analysis', 'on', 'two', 'benchmark', 'datasets', 'AOL', 'and', 'Tiangong', 'ST', 'confirm', 'the', 'superiority', 'of', 'our', 'approach', 'Our', 'paradigm', 'also', 'offers', 'a', 'novel', 'and', 'effective', 'methodology', 'that', 'bridges', 'the', 'gap', 'between', 'traditional', 'search', 'strategies', 'and', 'modern', 'LLMs']\n",
      "['The', 'description', 'of', 'an', 'item', 'plays', 'a', 'pivotal', 'role', 'in', 'providing', 'concise', 'and', 'informative', 'summaries', 'to', 'captivate', 'potential', 'viewers', 'and', 'is', 'essential', 'for', 'recommendation', 'systems', 'Traditionally', 'such', 'descriptions', 'were', 'obtained', 'through', 'manual', 'web', 'scraping', 'techniques', 'which', 'are', 'time', 'consuming', 'and', 'susceptible', 'to', 'data', 'inconsistencies', 'In', 'recent', 'years', 'Large', 'Language', 'Models', 'LLMs', 'such', 'as', 'GPT', '3', '5', 'and', 'open', 'source', 'LLMs', 'like', 'Alpaca', 'have', 'emerged', 'as', 'powerful', 'tools', 'for', 'natural', 'language', 'processing', 'tasks', 'In', 'this', 'paper', 'we', 'have', 'explored', 'how', 'we', 'can', 'use', 'LLMs', 'to', 'generate', 'detailed', 'descriptions', 'of', 'the', 'items', 'To', 'conduct', 'the', 'study', 'we', 'have', 'used', 'the', 'MovieLens', '1M', 'dataset', 'comprising', 'movie', 'titles', 'and', 'the', 'Goodreads', 'Dataset', 'consisting', 'of', 'names', 'of', 'books', 'and', 'subsequently', 'an', 'open', 'sourced', 'LLM', 'Alpaca', 'was', 'prompted', 'with', 'few', 'shot', 'prompting', 'on', 'this', 'dataset', 'to', 'generate', 'detailed', 'movie', 'descriptions', 'considering', 'multiple', 'features', 'like', 'the', 'names', 'of', 'the', 'cast', 'and', 'directors', 'for', 'the', 'ML', 'dataset', 'and', 'the', 'names', 'of', 'the', 'author', 'and', 'publisher', 'for', 'the', 'Goodreads', 'dataset', 'The', 'generated', 'description', 'was', 'then', 'compared', 'with', 'the', 'scraped', 'descriptions', 'using', 'a', 'combination', 'of', 'Top', 'Hits', 'MRR', 'and', 'NDCG', 'as', 'evaluation', 'metrics', 'The', 'results', 'demonstrated', 'that', 'LLM', 'based', 'movie', 'description', 'generation', 'exhibits', 'significant', 'promise', 'with', 'results', 'comparable', 'to', 'the', 'ones', 'obtained', 'by', 'web', 'scraped', 'descriptions']\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    print(termes_reg[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "StopWords = nltk.corpus.stopwords.words('english') \n",
    "\n",
    "for i in range(6):\n",
    "    termes_split[i] = [terme for terme in termes_split[i] if terme.lower() not in StopWords] \n",
    "    termes_reg[i] = [terme for terme in termes_reg[i] if terme.lower() not in StopWords]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "termes_split_porter = []\n",
    "termes_reg_porter = []\n",
    "Porter = nltk.PorterStemmer()\n",
    "\n",
    "for i in range(6):\n",
    "    termes_split_porter.append([Porter.stem(terme) for terme in termes_split[i]])\n",
    "    termes_reg_porter.append([Porter.stem(terme) for terme in termes_reg[i]])\n",
    "        \n",
    "print(len(termes_split_porter))\n",
    "print(len(termes_reg_porter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "termes_split_lancaster = []\n",
    "termes_reg_lancaster = []\n",
    "Lancaster = nltk.LancasterStemmer() \n",
    "\n",
    "for i in range(6):\n",
    "    termes_split_lancaster.append([Lancaster.stem(terme) for terme in termes_split[i]])\n",
    "    termes_reg_lancaster.append([Lancaster.stem(terme)  for terme in termes_reg[i]])\n",
    "        \n",
    "print(len(termes_split_lancaster))\n",
    "print(len(termes_reg_lancaster))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['queri', 'reformulation(qr)', 'set', 'techniqu', 'use', 'transform', 'user’', 'origin', 'search', 'queri', 'text', 'better', 'align', 'user’', 'intent', 'improv', 'search', 'experience.', 'recently,', 'zero-shot', 'qr', 'shown', 'promis', 'approach', 'due', 'abil', 'exploit', 'knowledg', 'inher', 'larg', 'languag', 'models.', 'take', 'inspir', 'success', 'ensembl', 'prompt', 'strategi', 'benefit', 'mani', 'tasks,', 'investig', 'help', 'improv', 'queri', 'reformulation.', 'context,', 'propos', 'ensembl', 'base', 'prompt', 'technique,', 'genqrensembl', 'leverag', 'paraphras', 'zero-shot', 'instruct', 'gener', 'multipl', 'set', 'keyword', 'ultim', 'improv', 'retriev', 'performance.', 'introduc', 'post-retriev', 'variant,', 'genqrensemblerf', 'incorpor', 'pseudo', 'relev', 'feedback.', 'evalu', 'four', 'ir', 'benchmarks,', 'find', 'genqrensembl', 'gener', 'better', 'reformul', 'rel', 'ndcg@10', 'improv', '18%', 'map', 'improv', 'upto', '24%', 'previou', 'zero-shot', 'state-of-art.', 'msmarco', 'passag', 'rank', 'task,', 'genqrensemblerf', 'show', 'rel', 'gain', '5%', 'mrr', 'use', 'pseudo-relev', 'feedback,', '9%', 'ndcg@10', 'use', 'relev', 'feedback', 'documents.']\n"
     ]
    }
   ],
   "source": [
    "print(termes_split_porter[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description file creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descripteur_split =\"\"\n",
    "\n",
    "for i in range(len(termes_split)):\n",
    "    for j in range(len(termes_split[i])):\n",
    "       \n",
    "        descripteur_split = descripteur_split + (str(i+1)+ \"  \" +termes_split[i][j]+\"\\n\")\n",
    "\n",
    "\n",
    "print(descripteur_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  Query\n",
      "1  Reformulation\n",
      "1  QR\n",
      "1  set\n",
      "1  techniques\n",
      "1  used\n",
      "1  transform\n",
      "1  user\n",
      "1  original\n",
      "1  search\n",
      "1  query\n",
      "1  text\n",
      "1  better\n",
      "1  aligns\n",
      "1  user\n",
      "1  intent\n",
      "1  improves\n",
      "1  search\n",
      "1  experience\n",
      "1  Recently\n",
      "1  zero\n",
      "1  shot\n",
      "1  QR\n",
      "1  shown\n",
      "1  promising\n",
      "1  approach\n",
      "1  due\n",
      "1  ability\n",
      "1  exploit\n",
      "1  knowledge\n",
      "1  inherent\n",
      "1  large\n",
      "1  language\n",
      "1  models\n",
      "1  taking\n",
      "1  inspiration\n",
      "1  success\n",
      "1  ensemble\n",
      "1  prompting\n",
      "1  strategies\n",
      "1  benefited\n",
      "1  many\n",
      "1  tasks\n",
      "1  investigate\n",
      "1  help\n",
      "1  improve\n",
      "1  query\n",
      "1  reformulation\n",
      "1  context\n",
      "1  propose\n",
      "1  ensemble\n",
      "1  based\n",
      "1  prompting\n",
      "1  technique\n",
      "1  GenQREnsemble\n",
      "1  leverages\n",
      "1  paraphrases\n",
      "1  zero\n",
      "1  shot\n",
      "1  instruction\n",
      "1  generate\n",
      "1  multiple\n",
      "1  sets\n",
      "1  keywords\n",
      "1  ultimately\n",
      "1  improving\n",
      "1  retrieval\n",
      "1  performance\n",
      "1  introduce\n",
      "1  post\n",
      "1  retrieval\n",
      "1  variant\n",
      "1  GenQREnsembleRF\n",
      "1  incorporate\n",
      "1  pseudo\n",
      "1  relevant\n",
      "1  feedback\n",
      "1  evaluations\n",
      "1  four\n",
      "1  IR\n",
      "1  benchmarks\n",
      "1  find\n",
      "1  GenQREnsemble\n",
      "1  generates\n",
      "1  better\n",
      "1  reformulations\n",
      "1  relative\n",
      "1  nDCG\n",
      "1  10\n",
      "1  improvements\n",
      "1  18\n",
      "1  MAP\n",
      "1  improvements\n",
      "1  upto\n",
      "1  24\n",
      "1  previous\n",
      "1  zero\n",
      "1  shot\n",
      "1  state\n",
      "1  art\n",
      "1  MSMarco\n",
      "1  Passage\n",
      "1  Ranking\n",
      "1  task\n",
      "1  GenQREnsembleRF\n",
      "1  shows\n",
      "1  relative\n",
      "1  gains\n",
      "1  5\n",
      "1  MRR\n",
      "1  using\n",
      "1  pseudo\n",
      "1  relevance\n",
      "1  feedback\n",
      "1  9\n",
      "1  nDCG\n",
      "1  10\n",
      "1  using\n",
      "1  relevant\n",
      "1  feedback\n",
      "1  documents\n",
      "2  Ranking\n",
      "2  documents\n",
      "2  using\n",
      "2  Large\n",
      "2  Language\n",
      "2  Models\n",
      "2  LLMs\n",
      "2  directly\n",
      "2  feeding\n",
      "2  query\n",
      "2  candidate\n",
      "2  documents\n",
      "2  prompt\n",
      "2  interesting\n",
      "2  practical\n",
      "2  problem\n",
      "2  However\n",
      "2  researchers\n",
      "2  found\n",
      "2  difficult\n",
      "2  outperform\n",
      "2  fine\n",
      "2  tuned\n",
      "2  baseline\n",
      "2  rankers\n",
      "2  benchmark\n",
      "2  datasets\n",
      "2  analyze\n",
      "2  pointwise\n",
      "2  listwise\n",
      "2  ranking\n",
      "2  prompts\n",
      "2  used\n",
      "2  existing\n",
      "2  methods\n",
      "2  argue\n",
      "2  shelf\n",
      "2  LLMs\n",
      "2  fully\n",
      "2  understand\n",
      "2  challenging\n",
      "2  ranking\n",
      "2  formulations\n",
      "2  paper\n",
      "2  propose\n",
      "2  significantly\n",
      "2  reduce\n",
      "2  burden\n",
      "2  LLMs\n",
      "2  using\n",
      "2  new\n",
      "2  technique\n",
      "2  called\n",
      "2  Pairwise\n",
      "2  Ranking\n",
      "2  Prompting\n",
      "2  PRP\n",
      "2  results\n",
      "2  first\n",
      "2  literature\n",
      "2  achieve\n",
      "2  state\n",
      "2  art\n",
      "2  ranking\n",
      "2  performance\n",
      "2  standard\n",
      "2  benchmarks\n",
      "2  using\n",
      "2  moderate\n",
      "2  sized\n",
      "2  open\n",
      "2  sourced\n",
      "2  LLMs\n",
      "2  TREC\n",
      "2  DL\n",
      "2  2019\n",
      "2  2020\n",
      "2  PRP\n",
      "2  based\n",
      "2  Flan\n",
      "2  UL2\n",
      "2  model\n",
      "2  20B\n",
      "2  parameters\n",
      "2  performs\n",
      "2  favorably\n",
      "2  previous\n",
      "2  best\n",
      "2  approach\n",
      "2  literature\n",
      "2  based\n",
      "2  blackbox\n",
      "2  commercial\n",
      "2  GPT\n",
      "2  4\n",
      "2  50x\n",
      "2  estimated\n",
      "2  model\n",
      "2  size\n",
      "2  outperforming\n",
      "2  LLM\n",
      "2  based\n",
      "2  solutions\n",
      "2  InstructGPT\n",
      "2  175B\n",
      "2  parameters\n",
      "2  10\n",
      "2  ranking\n",
      "2  metrics\n",
      "2  using\n",
      "2  prompt\n",
      "2  template\n",
      "2  seven\n",
      "2  BEIR\n",
      "2  tasks\n",
      "2  PRP\n",
      "2  outperforms\n",
      "2  supervised\n",
      "2  baselines\n",
      "2  outperforms\n",
      "2  blackbox\n",
      "2  commercial\n",
      "2  ChatGPT\n",
      "2  solution\n",
      "2  4\n",
      "2  2\n",
      "2  pointwise\n",
      "2  LLM\n",
      "2  based\n",
      "2  solutions\n",
      "2  10\n",
      "2  average\n",
      "2  NDCG\n",
      "2  10\n",
      "2  Furthermore\n",
      "2  propose\n",
      "2  several\n",
      "2  variants\n",
      "2  PRP\n",
      "2  improve\n",
      "2  efficiency\n",
      "2  show\n",
      "2  possible\n",
      "2  achieve\n",
      "2  competitive\n",
      "2  results\n",
      "2  even\n",
      "2  linear\n",
      "2  complexity\n",
      "3  Large\n",
      "3  language\n",
      "3  models\n",
      "3  LLM\n",
      "3  manifested\n",
      "3  unparalleled\n",
      "3  modeling\n",
      "3  capability\n",
      "3  various\n",
      "3  tasks\n",
      "3  e\n",
      "3  g\n",
      "3  multi\n",
      "3  step\n",
      "3  reasoning\n",
      "3  input\n",
      "3  models\n",
      "3  mostly\n",
      "3  limited\n",
      "3  plain\n",
      "3  text\n",
      "3  could\n",
      "3  long\n",
      "3  contain\n",
      "3  noisy\n",
      "3  information\n",
      "3  Long\n",
      "3  text\n",
      "3  could\n",
      "3  take\n",
      "3  long\n",
      "3  time\n",
      "3  process\n",
      "3  thus\n",
      "3  may\n",
      "3  efficient\n",
      "3  enough\n",
      "3  recommender\n",
      "3  systems\n",
      "3  require\n",
      "3  immediate\n",
      "3  response\n",
      "3  LLM\n",
      "3  based\n",
      "3  recommendation\n",
      "3  models\n",
      "3  user\n",
      "3  item\n",
      "3  IDs\n",
      "3  usually\n",
      "3  filled\n",
      "3  template\n",
      "3  e\n",
      "3  discrete\n",
      "3  prompt\n",
      "3  allow\n",
      "3  models\n",
      "3  understand\n",
      "3  given\n",
      "3  task\n",
      "3  models\n",
      "3  usually\n",
      "3  need\n",
      "3  extensive\n",
      "3  fine\n",
      "3  tuning\n",
      "3  bridge\n",
      "3  user\n",
      "3  item\n",
      "3  IDs\n",
      "3  template\n",
      "3  words\n",
      "3  unleash\n",
      "3  power\n",
      "3  LLM\n",
      "3  recommendation\n",
      "3  address\n",
      "3  problems\n",
      "3  propose\n",
      "3  distill\n",
      "3  discrete\n",
      "3  prompt\n",
      "3  specific\n",
      "3  task\n",
      "3  set\n",
      "3  continuous\n",
      "3  prompt\n",
      "3  vectors\n",
      "3  bridge\n",
      "3  IDs\n",
      "3  words\n",
      "3  reduce\n",
      "3  inference\n",
      "3  time\n",
      "3  also\n",
      "3  design\n",
      "3  training\n",
      "3  strategy\n",
      "3  attempt\n",
      "3  improve\n",
      "3  efficiency\n",
      "3  training\n",
      "3  models\n",
      "3  Experimental\n",
      "3  results\n",
      "3  three\n",
      "3  real\n",
      "3  world\n",
      "3  datasets\n",
      "3  demonstrate\n",
      "3  effectiveness\n",
      "3  PrOmpt\n",
      "3  Distillation\n",
      "3  POD\n",
      "3  approach\n",
      "3  sequential\n",
      "3  recommendation\n",
      "3  top\n",
      "3  N\n",
      "3  recommendation\n",
      "3  tasks\n",
      "3  Although\n",
      "3  training\n",
      "3  efficiency\n",
      "3  significantly\n",
      "3  improved\n",
      "3  improvement\n",
      "3  inference\n",
      "3  efficiency\n",
      "3  limited\n",
      "3  finding\n",
      "3  may\n",
      "3  inspire\n",
      "3  researchers\n",
      "3  community\n",
      "3  improve\n",
      "3  inference\n",
      "3  efficiency\n",
      "3  LLM\n",
      "3  based\n",
      "3  recommendation\n",
      "3  models\n",
      "4  Query\n",
      "4  reformulation\n",
      "4  well\n",
      "4  known\n",
      "4  problem\n",
      "4  Information\n",
      "4  Retrieval\n",
      "4  IR\n",
      "4  aimed\n",
      "4  enhancing\n",
      "4  single\n",
      "4  search\n",
      "4  successful\n",
      "4  completion\n",
      "4  rate\n",
      "4  automatically\n",
      "4  modifying\n",
      "4  user\n",
      "4  input\n",
      "4  query\n",
      "4  Recent\n",
      "4  methods\n",
      "4  leverage\n",
      "4  Large\n",
      "4  Language\n",
      "4  Models\n",
      "4  LLMs\n",
      "4  improve\n",
      "4  query\n",
      "4  reformulation\n",
      "4  often\n",
      "4  generate\n",
      "4  limited\n",
      "4  redundant\n",
      "4  expansions\n",
      "4  potentially\n",
      "4  constraining\n",
      "4  effectiveness\n",
      "4  capturing\n",
      "4  diverse\n",
      "4  intents\n",
      "4  paper\n",
      "4  propose\n",
      "4  GenCRF\n",
      "4  Generative\n",
      "4  Clustering\n",
      "4  Reformulation\n",
      "4  Framework\n",
      "4  capture\n",
      "4  diverse\n",
      "4  intentions\n",
      "4  adaptively\n",
      "4  based\n",
      "4  multiple\n",
      "4  differentiated\n",
      "4  well\n",
      "4  generated\n",
      "4  queries\n",
      "4  retrieval\n",
      "4  phase\n",
      "4  first\n",
      "4  time\n",
      "4  GenCRF\n",
      "4  leverages\n",
      "4  LLMs\n",
      "4  generate\n",
      "4  variable\n",
      "4  queries\n",
      "4  initial\n",
      "4  query\n",
      "4  using\n",
      "4  customized\n",
      "4  prompts\n",
      "4  clusters\n",
      "4  groups\n",
      "4  distinctly\n",
      "4  represent\n",
      "4  diverse\n",
      "4  intents\n",
      "4  Furthermore\n",
      "4  framework\n",
      "4  explores\n",
      "4  combine\n",
      "4  diverse\n",
      "4  intents\n",
      "4  query\n",
      "4  innovative\n",
      "4  weighted\n",
      "4  aggregation\n",
      "4  strategies\n",
      "4  optimize\n",
      "4  retrieval\n",
      "4  performance\n",
      "4  crucially\n",
      "4  integrates\n",
      "4  novel\n",
      "4  Query\n",
      "4  Evaluation\n",
      "4  Rewarding\n",
      "4  Model\n",
      "4  QERM\n",
      "4  refine\n",
      "4  process\n",
      "4  feedback\n",
      "4  loops\n",
      "4  Empirical\n",
      "4  experiments\n",
      "4  BEIR\n",
      "4  benchmark\n",
      "4  demonstrate\n",
      "4  GenCRF\n",
      "4  achieves\n",
      "4  state\n",
      "4  art\n",
      "4  performance\n",
      "4  surpassing\n",
      "4  previous\n",
      "4  query\n",
      "4  reformulation\n",
      "4  SOTAs\n",
      "4  12\n",
      "4  nDCG\n",
      "4  10\n",
      "4  techniques\n",
      "4  adapted\n",
      "4  various\n",
      "4  LLMs\n",
      "4  significantly\n",
      "4  boosting\n",
      "4  retriever\n",
      "4  performance\n",
      "4  advancing\n",
      "4  field\n",
      "4  Information\n",
      "4  Retrieval\n",
      "5  Session\n",
      "5  search\n",
      "5  involves\n",
      "5  series\n",
      "5  interactive\n",
      "5  queries\n",
      "5  actions\n",
      "5  fulfill\n",
      "5  user\n",
      "5  complex\n",
      "5  information\n",
      "5  need\n",
      "5  Current\n",
      "5  strategies\n",
      "5  typically\n",
      "5  prioritize\n",
      "5  sequential\n",
      "5  modeling\n",
      "5  deep\n",
      "5  semantic\n",
      "5  understanding\n",
      "5  overlooking\n",
      "5  graph\n",
      "5  structure\n",
      "5  interactions\n",
      "5  approaches\n",
      "5  focus\n",
      "5  capturing\n",
      "5  structural\n",
      "5  information\n",
      "5  use\n",
      "5  generalized\n",
      "5  representation\n",
      "5  documents\n",
      "5  neglecting\n",
      "5  word\n",
      "5  level\n",
      "5  semantic\n",
      "5  modeling\n",
      "5  paper\n",
      "5  propose\n",
      "5  Symbolic\n",
      "5  Graph\n",
      "5  Ranker\n",
      "5  SGR\n",
      "5  aims\n",
      "5  take\n",
      "5  advantage\n",
      "5  text\n",
      "5  based\n",
      "5  graph\n",
      "5  based\n",
      "5  approaches\n",
      "5  leveraging\n",
      "5  power\n",
      "5  recent\n",
      "5  Large\n",
      "5  Language\n",
      "5  Models\n",
      "5  LLMs\n",
      "5  Concretely\n",
      "5  first\n",
      "5  introduce\n",
      "5  set\n",
      "5  symbolic\n",
      "5  grammar\n",
      "5  rules\n",
      "5  convert\n",
      "5  session\n",
      "5  graph\n",
      "5  text\n",
      "5  allows\n",
      "5  integrating\n",
      "5  session\n",
      "5  history\n",
      "5  interaction\n",
      "5  process\n",
      "5  task\n",
      "5  instruction\n",
      "5  seamlessly\n",
      "5  inputs\n",
      "5  LLM\n",
      "5  Moreover\n",
      "5  given\n",
      "5  natural\n",
      "5  discrepancy\n",
      "5  LLMs\n",
      "5  pre\n",
      "5  trained\n",
      "5  textual\n",
      "5  corpora\n",
      "5  symbolic\n",
      "5  language\n",
      "5  produce\n",
      "5  using\n",
      "5  graph\n",
      "5  text\n",
      "5  grammar\n",
      "5  objective\n",
      "5  enhance\n",
      "5  LLMs\n",
      "5  ability\n",
      "5  capture\n",
      "5  graph\n",
      "5  structures\n",
      "5  within\n",
      "5  textual\n",
      "5  format\n",
      "5  achieve\n",
      "5  introduce\n",
      "5  set\n",
      "5  self\n",
      "5  supervised\n",
      "5  symbolic\n",
      "5  learning\n",
      "5  tasks\n",
      "5  including\n",
      "5  link\n",
      "5  prediction\n",
      "5  node\n",
      "5  content\n",
      "5  generation\n",
      "5  generative\n",
      "5  contrastive\n",
      "5  learning\n",
      "5  enable\n",
      "5  LLMs\n",
      "5  capture\n",
      "5  topological\n",
      "5  information\n",
      "5  coarse\n",
      "5  grained\n",
      "5  fine\n",
      "5  grained\n",
      "5  Experiment\n",
      "5  results\n",
      "5  comprehensive\n",
      "5  analysis\n",
      "5  two\n",
      "5  benchmark\n",
      "5  datasets\n",
      "5  AOL\n",
      "5  Tiangong\n",
      "5  ST\n",
      "5  confirm\n",
      "5  superiority\n",
      "5  approach\n",
      "5  paradigm\n",
      "5  also\n",
      "5  offers\n",
      "5  novel\n",
      "5  effective\n",
      "5  methodology\n",
      "5  bridges\n",
      "5  gap\n",
      "5  traditional\n",
      "5  search\n",
      "5  strategies\n",
      "5  modern\n",
      "5  LLMs\n",
      "6  description\n",
      "6  item\n",
      "6  plays\n",
      "6  pivotal\n",
      "6  role\n",
      "6  providing\n",
      "6  concise\n",
      "6  informative\n",
      "6  summaries\n",
      "6  captivate\n",
      "6  potential\n",
      "6  viewers\n",
      "6  essential\n",
      "6  recommendation\n",
      "6  systems\n",
      "6  Traditionally\n",
      "6  descriptions\n",
      "6  obtained\n",
      "6  manual\n",
      "6  web\n",
      "6  scraping\n",
      "6  techniques\n",
      "6  time\n",
      "6  consuming\n",
      "6  susceptible\n",
      "6  data\n",
      "6  inconsistencies\n",
      "6  recent\n",
      "6  years\n",
      "6  Large\n",
      "6  Language\n",
      "6  Models\n",
      "6  LLMs\n",
      "6  GPT\n",
      "6  3\n",
      "6  5\n",
      "6  open\n",
      "6  source\n",
      "6  LLMs\n",
      "6  like\n",
      "6  Alpaca\n",
      "6  emerged\n",
      "6  powerful\n",
      "6  tools\n",
      "6  natural\n",
      "6  language\n",
      "6  processing\n",
      "6  tasks\n",
      "6  paper\n",
      "6  explored\n",
      "6  use\n",
      "6  LLMs\n",
      "6  generate\n",
      "6  detailed\n",
      "6  descriptions\n",
      "6  items\n",
      "6  conduct\n",
      "6  study\n",
      "6  used\n",
      "6  MovieLens\n",
      "6  1M\n",
      "6  dataset\n",
      "6  comprising\n",
      "6  movie\n",
      "6  titles\n",
      "6  Goodreads\n",
      "6  Dataset\n",
      "6  consisting\n",
      "6  names\n",
      "6  books\n",
      "6  subsequently\n",
      "6  open\n",
      "6  sourced\n",
      "6  LLM\n",
      "6  Alpaca\n",
      "6  prompted\n",
      "6  shot\n",
      "6  prompting\n",
      "6  dataset\n",
      "6  generate\n",
      "6  detailed\n",
      "6  movie\n",
      "6  descriptions\n",
      "6  considering\n",
      "6  multiple\n",
      "6  features\n",
      "6  like\n",
      "6  names\n",
      "6  cast\n",
      "6  directors\n",
      "6  ML\n",
      "6  dataset\n",
      "6  names\n",
      "6  author\n",
      "6  publisher\n",
      "6  Goodreads\n",
      "6  dataset\n",
      "6  generated\n",
      "6  description\n",
      "6  compared\n",
      "6  scraped\n",
      "6  descriptions\n",
      "6  using\n",
      "6  combination\n",
      "6  Top\n",
      "6  Hits\n",
      "6  MRR\n",
      "6  NDCG\n",
      "6  evaluation\n",
      "6  metrics\n",
      "6  results\n",
      "6  demonstrated\n",
      "6  LLM\n",
      "6  based\n",
      "6  movie\n",
      "6  description\n",
      "6  generation\n",
      "6  exhibits\n",
      "6  significant\n",
      "6  promise\n",
      "6  results\n",
      "6  comparable\n",
      "6  ones\n",
      "6  obtained\n",
      "6  web\n",
      "6  scraped\n",
      "6  descriptions\n",
      "\n"
     ]
    }
   ],
   "source": [
    "descripteur_reg =\"\"\n",
    "\n",
    "for i in range(len(termes_reg)):\n",
    "    for j in range(len(termes_reg[i])):\n",
    "        descripteur_reg = descripteur_reg + (str(i+1)+ \"  \" +termes_reg[i][j]+\"\\n\")\n",
    "\n",
    "\n",
    "print(descripteur_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  queri\n",
      "1  reformulation(qr)\n",
      "1  set\n",
      "1  techniqu\n",
      "1  use\n",
      "1  transform\n",
      "1  user’\n",
      "1  origin\n",
      "1  search\n",
      "1  queri\n",
      "1  text\n",
      "1  better\n",
      "1  align\n",
      "1  user’\n",
      "1  intent\n",
      "1  improv\n",
      "1  search\n",
      "1  experience.\n",
      "1  recently,\n",
      "1  zero-shot\n",
      "1  qr\n",
      "1  shown\n",
      "1  promis\n",
      "1  approach\n",
      "1  due\n",
      "1  abil\n",
      "1  exploit\n",
      "1  knowledg\n",
      "1  inher\n",
      "1  larg\n",
      "1  languag\n",
      "1  models.\n",
      "1  take\n",
      "1  inspir\n",
      "1  success\n",
      "1  ensembl\n",
      "1  prompt\n",
      "1  strategi\n",
      "1  benefit\n",
      "1  mani\n",
      "1  tasks,\n",
      "1  investig\n",
      "1  help\n",
      "1  improv\n",
      "1  queri\n",
      "1  reformulation.\n",
      "1  context,\n",
      "1  propos\n",
      "1  ensembl\n",
      "1  base\n",
      "1  prompt\n",
      "1  technique,\n",
      "1  genqrensembl\n",
      "1  leverag\n",
      "1  paraphras\n",
      "1  zero-shot\n",
      "1  instruct\n",
      "1  gener\n",
      "1  multipl\n",
      "1  set\n",
      "1  keyword\n",
      "1  ultim\n",
      "1  improv\n",
      "1  retriev\n",
      "1  performance.\n",
      "1  introduc\n",
      "1  post-retriev\n",
      "1  variant,\n",
      "1  genqrensemblerf\n",
      "1  incorpor\n",
      "1  pseudo\n",
      "1  relev\n",
      "1  feedback.\n",
      "1  evalu\n",
      "1  four\n",
      "1  ir\n",
      "1  benchmarks,\n",
      "1  find\n",
      "1  genqrensembl\n",
      "1  gener\n",
      "1  better\n",
      "1  reformul\n",
      "1  rel\n",
      "1  ndcg@10\n",
      "1  improv\n",
      "1  18%\n",
      "1  map\n",
      "1  improv\n",
      "1  upto\n",
      "1  24%\n",
      "1  previou\n",
      "1  zero-shot\n",
      "1  state-of-art.\n",
      "1  msmarco\n",
      "1  passag\n",
      "1  rank\n",
      "1  task,\n",
      "1  genqrensemblerf\n",
      "1  show\n",
      "1  rel\n",
      "1  gain\n",
      "1  5%\n",
      "1  mrr\n",
      "1  use\n",
      "1  pseudo-relev\n",
      "1  feedback,\n",
      "1  9%\n",
      "1  ndcg@10\n",
      "1  use\n",
      "1  relev\n",
      "1  feedback\n",
      "1  documents.\n",
      "2  rank\n",
      "2  document\n",
      "2  use\n",
      "2  larg\n",
      "2  languag\n",
      "2  model\n",
      "2  (llms)\n",
      "2  directli\n",
      "2  feed\n",
      "2  queri\n",
      "2  candid\n",
      "2  document\n",
      "2  prompt\n",
      "2  interest\n",
      "2  practic\n",
      "2  problem.\n",
      "2  however,\n",
      "2  research\n",
      "2  found\n",
      "2  difficult\n",
      "2  outperform\n",
      "2  fine-tun\n",
      "2  baselin\n",
      "2  ranker\n",
      "2  benchmark\n",
      "2  datasets.\n",
      "2  analyz\n",
      "2  pointwis\n",
      "2  listwis\n",
      "2  rank\n",
      "2  prompt\n",
      "2  use\n",
      "2  exist\n",
      "2  method\n",
      "2  argu\n",
      "2  off-the-shelf\n",
      "2  llm\n",
      "2  fulli\n",
      "2  understand\n",
      "2  challeng\n",
      "2  rank\n",
      "2  formulations.\n",
      "2  paper,\n",
      "2  propos\n",
      "2  significantli\n",
      "2  reduc\n",
      "2  burden\n",
      "2  llm\n",
      "2  use\n",
      "2  new\n",
      "2  techniqu\n",
      "2  call\n",
      "2  pairwis\n",
      "2  rank\n",
      "2  prompt\n",
      "2  (prp).\n",
      "2  result\n",
      "2  first\n",
      "2  literatur\n",
      "2  achiev\n",
      "2  state-of-the-art\n",
      "2  rank\n",
      "2  perform\n",
      "2  standard\n",
      "2  benchmark\n",
      "2  use\n",
      "2  moderate-s\n",
      "2  open-sourc\n",
      "2  llms.\n",
      "2  trec-dl\n",
      "2  2019\n",
      "2  2020,\n",
      "2  prp\n",
      "2  base\n",
      "2  flan-ul2\n",
      "2  model\n",
      "2  20b\n",
      "2  paramet\n",
      "2  perform\n",
      "2  favor\n",
      "2  previou\n",
      "2  best\n",
      "2  approach\n",
      "2  literature,\n",
      "2  base\n",
      "2  blackbox\n",
      "2  commerci\n",
      "2  gpt-4\n",
      "2  50x\n",
      "2  (estimated)\n",
      "2  model\n",
      "2  size,\n",
      "2  outperform\n",
      "2  llm-base\n",
      "2  solutions,\n",
      "2  instructgpt\n",
      "2  175b\n",
      "2  parameters,\n",
      "2  10%\n",
      "2  rank\n",
      "2  metrics.\n",
      "2  use\n",
      "2  prompt\n",
      "2  templat\n",
      "2  seven\n",
      "2  beir\n",
      "2  tasks,\n",
      "2  prp\n",
      "2  outperform\n",
      "2  supervis\n",
      "2  baselin\n",
      "2  outperform\n",
      "2  blackbox\n",
      "2  commerci\n",
      "2  chatgpt\n",
      "2  solut\n",
      "2  4.2%\n",
      "2  pointwis\n",
      "2  llm-base\n",
      "2  solut\n",
      "2  10%\n",
      "2  averag\n",
      "2  ndcg@10.\n",
      "2  furthermore,\n",
      "2  propos\n",
      "2  sever\n",
      "2  variant\n",
      "2  prp\n",
      "2  improv\n",
      "2  effici\n",
      "2  show\n",
      "2  possibl\n",
      "2  achiev\n",
      "2  competit\n",
      "2  result\n",
      "2  even\n",
      "2  linear\n",
      "2  complex\n",
      "3  larg\n",
      "3  languag\n",
      "3  model\n",
      "3  (llm)\n",
      "3  manifest\n",
      "3  unparallel\n",
      "3  model\n",
      "3  capabl\n",
      "3  variou\n",
      "3  tasks,\n",
      "3  e.g.,\n",
      "3  multi-step\n",
      "3  reasoning,\n",
      "3  input\n",
      "3  model\n",
      "3  mostli\n",
      "3  limit\n",
      "3  plain\n",
      "3  text,\n",
      "3  could\n",
      "3  long\n",
      "3  contain\n",
      "3  noisi\n",
      "3  information.\n",
      "3  long\n",
      "3  text\n",
      "3  could\n",
      "3  take\n",
      "3  long\n",
      "3  time\n",
      "3  process,\n",
      "3  thu\n",
      "3  may\n",
      "3  effici\n",
      "3  enough\n",
      "3  recommend\n",
      "3  system\n",
      "3  requir\n",
      "3  immedi\n",
      "3  response.\n",
      "3  llm-base\n",
      "3  recommend\n",
      "3  models,\n",
      "3  user\n",
      "3  item\n",
      "3  id\n",
      "3  usual\n",
      "3  fill\n",
      "3  templat\n",
      "3  (i.e.,\n",
      "3  discret\n",
      "3  prompt)\n",
      "3  allow\n",
      "3  model\n",
      "3  understand\n",
      "3  given\n",
      "3  task,\n",
      "3  model\n",
      "3  usual\n",
      "3  need\n",
      "3  extens\n",
      "3  fine-tun\n",
      "3  bridg\n",
      "3  user/item\n",
      "3  id\n",
      "3  templat\n",
      "3  word\n",
      "3  unleash\n",
      "3  power\n",
      "3  llm\n",
      "3  recommendation.\n",
      "3  address\n",
      "3  problems,\n",
      "3  propos\n",
      "3  distil\n",
      "3  discret\n",
      "3  prompt\n",
      "3  specif\n",
      "3  task\n",
      "3  set\n",
      "3  continu\n",
      "3  prompt\n",
      "3  vector\n",
      "3  bridg\n",
      "3  id\n",
      "3  word\n",
      "3  reduc\n",
      "3  infer\n",
      "3  time.\n",
      "3  also\n",
      "3  design\n",
      "3  train\n",
      "3  strategi\n",
      "3  attempt\n",
      "3  improv\n",
      "3  effici\n",
      "3  train\n",
      "3  models.\n",
      "3  experiment\n",
      "3  result\n",
      "3  three\n",
      "3  real-world\n",
      "3  dataset\n",
      "3  demonstr\n",
      "3  effect\n",
      "3  prompt\n",
      "3  distil\n",
      "3  (pod)\n",
      "3  approach\n",
      "3  sequenti\n",
      "3  recommend\n",
      "3  top-n\n",
      "3  recommend\n",
      "3  tasks.\n",
      "3  although\n",
      "3  train\n",
      "3  effici\n",
      "3  significantli\n",
      "3  improved,\n",
      "3  improv\n",
      "3  infer\n",
      "3  effici\n",
      "3  limited.\n",
      "3  find\n",
      "3  may\n",
      "3  inspir\n",
      "3  research\n",
      "3  commun\n",
      "3  improv\n",
      "3  infer\n",
      "3  effici\n",
      "3  llm-base\n",
      "3  recommend\n",
      "3  models.\n",
      "4  queri\n",
      "4  reformul\n",
      "4  well-known\n",
      "4  problem\n",
      "4  inform\n",
      "4  retriev\n",
      "4  (ir)\n",
      "4  aim\n",
      "4  enhanc\n",
      "4  singl\n",
      "4  search\n",
      "4  success\n",
      "4  complet\n",
      "4  rate\n",
      "4  automat\n",
      "4  modifi\n",
      "4  user'\n",
      "4  input\n",
      "4  query.\n",
      "4  recent\n",
      "4  method\n",
      "4  leverag\n",
      "4  larg\n",
      "4  languag\n",
      "4  model\n",
      "4  (llms)\n",
      "4  improv\n",
      "4  queri\n",
      "4  reformulation,\n",
      "4  often\n",
      "4  gener\n",
      "4  limit\n",
      "4  redund\n",
      "4  expansions,\n",
      "4  potenti\n",
      "4  constrain\n",
      "4  effect\n",
      "4  captur\n",
      "4  divers\n",
      "4  intents.\n",
      "4  paper,\n",
      "4  propos\n",
      "4  gencrf:\n",
      "4  gener\n",
      "4  cluster\n",
      "4  reformul\n",
      "4  framework\n",
      "4  captur\n",
      "4  divers\n",
      "4  intent\n",
      "4  adapt\n",
      "4  base\n",
      "4  multipl\n",
      "4  differentiated,\n",
      "4  well-gener\n",
      "4  queri\n",
      "4  retriev\n",
      "4  phase\n",
      "4  first\n",
      "4  time.\n",
      "4  gencrf\n",
      "4  leverag\n",
      "4  llm\n",
      "4  gener\n",
      "4  variabl\n",
      "4  queri\n",
      "4  initi\n",
      "4  queri\n",
      "4  use\n",
      "4  custom\n",
      "4  prompts,\n",
      "4  cluster\n",
      "4  group\n",
      "4  distinctli\n",
      "4  repres\n",
      "4  divers\n",
      "4  intents.\n",
      "4  furthermore,\n",
      "4  framework\n",
      "4  explor\n",
      "4  combin\n",
      "4  divers\n",
      "4  intent\n",
      "4  queri\n",
      "4  innov\n",
      "4  weight\n",
      "4  aggreg\n",
      "4  strategi\n",
      "4  optim\n",
      "4  retriev\n",
      "4  perform\n",
      "4  crucial\n",
      "4  integr\n",
      "4  novel\n",
      "4  queri\n",
      "4  evalu\n",
      "4  reward\n",
      "4  model\n",
      "4  (qerm)\n",
      "4  refin\n",
      "4  process\n",
      "4  feedback\n",
      "4  loops.\n",
      "4  empir\n",
      "4  experi\n",
      "4  beir\n",
      "4  benchmark\n",
      "4  demonstr\n",
      "4  gencrf\n",
      "4  achiev\n",
      "4  state-of-the-art\n",
      "4  performance,\n",
      "4  surpass\n",
      "4  previou\n",
      "4  queri\n",
      "4  reformul\n",
      "4  sota\n",
      "4  12%\n",
      "4  ndcg@10.\n",
      "4  techniqu\n",
      "4  adapt\n",
      "4  variou\n",
      "4  llms,\n",
      "4  significantli\n",
      "4  boost\n",
      "4  retriev\n",
      "4  perform\n",
      "4  advanc\n",
      "4  field\n",
      "4  inform\n",
      "4  retrieval.\n",
      "5  session\n",
      "5  search\n",
      "5  involv\n",
      "5  seri\n",
      "5  interact\n",
      "5  queri\n",
      "5  action\n",
      "5  fulfil\n",
      "5  user'\n",
      "5  complex\n",
      "5  inform\n",
      "5  need.\n",
      "5  current\n",
      "5  strategi\n",
      "5  typic\n",
      "5  priorit\n",
      "5  sequenti\n",
      "5  model\n",
      "5  deep\n",
      "5  semant\n",
      "5  understanding,\n",
      "5  overlook\n",
      "5  graph\n",
      "5  structur\n",
      "5  interactions.\n",
      "5  approach\n",
      "5  focu\n",
      "5  captur\n",
      "5  structur\n",
      "5  information,\n",
      "5  use\n",
      "5  gener\n",
      "5  represent\n",
      "5  documents,\n",
      "5  neglect\n",
      "5  word-level\n",
      "5  semant\n",
      "5  modeling.\n",
      "5  paper,\n",
      "5  propos\n",
      "5  symbol\n",
      "5  graph\n",
      "5  ranker\n",
      "5  (sgr),\n",
      "5  aim\n",
      "5  take\n",
      "5  advantag\n",
      "5  text-bas\n",
      "5  graph-bas\n",
      "5  approach\n",
      "5  leverag\n",
      "5  power\n",
      "5  recent\n",
      "5  larg\n",
      "5  languag\n",
      "5  model\n",
      "5  (llms).\n",
      "5  concretely,\n",
      "5  first\n",
      "5  introduc\n",
      "5  set\n",
      "5  symbol\n",
      "5  grammar\n",
      "5  rule\n",
      "5  convert\n",
      "5  session\n",
      "5  graph\n",
      "5  text.\n",
      "5  allow\n",
      "5  integr\n",
      "5  session\n",
      "5  history,\n",
      "5  interact\n",
      "5  process,\n",
      "5  task\n",
      "5  instruct\n",
      "5  seamlessli\n",
      "5  input\n",
      "5  llm.\n",
      "5  moreover,\n",
      "5  given\n",
      "5  natur\n",
      "5  discrep\n",
      "5  llm\n",
      "5  pre-train\n",
      "5  textual\n",
      "5  corpora,\n",
      "5  symbol\n",
      "5  languag\n",
      "5  produc\n",
      "5  use\n",
      "5  graph-to-text\n",
      "5  grammar,\n",
      "5  object\n",
      "5  enhanc\n",
      "5  llms'\n",
      "5  abil\n",
      "5  captur\n",
      "5  graph\n",
      "5  structur\n",
      "5  within\n",
      "5  textual\n",
      "5  format.\n",
      "5  achiev\n",
      "5  this,\n",
      "5  introduc\n",
      "5  set\n",
      "5  self-supervis\n",
      "5  symbol\n",
      "5  learn\n",
      "5  task\n",
      "5  includ\n",
      "5  link\n",
      "5  prediction,\n",
      "5  node\n",
      "5  content\n",
      "5  generation,\n",
      "5  gener\n",
      "5  contrast\n",
      "5  learning,\n",
      "5  enabl\n",
      "5  llm\n",
      "5  captur\n",
      "5  topolog\n",
      "5  inform\n",
      "5  coarse-grain\n",
      "5  fine-grained.\n",
      "5  experi\n",
      "5  result\n",
      "5  comprehens\n",
      "5  analysi\n",
      "5  two\n",
      "5  benchmark\n",
      "5  datasets,\n",
      "5  aol\n",
      "5  tiangong-st,\n",
      "5  confirm\n",
      "5  superior\n",
      "5  approach.\n",
      "5  paradigm\n",
      "5  also\n",
      "5  offer\n",
      "5  novel\n",
      "5  effect\n",
      "5  methodolog\n",
      "5  bridg\n",
      "5  gap\n",
      "5  tradit\n",
      "5  search\n",
      "5  strategi\n",
      "5  modern\n",
      "5  llms.\n",
      "6  descript\n",
      "6  item\n",
      "6  play\n",
      "6  pivot\n",
      "6  role\n",
      "6  provid\n",
      "6  concis\n",
      "6  inform\n",
      "6  summari\n",
      "6  captiv\n",
      "6  potenti\n",
      "6  viewer\n",
      "6  essenti\n",
      "6  recommend\n",
      "6  systems.\n",
      "6  traditionally,\n",
      "6  descript\n",
      "6  obtain\n",
      "6  manual\n",
      "6  web\n",
      "6  scrape\n",
      "6  techniques,\n",
      "6  time-consum\n",
      "6  suscept\n",
      "6  data\n",
      "6  inconsistencies.\n",
      "6  recent\n",
      "6  years,\n",
      "6  larg\n",
      "6  languag\n",
      "6  model\n",
      "6  (llms),\n",
      "6  gpt-3.5,\n",
      "6  open\n",
      "6  sourc\n",
      "6  llm\n",
      "6  like\n",
      "6  alpaca\n",
      "6  emerg\n",
      "6  power\n",
      "6  tool\n",
      "6  natur\n",
      "6  languag\n",
      "6  process\n",
      "6  tasks.\n",
      "6  paper,\n",
      "6  explor\n",
      "6  use\n",
      "6  llm\n",
      "6  gener\n",
      "6  detail\n",
      "6  descript\n",
      "6  items.\n",
      "6  conduct\n",
      "6  study,\n",
      "6  use\n",
      "6  movielen\n",
      "6  1m\n",
      "6  dataset\n",
      "6  compris\n",
      "6  movi\n",
      "6  titl\n",
      "6  goodread\n",
      "6  dataset\n",
      "6  consist\n",
      "6  name\n",
      "6  book\n",
      "6  subsequently,\n",
      "6  open-sourc\n",
      "6  llm,\n",
      "6  alpaca,\n",
      "6  prompt\n",
      "6  few-shot\n",
      "6  prompt\n",
      "6  dataset\n",
      "6  gener\n",
      "6  detail\n",
      "6  movi\n",
      "6  descript\n",
      "6  consid\n",
      "6  multipl\n",
      "6  featur\n",
      "6  like\n",
      "6  name\n",
      "6  cast\n",
      "6  director\n",
      "6  ml\n",
      "6  dataset\n",
      "6  name\n",
      "6  author\n",
      "6  publish\n",
      "6  goodread\n",
      "6  dataset.\n",
      "6  gener\n",
      "6  descript\n",
      "6  compar\n",
      "6  scrape\n",
      "6  descript\n",
      "6  use\n",
      "6  combin\n",
      "6  top\n",
      "6  hits,\n",
      "6  mrr,\n",
      "6  ndcg\n",
      "6  evalu\n",
      "6  metrics.\n",
      "6  result\n",
      "6  demonstr\n",
      "6  llm-base\n",
      "6  movi\n",
      "6  descript\n",
      "6  gener\n",
      "6  exhibit\n",
      "6  signific\n",
      "6  promise,\n",
      "6  result\n",
      "6  compar\n",
      "6  one\n",
      "6  obtain\n",
      "6  web-scrap\n",
      "6  descriptions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "descripteur_split_porter =\"\"\n",
    "\n",
    "for i in range(len(termes_split_porter)):\n",
    "    for j in range(len(termes_split_porter[i])):\n",
    "        descripteur_split_porter = descripteur_split_porter + (str(i+1)+ \"  \" +termes_split_porter[i][j]+\"\\n\")\n",
    "\n",
    "\n",
    "print(descripteur_split_porter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  queri\n",
      "1  reformul\n",
      "1  qr\n",
      "1  set\n",
      "1  techniqu\n",
      "1  use\n",
      "1  transform\n",
      "1  user\n",
      "1  origin\n",
      "1  search\n",
      "1  queri\n",
      "1  text\n",
      "1  better\n",
      "1  align\n",
      "1  user\n",
      "1  intent\n",
      "1  improv\n",
      "1  search\n",
      "1  experi\n",
      "1  recent\n",
      "1  zero\n",
      "1  shot\n",
      "1  qr\n",
      "1  shown\n",
      "1  promis\n",
      "1  approach\n",
      "1  due\n",
      "1  abil\n",
      "1  exploit\n",
      "1  knowledg\n",
      "1  inher\n",
      "1  larg\n",
      "1  languag\n",
      "1  model\n",
      "1  take\n",
      "1  inspir\n",
      "1  success\n",
      "1  ensembl\n",
      "1  prompt\n",
      "1  strategi\n",
      "1  benefit\n",
      "1  mani\n",
      "1  task\n",
      "1  investig\n",
      "1  help\n",
      "1  improv\n",
      "1  queri\n",
      "1  reformul\n",
      "1  context\n",
      "1  propos\n",
      "1  ensembl\n",
      "1  base\n",
      "1  prompt\n",
      "1  techniqu\n",
      "1  genqrensembl\n",
      "1  leverag\n",
      "1  paraphras\n",
      "1  zero\n",
      "1  shot\n",
      "1  instruct\n",
      "1  gener\n",
      "1  multipl\n",
      "1  set\n",
      "1  keyword\n",
      "1  ultim\n",
      "1  improv\n",
      "1  retriev\n",
      "1  perform\n",
      "1  introduc\n",
      "1  post\n",
      "1  retriev\n",
      "1  variant\n",
      "1  genqrensemblerf\n",
      "1  incorpor\n",
      "1  pseudo\n",
      "1  relev\n",
      "1  feedback\n",
      "1  evalu\n",
      "1  four\n",
      "1  ir\n",
      "1  benchmark\n",
      "1  find\n",
      "1  genqrensembl\n",
      "1  gener\n",
      "1  better\n",
      "1  reformul\n",
      "1  rel\n",
      "1  ndcg\n",
      "1  10\n",
      "1  improv\n",
      "1  18\n",
      "1  map\n",
      "1  improv\n",
      "1  upto\n",
      "1  24\n",
      "1  previou\n",
      "1  zero\n",
      "1  shot\n",
      "1  state\n",
      "1  art\n",
      "1  msmarco\n",
      "1  passag\n",
      "1  rank\n",
      "1  task\n",
      "1  genqrensemblerf\n",
      "1  show\n",
      "1  rel\n",
      "1  gain\n",
      "1  5\n",
      "1  mrr\n",
      "1  use\n",
      "1  pseudo\n",
      "1  relev\n",
      "1  feedback\n",
      "1  9\n",
      "1  ndcg\n",
      "1  10\n",
      "1  use\n",
      "1  relev\n",
      "1  feedback\n",
      "1  document\n",
      "2  rank\n",
      "2  document\n",
      "2  use\n",
      "2  larg\n",
      "2  languag\n",
      "2  model\n",
      "2  llm\n",
      "2  directli\n",
      "2  feed\n",
      "2  queri\n",
      "2  candid\n",
      "2  document\n",
      "2  prompt\n",
      "2  interest\n",
      "2  practic\n",
      "2  problem\n",
      "2  howev\n",
      "2  research\n",
      "2  found\n",
      "2  difficult\n",
      "2  outperform\n",
      "2  fine\n",
      "2  tune\n",
      "2  baselin\n",
      "2  ranker\n",
      "2  benchmark\n",
      "2  dataset\n",
      "2  analyz\n",
      "2  pointwis\n",
      "2  listwis\n",
      "2  rank\n",
      "2  prompt\n",
      "2  use\n",
      "2  exist\n",
      "2  method\n",
      "2  argu\n",
      "2  shelf\n",
      "2  llm\n",
      "2  fulli\n",
      "2  understand\n",
      "2  challeng\n",
      "2  rank\n",
      "2  formul\n",
      "2  paper\n",
      "2  propos\n",
      "2  significantli\n",
      "2  reduc\n",
      "2  burden\n",
      "2  llm\n",
      "2  use\n",
      "2  new\n",
      "2  techniqu\n",
      "2  call\n",
      "2  pairwis\n",
      "2  rank\n",
      "2  prompt\n",
      "2  prp\n",
      "2  result\n",
      "2  first\n",
      "2  literatur\n",
      "2  achiev\n",
      "2  state\n",
      "2  art\n",
      "2  rank\n",
      "2  perform\n",
      "2  standard\n",
      "2  benchmark\n",
      "2  use\n",
      "2  moder\n",
      "2  size\n",
      "2  open\n",
      "2  sourc\n",
      "2  llm\n",
      "2  trec\n",
      "2  dl\n",
      "2  2019\n",
      "2  2020\n",
      "2  prp\n",
      "2  base\n",
      "2  flan\n",
      "2  ul2\n",
      "2  model\n",
      "2  20b\n",
      "2  paramet\n",
      "2  perform\n",
      "2  favor\n",
      "2  previou\n",
      "2  best\n",
      "2  approach\n",
      "2  literatur\n",
      "2  base\n",
      "2  blackbox\n",
      "2  commerci\n",
      "2  gpt\n",
      "2  4\n",
      "2  50x\n",
      "2  estim\n",
      "2  model\n",
      "2  size\n",
      "2  outperform\n",
      "2  llm\n",
      "2  base\n",
      "2  solut\n",
      "2  instructgpt\n",
      "2  175b\n",
      "2  paramet\n",
      "2  10\n",
      "2  rank\n",
      "2  metric\n",
      "2  use\n",
      "2  prompt\n",
      "2  templat\n",
      "2  seven\n",
      "2  beir\n",
      "2  task\n",
      "2  prp\n",
      "2  outperform\n",
      "2  supervis\n",
      "2  baselin\n",
      "2  outperform\n",
      "2  blackbox\n",
      "2  commerci\n",
      "2  chatgpt\n",
      "2  solut\n",
      "2  4\n",
      "2  2\n",
      "2  pointwis\n",
      "2  llm\n",
      "2  base\n",
      "2  solut\n",
      "2  10\n",
      "2  averag\n",
      "2  ndcg\n",
      "2  10\n",
      "2  furthermor\n",
      "2  propos\n",
      "2  sever\n",
      "2  variant\n",
      "2  prp\n",
      "2  improv\n",
      "2  effici\n",
      "2  show\n",
      "2  possibl\n",
      "2  achiev\n",
      "2  competit\n",
      "2  result\n",
      "2  even\n",
      "2  linear\n",
      "2  complex\n",
      "3  larg\n",
      "3  languag\n",
      "3  model\n",
      "3  llm\n",
      "3  manifest\n",
      "3  unparallel\n",
      "3  model\n",
      "3  capabl\n",
      "3  variou\n",
      "3  task\n",
      "3  e\n",
      "3  g\n",
      "3  multi\n",
      "3  step\n",
      "3  reason\n",
      "3  input\n",
      "3  model\n",
      "3  mostli\n",
      "3  limit\n",
      "3  plain\n",
      "3  text\n",
      "3  could\n",
      "3  long\n",
      "3  contain\n",
      "3  noisi\n",
      "3  inform\n",
      "3  long\n",
      "3  text\n",
      "3  could\n",
      "3  take\n",
      "3  long\n",
      "3  time\n",
      "3  process\n",
      "3  thu\n",
      "3  may\n",
      "3  effici\n",
      "3  enough\n",
      "3  recommend\n",
      "3  system\n",
      "3  requir\n",
      "3  immedi\n",
      "3  respons\n",
      "3  llm\n",
      "3  base\n",
      "3  recommend\n",
      "3  model\n",
      "3  user\n",
      "3  item\n",
      "3  id\n",
      "3  usual\n",
      "3  fill\n",
      "3  templat\n",
      "3  e\n",
      "3  discret\n",
      "3  prompt\n",
      "3  allow\n",
      "3  model\n",
      "3  understand\n",
      "3  given\n",
      "3  task\n",
      "3  model\n",
      "3  usual\n",
      "3  need\n",
      "3  extens\n",
      "3  fine\n",
      "3  tune\n",
      "3  bridg\n",
      "3  user\n",
      "3  item\n",
      "3  id\n",
      "3  templat\n",
      "3  word\n",
      "3  unleash\n",
      "3  power\n",
      "3  llm\n",
      "3  recommend\n",
      "3  address\n",
      "3  problem\n",
      "3  propos\n",
      "3  distil\n",
      "3  discret\n",
      "3  prompt\n",
      "3  specif\n",
      "3  task\n",
      "3  set\n",
      "3  continu\n",
      "3  prompt\n",
      "3  vector\n",
      "3  bridg\n",
      "3  id\n",
      "3  word\n",
      "3  reduc\n",
      "3  infer\n",
      "3  time\n",
      "3  also\n",
      "3  design\n",
      "3  train\n",
      "3  strategi\n",
      "3  attempt\n",
      "3  improv\n",
      "3  effici\n",
      "3  train\n",
      "3  model\n",
      "3  experiment\n",
      "3  result\n",
      "3  three\n",
      "3  real\n",
      "3  world\n",
      "3  dataset\n",
      "3  demonstr\n",
      "3  effect\n",
      "3  prompt\n",
      "3  distil\n",
      "3  pod\n",
      "3  approach\n",
      "3  sequenti\n",
      "3  recommend\n",
      "3  top\n",
      "3  n\n",
      "3  recommend\n",
      "3  task\n",
      "3  although\n",
      "3  train\n",
      "3  effici\n",
      "3  significantli\n",
      "3  improv\n",
      "3  improv\n",
      "3  infer\n",
      "3  effici\n",
      "3  limit\n",
      "3  find\n",
      "3  may\n",
      "3  inspir\n",
      "3  research\n",
      "3  commun\n",
      "3  improv\n",
      "3  infer\n",
      "3  effici\n",
      "3  llm\n",
      "3  base\n",
      "3  recommend\n",
      "3  model\n",
      "4  queri\n",
      "4  reformul\n",
      "4  well\n",
      "4  known\n",
      "4  problem\n",
      "4  inform\n",
      "4  retriev\n",
      "4  ir\n",
      "4  aim\n",
      "4  enhanc\n",
      "4  singl\n",
      "4  search\n",
      "4  success\n",
      "4  complet\n",
      "4  rate\n",
      "4  automat\n",
      "4  modifi\n",
      "4  user\n",
      "4  input\n",
      "4  queri\n",
      "4  recent\n",
      "4  method\n",
      "4  leverag\n",
      "4  larg\n",
      "4  languag\n",
      "4  model\n",
      "4  llm\n",
      "4  improv\n",
      "4  queri\n",
      "4  reformul\n",
      "4  often\n",
      "4  gener\n",
      "4  limit\n",
      "4  redund\n",
      "4  expans\n",
      "4  potenti\n",
      "4  constrain\n",
      "4  effect\n",
      "4  captur\n",
      "4  divers\n",
      "4  intent\n",
      "4  paper\n",
      "4  propos\n",
      "4  gencrf\n",
      "4  gener\n",
      "4  cluster\n",
      "4  reformul\n",
      "4  framework\n",
      "4  captur\n",
      "4  divers\n",
      "4  intent\n",
      "4  adapt\n",
      "4  base\n",
      "4  multipl\n",
      "4  differenti\n",
      "4  well\n",
      "4  gener\n",
      "4  queri\n",
      "4  retriev\n",
      "4  phase\n",
      "4  first\n",
      "4  time\n",
      "4  gencrf\n",
      "4  leverag\n",
      "4  llm\n",
      "4  gener\n",
      "4  variabl\n",
      "4  queri\n",
      "4  initi\n",
      "4  queri\n",
      "4  use\n",
      "4  custom\n",
      "4  prompt\n",
      "4  cluster\n",
      "4  group\n",
      "4  distinctli\n",
      "4  repres\n",
      "4  divers\n",
      "4  intent\n",
      "4  furthermor\n",
      "4  framework\n",
      "4  explor\n",
      "4  combin\n",
      "4  divers\n",
      "4  intent\n",
      "4  queri\n",
      "4  innov\n",
      "4  weight\n",
      "4  aggreg\n",
      "4  strategi\n",
      "4  optim\n",
      "4  retriev\n",
      "4  perform\n",
      "4  crucial\n",
      "4  integr\n",
      "4  novel\n",
      "4  queri\n",
      "4  evalu\n",
      "4  reward\n",
      "4  model\n",
      "4  qerm\n",
      "4  refin\n",
      "4  process\n",
      "4  feedback\n",
      "4  loop\n",
      "4  empir\n",
      "4  experi\n",
      "4  beir\n",
      "4  benchmark\n",
      "4  demonstr\n",
      "4  gencrf\n",
      "4  achiev\n",
      "4  state\n",
      "4  art\n",
      "4  perform\n",
      "4  surpass\n",
      "4  previou\n",
      "4  queri\n",
      "4  reformul\n",
      "4  sota\n",
      "4  12\n",
      "4  ndcg\n",
      "4  10\n",
      "4  techniqu\n",
      "4  adapt\n",
      "4  variou\n",
      "4  llm\n",
      "4  significantli\n",
      "4  boost\n",
      "4  retriev\n",
      "4  perform\n",
      "4  advanc\n",
      "4  field\n",
      "4  inform\n",
      "4  retriev\n",
      "5  session\n",
      "5  search\n",
      "5  involv\n",
      "5  seri\n",
      "5  interact\n",
      "5  queri\n",
      "5  action\n",
      "5  fulfil\n",
      "5  user\n",
      "5  complex\n",
      "5  inform\n",
      "5  need\n",
      "5  current\n",
      "5  strategi\n",
      "5  typic\n",
      "5  priorit\n",
      "5  sequenti\n",
      "5  model\n",
      "5  deep\n",
      "5  semant\n",
      "5  understand\n",
      "5  overlook\n",
      "5  graph\n",
      "5  structur\n",
      "5  interact\n",
      "5  approach\n",
      "5  focu\n",
      "5  captur\n",
      "5  structur\n",
      "5  inform\n",
      "5  use\n",
      "5  gener\n",
      "5  represent\n",
      "5  document\n",
      "5  neglect\n",
      "5  word\n",
      "5  level\n",
      "5  semant\n",
      "5  model\n",
      "5  paper\n",
      "5  propos\n",
      "5  symbol\n",
      "5  graph\n",
      "5  ranker\n",
      "5  sgr\n",
      "5  aim\n",
      "5  take\n",
      "5  advantag\n",
      "5  text\n",
      "5  base\n",
      "5  graph\n",
      "5  base\n",
      "5  approach\n",
      "5  leverag\n",
      "5  power\n",
      "5  recent\n",
      "5  larg\n",
      "5  languag\n",
      "5  model\n",
      "5  llm\n",
      "5  concret\n",
      "5  first\n",
      "5  introduc\n",
      "5  set\n",
      "5  symbol\n",
      "5  grammar\n",
      "5  rule\n",
      "5  convert\n",
      "5  session\n",
      "5  graph\n",
      "5  text\n",
      "5  allow\n",
      "5  integr\n",
      "5  session\n",
      "5  histori\n",
      "5  interact\n",
      "5  process\n",
      "5  task\n",
      "5  instruct\n",
      "5  seamlessli\n",
      "5  input\n",
      "5  llm\n",
      "5  moreov\n",
      "5  given\n",
      "5  natur\n",
      "5  discrep\n",
      "5  llm\n",
      "5  pre\n",
      "5  train\n",
      "5  textual\n",
      "5  corpora\n",
      "5  symbol\n",
      "5  languag\n",
      "5  produc\n",
      "5  use\n",
      "5  graph\n",
      "5  text\n",
      "5  grammar\n",
      "5  object\n",
      "5  enhanc\n",
      "5  llm\n",
      "5  abil\n",
      "5  captur\n",
      "5  graph\n",
      "5  structur\n",
      "5  within\n",
      "5  textual\n",
      "5  format\n",
      "5  achiev\n",
      "5  introduc\n",
      "5  set\n",
      "5  self\n",
      "5  supervis\n",
      "5  symbol\n",
      "5  learn\n",
      "5  task\n",
      "5  includ\n",
      "5  link\n",
      "5  predict\n",
      "5  node\n",
      "5  content\n",
      "5  gener\n",
      "5  gener\n",
      "5  contrast\n",
      "5  learn\n",
      "5  enabl\n",
      "5  llm\n",
      "5  captur\n",
      "5  topolog\n",
      "5  inform\n",
      "5  coars\n",
      "5  grain\n",
      "5  fine\n",
      "5  grain\n",
      "5  experi\n",
      "5  result\n",
      "5  comprehens\n",
      "5  analysi\n",
      "5  two\n",
      "5  benchmark\n",
      "5  dataset\n",
      "5  aol\n",
      "5  tiangong\n",
      "5  st\n",
      "5  confirm\n",
      "5  superior\n",
      "5  approach\n",
      "5  paradigm\n",
      "5  also\n",
      "5  offer\n",
      "5  novel\n",
      "5  effect\n",
      "5  methodolog\n",
      "5  bridg\n",
      "5  gap\n",
      "5  tradit\n",
      "5  search\n",
      "5  strategi\n",
      "5  modern\n",
      "5  llm\n",
      "6  descript\n",
      "6  item\n",
      "6  play\n",
      "6  pivot\n",
      "6  role\n",
      "6  provid\n",
      "6  concis\n",
      "6  inform\n",
      "6  summari\n",
      "6  captiv\n",
      "6  potenti\n",
      "6  viewer\n",
      "6  essenti\n",
      "6  recommend\n",
      "6  system\n",
      "6  tradit\n",
      "6  descript\n",
      "6  obtain\n",
      "6  manual\n",
      "6  web\n",
      "6  scrape\n",
      "6  techniqu\n",
      "6  time\n",
      "6  consum\n",
      "6  suscept\n",
      "6  data\n",
      "6  inconsist\n",
      "6  recent\n",
      "6  year\n",
      "6  larg\n",
      "6  languag\n",
      "6  model\n",
      "6  llm\n",
      "6  gpt\n",
      "6  3\n",
      "6  5\n",
      "6  open\n",
      "6  sourc\n",
      "6  llm\n",
      "6  like\n",
      "6  alpaca\n",
      "6  emerg\n",
      "6  power\n",
      "6  tool\n",
      "6  natur\n",
      "6  languag\n",
      "6  process\n",
      "6  task\n",
      "6  paper\n",
      "6  explor\n",
      "6  use\n",
      "6  llm\n",
      "6  gener\n",
      "6  detail\n",
      "6  descript\n",
      "6  item\n",
      "6  conduct\n",
      "6  studi\n",
      "6  use\n",
      "6  movielen\n",
      "6  1m\n",
      "6  dataset\n",
      "6  compris\n",
      "6  movi\n",
      "6  titl\n",
      "6  goodread\n",
      "6  dataset\n",
      "6  consist\n",
      "6  name\n",
      "6  book\n",
      "6  subsequ\n",
      "6  open\n",
      "6  sourc\n",
      "6  llm\n",
      "6  alpaca\n",
      "6  prompt\n",
      "6  shot\n",
      "6  prompt\n",
      "6  dataset\n",
      "6  gener\n",
      "6  detail\n",
      "6  movi\n",
      "6  descript\n",
      "6  consid\n",
      "6  multipl\n",
      "6  featur\n",
      "6  like\n",
      "6  name\n",
      "6  cast\n",
      "6  director\n",
      "6  ml\n",
      "6  dataset\n",
      "6  name\n",
      "6  author\n",
      "6  publish\n",
      "6  goodread\n",
      "6  dataset\n",
      "6  gener\n",
      "6  descript\n",
      "6  compar\n",
      "6  scrape\n",
      "6  descript\n",
      "6  use\n",
      "6  combin\n",
      "6  top\n",
      "6  hit\n",
      "6  mrr\n",
      "6  ndcg\n",
      "6  evalu\n",
      "6  metric\n",
      "6  result\n",
      "6  demonstr\n",
      "6  llm\n",
      "6  base\n",
      "6  movi\n",
      "6  descript\n",
      "6  gener\n",
      "6  exhibit\n",
      "6  signific\n",
      "6  promis\n",
      "6  result\n",
      "6  compar\n",
      "6  one\n",
      "6  obtain\n",
      "6  web\n",
      "6  scrape\n",
      "6  descript\n",
      "\n"
     ]
    }
   ],
   "source": [
    "descripteur_reg_porter =\"\"\n",
    "\n",
    "for i in range(len(termes_reg_porter)):\n",
    "    for j in range(len(termes_reg_porter[i])):\n",
    "        descripteur_reg_porter = descripteur_reg_porter + (str(i+1)+ \"  \" + termes_reg_porter[i][j]+\"\\n\")\n",
    "\n",
    "\n",
    "print(descripteur_reg_porter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  query\n",
      "1  reformulation(qr)\n",
      "1  set\n",
      "1  techn\n",
      "1  us\n",
      "1  transform\n",
      "1  user’s\n",
      "1  origin\n",
      "1  search\n",
      "1  query\n",
      "1  text\n",
      "1  bet\n",
      "1  align\n",
      "1  user’s\n",
      "1  int\n",
      "1  improv\n",
      "1  search\n",
      "1  experience.\n",
      "1  recently,\n",
      "1  zero-shot\n",
      "1  qr\n",
      "1  shown\n",
      "1  prom\n",
      "1  approach\n",
      "1  due\n",
      "1  abl\n",
      "1  exploit\n",
      "1  knowledg\n",
      "1  inh\n",
      "1  larg\n",
      "1  langu\n",
      "1  models.\n",
      "1  tak\n",
      "1  inspir\n",
      "1  success\n",
      "1  ensembl\n",
      "1  prompt\n",
      "1  strategies\n",
      "1  benefit\n",
      "1  many\n",
      "1  tasks,\n",
      "1  investig\n",
      "1  help\n",
      "1  improv\n",
      "1  query\n",
      "1  reformulation.\n",
      "1  context,\n",
      "1  propos\n",
      "1  ensembl\n",
      "1  bas\n",
      "1  prompt\n",
      "1  technique,\n",
      "1  genqrensembl\n",
      "1  lev\n",
      "1  paraphras\n",
      "1  zero-shot\n",
      "1  instruct\n",
      "1  gen\n",
      "1  multipl\n",
      "1  set\n",
      "1  keyword\n",
      "1  ultim\n",
      "1  improv\n",
      "1  retriev\n",
      "1  performance.\n",
      "1  introduc\n",
      "1  post-retrieval\n",
      "1  variant,\n",
      "1  genqrensemblerf\n",
      "1  incorp\n",
      "1  pseudo\n",
      "1  relev\n",
      "1  feedback.\n",
      "1  evalu\n",
      "1  four\n",
      "1  ir\n",
      "1  benchmarks,\n",
      "1  find\n",
      "1  genqrensembl\n",
      "1  gen\n",
      "1  bet\n",
      "1  reform\n",
      "1  rel\n",
      "1  ndcg@10\n",
      "1  improv\n",
      "1  18%\n",
      "1  map\n",
      "1  improv\n",
      "1  upto\n",
      "1  24%\n",
      "1  prevy\n",
      "1  zero-shot\n",
      "1  state-of-art.\n",
      "1  msmarco\n",
      "1  pass\n",
      "1  rank\n",
      "1  task,\n",
      "1  genqrensemblerf\n",
      "1  show\n",
      "1  rel\n",
      "1  gain\n",
      "1  5%\n",
      "1  mrr\n",
      "1  us\n",
      "1  pseudo-relevance\n",
      "1  feedback,\n",
      "1  9%\n",
      "1  ndcg@10\n",
      "1  us\n",
      "1  relev\n",
      "1  feedback\n",
      "1  documents.\n",
      "2  rank\n",
      "2  docu\n",
      "2  us\n",
      "2  larg\n",
      "2  langu\n",
      "2  model\n",
      "2  (llms)\n",
      "2  direct\n",
      "2  fee\n",
      "2  query\n",
      "2  candid\n",
      "2  docu\n",
      "2  prompt\n",
      "2  interest\n",
      "2  pract\n",
      "2  problem.\n",
      "2  however,\n",
      "2  research\n",
      "2  found\n",
      "2  difficult\n",
      "2  outperform\n",
      "2  fine-tuned\n",
      "2  baselin\n",
      "2  rank\n",
      "2  benchmark\n",
      "2  datasets.\n",
      "2  analys\n",
      "2  pointw\n",
      "2  listw\n",
      "2  rank\n",
      "2  prompt\n",
      "2  us\n",
      "2  ex\n",
      "2  method\n",
      "2  argu\n",
      "2  off-the-shelf\n",
      "2  llms\n",
      "2  ful\n",
      "2  understand\n",
      "2  challeng\n",
      "2  rank\n",
      "2  formulations.\n",
      "2  paper,\n",
      "2  propos\n",
      "2  sign\n",
      "2  reduc\n",
      "2  burd\n",
      "2  llms\n",
      "2  us\n",
      "2  new\n",
      "2  techn\n",
      "2  cal\n",
      "2  pairw\n",
      "2  rank\n",
      "2  prompt\n",
      "2  (prp).\n",
      "2  result\n",
      "2  first\n",
      "2  lit\n",
      "2  achiev\n",
      "2  state-of-the-art\n",
      "2  rank\n",
      "2  perform\n",
      "2  standard\n",
      "2  benchmark\n",
      "2  us\n",
      "2  moderate-sized\n",
      "2  open-sourced\n",
      "2  llms.\n",
      "2  trec-dl\n",
      "2  2019\n",
      "2  2020,\n",
      "2  prp\n",
      "2  bas\n",
      "2  flan-ul2\n",
      "2  model\n",
      "2  20b\n",
      "2  paramet\n",
      "2  perform\n",
      "2  fav\n",
      "2  prevy\n",
      "2  best\n",
      "2  approach\n",
      "2  literature,\n",
      "2  bas\n",
      "2  blackbox\n",
      "2  commerc\n",
      "2  gpt-4\n",
      "2  50x\n",
      "2  (estimated)\n",
      "2  model\n",
      "2  size,\n",
      "2  outperform\n",
      "2  llm-based\n",
      "2  solutions,\n",
      "2  instructgpt\n",
      "2  175b\n",
      "2  parameters,\n",
      "2  10%\n",
      "2  rank\n",
      "2  metrics.\n",
      "2  us\n",
      "2  prompt\n",
      "2  templ\n",
      "2  sev\n",
      "2  beir\n",
      "2  tasks,\n",
      "2  prp\n",
      "2  outperform\n",
      "2  superv\n",
      "2  baselin\n",
      "2  outperform\n",
      "2  blackbox\n",
      "2  commerc\n",
      "2  chatgpt\n",
      "2  solv\n",
      "2  4.2%\n",
      "2  pointw\n",
      "2  llm-based\n",
      "2  solv\n",
      "2  10%\n",
      "2  av\n",
      "2  ndcg@10.\n",
      "2  furthermore,\n",
      "2  propos\n",
      "2  sev\n",
      "2  vary\n",
      "2  prp\n",
      "2  improv\n",
      "2  efficy\n",
      "2  show\n",
      "2  poss\n",
      "2  achiev\n",
      "2  competit\n",
      "2  result\n",
      "2  ev\n",
      "2  linear\n",
      "2  complex\n",
      "3  larg\n",
      "3  langu\n",
      "3  model\n",
      "3  (llm)\n",
      "3  manifest\n",
      "3  unparallel\n",
      "3  model\n",
      "3  cap\n",
      "3  vary\n",
      "3  tasks,\n",
      "3  e.g.,\n",
      "3  multi-step\n",
      "3  reasoning,\n",
      "3  input\n",
      "3  model\n",
      "3  most\n",
      "3  limit\n",
      "3  plain\n",
      "3  text,\n",
      "3  could\n",
      "3  long\n",
      "3  contain\n",
      "3  noisy\n",
      "3  information.\n",
      "3  long\n",
      "3  text\n",
      "3  could\n",
      "3  tak\n",
      "3  long\n",
      "3  tim\n",
      "3  process,\n",
      "3  thu\n",
      "3  may\n",
      "3  efficy\n",
      "3  enough\n",
      "3  recommend\n",
      "3  system\n",
      "3  requir\n",
      "3  immedy\n",
      "3  response.\n",
      "3  llm-based\n",
      "3  recommend\n",
      "3  models,\n",
      "3  us\n",
      "3  item\n",
      "3  id\n",
      "3  us\n",
      "3  fil\n",
      "3  templ\n",
      "3  (i.e.,\n",
      "3  discret\n",
      "3  prompt)\n",
      "3  allow\n",
      "3  model\n",
      "3  understand\n",
      "3  giv\n",
      "3  task,\n",
      "3  model\n",
      "3  us\n",
      "3  nee\n",
      "3  extend\n",
      "3  fine-tuning\n",
      "3  bridg\n",
      "3  user/item\n",
      "3  id\n",
      "3  templ\n",
      "3  word\n",
      "3  unleash\n",
      "3  pow\n",
      "3  llm\n",
      "3  recommendation.\n",
      "3  address\n",
      "3  problems,\n",
      "3  propos\n",
      "3  distil\n",
      "3  discret\n",
      "3  prompt\n",
      "3  spec\n",
      "3  task\n",
      "3  set\n",
      "3  continu\n",
      "3  prompt\n",
      "3  vect\n",
      "3  bridg\n",
      "3  id\n",
      "3  word\n",
      "3  reduc\n",
      "3  inf\n",
      "3  time.\n",
      "3  also\n",
      "3  design\n",
      "3  train\n",
      "3  strategy\n",
      "3  attempt\n",
      "3  improv\n",
      "3  efficy\n",
      "3  train\n",
      "3  models.\n",
      "3  expery\n",
      "3  result\n",
      "3  three\n",
      "3  real-world\n",
      "3  dataset\n",
      "3  demonst\n",
      "3  effect\n",
      "3  prompt\n",
      "3  distil\n",
      "3  (pod)\n",
      "3  approach\n",
      "3  sequ\n",
      "3  recommend\n",
      "3  top-n\n",
      "3  recommend\n",
      "3  tasks.\n",
      "3  although\n",
      "3  train\n",
      "3  efficy\n",
      "3  sign\n",
      "3  improved,\n",
      "3  improv\n",
      "3  inf\n",
      "3  efficy\n",
      "3  limited.\n",
      "3  find\n",
      "3  may\n",
      "3  inspir\n",
      "3  research\n",
      "3  commun\n",
      "3  improv\n",
      "3  inf\n",
      "3  efficy\n",
      "3  llm-based\n",
      "3  recommend\n",
      "3  models.\n",
      "4  query\n",
      "4  reform\n",
      "4  well-known\n",
      "4  problem\n",
      "4  inform\n",
      "4  retriev\n",
      "4  (ir)\n",
      "4  aim\n",
      "4  enh\n",
      "4  singl\n",
      "4  search\n",
      "4  success\n",
      "4  complet\n",
      "4  rat\n",
      "4  autom\n",
      "4  mod\n",
      "4  user's\n",
      "4  input\n",
      "4  query.\n",
      "4  rec\n",
      "4  method\n",
      "4  lev\n",
      "4  larg\n",
      "4  langu\n",
      "4  model\n",
      "4  (llms)\n",
      "4  improv\n",
      "4  query\n",
      "4  reformulation,\n",
      "4  oft\n",
      "4  gen\n",
      "4  limit\n",
      "4  redund\n",
      "4  expansions,\n",
      "4  pot\n",
      "4  constrain\n",
      "4  effect\n",
      "4  capt\n",
      "4  divers\n",
      "4  intents.\n",
      "4  paper,\n",
      "4  propos\n",
      "4  gencrf:\n",
      "4  gen\n",
      "4  clust\n",
      "4  reform\n",
      "4  framework\n",
      "4  capt\n",
      "4  divers\n",
      "4  int\n",
      "4  adapt\n",
      "4  bas\n",
      "4  multipl\n",
      "4  differentiated,\n",
      "4  well-generated\n",
      "4  query\n",
      "4  retriev\n",
      "4  phas\n",
      "4  first\n",
      "4  time.\n",
      "4  gencrf\n",
      "4  lev\n",
      "4  llms\n",
      "4  gen\n",
      "4  vary\n",
      "4  query\n",
      "4  init\n",
      "4  query\n",
      "4  us\n",
      "4  custom\n",
      "4  prompts,\n",
      "4  clust\n",
      "4  group\n",
      "4  distinct\n",
      "4  repres\n",
      "4  divers\n",
      "4  intents.\n",
      "4  furthermore,\n",
      "4  framework\n",
      "4  expl\n",
      "4  combin\n",
      "4  divers\n",
      "4  int\n",
      "4  query\n",
      "4  innov\n",
      "4  weight\n",
      "4  aggreg\n",
      "4  strategies\n",
      "4  optim\n",
      "4  retriev\n",
      "4  perform\n",
      "4  cruc\n",
      "4  integr\n",
      "4  novel\n",
      "4  query\n",
      "4  evalu\n",
      "4  reward\n",
      "4  model\n",
      "4  (qerm)\n",
      "4  refin\n",
      "4  process\n",
      "4  feedback\n",
      "4  loops.\n",
      "4  empir\n",
      "4  expery\n",
      "4  beir\n",
      "4  benchmark\n",
      "4  demonst\n",
      "4  gencrf\n",
      "4  achiev\n",
      "4  state-of-the-art\n",
      "4  performance,\n",
      "4  surpass\n",
      "4  prevy\n",
      "4  query\n",
      "4  reform\n",
      "4  sota\n",
      "4  12%\n",
      "4  ndcg@10.\n",
      "4  techn\n",
      "4  adapt\n",
      "4  vary\n",
      "4  llms,\n",
      "4  sign\n",
      "4  boost\n",
      "4  retriev\n",
      "4  perform\n",
      "4  adv\n",
      "4  field\n",
      "4  inform\n",
      "4  retrieval.\n",
      "5  sess\n",
      "5  search\n",
      "5  involv\n",
      "5  sery\n",
      "5  interact\n",
      "5  query\n",
      "5  act\n",
      "5  fulfil\n",
      "5  user's\n",
      "5  complex\n",
      "5  inform\n",
      "5  need.\n",
      "5  cur\n",
      "5  strategies\n",
      "5  typ\n",
      "5  priorit\n",
      "5  sequ\n",
      "5  model\n",
      "5  deep\n",
      "5  sem\n",
      "5  understanding,\n",
      "5  overlook\n",
      "5  graph\n",
      "5  structure\n",
      "5  interactions.\n",
      "5  approach\n",
      "5  foc\n",
      "5  capt\n",
      "5  structural\n",
      "5  information,\n",
      "5  us\n",
      "5  gen\n",
      "5  repres\n",
      "5  documents,\n",
      "5  neglect\n",
      "5  word-level\n",
      "5  sem\n",
      "5  modeling.\n",
      "5  paper,\n",
      "5  propos\n",
      "5  symbol\n",
      "5  graph\n",
      "5  rank\n",
      "5  (sgr),\n",
      "5  aim\n",
      "5  tak\n",
      "5  adv\n",
      "5  text-based\n",
      "5  graph-based\n",
      "5  approach\n",
      "5  lev\n",
      "5  pow\n",
      "5  rec\n",
      "5  larg\n",
      "5  langu\n",
      "5  model\n",
      "5  (llms).\n",
      "5  concretely,\n",
      "5  first\n",
      "5  introduc\n",
      "5  set\n",
      "5  symbol\n",
      "5  gramm\n",
      "5  rul\n",
      "5  convert\n",
      "5  sess\n",
      "5  graph\n",
      "5  text.\n",
      "5  allow\n",
      "5  integr\n",
      "5  sess\n",
      "5  history,\n",
      "5  interact\n",
      "5  process,\n",
      "5  task\n",
      "5  instruct\n",
      "5  seamless\n",
      "5  input\n",
      "5  llm.\n",
      "5  moreover,\n",
      "5  giv\n",
      "5  nat\n",
      "5  discrep\n",
      "5  llms\n",
      "5  pre-trained\n",
      "5  text\n",
      "5  corpora,\n",
      "5  symbol\n",
      "5  langu\n",
      "5  produc\n",
      "5  us\n",
      "5  graph-to-text\n",
      "5  grammar,\n",
      "5  object\n",
      "5  enh\n",
      "5  llms'\n",
      "5  abl\n",
      "5  capt\n",
      "5  graph\n",
      "5  structures\n",
      "5  within\n",
      "5  text\n",
      "5  format.\n",
      "5  achiev\n",
      "5  this,\n",
      "5  introduc\n",
      "5  set\n",
      "5  self-supervised\n",
      "5  symbol\n",
      "5  learn\n",
      "5  task\n",
      "5  includ\n",
      "5  link\n",
      "5  prediction,\n",
      "5  nod\n",
      "5  cont\n",
      "5  generation,\n",
      "5  gen\n",
      "5  contrast\n",
      "5  learning,\n",
      "5  en\n",
      "5  llms\n",
      "5  capt\n",
      "5  topolog\n",
      "5  inform\n",
      "5  coarse-grained\n",
      "5  fine-grained.\n",
      "5  expery\n",
      "5  result\n",
      "5  comprehend\n",
      "5  analys\n",
      "5  two\n",
      "5  benchmark\n",
      "5  datasets,\n",
      "5  aol\n",
      "5  tiangong-st,\n",
      "5  confirm\n",
      "5  supery\n",
      "5  approach.\n",
      "5  paradigm\n",
      "5  also\n",
      "5  off\n",
      "5  novel\n",
      "5  effect\n",
      "5  methodolog\n",
      "5  bridg\n",
      "5  gap\n",
      "5  tradit\n",
      "5  search\n",
      "5  strategies\n",
      "5  modern\n",
      "5  llms.\n",
      "6  describ\n",
      "6  item\n",
      "6  play\n",
      "6  pivot\n",
      "6  rol\n",
      "6  provid\n",
      "6  cont\n",
      "6  inform\n",
      "6  sum\n",
      "6  capt\n",
      "6  pot\n",
      "6  view\n",
      "6  ess\n",
      "6  recommend\n",
      "6  systems.\n",
      "6  traditionally,\n",
      "6  describ\n",
      "6  obtain\n",
      "6  man\n",
      "6  web\n",
      "6  scraping\n",
      "6  techniques,\n",
      "6  time-consuming\n",
      "6  suscept\n",
      "6  dat\n",
      "6  inconsistencies.\n",
      "6  rec\n",
      "6  years,\n",
      "6  larg\n",
      "6  langu\n",
      "6  model\n",
      "6  (llms),\n",
      "6  gpt-3.5,\n",
      "6  op\n",
      "6  sourc\n",
      "6  llms\n",
      "6  lik\n",
      "6  alpac\n",
      "6  emerg\n",
      "6  pow\n",
      "6  tool\n",
      "6  nat\n",
      "6  langu\n",
      "6  process\n",
      "6  tasks.\n",
      "6  paper,\n",
      "6  expl\n",
      "6  us\n",
      "6  llms\n",
      "6  gen\n",
      "6  detail\n",
      "6  describ\n",
      "6  items.\n",
      "6  conduc\n",
      "6  study,\n",
      "6  us\n",
      "6  moviel\n",
      "6  1m\n",
      "6  dataset\n",
      "6  compr\n",
      "6  movy\n",
      "6  titl\n",
      "6  goodread\n",
      "6  dataset\n",
      "6  consist\n",
      "6  nam\n",
      "6  book\n",
      "6  subsequently,\n",
      "6  open-sourced\n",
      "6  llm,\n",
      "6  alpaca,\n",
      "6  prompt\n",
      "6  few-shot\n",
      "6  prompt\n",
      "6  dataset\n",
      "6  gen\n",
      "6  detail\n",
      "6  movy\n",
      "6  describ\n",
      "6  consid\n",
      "6  multipl\n",
      "6  feat\n",
      "6  lik\n",
      "6  nam\n",
      "6  cast\n",
      "6  direct\n",
      "6  ml\n",
      "6  dataset\n",
      "6  nam\n",
      "6  auth\n",
      "6  publ\n",
      "6  goodread\n",
      "6  dataset.\n",
      "6  gen\n",
      "6  describ\n",
      "6  comp\n",
      "6  scraped\n",
      "6  describ\n",
      "6  us\n",
      "6  combin\n",
      "6  top\n",
      "6  hits,\n",
      "6  mrr,\n",
      "6  ndcg\n",
      "6  evalu\n",
      "6  metrics.\n",
      "6  result\n",
      "6  demonst\n",
      "6  llm-based\n",
      "6  movy\n",
      "6  describ\n",
      "6  gen\n",
      "6  exhibit\n",
      "6  sign\n",
      "6  promise,\n",
      "6  result\n",
      "6  comp\n",
      "6  on\n",
      "6  obtain\n",
      "6  web-scraped\n",
      "6  descriptions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "descripteur_split_lancaster =\"\"\n",
    "\n",
    "for i in range(len(termes_split_lancaster)):\n",
    "    for j in range(len(termes_split_lancaster[i])):\n",
    "        descripteur_split_lancaster = descripteur_split_lancaster + (str(i+1)+ \"  \" +termes_split_lancaster[i][j]+\"\\n\")\n",
    "\n",
    "\n",
    "print(descripteur_split_lancaster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  query\n",
      "1  reform\n",
      "1  qr\n",
      "1  set\n",
      "1  techn\n",
      "1  us\n",
      "1  transform\n",
      "1  us\n",
      "1  origin\n",
      "1  search\n",
      "1  query\n",
      "1  text\n",
      "1  bet\n",
      "1  align\n",
      "1  us\n",
      "1  int\n",
      "1  improv\n",
      "1  search\n",
      "1  expery\n",
      "1  rec\n",
      "1  zero\n",
      "1  shot\n",
      "1  qr\n",
      "1  shown\n",
      "1  prom\n",
      "1  approach\n",
      "1  due\n",
      "1  abl\n",
      "1  exploit\n",
      "1  knowledg\n",
      "1  inh\n",
      "1  larg\n",
      "1  langu\n",
      "1  model\n",
      "1  tak\n",
      "1  inspir\n",
      "1  success\n",
      "1  ensembl\n",
      "1  prompt\n",
      "1  strategies\n",
      "1  benefit\n",
      "1  many\n",
      "1  task\n",
      "1  investig\n",
      "1  help\n",
      "1  improv\n",
      "1  query\n",
      "1  reform\n",
      "1  context\n",
      "1  propos\n",
      "1  ensembl\n",
      "1  bas\n",
      "1  prompt\n",
      "1  techn\n",
      "1  genqrensembl\n",
      "1  lev\n",
      "1  paraphras\n",
      "1  zero\n",
      "1  shot\n",
      "1  instruct\n",
      "1  gen\n",
      "1  multipl\n",
      "1  set\n",
      "1  keyword\n",
      "1  ultim\n",
      "1  improv\n",
      "1  retriev\n",
      "1  perform\n",
      "1  introduc\n",
      "1  post\n",
      "1  retriev\n",
      "1  vary\n",
      "1  genqrensemblerf\n",
      "1  incorp\n",
      "1  pseudo\n",
      "1  relev\n",
      "1  feedback\n",
      "1  evalu\n",
      "1  four\n",
      "1  ir\n",
      "1  benchmark\n",
      "1  find\n",
      "1  genqrensembl\n",
      "1  gen\n",
      "1  bet\n",
      "1  reform\n",
      "1  rel\n",
      "1  ndcg\n",
      "1  10\n",
      "1  improv\n",
      "1  18\n",
      "1  map\n",
      "1  improv\n",
      "1  upto\n",
      "1  24\n",
      "1  prevy\n",
      "1  zero\n",
      "1  shot\n",
      "1  stat\n",
      "1  art\n",
      "1  msmarco\n",
      "1  pass\n",
      "1  rank\n",
      "1  task\n",
      "1  genqrensemblerf\n",
      "1  show\n",
      "1  rel\n",
      "1  gain\n",
      "1  5\n",
      "1  mrr\n",
      "1  us\n",
      "1  pseudo\n",
      "1  relev\n",
      "1  feedback\n",
      "1  9\n",
      "1  ndcg\n",
      "1  10\n",
      "1  us\n",
      "1  relev\n",
      "1  feedback\n",
      "1  docu\n",
      "2  rank\n",
      "2  docu\n",
      "2  us\n",
      "2  larg\n",
      "2  langu\n",
      "2  model\n",
      "2  llms\n",
      "2  direct\n",
      "2  fee\n",
      "2  query\n",
      "2  candid\n",
      "2  docu\n",
      "2  prompt\n",
      "2  interest\n",
      "2  pract\n",
      "2  problem\n",
      "2  howev\n",
      "2  research\n",
      "2  found\n",
      "2  difficult\n",
      "2  outperform\n",
      "2  fin\n",
      "2  tun\n",
      "2  baselin\n",
      "2  rank\n",
      "2  benchmark\n",
      "2  dataset\n",
      "2  analys\n",
      "2  pointw\n",
      "2  listw\n",
      "2  rank\n",
      "2  prompt\n",
      "2  us\n",
      "2  ex\n",
      "2  method\n",
      "2  argu\n",
      "2  shelf\n",
      "2  llms\n",
      "2  ful\n",
      "2  understand\n",
      "2  challeng\n",
      "2  rank\n",
      "2  form\n",
      "2  pap\n",
      "2  propos\n",
      "2  sign\n",
      "2  reduc\n",
      "2  burd\n",
      "2  llms\n",
      "2  us\n",
      "2  new\n",
      "2  techn\n",
      "2  cal\n",
      "2  pairw\n",
      "2  rank\n",
      "2  prompt\n",
      "2  prp\n",
      "2  result\n",
      "2  first\n",
      "2  lit\n",
      "2  achiev\n",
      "2  stat\n",
      "2  art\n",
      "2  rank\n",
      "2  perform\n",
      "2  standard\n",
      "2  benchmark\n",
      "2  us\n",
      "2  mod\n",
      "2  siz\n",
      "2  op\n",
      "2  sourc\n",
      "2  llms\n",
      "2  trec\n",
      "2  dl\n",
      "2  2019\n",
      "2  2020\n",
      "2  prp\n",
      "2  bas\n",
      "2  flan\n",
      "2  ul2\n",
      "2  model\n",
      "2  20b\n",
      "2  paramet\n",
      "2  perform\n",
      "2  fav\n",
      "2  prevy\n",
      "2  best\n",
      "2  approach\n",
      "2  lit\n",
      "2  bas\n",
      "2  blackbox\n",
      "2  commerc\n",
      "2  gpt\n",
      "2  4\n",
      "2  50x\n",
      "2  estim\n",
      "2  model\n",
      "2  siz\n",
      "2  outperform\n",
      "2  llm\n",
      "2  bas\n",
      "2  solv\n",
      "2  instructgpt\n",
      "2  175b\n",
      "2  paramet\n",
      "2  10\n",
      "2  rank\n",
      "2  met\n",
      "2  us\n",
      "2  prompt\n",
      "2  templ\n",
      "2  sev\n",
      "2  beir\n",
      "2  task\n",
      "2  prp\n",
      "2  outperform\n",
      "2  superv\n",
      "2  baselin\n",
      "2  outperform\n",
      "2  blackbox\n",
      "2  commerc\n",
      "2  chatgpt\n",
      "2  solv\n",
      "2  4\n",
      "2  2\n",
      "2  pointw\n",
      "2  llm\n",
      "2  bas\n",
      "2  solv\n",
      "2  10\n",
      "2  av\n",
      "2  ndcg\n",
      "2  10\n",
      "2  furtherm\n",
      "2  propos\n",
      "2  sev\n",
      "2  vary\n",
      "2  prp\n",
      "2  improv\n",
      "2  efficy\n",
      "2  show\n",
      "2  poss\n",
      "2  achiev\n",
      "2  competit\n",
      "2  result\n",
      "2  ev\n",
      "2  linear\n",
      "2  complex\n",
      "3  larg\n",
      "3  langu\n",
      "3  model\n",
      "3  llm\n",
      "3  manifest\n",
      "3  unparallel\n",
      "3  model\n",
      "3  cap\n",
      "3  vary\n",
      "3  task\n",
      "3  e\n",
      "3  g\n",
      "3  mult\n",
      "3  step\n",
      "3  reason\n",
      "3  input\n",
      "3  model\n",
      "3  most\n",
      "3  limit\n",
      "3  plain\n",
      "3  text\n",
      "3  could\n",
      "3  long\n",
      "3  contain\n",
      "3  noisy\n",
      "3  inform\n",
      "3  long\n",
      "3  text\n",
      "3  could\n",
      "3  tak\n",
      "3  long\n",
      "3  tim\n",
      "3  process\n",
      "3  thu\n",
      "3  may\n",
      "3  efficy\n",
      "3  enough\n",
      "3  recommend\n",
      "3  system\n",
      "3  requir\n",
      "3  immedy\n",
      "3  respons\n",
      "3  llm\n",
      "3  bas\n",
      "3  recommend\n",
      "3  model\n",
      "3  us\n",
      "3  item\n",
      "3  id\n",
      "3  us\n",
      "3  fil\n",
      "3  templ\n",
      "3  e\n",
      "3  discret\n",
      "3  prompt\n",
      "3  allow\n",
      "3  model\n",
      "3  understand\n",
      "3  giv\n",
      "3  task\n",
      "3  model\n",
      "3  us\n",
      "3  nee\n",
      "3  extend\n",
      "3  fin\n",
      "3  tun\n",
      "3  bridg\n",
      "3  us\n",
      "3  item\n",
      "3  id\n",
      "3  templ\n",
      "3  word\n",
      "3  unleash\n",
      "3  pow\n",
      "3  llm\n",
      "3  recommend\n",
      "3  address\n",
      "3  problem\n",
      "3  propos\n",
      "3  distil\n",
      "3  discret\n",
      "3  prompt\n",
      "3  spec\n",
      "3  task\n",
      "3  set\n",
      "3  continu\n",
      "3  prompt\n",
      "3  vect\n",
      "3  bridg\n",
      "3  id\n",
      "3  word\n",
      "3  reduc\n",
      "3  inf\n",
      "3  tim\n",
      "3  also\n",
      "3  design\n",
      "3  train\n",
      "3  strategy\n",
      "3  attempt\n",
      "3  improv\n",
      "3  efficy\n",
      "3  train\n",
      "3  model\n",
      "3  expery\n",
      "3  result\n",
      "3  three\n",
      "3  real\n",
      "3  world\n",
      "3  dataset\n",
      "3  demonst\n",
      "3  effect\n",
      "3  prompt\n",
      "3  distil\n",
      "3  pod\n",
      "3  approach\n",
      "3  sequ\n",
      "3  recommend\n",
      "3  top\n",
      "3  n\n",
      "3  recommend\n",
      "3  task\n",
      "3  although\n",
      "3  train\n",
      "3  efficy\n",
      "3  sign\n",
      "3  improv\n",
      "3  improv\n",
      "3  inf\n",
      "3  efficy\n",
      "3  limit\n",
      "3  find\n",
      "3  may\n",
      "3  inspir\n",
      "3  research\n",
      "3  commun\n",
      "3  improv\n",
      "3  inf\n",
      "3  efficy\n",
      "3  llm\n",
      "3  bas\n",
      "3  recommend\n",
      "3  model\n",
      "4  query\n",
      "4  reform\n",
      "4  wel\n",
      "4  known\n",
      "4  problem\n",
      "4  inform\n",
      "4  retriev\n",
      "4  ir\n",
      "4  aim\n",
      "4  enh\n",
      "4  singl\n",
      "4  search\n",
      "4  success\n",
      "4  complet\n",
      "4  rat\n",
      "4  autom\n",
      "4  mod\n",
      "4  us\n",
      "4  input\n",
      "4  query\n",
      "4  rec\n",
      "4  method\n",
      "4  lev\n",
      "4  larg\n",
      "4  langu\n",
      "4  model\n",
      "4  llms\n",
      "4  improv\n",
      "4  query\n",
      "4  reform\n",
      "4  oft\n",
      "4  gen\n",
      "4  limit\n",
      "4  redund\n",
      "4  expand\n",
      "4  pot\n",
      "4  constrain\n",
      "4  effect\n",
      "4  capt\n",
      "4  divers\n",
      "4  int\n",
      "4  pap\n",
      "4  propos\n",
      "4  gencrf\n",
      "4  gen\n",
      "4  clust\n",
      "4  reform\n",
      "4  framework\n",
      "4  capt\n",
      "4  divers\n",
      "4  int\n",
      "4  adapt\n",
      "4  bas\n",
      "4  multipl\n",
      "4  differenty\n",
      "4  wel\n",
      "4  gen\n",
      "4  query\n",
      "4  retriev\n",
      "4  phas\n",
      "4  first\n",
      "4  tim\n",
      "4  gencrf\n",
      "4  lev\n",
      "4  llms\n",
      "4  gen\n",
      "4  vary\n",
      "4  query\n",
      "4  init\n",
      "4  query\n",
      "4  us\n",
      "4  custom\n",
      "4  prompt\n",
      "4  clust\n",
      "4  group\n",
      "4  distinct\n",
      "4  repres\n",
      "4  divers\n",
      "4  int\n",
      "4  furtherm\n",
      "4  framework\n",
      "4  expl\n",
      "4  combin\n",
      "4  divers\n",
      "4  int\n",
      "4  query\n",
      "4  innov\n",
      "4  weight\n",
      "4  aggreg\n",
      "4  strategies\n",
      "4  optim\n",
      "4  retriev\n",
      "4  perform\n",
      "4  cruc\n",
      "4  integr\n",
      "4  novel\n",
      "4  query\n",
      "4  evalu\n",
      "4  reward\n",
      "4  model\n",
      "4  qerm\n",
      "4  refin\n",
      "4  process\n",
      "4  feedback\n",
      "4  loop\n",
      "4  empir\n",
      "4  expery\n",
      "4  beir\n",
      "4  benchmark\n",
      "4  demonst\n",
      "4  gencrf\n",
      "4  achiev\n",
      "4  stat\n",
      "4  art\n",
      "4  perform\n",
      "4  surpass\n",
      "4  prevy\n",
      "4  query\n",
      "4  reform\n",
      "4  sota\n",
      "4  12\n",
      "4  ndcg\n",
      "4  10\n",
      "4  techn\n",
      "4  adapt\n",
      "4  vary\n",
      "4  llms\n",
      "4  sign\n",
      "4  boost\n",
      "4  retriev\n",
      "4  perform\n",
      "4  adv\n",
      "4  field\n",
      "4  inform\n",
      "4  retriev\n",
      "5  sess\n",
      "5  search\n",
      "5  involv\n",
      "5  sery\n",
      "5  interact\n",
      "5  query\n",
      "5  act\n",
      "5  fulfil\n",
      "5  us\n",
      "5  complex\n",
      "5  inform\n",
      "5  nee\n",
      "5  cur\n",
      "5  strategies\n",
      "5  typ\n",
      "5  priorit\n",
      "5  sequ\n",
      "5  model\n",
      "5  deep\n",
      "5  sem\n",
      "5  understand\n",
      "5  overlook\n",
      "5  graph\n",
      "5  structure\n",
      "5  interact\n",
      "5  approach\n",
      "5  foc\n",
      "5  capt\n",
      "5  structural\n",
      "5  inform\n",
      "5  us\n",
      "5  gen\n",
      "5  repres\n",
      "5  docu\n",
      "5  neglect\n",
      "5  word\n",
      "5  level\n",
      "5  sem\n",
      "5  model\n",
      "5  pap\n",
      "5  propos\n",
      "5  symbol\n",
      "5  graph\n",
      "5  rank\n",
      "5  sgr\n",
      "5  aim\n",
      "5  tak\n",
      "5  adv\n",
      "5  text\n",
      "5  bas\n",
      "5  graph\n",
      "5  bas\n",
      "5  approach\n",
      "5  lev\n",
      "5  pow\n",
      "5  rec\n",
      "5  larg\n",
      "5  langu\n",
      "5  model\n",
      "5  llms\n",
      "5  concret\n",
      "5  first\n",
      "5  introduc\n",
      "5  set\n",
      "5  symbol\n",
      "5  gramm\n",
      "5  rul\n",
      "5  convert\n",
      "5  sess\n",
      "5  graph\n",
      "5  text\n",
      "5  allow\n",
      "5  integr\n",
      "5  sess\n",
      "5  hist\n",
      "5  interact\n",
      "5  process\n",
      "5  task\n",
      "5  instruct\n",
      "5  seamless\n",
      "5  input\n",
      "5  llm\n",
      "5  moreov\n",
      "5  giv\n",
      "5  nat\n",
      "5  discrep\n",
      "5  llms\n",
      "5  pre\n",
      "5  train\n",
      "5  text\n",
      "5  corpor\n",
      "5  symbol\n",
      "5  langu\n",
      "5  produc\n",
      "5  us\n",
      "5  graph\n",
      "5  text\n",
      "5  gramm\n",
      "5  object\n",
      "5  enh\n",
      "5  llms\n",
      "5  abl\n",
      "5  capt\n",
      "5  graph\n",
      "5  structures\n",
      "5  within\n",
      "5  text\n",
      "5  form\n",
      "5  achiev\n",
      "5  introduc\n",
      "5  set\n",
      "5  self\n",
      "5  superv\n",
      "5  symbol\n",
      "5  learn\n",
      "5  task\n",
      "5  includ\n",
      "5  link\n",
      "5  predict\n",
      "5  nod\n",
      "5  cont\n",
      "5  gen\n",
      "5  gen\n",
      "5  contrast\n",
      "5  learn\n",
      "5  en\n",
      "5  llms\n",
      "5  capt\n",
      "5  topolog\n",
      "5  inform\n",
      "5  coars\n",
      "5  grain\n",
      "5  fin\n",
      "5  grain\n",
      "5  expery\n",
      "5  result\n",
      "5  comprehend\n",
      "5  analys\n",
      "5  two\n",
      "5  benchmark\n",
      "5  dataset\n",
      "5  aol\n",
      "5  tiangong\n",
      "5  st\n",
      "5  confirm\n",
      "5  supery\n",
      "5  approach\n",
      "5  paradigm\n",
      "5  also\n",
      "5  off\n",
      "5  novel\n",
      "5  effect\n",
      "5  methodolog\n",
      "5  bridg\n",
      "5  gap\n",
      "5  tradit\n",
      "5  search\n",
      "5  strategies\n",
      "5  modern\n",
      "5  llms\n",
      "6  describ\n",
      "6  item\n",
      "6  play\n",
      "6  pivot\n",
      "6  rol\n",
      "6  provid\n",
      "6  cont\n",
      "6  inform\n",
      "6  sum\n",
      "6  capt\n",
      "6  pot\n",
      "6  view\n",
      "6  ess\n",
      "6  recommend\n",
      "6  system\n",
      "6  tradit\n",
      "6  describ\n",
      "6  obtain\n",
      "6  man\n",
      "6  web\n",
      "6  scraping\n",
      "6  techn\n",
      "6  tim\n",
      "6  consum\n",
      "6  suscept\n",
      "6  dat\n",
      "6  inconsist\n",
      "6  rec\n",
      "6  year\n",
      "6  larg\n",
      "6  langu\n",
      "6  model\n",
      "6  llms\n",
      "6  gpt\n",
      "6  3\n",
      "6  5\n",
      "6  op\n",
      "6  sourc\n",
      "6  llms\n",
      "6  lik\n",
      "6  alpac\n",
      "6  emerg\n",
      "6  pow\n",
      "6  tool\n",
      "6  nat\n",
      "6  langu\n",
      "6  process\n",
      "6  task\n",
      "6  pap\n",
      "6  expl\n",
      "6  us\n",
      "6  llms\n",
      "6  gen\n",
      "6  detail\n",
      "6  describ\n",
      "6  item\n",
      "6  conduc\n",
      "6  study\n",
      "6  us\n",
      "6  moviel\n",
      "6  1m\n",
      "6  dataset\n",
      "6  compr\n",
      "6  movy\n",
      "6  titl\n",
      "6  goodread\n",
      "6  dataset\n",
      "6  consist\n",
      "6  nam\n",
      "6  book\n",
      "6  subsequ\n",
      "6  op\n",
      "6  sourc\n",
      "6  llm\n",
      "6  alpac\n",
      "6  prompt\n",
      "6  shot\n",
      "6  prompt\n",
      "6  dataset\n",
      "6  gen\n",
      "6  detail\n",
      "6  movy\n",
      "6  describ\n",
      "6  consid\n",
      "6  multipl\n",
      "6  feat\n",
      "6  lik\n",
      "6  nam\n",
      "6  cast\n",
      "6  direct\n",
      "6  ml\n",
      "6  dataset\n",
      "6  nam\n",
      "6  auth\n",
      "6  publ\n",
      "6  goodread\n",
      "6  dataset\n",
      "6  gen\n",
      "6  describ\n",
      "6  comp\n",
      "6  scraped\n",
      "6  describ\n",
      "6  us\n",
      "6  combin\n",
      "6  top\n",
      "6  hit\n",
      "6  mrr\n",
      "6  ndcg\n",
      "6  evalu\n",
      "6  met\n",
      "6  result\n",
      "6  demonst\n",
      "6  llm\n",
      "6  bas\n",
      "6  movy\n",
      "6  describ\n",
      "6  gen\n",
      "6  exhibit\n",
      "6  sign\n",
      "6  prom\n",
      "6  result\n",
      "6  comp\n",
      "6  on\n",
      "6  obtain\n",
      "6  web\n",
      "6  scraped\n",
      "6  describ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "descripteur_reg_lancaster =\"\"\n",
    "\n",
    "for i in range(len(termes_reg_lancaster)):\n",
    "    for j in range(len(termes_reg_lancaster[i])):\n",
    "        descripteur_reg_lancaster= descripteur_reg_lancaster + (str(i+1)+ \"  \" +termes_reg_lancaster[i][j]+\"\\n\")\n",
    "\n",
    "\n",
    "print(descripteur_reg_lancaster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inverse file creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1\n",
      "Query 4\n",
      "Reformulation(QR) 1\n",
      "set 1\n",
      "set 3\n",
      "set 5\n",
      "techniques 1\n",
      "techniques 4\n",
      "used 1\n",
      "used 2\n",
      "used 6\n",
      "transform 1\n",
      "user’s 1\n",
      "original 1\n",
      "search 1\n",
      "search 4\n",
      "search 5\n",
      "query 1\n",
      "query 2\n",
      "query 4\n",
      "text 1\n",
      "text 3\n",
      "better 1\n",
      "aligns 1\n",
      "intent 1\n",
      "improves 1\n",
      "experience. 1\n",
      "Recently, 1\n",
      "zero-shot 1\n",
      "QR 1\n",
      "shown 1\n",
      "promising 1\n",
      "approach 1\n",
      "approach 2\n",
      "approach 3\n",
      "due 1\n",
      "ability 1\n",
      "ability 5\n",
      "exploit 1\n",
      "knowledge 1\n",
      "inherent 1\n",
      "large 1\n",
      "language 1\n",
      "language 3\n",
      "language 5\n",
      "language 6\n",
      "models. 1\n",
      "models. 3\n",
      "taking 1\n",
      "inspiration 1\n",
      "success 1\n",
      "ensemble 1\n",
      "prompting 1\n",
      "prompting 6\n",
      "strategies 1\n",
      "strategies 4\n",
      "strategies 5\n",
      "benefited 1\n",
      "many 1\n",
      "tasks, 1\n",
      "tasks, 2\n",
      "tasks, 3\n",
      "investigate 1\n",
      "help 1\n",
      "improve 1\n",
      "improve 2\n",
      "improve 3\n",
      "improve 4\n",
      "reformulation. 1\n",
      "context, 1\n",
      "propose 1\n",
      "propose 2\n",
      "propose 3\n",
      "propose 4\n",
      "propose 5\n",
      "based 1\n",
      "based 2\n",
      "based 4\n",
      "technique, 1\n",
      "GenQREnsemble 1\n",
      "leverages 1\n",
      "leverages 4\n",
      "paraphrases 1\n",
      "instruction 1\n",
      "instruction 5\n",
      "generate 1\n",
      "generate 4\n",
      "generate 6\n",
      "multiple 1\n",
      "multiple 4\n",
      "multiple 6\n",
      "sets 1\n",
      "keywords 1\n",
      "ultimately 1\n",
      "improving 1\n",
      "retrieval 1\n",
      "retrieval 4\n",
      "performance. 1\n",
      "introduce 1\n",
      "introduce 5\n",
      "post-retrieval 1\n",
      "variant, 1\n",
      "GenQREnsembleRF 1\n",
      "incorporate 1\n",
      "pseudo 1\n",
      "relevant 1\n",
      "feedback. 1\n",
      "evaluations 1\n",
      "four 1\n",
      "IR 1\n",
      "benchmarks, 1\n",
      "find 1\n",
      "generates 1\n",
      "reformulations 1\n",
      "relative 1\n",
      "nDCG@10 1\n",
      "improvements 1\n",
      "18% 1\n",
      "MAP 1\n",
      "upto 1\n",
      "24% 1\n",
      "previous 1\n",
      "previous 2\n",
      "previous 4\n",
      "state-of-art. 1\n",
      "MSMarco 1\n",
      "Passage 1\n",
      "Ranking 1\n",
      "Ranking 2\n",
      "task, 1\n",
      "task, 3\n",
      "shows 1\n",
      "gains 1\n",
      "5% 1\n",
      "MRR 1\n",
      "using 1\n",
      "using 2\n",
      "using 4\n",
      "using 5\n",
      "using 6\n",
      "pseudo-relevance 1\n",
      "feedback, 1\n",
      "9% 1\n",
      "feedback 1\n",
      "feedback 4\n",
      "documents. 1\n",
      "documents 2\n",
      "Large 2\n",
      "Large 3\n",
      "Large 4\n",
      "Large 5\n",
      "Large 6\n",
      "Language 2\n",
      "Language 4\n",
      "Language 5\n",
      "Language 6\n",
      "Models 2\n",
      "Models 4\n",
      "Models 5\n",
      "Models 6\n",
      "(LLMs) 2\n",
      "(LLMs) 4\n",
      "directly 2\n",
      "feeding 2\n",
      "candidate 2\n",
      "prompt 2\n",
      "prompt 3\n",
      "interesting 2\n",
      "practical 2\n",
      "problem. 2\n",
      "However, 2\n",
      "researchers 2\n",
      "researchers 3\n",
      "found 2\n",
      "difficult 2\n",
      "outperform 2\n",
      "fine-tuned 2\n",
      "baseline 2\n",
      "rankers 2\n",
      "benchmark 2\n",
      "benchmark 4\n",
      "benchmark 5\n",
      "datasets. 2\n",
      "analyze 2\n",
      "pointwise 2\n",
      "listwise 2\n",
      "ranking 2\n",
      "prompts 2\n",
      "existing 2\n",
      "methods 2\n",
      "methods 4\n",
      "argue 2\n",
      "off-the-shelf 2\n",
      "LLMs 2\n",
      "LLMs 4\n",
      "LLMs 5\n",
      "LLMs 6\n",
      "fully 2\n",
      "understand 2\n",
      "understand 3\n",
      "challenging 2\n",
      "formulations. 2\n",
      "paper, 2\n",
      "paper, 4\n",
      "paper, 5\n",
      "paper, 6\n",
      "significantly 2\n",
      "significantly 3\n",
      "significantly 4\n",
      "reduce 2\n",
      "reduce 3\n",
      "burden 2\n",
      "new 2\n",
      "technique 2\n",
      "called 2\n",
      "Pairwise 2\n",
      "Prompting 2\n",
      "(PRP). 2\n",
      "results 2\n",
      "results 3\n",
      "results 5\n",
      "results 6\n",
      "first 2\n",
      "first 4\n",
      "first 5\n",
      "literature 2\n",
      "achieve 2\n",
      "achieve 5\n",
      "state-of-the-art 2\n",
      "state-of-the-art 4\n",
      "performance 2\n",
      "performance 4\n",
      "standard 2\n",
      "benchmarks 2\n",
      "moderate-sized 2\n",
      "open-sourced 2\n",
      "open-sourced 6\n",
      "LLMs. 2\n",
      "LLMs. 5\n",
      "TREC-DL 2\n",
      "2019 2\n",
      "2020, 2\n",
      "PRP 2\n",
      "Flan-UL2 2\n",
      "model 2\n",
      "20B 2\n",
      "parameters 2\n",
      "performs 2\n",
      "favorably 2\n",
      "best 2\n",
      "literature, 2\n",
      "blackbox 2\n",
      "commercial 2\n",
      "GPT-4 2\n",
      "50x 2\n",
      "(estimated) 2\n",
      "size, 2\n",
      "outperforming 2\n",
      "LLM-based 2\n",
      "LLM-based 3\n",
      "LLM-based 6\n",
      "solutions, 2\n",
      "InstructGPT 2\n",
      "175B 2\n",
      "parameters, 2\n",
      "10% 2\n",
      "metrics. 2\n",
      "metrics. 6\n",
      "template 2\n",
      "template 3\n",
      "seven 2\n",
      "BEIR 2\n",
      "BEIR 4\n",
      "outperforms 2\n",
      "supervised 2\n",
      "baselines 2\n",
      "ChatGPT 2\n",
      "solution 2\n",
      "4.2% 2\n",
      "solutions 2\n",
      "average 2\n",
      "NDCG@10. 2\n",
      "Furthermore, 2\n",
      "Furthermore, 4\n",
      "several 2\n",
      "variants 2\n",
      "efficiency 2\n",
      "efficiency 3\n",
      "show 2\n",
      "possible 2\n",
      "competitive 2\n",
      "even 2\n",
      "linear 2\n",
      "complexity 2\n",
      "models 3\n",
      "(LLM) 3\n",
      "manifested 3\n",
      "unparalleled 3\n",
      "modeling 3\n",
      "modeling 5\n",
      "capability 3\n",
      "various 3\n",
      "various 4\n",
      "e.g., 3\n",
      "multi-step 3\n",
      "reasoning, 3\n",
      "input 3\n",
      "input 4\n",
      "mostly 3\n",
      "limited 3\n",
      "limited 4\n",
      "plain 3\n",
      "text, 3\n",
      "could 3\n",
      "long 3\n",
      "contain 3\n",
      "noisy 3\n",
      "information. 3\n",
      "Long 3\n",
      "take 3\n",
      "take 5\n",
      "time 3\n",
      "process, 3\n",
      "process, 5\n",
      "thus 3\n",
      "may 3\n",
      "efficient 3\n",
      "enough 3\n",
      "recommender 3\n",
      "systems 3\n",
      "require 3\n",
      "immediate 3\n",
      "response. 3\n",
      "recommendation 3\n",
      "recommendation 6\n",
      "models, 3\n",
      "user 3\n",
      "item 3\n",
      "item 6\n",
      "IDs 3\n",
      "usually 3\n",
      "filled 3\n",
      "(i.e., 3\n",
      "discrete 3\n",
      "prompt) 3\n",
      "allow 3\n",
      "given 3\n",
      "given 5\n",
      "need 3\n",
      "extensive 3\n",
      "fine-tuning 3\n",
      "bridge 3\n",
      "user/item 3\n",
      "words 3\n",
      "unleash 3\n",
      "power 3\n",
      "power 5\n",
      "LLM 3\n",
      "recommendation. 3\n",
      "address 3\n",
      "problems, 3\n",
      "distill 3\n",
      "specific 3\n",
      "task 3\n",
      "task 5\n",
      "continuous 3\n",
      "vectors 3\n",
      "inference 3\n",
      "time. 3\n",
      "time. 4\n",
      "also 3\n",
      "also 5\n",
      "design 3\n",
      "training 3\n",
      "strategy 3\n",
      "attempt 3\n",
      "Experimental 3\n",
      "three 3\n",
      "real-world 3\n",
      "datasets 3\n",
      "demonstrate 3\n",
      "demonstrate 4\n",
      "effectiveness 3\n",
      "effectiveness 4\n",
      "PrOmpt 3\n",
      "Distillation 3\n",
      "(POD) 3\n",
      "sequential 3\n",
      "sequential 5\n",
      "top-N 3\n",
      "tasks. 3\n",
      "tasks. 6\n",
      "Although 3\n",
      "improved, 3\n",
      "improvement 3\n",
      "limited. 3\n",
      "finding 3\n",
      "inspire 3\n",
      "community 3\n",
      "reformulation 4\n",
      "well-known 4\n",
      "problem 4\n",
      "Information 4\n",
      "Retrieval 4\n",
      "(IR) 4\n",
      "aimed 4\n",
      "enhancing 4\n",
      "single 4\n",
      "successful 4\n",
      "completion 4\n",
      "rate 4\n",
      "automatically 4\n",
      "modifying 4\n",
      "user's 4\n",
      "user's 5\n",
      "query. 4\n",
      "Recent 4\n",
      "leverage 4\n",
      "reformulation, 4\n",
      "often 4\n",
      "redundant 4\n",
      "expansions, 4\n",
      "potentially 4\n",
      "constraining 4\n",
      "capturing 4\n",
      "capturing 5\n",
      "diverse 4\n",
      "intents. 4\n",
      "GenCRF: 4\n",
      "Generative 4\n",
      "Clustering 4\n",
      "Reformulation 4\n",
      "Framework 4\n",
      "capture 4\n",
      "capture 5\n",
      "intentions 4\n",
      "adaptively 4\n",
      "differentiated, 4\n",
      "well-generated 4\n",
      "queries 4\n",
      "queries 5\n",
      "phase 4\n",
      "GenCRF 4\n",
      "variable 4\n",
      "initial 4\n",
      "customized 4\n",
      "prompts, 4\n",
      "clusters 4\n",
      "groups 4\n",
      "distinctly 4\n",
      "represent 4\n",
      "framework 4\n",
      "explores 4\n",
      "combine 4\n",
      "intents 4\n",
      "innovative 4\n",
      "weighted 4\n",
      "aggregation 4\n",
      "optimize 4\n",
      "crucially 4\n",
      "integrates 4\n",
      "novel 4\n",
      "novel 5\n",
      "Evaluation 4\n",
      "Rewarding 4\n",
      "Model 4\n",
      "(QERM) 4\n",
      "refine 4\n",
      "process 4\n",
      "loops. 4\n",
      "Empirical 4\n",
      "experiments 4\n",
      "achieves 4\n",
      "performance, 4\n",
      "surpassing 4\n",
      "SOTAs 4\n",
      "12% 4\n",
      "nDCG@10. 4\n",
      "adapted 4\n",
      "LLMs, 4\n",
      "boosting 4\n",
      "retriever 4\n",
      "advancing 4\n",
      "field 4\n",
      "Retrieval. 4\n",
      "Session 5\n",
      "involves 5\n",
      "series 5\n",
      "interactive 5\n",
      "actions 5\n",
      "fulfill 5\n",
      "complex 5\n",
      "information 5\n",
      "need. 5\n",
      "Current 5\n",
      "typically 5\n",
      "prioritize 5\n",
      "deep 5\n",
      "semantic 5\n",
      "understanding, 5\n",
      "overlooking 5\n",
      "graph 5\n",
      "structure 5\n",
      "interactions. 5\n",
      "approaches 5\n",
      "focus 5\n",
      "structural 5\n",
      "information, 5\n",
      "use 5\n",
      "use 6\n",
      "generalized 5\n",
      "representation 5\n",
      "documents, 5\n",
      "neglecting 5\n",
      "word-level 5\n",
      "modeling. 5\n",
      "Symbolic 5\n",
      "Graph 5\n",
      "Ranker 5\n",
      "(SGR), 5\n",
      "aims 5\n",
      "advantage 5\n",
      "text-based 5\n",
      "graph-based 5\n",
      "leveraging 5\n",
      "recent 5\n",
      "recent 6\n",
      "(LLMs). 5\n",
      "Concretely, 5\n",
      "symbolic 5\n",
      "grammar 5\n",
      "rules 5\n",
      "convert 5\n",
      "session 5\n",
      "text. 5\n",
      "allows 5\n",
      "integrating 5\n",
      "history, 5\n",
      "interaction 5\n",
      "seamlessly 5\n",
      "inputs 5\n",
      "LLM. 5\n",
      "Moreover, 5\n",
      "natural 5\n",
      "natural 6\n",
      "discrepancy 5\n",
      "pre-trained 5\n",
      "textual 5\n",
      "corpora, 5\n",
      "produce 5\n",
      "graph-to-text 5\n",
      "grammar, 5\n",
      "objective 5\n",
      "enhance 5\n",
      "LLMs' 5\n",
      "structures 5\n",
      "within 5\n",
      "format. 5\n",
      "this, 5\n",
      "self-supervised 5\n",
      "learning 5\n",
      "tasks 5\n",
      "including 5\n",
      "link 5\n",
      "prediction, 5\n",
      "node 5\n",
      "content 5\n",
      "generation, 5\n",
      "generative 5\n",
      "contrastive 5\n",
      "learning, 5\n",
      "enable 5\n",
      "topological 5\n",
      "coarse-grained 5\n",
      "fine-grained. 5\n",
      "Experiment 5\n",
      "comprehensive 5\n",
      "analysis 5\n",
      "two 5\n",
      "datasets, 5\n",
      "AOL 5\n",
      "Tiangong-ST, 5\n",
      "confirm 5\n",
      "superiority 5\n",
      "approach. 5\n",
      "paradigm 5\n",
      "offers 5\n",
      "effective 5\n",
      "methodology 5\n",
      "bridges 5\n",
      "gap 5\n",
      "traditional 5\n",
      "modern 5\n",
      "description 6\n",
      "plays 6\n",
      "pivotal 6\n",
      "role 6\n",
      "providing 6\n",
      "concise 6\n",
      "informative 6\n",
      "summaries 6\n",
      "captivate 6\n",
      "potential 6\n",
      "viewers 6\n",
      "essential 6\n",
      "systems. 6\n",
      "Traditionally, 6\n",
      "descriptions 6\n",
      "obtained 6\n",
      "manual 6\n",
      "web 6\n",
      "scraping 6\n",
      "techniques, 6\n",
      "time-consuming 6\n",
      "susceptible 6\n",
      "data 6\n",
      "inconsistencies. 6\n",
      "years, 6\n",
      "(LLMs), 6\n",
      "GPT-3.5, 6\n",
      "open 6\n",
      "source 6\n",
      "like 6\n",
      "Alpaca 6\n",
      "emerged 6\n",
      "powerful 6\n",
      "tools 6\n",
      "processing 6\n",
      "explored 6\n",
      "detailed 6\n",
      "items. 6\n",
      "conduct 6\n",
      "study, 6\n",
      "MovieLens 6\n",
      "1M 6\n",
      "dataset 6\n",
      "comprising 6\n",
      "movie 6\n",
      "titles 6\n",
      "Goodreads 6\n",
      "Dataset 6\n",
      "consisting 6\n",
      "names 6\n",
      "books 6\n",
      "subsequently, 6\n",
      "LLM, 6\n",
      "Alpaca, 6\n",
      "prompted 6\n",
      "few-shot 6\n",
      "considering 6\n",
      "features 6\n",
      "cast 6\n",
      "directors 6\n",
      "ML 6\n",
      "author 6\n",
      "publisher 6\n",
      "dataset. 6\n",
      "generated 6\n",
      "compared 6\n",
      "scraped 6\n",
      "combination 6\n",
      "Top 6\n",
      "Hits, 6\n",
      "MRR, 6\n",
      "NDCG 6\n",
      "evaluation 6\n",
      "demonstrated 6\n",
      "generation 6\n",
      "exhibits 6\n",
      "significant 6\n",
      "promise, 6\n",
      "comparable 6\n",
      "ones 6\n",
      "web-scraped 6\n",
      "descriptions. 6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inverse_split = {}\n",
    "\n",
    "\n",
    "for i in range(len(termes_split)):\n",
    "    for term in termes_split[i]:\n",
    "        if term not in inverse_split:\n",
    "            inverse_split[term] = set()  \n",
    " \n",
    "        inverse_split[term].add(i + 1)\n",
    "\n",
    "\n",
    "inverse_split_output  = \"\"\n",
    "for term, docs in inverse_split.items():\n",
    "    for doc in sorted(docs):\n",
    "        inverse_split_output += f\"{term} {doc}\\n\"\n",
    "\n",
    "\n",
    "print(inverse_split_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1\n",
      "Query 4\n",
      "Reformulation 1\n",
      "Reformulation 4\n",
      "QR 1\n",
      "set 1\n",
      "set 3\n",
      "set 5\n",
      "techniques 1\n",
      "techniques 4\n",
      "techniques 6\n",
      "used 1\n",
      "used 2\n",
      "used 6\n",
      "transform 1\n",
      "user 1\n",
      "user 3\n",
      "user 4\n",
      "user 5\n",
      "original 1\n",
      "search 1\n",
      "search 4\n",
      "search 5\n",
      "query 1\n",
      "query 2\n",
      "query 4\n",
      "text 1\n",
      "text 3\n",
      "text 5\n",
      "better 1\n",
      "aligns 1\n",
      "intent 1\n",
      "improves 1\n",
      "experience 1\n",
      "Recently 1\n",
      "zero 1\n",
      "shot 1\n",
      "shot 6\n",
      "shown 1\n",
      "promising 1\n",
      "approach 1\n",
      "approach 2\n",
      "approach 3\n",
      "approach 5\n",
      "due 1\n",
      "ability 1\n",
      "ability 5\n",
      "exploit 1\n",
      "knowledge 1\n",
      "inherent 1\n",
      "large 1\n",
      "language 1\n",
      "language 3\n",
      "language 5\n",
      "language 6\n",
      "models 1\n",
      "models 3\n",
      "taking 1\n",
      "inspiration 1\n",
      "success 1\n",
      "ensemble 1\n",
      "prompting 1\n",
      "prompting 6\n",
      "strategies 1\n",
      "strategies 4\n",
      "strategies 5\n",
      "benefited 1\n",
      "many 1\n",
      "tasks 1\n",
      "tasks 2\n",
      "tasks 3\n",
      "tasks 5\n",
      "tasks 6\n",
      "investigate 1\n",
      "help 1\n",
      "improve 1\n",
      "improve 2\n",
      "improve 3\n",
      "improve 4\n",
      "reformulation 1\n",
      "reformulation 4\n",
      "context 1\n",
      "propose 1\n",
      "propose 2\n",
      "propose 3\n",
      "propose 4\n",
      "propose 5\n",
      "based 1\n",
      "based 2\n",
      "based 3\n",
      "based 4\n",
      "based 5\n",
      "based 6\n",
      "technique 1\n",
      "technique 2\n",
      "GenQREnsemble 1\n",
      "leverages 1\n",
      "leverages 4\n",
      "paraphrases 1\n",
      "instruction 1\n",
      "instruction 5\n",
      "generate 1\n",
      "generate 4\n",
      "generate 6\n",
      "multiple 1\n",
      "multiple 4\n",
      "multiple 6\n",
      "sets 1\n",
      "keywords 1\n",
      "ultimately 1\n",
      "improving 1\n",
      "retrieval 1\n",
      "retrieval 4\n",
      "performance 1\n",
      "performance 2\n",
      "performance 4\n",
      "introduce 1\n",
      "introduce 5\n",
      "post 1\n",
      "variant 1\n",
      "GenQREnsembleRF 1\n",
      "incorporate 1\n",
      "pseudo 1\n",
      "relevant 1\n",
      "feedback 1\n",
      "feedback 4\n",
      "evaluations 1\n",
      "four 1\n",
      "IR 1\n",
      "IR 4\n",
      "benchmarks 1\n",
      "benchmarks 2\n",
      "find 1\n",
      "generates 1\n",
      "reformulations 1\n",
      "relative 1\n",
      "nDCG 1\n",
      "nDCG 4\n",
      "10 1\n",
      "10 2\n",
      "10 4\n",
      "improvements 1\n",
      "18 1\n",
      "MAP 1\n",
      "upto 1\n",
      "24 1\n",
      "previous 1\n",
      "previous 2\n",
      "previous 4\n",
      "state 1\n",
      "state 2\n",
      "state 4\n",
      "art 1\n",
      "art 2\n",
      "art 4\n",
      "MSMarco 1\n",
      "Passage 1\n",
      "Ranking 1\n",
      "Ranking 2\n",
      "task 1\n",
      "task 3\n",
      "task 5\n",
      "shows 1\n",
      "gains 1\n",
      "5 1\n",
      "5 6\n",
      "MRR 1\n",
      "MRR 6\n",
      "using 1\n",
      "using 2\n",
      "using 4\n",
      "using 5\n",
      "using 6\n",
      "relevance 1\n",
      "9 1\n",
      "documents 1\n",
      "documents 2\n",
      "documents 5\n",
      "Large 2\n",
      "Large 3\n",
      "Large 4\n",
      "Large 5\n",
      "Large 6\n",
      "Language 2\n",
      "Language 4\n",
      "Language 5\n",
      "Language 6\n",
      "Models 2\n",
      "Models 4\n",
      "Models 5\n",
      "Models 6\n",
      "LLMs 2\n",
      "LLMs 4\n",
      "LLMs 5\n",
      "LLMs 6\n",
      "directly 2\n",
      "feeding 2\n",
      "candidate 2\n",
      "prompt 2\n",
      "prompt 3\n",
      "interesting 2\n",
      "practical 2\n",
      "problem 2\n",
      "problem 4\n",
      "However 2\n",
      "researchers 2\n",
      "researchers 3\n",
      "found 2\n",
      "difficult 2\n",
      "outperform 2\n",
      "fine 2\n",
      "fine 3\n",
      "fine 5\n",
      "tuned 2\n",
      "baseline 2\n",
      "rankers 2\n",
      "benchmark 2\n",
      "benchmark 4\n",
      "benchmark 5\n",
      "datasets 2\n",
      "datasets 3\n",
      "datasets 5\n",
      "analyze 2\n",
      "pointwise 2\n",
      "listwise 2\n",
      "ranking 2\n",
      "prompts 2\n",
      "prompts 4\n",
      "existing 2\n",
      "methods 2\n",
      "methods 4\n",
      "argue 2\n",
      "shelf 2\n",
      "fully 2\n",
      "understand 2\n",
      "understand 3\n",
      "challenging 2\n",
      "formulations 2\n",
      "paper 2\n",
      "paper 4\n",
      "paper 5\n",
      "paper 6\n",
      "significantly 2\n",
      "significantly 3\n",
      "significantly 4\n",
      "reduce 2\n",
      "reduce 3\n",
      "burden 2\n",
      "new 2\n",
      "called 2\n",
      "Pairwise 2\n",
      "Prompting 2\n",
      "PRP 2\n",
      "results 2\n",
      "results 3\n",
      "results 5\n",
      "results 6\n",
      "first 2\n",
      "first 4\n",
      "first 5\n",
      "literature 2\n",
      "achieve 2\n",
      "achieve 5\n",
      "standard 2\n",
      "moderate 2\n",
      "sized 2\n",
      "open 2\n",
      "open 6\n",
      "sourced 2\n",
      "sourced 6\n",
      "TREC 2\n",
      "DL 2\n",
      "2019 2\n",
      "2020 2\n",
      "Flan 2\n",
      "UL2 2\n",
      "model 2\n",
      "20B 2\n",
      "parameters 2\n",
      "performs 2\n",
      "favorably 2\n",
      "best 2\n",
      "blackbox 2\n",
      "commercial 2\n",
      "GPT 2\n",
      "GPT 6\n",
      "4 2\n",
      "50x 2\n",
      "estimated 2\n",
      "size 2\n",
      "outperforming 2\n",
      "LLM 2\n",
      "LLM 3\n",
      "LLM 5\n",
      "LLM 6\n",
      "solutions 2\n",
      "InstructGPT 2\n",
      "175B 2\n",
      "metrics 2\n",
      "metrics 6\n",
      "template 2\n",
      "template 3\n",
      "seven 2\n",
      "BEIR 2\n",
      "BEIR 4\n",
      "outperforms 2\n",
      "supervised 2\n",
      "supervised 5\n",
      "baselines 2\n",
      "ChatGPT 2\n",
      "solution 2\n",
      "2 2\n",
      "average 2\n",
      "NDCG 2\n",
      "NDCG 6\n",
      "Furthermore 2\n",
      "Furthermore 4\n",
      "several 2\n",
      "variants 2\n",
      "efficiency 2\n",
      "efficiency 3\n",
      "show 2\n",
      "possible 2\n",
      "competitive 2\n",
      "even 2\n",
      "linear 2\n",
      "complexity 2\n",
      "manifested 3\n",
      "unparalleled 3\n",
      "modeling 3\n",
      "modeling 5\n",
      "capability 3\n",
      "various 3\n",
      "various 4\n",
      "e 3\n",
      "g 3\n",
      "multi 3\n",
      "step 3\n",
      "reasoning 3\n",
      "input 3\n",
      "input 4\n",
      "mostly 3\n",
      "limited 3\n",
      "limited 4\n",
      "plain 3\n",
      "could 3\n",
      "long 3\n",
      "contain 3\n",
      "noisy 3\n",
      "information 3\n",
      "information 5\n",
      "Long 3\n",
      "take 3\n",
      "take 5\n",
      "time 3\n",
      "time 4\n",
      "time 6\n",
      "process 3\n",
      "process 4\n",
      "process 5\n",
      "thus 3\n",
      "may 3\n",
      "efficient 3\n",
      "enough 3\n",
      "recommender 3\n",
      "systems 3\n",
      "systems 6\n",
      "require 3\n",
      "immediate 3\n",
      "response 3\n",
      "recommendation 3\n",
      "recommendation 6\n",
      "item 3\n",
      "item 6\n",
      "IDs 3\n",
      "usually 3\n",
      "filled 3\n",
      "discrete 3\n",
      "allow 3\n",
      "given 3\n",
      "given 5\n",
      "need 3\n",
      "need 5\n",
      "extensive 3\n",
      "tuning 3\n",
      "bridge 3\n",
      "words 3\n",
      "unleash 3\n",
      "power 3\n",
      "power 5\n",
      "address 3\n",
      "problems 3\n",
      "distill 3\n",
      "specific 3\n",
      "continuous 3\n",
      "vectors 3\n",
      "inference 3\n",
      "also 3\n",
      "also 5\n",
      "design 3\n",
      "training 3\n",
      "strategy 3\n",
      "attempt 3\n",
      "Experimental 3\n",
      "three 3\n",
      "real 3\n",
      "world 3\n",
      "demonstrate 3\n",
      "demonstrate 4\n",
      "effectiveness 3\n",
      "effectiveness 4\n",
      "PrOmpt 3\n",
      "Distillation 3\n",
      "POD 3\n",
      "sequential 3\n",
      "sequential 5\n",
      "top 3\n",
      "N 3\n",
      "Although 3\n",
      "improved 3\n",
      "improvement 3\n",
      "finding 3\n",
      "inspire 3\n",
      "community 3\n",
      "well 4\n",
      "known 4\n",
      "Information 4\n",
      "Retrieval 4\n",
      "aimed 4\n",
      "enhancing 4\n",
      "single 4\n",
      "successful 4\n",
      "completion 4\n",
      "rate 4\n",
      "automatically 4\n",
      "modifying 4\n",
      "Recent 4\n",
      "leverage 4\n",
      "often 4\n",
      "redundant 4\n",
      "expansions 4\n",
      "potentially 4\n",
      "constraining 4\n",
      "capturing 4\n",
      "capturing 5\n",
      "diverse 4\n",
      "intents 4\n",
      "GenCRF 4\n",
      "Generative 4\n",
      "Clustering 4\n",
      "Framework 4\n",
      "capture 4\n",
      "capture 5\n",
      "intentions 4\n",
      "adaptively 4\n",
      "differentiated 4\n",
      "generated 4\n",
      "generated 6\n",
      "queries 4\n",
      "queries 5\n",
      "phase 4\n",
      "variable 4\n",
      "initial 4\n",
      "customized 4\n",
      "clusters 4\n",
      "groups 4\n",
      "distinctly 4\n",
      "represent 4\n",
      "framework 4\n",
      "explores 4\n",
      "combine 4\n",
      "innovative 4\n",
      "weighted 4\n",
      "aggregation 4\n",
      "optimize 4\n",
      "crucially 4\n",
      "integrates 4\n",
      "novel 4\n",
      "novel 5\n",
      "Evaluation 4\n",
      "Rewarding 4\n",
      "Model 4\n",
      "QERM 4\n",
      "refine 4\n",
      "loops 4\n",
      "Empirical 4\n",
      "experiments 4\n",
      "achieves 4\n",
      "surpassing 4\n",
      "SOTAs 4\n",
      "12 4\n",
      "adapted 4\n",
      "boosting 4\n",
      "retriever 4\n",
      "advancing 4\n",
      "field 4\n",
      "Session 5\n",
      "involves 5\n",
      "series 5\n",
      "interactive 5\n",
      "actions 5\n",
      "fulfill 5\n",
      "complex 5\n",
      "Current 5\n",
      "typically 5\n",
      "prioritize 5\n",
      "deep 5\n",
      "semantic 5\n",
      "understanding 5\n",
      "overlooking 5\n",
      "graph 5\n",
      "structure 5\n",
      "interactions 5\n",
      "approaches 5\n",
      "focus 5\n",
      "structural 5\n",
      "use 5\n",
      "use 6\n",
      "generalized 5\n",
      "representation 5\n",
      "neglecting 5\n",
      "word 5\n",
      "level 5\n",
      "Symbolic 5\n",
      "Graph 5\n",
      "Ranker 5\n",
      "SGR 5\n",
      "aims 5\n",
      "advantage 5\n",
      "leveraging 5\n",
      "recent 5\n",
      "recent 6\n",
      "Concretely 5\n",
      "symbolic 5\n",
      "grammar 5\n",
      "rules 5\n",
      "convert 5\n",
      "session 5\n",
      "allows 5\n",
      "integrating 5\n",
      "history 5\n",
      "interaction 5\n",
      "seamlessly 5\n",
      "inputs 5\n",
      "Moreover 5\n",
      "natural 5\n",
      "natural 6\n",
      "discrepancy 5\n",
      "pre 5\n",
      "trained 5\n",
      "textual 5\n",
      "corpora 5\n",
      "produce 5\n",
      "objective 5\n",
      "enhance 5\n",
      "structures 5\n",
      "within 5\n",
      "format 5\n",
      "self 5\n",
      "learning 5\n",
      "including 5\n",
      "link 5\n",
      "prediction 5\n",
      "node 5\n",
      "content 5\n",
      "generation 5\n",
      "generation 6\n",
      "generative 5\n",
      "contrastive 5\n",
      "enable 5\n",
      "topological 5\n",
      "coarse 5\n",
      "grained 5\n",
      "Experiment 5\n",
      "comprehensive 5\n",
      "analysis 5\n",
      "two 5\n",
      "AOL 5\n",
      "Tiangong 5\n",
      "ST 5\n",
      "confirm 5\n",
      "superiority 5\n",
      "paradigm 5\n",
      "offers 5\n",
      "effective 5\n",
      "methodology 5\n",
      "bridges 5\n",
      "gap 5\n",
      "traditional 5\n",
      "modern 5\n",
      "description 6\n",
      "plays 6\n",
      "pivotal 6\n",
      "role 6\n",
      "providing 6\n",
      "concise 6\n",
      "informative 6\n",
      "summaries 6\n",
      "captivate 6\n",
      "potential 6\n",
      "viewers 6\n",
      "essential 6\n",
      "Traditionally 6\n",
      "descriptions 6\n",
      "obtained 6\n",
      "manual 6\n",
      "web 6\n",
      "scraping 6\n",
      "consuming 6\n",
      "susceptible 6\n",
      "data 6\n",
      "inconsistencies 6\n",
      "years 6\n",
      "3 6\n",
      "source 6\n",
      "like 6\n",
      "Alpaca 6\n",
      "emerged 6\n",
      "powerful 6\n",
      "tools 6\n",
      "processing 6\n",
      "explored 6\n",
      "detailed 6\n",
      "items 6\n",
      "conduct 6\n",
      "study 6\n",
      "MovieLens 6\n",
      "1M 6\n",
      "dataset 6\n",
      "comprising 6\n",
      "movie 6\n",
      "titles 6\n",
      "Goodreads 6\n",
      "Dataset 6\n",
      "consisting 6\n",
      "names 6\n",
      "books 6\n",
      "subsequently 6\n",
      "prompted 6\n",
      "considering 6\n",
      "features 6\n",
      "cast 6\n",
      "directors 6\n",
      "ML 6\n",
      "author 6\n",
      "publisher 6\n",
      "compared 6\n",
      "scraped 6\n",
      "combination 6\n",
      "Top 6\n",
      "Hits 6\n",
      "evaluation 6\n",
      "demonstrated 6\n",
      "exhibits 6\n",
      "significant 6\n",
      "promise 6\n",
      "comparable 6\n",
      "ones 6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inverse_reg = {}\n",
    "\n",
    "\n",
    "for i in range(len(termes_reg)):\n",
    "    for term in termes_reg[i]:\n",
    "        if term not in inverse_reg:\n",
    "            inverse_reg[term] = set()  \n",
    " \n",
    "        inverse_reg[term].add(i + 1)\n",
    "\n",
    "\n",
    "inverse_reg_output = \"\"\n",
    "for term, docs in inverse_reg.items():\n",
    "    for doc in sorted(docs):\n",
    "        inverse_reg_output += f\"{term} {doc}\\n\"\n",
    "\n",
    "\n",
    "print(inverse_reg_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queri 1\n",
      "queri 2\n",
      "queri 4\n",
      "queri 5\n",
      "reformulation(qr) 1\n",
      "set 1\n",
      "set 3\n",
      "set 5\n",
      "techniqu 1\n",
      "techniqu 2\n",
      "techniqu 4\n",
      "use 1\n",
      "use 2\n",
      "use 4\n",
      "use 5\n",
      "use 6\n",
      "transform 1\n",
      "user’ 1\n",
      "origin 1\n",
      "search 1\n",
      "search 4\n",
      "search 5\n",
      "text 1\n",
      "text 3\n",
      "better 1\n",
      "align 1\n",
      "intent 1\n",
      "intent 4\n",
      "improv 1\n",
      "improv 2\n",
      "improv 3\n",
      "improv 4\n",
      "experience. 1\n",
      "recently, 1\n",
      "zero-shot 1\n",
      "qr 1\n",
      "shown 1\n",
      "promis 1\n",
      "approach 1\n",
      "approach 2\n",
      "approach 3\n",
      "approach 5\n",
      "due 1\n",
      "abil 1\n",
      "abil 5\n",
      "exploit 1\n",
      "knowledg 1\n",
      "inher 1\n",
      "larg 1\n",
      "larg 2\n",
      "larg 3\n",
      "larg 4\n",
      "larg 5\n",
      "larg 6\n",
      "languag 1\n",
      "languag 2\n",
      "languag 3\n",
      "languag 4\n",
      "languag 5\n",
      "languag 6\n",
      "models. 1\n",
      "models. 3\n",
      "take 1\n",
      "take 3\n",
      "take 5\n",
      "inspir 1\n",
      "inspir 3\n",
      "success 1\n",
      "success 4\n",
      "ensembl 1\n",
      "prompt 1\n",
      "prompt 2\n",
      "prompt 3\n",
      "prompt 6\n",
      "strategi 1\n",
      "strategi 3\n",
      "strategi 4\n",
      "strategi 5\n",
      "benefit 1\n",
      "mani 1\n",
      "tasks, 1\n",
      "tasks, 2\n",
      "tasks, 3\n",
      "investig 1\n",
      "help 1\n",
      "reformulation. 1\n",
      "context, 1\n",
      "propos 1\n",
      "propos 2\n",
      "propos 3\n",
      "propos 4\n",
      "propos 5\n",
      "base 1\n",
      "base 2\n",
      "base 4\n",
      "technique, 1\n",
      "genqrensembl 1\n",
      "leverag 1\n",
      "leverag 4\n",
      "leverag 5\n",
      "paraphras 1\n",
      "instruct 1\n",
      "instruct 5\n",
      "gener 1\n",
      "gener 4\n",
      "gener 5\n",
      "gener 6\n",
      "multipl 1\n",
      "multipl 4\n",
      "multipl 6\n",
      "keyword 1\n",
      "ultim 1\n",
      "retriev 1\n",
      "retriev 4\n",
      "performance. 1\n",
      "introduc 1\n",
      "introduc 5\n",
      "post-retriev 1\n",
      "variant, 1\n",
      "genqrensemblerf 1\n",
      "incorpor 1\n",
      "pseudo 1\n",
      "relev 1\n",
      "feedback. 1\n",
      "evalu 1\n",
      "evalu 4\n",
      "evalu 6\n",
      "four 1\n",
      "ir 1\n",
      "benchmarks, 1\n",
      "find 1\n",
      "find 3\n",
      "reformul 1\n",
      "reformul 4\n",
      "rel 1\n",
      "ndcg@10 1\n",
      "18% 1\n",
      "map 1\n",
      "upto 1\n",
      "24% 1\n",
      "previou 1\n",
      "previou 2\n",
      "previou 4\n",
      "state-of-art. 1\n",
      "msmarco 1\n",
      "passag 1\n",
      "rank 1\n",
      "rank 2\n",
      "task, 1\n",
      "task, 3\n",
      "show 1\n",
      "show 2\n",
      "gain 1\n",
      "5% 1\n",
      "mrr 1\n",
      "pseudo-relev 1\n",
      "feedback, 1\n",
      "9% 1\n",
      "feedback 1\n",
      "feedback 4\n",
      "documents. 1\n",
      "document 2\n",
      "model 2\n",
      "model 3\n",
      "model 4\n",
      "model 5\n",
      "model 6\n",
      "(llms) 2\n",
      "(llms) 4\n",
      "directli 2\n",
      "feed 2\n",
      "candid 2\n",
      "interest 2\n",
      "practic 2\n",
      "problem. 2\n",
      "however, 2\n",
      "research 2\n",
      "research 3\n",
      "found 2\n",
      "difficult 2\n",
      "outperform 2\n",
      "fine-tun 2\n",
      "fine-tun 3\n",
      "baselin 2\n",
      "ranker 2\n",
      "ranker 5\n",
      "benchmark 2\n",
      "benchmark 4\n",
      "benchmark 5\n",
      "datasets. 2\n",
      "analyz 2\n",
      "pointwis 2\n",
      "listwis 2\n",
      "exist 2\n",
      "method 2\n",
      "method 4\n",
      "argu 2\n",
      "off-the-shelf 2\n",
      "llm 2\n",
      "llm 3\n",
      "llm 4\n",
      "llm 5\n",
      "llm 6\n",
      "fulli 2\n",
      "understand 2\n",
      "understand 3\n",
      "challeng 2\n",
      "formulations. 2\n",
      "paper, 2\n",
      "paper, 4\n",
      "paper, 5\n",
      "paper, 6\n",
      "significantli 2\n",
      "significantli 3\n",
      "significantli 4\n",
      "reduc 2\n",
      "reduc 3\n",
      "burden 2\n",
      "new 2\n",
      "call 2\n",
      "pairwis 2\n",
      "(prp). 2\n",
      "result 2\n",
      "result 3\n",
      "result 5\n",
      "result 6\n",
      "first 2\n",
      "first 4\n",
      "first 5\n",
      "literatur 2\n",
      "achiev 2\n",
      "achiev 4\n",
      "achiev 5\n",
      "state-of-the-art 2\n",
      "state-of-the-art 4\n",
      "perform 2\n",
      "perform 4\n",
      "standard 2\n",
      "moderate-s 2\n",
      "open-sourc 2\n",
      "open-sourc 6\n",
      "llms. 2\n",
      "llms. 5\n",
      "trec-dl 2\n",
      "2019 2\n",
      "2020, 2\n",
      "prp 2\n",
      "flan-ul2 2\n",
      "20b 2\n",
      "paramet 2\n",
      "favor 2\n",
      "best 2\n",
      "literature, 2\n",
      "blackbox 2\n",
      "commerci 2\n",
      "gpt-4 2\n",
      "50x 2\n",
      "(estimated) 2\n",
      "size, 2\n",
      "llm-base 2\n",
      "llm-base 3\n",
      "llm-base 6\n",
      "solutions, 2\n",
      "instructgpt 2\n",
      "175b 2\n",
      "parameters, 2\n",
      "10% 2\n",
      "metrics. 2\n",
      "metrics. 6\n",
      "templat 2\n",
      "templat 3\n",
      "seven 2\n",
      "beir 2\n",
      "beir 4\n",
      "supervis 2\n",
      "chatgpt 2\n",
      "solut 2\n",
      "4.2% 2\n",
      "averag 2\n",
      "ndcg@10. 2\n",
      "ndcg@10. 4\n",
      "furthermore, 2\n",
      "furthermore, 4\n",
      "sever 2\n",
      "variant 2\n",
      "effici 2\n",
      "effici 3\n",
      "possibl 2\n",
      "competit 2\n",
      "even 2\n",
      "linear 2\n",
      "complex 2\n",
      "complex 5\n",
      "(llm) 3\n",
      "manifest 3\n",
      "unparallel 3\n",
      "capabl 3\n",
      "variou 3\n",
      "variou 4\n",
      "e.g., 3\n",
      "multi-step 3\n",
      "reasoning, 3\n",
      "input 3\n",
      "input 4\n",
      "input 5\n",
      "mostli 3\n",
      "limit 3\n",
      "limit 4\n",
      "plain 3\n",
      "text, 3\n",
      "could 3\n",
      "long 3\n",
      "contain 3\n",
      "noisi 3\n",
      "information. 3\n",
      "time 3\n",
      "process, 3\n",
      "process, 5\n",
      "thu 3\n",
      "may 3\n",
      "enough 3\n",
      "recommend 3\n",
      "recommend 6\n",
      "system 3\n",
      "requir 3\n",
      "immedi 3\n",
      "response. 3\n",
      "models, 3\n",
      "user 3\n",
      "item 3\n",
      "item 6\n",
      "id 3\n",
      "usual 3\n",
      "fill 3\n",
      "(i.e., 3\n",
      "discret 3\n",
      "prompt) 3\n",
      "allow 3\n",
      "allow 5\n",
      "given 3\n",
      "given 5\n",
      "need 3\n",
      "extens 3\n",
      "bridg 3\n",
      "bridg 5\n",
      "user/item 3\n",
      "word 3\n",
      "unleash 3\n",
      "power 3\n",
      "power 5\n",
      "power 6\n",
      "recommendation. 3\n",
      "address 3\n",
      "problems, 3\n",
      "distil 3\n",
      "specif 3\n",
      "task 3\n",
      "task 5\n",
      "continu 3\n",
      "vector 3\n",
      "infer 3\n",
      "time. 3\n",
      "time. 4\n",
      "also 3\n",
      "also 5\n",
      "design 3\n",
      "train 3\n",
      "attempt 3\n",
      "experiment 3\n",
      "three 3\n",
      "real-world 3\n",
      "dataset 3\n",
      "dataset 6\n",
      "demonstr 3\n",
      "demonstr 4\n",
      "demonstr 6\n",
      "effect 3\n",
      "effect 4\n",
      "effect 5\n",
      "(pod) 3\n",
      "sequenti 3\n",
      "sequenti 5\n",
      "top-n 3\n",
      "tasks. 3\n",
      "tasks. 6\n",
      "although 3\n",
      "improved, 3\n",
      "limited. 3\n",
      "commun 3\n",
      "well-known 4\n",
      "problem 4\n",
      "inform 4\n",
      "inform 5\n",
      "inform 6\n",
      "(ir) 4\n",
      "aim 4\n",
      "aim 5\n",
      "enhanc 4\n",
      "enhanc 5\n",
      "singl 4\n",
      "complet 4\n",
      "rate 4\n",
      "automat 4\n",
      "modifi 4\n",
      "user' 4\n",
      "user' 5\n",
      "query. 4\n",
      "recent 4\n",
      "recent 5\n",
      "recent 6\n",
      "reformulation, 4\n",
      "often 4\n",
      "redund 4\n",
      "expansions, 4\n",
      "potenti 4\n",
      "potenti 6\n",
      "constrain 4\n",
      "captur 4\n",
      "captur 5\n",
      "divers 4\n",
      "intents. 4\n",
      "gencrf: 4\n",
      "cluster 4\n",
      "framework 4\n",
      "adapt 4\n",
      "differentiated, 4\n",
      "well-gener 4\n",
      "phase 4\n",
      "gencrf 4\n",
      "variabl 4\n",
      "initi 4\n",
      "custom 4\n",
      "prompts, 4\n",
      "group 4\n",
      "distinctli 4\n",
      "repres 4\n",
      "explor 4\n",
      "explor 6\n",
      "combin 4\n",
      "combin 6\n",
      "innov 4\n",
      "weight 4\n",
      "aggreg 4\n",
      "optim 4\n",
      "crucial 4\n",
      "integr 4\n",
      "integr 5\n",
      "novel 4\n",
      "novel 5\n",
      "reward 4\n",
      "(qerm) 4\n",
      "refin 4\n",
      "process 4\n",
      "process 6\n",
      "loops. 4\n",
      "empir 4\n",
      "experi 4\n",
      "experi 5\n",
      "performance, 4\n",
      "surpass 4\n",
      "sota 4\n",
      "12% 4\n",
      "llms, 4\n",
      "boost 4\n",
      "advanc 4\n",
      "field 4\n",
      "retrieval. 4\n",
      "session 5\n",
      "involv 5\n",
      "seri 5\n",
      "interact 5\n",
      "action 5\n",
      "fulfil 5\n",
      "need. 5\n",
      "current 5\n",
      "typic 5\n",
      "priorit 5\n",
      "deep 5\n",
      "semant 5\n",
      "understanding, 5\n",
      "overlook 5\n",
      "graph 5\n",
      "structur 5\n",
      "interactions. 5\n",
      "focu 5\n",
      "information, 5\n",
      "represent 5\n",
      "documents, 5\n",
      "neglect 5\n",
      "word-level 5\n",
      "modeling. 5\n",
      "symbol 5\n",
      "(sgr), 5\n",
      "advantag 5\n",
      "text-bas 5\n",
      "graph-bas 5\n",
      "(llms). 5\n",
      "concretely, 5\n",
      "grammar 5\n",
      "rule 5\n",
      "convert 5\n",
      "text. 5\n",
      "history, 5\n",
      "seamlessli 5\n",
      "llm. 5\n",
      "moreover, 5\n",
      "natur 5\n",
      "natur 6\n",
      "discrep 5\n",
      "pre-train 5\n",
      "textual 5\n",
      "corpora, 5\n",
      "produc 5\n",
      "graph-to-text 5\n",
      "grammar, 5\n",
      "object 5\n",
      "llms' 5\n",
      "within 5\n",
      "format. 5\n",
      "this, 5\n",
      "self-supervis 5\n",
      "learn 5\n",
      "includ 5\n",
      "link 5\n",
      "prediction, 5\n",
      "node 5\n",
      "content 5\n",
      "generation, 5\n",
      "contrast 5\n",
      "learning, 5\n",
      "enabl 5\n",
      "topolog 5\n",
      "coarse-grain 5\n",
      "fine-grained. 5\n",
      "comprehens 5\n",
      "analysi 5\n",
      "two 5\n",
      "datasets, 5\n",
      "aol 5\n",
      "tiangong-st, 5\n",
      "confirm 5\n",
      "superior 5\n",
      "approach. 5\n",
      "paradigm 5\n",
      "offer 5\n",
      "methodolog 5\n",
      "gap 5\n",
      "tradit 5\n",
      "modern 5\n",
      "descript 6\n",
      "play 6\n",
      "pivot 6\n",
      "role 6\n",
      "provid 6\n",
      "concis 6\n",
      "summari 6\n",
      "captiv 6\n",
      "viewer 6\n",
      "essenti 6\n",
      "systems. 6\n",
      "traditionally, 6\n",
      "obtain 6\n",
      "manual 6\n",
      "web 6\n",
      "scrape 6\n",
      "techniques, 6\n",
      "time-consum 6\n",
      "suscept 6\n",
      "data 6\n",
      "inconsistencies. 6\n",
      "years, 6\n",
      "(llms), 6\n",
      "gpt-3.5, 6\n",
      "open 6\n",
      "sourc 6\n",
      "like 6\n",
      "alpaca 6\n",
      "emerg 6\n",
      "tool 6\n",
      "detail 6\n",
      "items. 6\n",
      "conduct 6\n",
      "study, 6\n",
      "movielen 6\n",
      "1m 6\n",
      "compris 6\n",
      "movi 6\n",
      "titl 6\n",
      "goodread 6\n",
      "consist 6\n",
      "name 6\n",
      "book 6\n",
      "subsequently, 6\n",
      "llm, 6\n",
      "alpaca, 6\n",
      "few-shot 6\n",
      "consid 6\n",
      "featur 6\n",
      "cast 6\n",
      "director 6\n",
      "ml 6\n",
      "author 6\n",
      "publish 6\n",
      "dataset. 6\n",
      "compar 6\n",
      "top 6\n",
      "hits, 6\n",
      "mrr, 6\n",
      "ndcg 6\n",
      "exhibit 6\n",
      "signific 6\n",
      "promise, 6\n",
      "one 6\n",
      "web-scrap 6\n",
      "descriptions. 6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inverse_split_porter = {}\n",
    "\n",
    "\n",
    "for i in range(len(termes_split_porter)):\n",
    "    for term in termes_split_porter[i]:\n",
    "        if term not in inverse_split_porter:\n",
    "            inverse_split_porter[term] = set()  \n",
    " \n",
    "        inverse_split_porter[term].add(i + 1)\n",
    "\n",
    "\n",
    "inverse_split_porter_output = \"\"\n",
    "for term, docs in inverse_split_porter.items():\n",
    "    for doc in sorted(docs):\n",
    "        inverse_split_porter_output += f\"{term} {doc}\\n\"\n",
    "\n",
    "\n",
    "print(inverse_split_porter_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queri 1\n",
      "queri 2\n",
      "queri 4\n",
      "queri 5\n",
      "reformul 1\n",
      "reformul 4\n",
      "qr 1\n",
      "set 1\n",
      "set 3\n",
      "set 5\n",
      "techniqu 1\n",
      "techniqu 2\n",
      "techniqu 4\n",
      "techniqu 6\n",
      "use 1\n",
      "use 2\n",
      "use 4\n",
      "use 5\n",
      "use 6\n",
      "transform 1\n",
      "user 1\n",
      "user 3\n",
      "user 4\n",
      "user 5\n",
      "origin 1\n",
      "search 1\n",
      "search 4\n",
      "search 5\n",
      "text 1\n",
      "text 3\n",
      "text 5\n",
      "better 1\n",
      "align 1\n",
      "intent 1\n",
      "intent 4\n",
      "improv 1\n",
      "improv 2\n",
      "improv 3\n",
      "improv 4\n",
      "experi 1\n",
      "experi 4\n",
      "experi 5\n",
      "recent 1\n",
      "recent 4\n",
      "recent 5\n",
      "recent 6\n",
      "zero 1\n",
      "shot 1\n",
      "shot 6\n",
      "shown 1\n",
      "promis 1\n",
      "promis 6\n",
      "approach 1\n",
      "approach 2\n",
      "approach 3\n",
      "approach 5\n",
      "due 1\n",
      "abil 1\n",
      "abil 5\n",
      "exploit 1\n",
      "knowledg 1\n",
      "inher 1\n",
      "larg 1\n",
      "larg 2\n",
      "larg 3\n",
      "larg 4\n",
      "larg 5\n",
      "larg 6\n",
      "languag 1\n",
      "languag 2\n",
      "languag 3\n",
      "languag 4\n",
      "languag 5\n",
      "languag 6\n",
      "model 1\n",
      "model 2\n",
      "model 3\n",
      "model 4\n",
      "model 5\n",
      "model 6\n",
      "take 1\n",
      "take 3\n",
      "take 5\n",
      "inspir 1\n",
      "inspir 3\n",
      "success 1\n",
      "success 4\n",
      "ensembl 1\n",
      "prompt 1\n",
      "prompt 2\n",
      "prompt 3\n",
      "prompt 4\n",
      "prompt 6\n",
      "strategi 1\n",
      "strategi 3\n",
      "strategi 4\n",
      "strategi 5\n",
      "benefit 1\n",
      "mani 1\n",
      "task 1\n",
      "task 2\n",
      "task 3\n",
      "task 5\n",
      "task 6\n",
      "investig 1\n",
      "help 1\n",
      "context 1\n",
      "propos 1\n",
      "propos 2\n",
      "propos 3\n",
      "propos 4\n",
      "propos 5\n",
      "base 1\n",
      "base 2\n",
      "base 3\n",
      "base 4\n",
      "base 5\n",
      "base 6\n",
      "genqrensembl 1\n",
      "leverag 1\n",
      "leverag 4\n",
      "leverag 5\n",
      "paraphras 1\n",
      "instruct 1\n",
      "instruct 5\n",
      "gener 1\n",
      "gener 4\n",
      "gener 5\n",
      "gener 6\n",
      "multipl 1\n",
      "multipl 4\n",
      "multipl 6\n",
      "keyword 1\n",
      "ultim 1\n",
      "retriev 1\n",
      "retriev 4\n",
      "perform 1\n",
      "perform 2\n",
      "perform 4\n",
      "introduc 1\n",
      "introduc 5\n",
      "post 1\n",
      "variant 1\n",
      "variant 2\n",
      "genqrensemblerf 1\n",
      "incorpor 1\n",
      "pseudo 1\n",
      "relev 1\n",
      "feedback 1\n",
      "feedback 4\n",
      "evalu 1\n",
      "evalu 4\n",
      "evalu 6\n",
      "four 1\n",
      "ir 1\n",
      "ir 4\n",
      "benchmark 1\n",
      "benchmark 2\n",
      "benchmark 4\n",
      "benchmark 5\n",
      "find 1\n",
      "find 3\n",
      "rel 1\n",
      "ndcg 1\n",
      "ndcg 2\n",
      "ndcg 4\n",
      "ndcg 6\n",
      "10 1\n",
      "10 2\n",
      "10 4\n",
      "18 1\n",
      "map 1\n",
      "upto 1\n",
      "24 1\n",
      "previou 1\n",
      "previou 2\n",
      "previou 4\n",
      "state 1\n",
      "state 2\n",
      "state 4\n",
      "art 1\n",
      "art 2\n",
      "art 4\n",
      "msmarco 1\n",
      "passag 1\n",
      "rank 1\n",
      "rank 2\n",
      "show 1\n",
      "show 2\n",
      "gain 1\n",
      "5 1\n",
      "5 6\n",
      "mrr 1\n",
      "mrr 6\n",
      "9 1\n",
      "document 1\n",
      "document 2\n",
      "document 5\n",
      "llm 2\n",
      "llm 3\n",
      "llm 4\n",
      "llm 5\n",
      "llm 6\n",
      "directli 2\n",
      "feed 2\n",
      "candid 2\n",
      "interest 2\n",
      "practic 2\n",
      "problem 2\n",
      "problem 3\n",
      "problem 4\n",
      "howev 2\n",
      "research 2\n",
      "research 3\n",
      "found 2\n",
      "difficult 2\n",
      "outperform 2\n",
      "fine 2\n",
      "fine 3\n",
      "fine 5\n",
      "tune 2\n",
      "tune 3\n",
      "baselin 2\n",
      "ranker 2\n",
      "ranker 5\n",
      "dataset 2\n",
      "dataset 3\n",
      "dataset 5\n",
      "dataset 6\n",
      "analyz 2\n",
      "pointwis 2\n",
      "listwis 2\n",
      "exist 2\n",
      "method 2\n",
      "method 4\n",
      "argu 2\n",
      "shelf 2\n",
      "fulli 2\n",
      "understand 2\n",
      "understand 3\n",
      "understand 5\n",
      "challeng 2\n",
      "formul 2\n",
      "paper 2\n",
      "paper 4\n",
      "paper 5\n",
      "paper 6\n",
      "significantli 2\n",
      "significantli 3\n",
      "significantli 4\n",
      "reduc 2\n",
      "reduc 3\n",
      "burden 2\n",
      "new 2\n",
      "call 2\n",
      "pairwis 2\n",
      "prp 2\n",
      "result 2\n",
      "result 3\n",
      "result 5\n",
      "result 6\n",
      "first 2\n",
      "first 4\n",
      "first 5\n",
      "literatur 2\n",
      "achiev 2\n",
      "achiev 4\n",
      "achiev 5\n",
      "standard 2\n",
      "moder 2\n",
      "size 2\n",
      "open 2\n",
      "open 6\n",
      "sourc 2\n",
      "sourc 6\n",
      "trec 2\n",
      "dl 2\n",
      "2019 2\n",
      "2020 2\n",
      "flan 2\n",
      "ul2 2\n",
      "20b 2\n",
      "paramet 2\n",
      "favor 2\n",
      "best 2\n",
      "blackbox 2\n",
      "commerci 2\n",
      "gpt 2\n",
      "gpt 6\n",
      "4 2\n",
      "50x 2\n",
      "estim 2\n",
      "solut 2\n",
      "instructgpt 2\n",
      "175b 2\n",
      "metric 2\n",
      "metric 6\n",
      "templat 2\n",
      "templat 3\n",
      "seven 2\n",
      "beir 2\n",
      "beir 4\n",
      "supervis 2\n",
      "supervis 5\n",
      "chatgpt 2\n",
      "2 2\n",
      "averag 2\n",
      "furthermor 2\n",
      "furthermor 4\n",
      "sever 2\n",
      "effici 2\n",
      "effici 3\n",
      "possibl 2\n",
      "competit 2\n",
      "even 2\n",
      "linear 2\n",
      "complex 2\n",
      "complex 5\n",
      "manifest 3\n",
      "unparallel 3\n",
      "capabl 3\n",
      "variou 3\n",
      "variou 4\n",
      "e 3\n",
      "g 3\n",
      "multi 3\n",
      "step 3\n",
      "reason 3\n",
      "input 3\n",
      "input 4\n",
      "input 5\n",
      "mostli 3\n",
      "limit 3\n",
      "limit 4\n",
      "plain 3\n",
      "could 3\n",
      "long 3\n",
      "contain 3\n",
      "noisi 3\n",
      "inform 3\n",
      "inform 4\n",
      "inform 5\n",
      "inform 6\n",
      "time 3\n",
      "time 4\n",
      "time 6\n",
      "process 3\n",
      "process 4\n",
      "process 5\n",
      "process 6\n",
      "thu 3\n",
      "may 3\n",
      "enough 3\n",
      "recommend 3\n",
      "recommend 6\n",
      "system 3\n",
      "system 6\n",
      "requir 3\n",
      "immedi 3\n",
      "respons 3\n",
      "item 3\n",
      "item 6\n",
      "id 3\n",
      "usual 3\n",
      "fill 3\n",
      "discret 3\n",
      "allow 3\n",
      "allow 5\n",
      "given 3\n",
      "given 5\n",
      "need 3\n",
      "need 5\n",
      "extens 3\n",
      "bridg 3\n",
      "bridg 5\n",
      "word 3\n",
      "word 5\n",
      "unleash 3\n",
      "power 3\n",
      "power 5\n",
      "power 6\n",
      "address 3\n",
      "distil 3\n",
      "specif 3\n",
      "continu 3\n",
      "vector 3\n",
      "infer 3\n",
      "also 3\n",
      "also 5\n",
      "design 3\n",
      "train 3\n",
      "train 5\n",
      "attempt 3\n",
      "experiment 3\n",
      "three 3\n",
      "real 3\n",
      "world 3\n",
      "demonstr 3\n",
      "demonstr 4\n",
      "demonstr 6\n",
      "effect 3\n",
      "effect 4\n",
      "effect 5\n",
      "pod 3\n",
      "sequenti 3\n",
      "sequenti 5\n",
      "top 3\n",
      "top 6\n",
      "n 3\n",
      "although 3\n",
      "commun 3\n",
      "well 4\n",
      "known 4\n",
      "aim 4\n",
      "aim 5\n",
      "enhanc 4\n",
      "enhanc 5\n",
      "singl 4\n",
      "complet 4\n",
      "rate 4\n",
      "automat 4\n",
      "modifi 4\n",
      "often 4\n",
      "redund 4\n",
      "expans 4\n",
      "potenti 4\n",
      "potenti 6\n",
      "constrain 4\n",
      "captur 4\n",
      "captur 5\n",
      "divers 4\n",
      "gencrf 4\n",
      "cluster 4\n",
      "framework 4\n",
      "adapt 4\n",
      "differenti 4\n",
      "phase 4\n",
      "variabl 4\n",
      "initi 4\n",
      "custom 4\n",
      "group 4\n",
      "distinctli 4\n",
      "repres 4\n",
      "explor 4\n",
      "explor 6\n",
      "combin 4\n",
      "combin 6\n",
      "innov 4\n",
      "weight 4\n",
      "aggreg 4\n",
      "optim 4\n",
      "crucial 4\n",
      "integr 4\n",
      "integr 5\n",
      "novel 4\n",
      "novel 5\n",
      "reward 4\n",
      "qerm 4\n",
      "refin 4\n",
      "loop 4\n",
      "empir 4\n",
      "surpass 4\n",
      "sota 4\n",
      "12 4\n",
      "boost 4\n",
      "advanc 4\n",
      "field 4\n",
      "session 5\n",
      "involv 5\n",
      "seri 5\n",
      "interact 5\n",
      "action 5\n",
      "fulfil 5\n",
      "current 5\n",
      "typic 5\n",
      "priorit 5\n",
      "deep 5\n",
      "semant 5\n",
      "overlook 5\n",
      "graph 5\n",
      "structur 5\n",
      "focu 5\n",
      "represent 5\n",
      "neglect 5\n",
      "level 5\n",
      "symbol 5\n",
      "sgr 5\n",
      "advantag 5\n",
      "concret 5\n",
      "grammar 5\n",
      "rule 5\n",
      "convert 5\n",
      "histori 5\n",
      "seamlessli 5\n",
      "moreov 5\n",
      "natur 5\n",
      "natur 6\n",
      "discrep 5\n",
      "pre 5\n",
      "textual 5\n",
      "corpora 5\n",
      "produc 5\n",
      "object 5\n",
      "within 5\n",
      "format 5\n",
      "self 5\n",
      "learn 5\n",
      "includ 5\n",
      "link 5\n",
      "predict 5\n",
      "node 5\n",
      "content 5\n",
      "contrast 5\n",
      "enabl 5\n",
      "topolog 5\n",
      "coars 5\n",
      "grain 5\n",
      "comprehens 5\n",
      "analysi 5\n",
      "two 5\n",
      "aol 5\n",
      "tiangong 5\n",
      "st 5\n",
      "confirm 5\n",
      "superior 5\n",
      "paradigm 5\n",
      "offer 5\n",
      "methodolog 5\n",
      "gap 5\n",
      "tradit 5\n",
      "tradit 6\n",
      "modern 5\n",
      "descript 6\n",
      "play 6\n",
      "pivot 6\n",
      "role 6\n",
      "provid 6\n",
      "concis 6\n",
      "summari 6\n",
      "captiv 6\n",
      "viewer 6\n",
      "essenti 6\n",
      "obtain 6\n",
      "manual 6\n",
      "web 6\n",
      "scrape 6\n",
      "consum 6\n",
      "suscept 6\n",
      "data 6\n",
      "inconsist 6\n",
      "year 6\n",
      "3 6\n",
      "like 6\n",
      "alpaca 6\n",
      "emerg 6\n",
      "tool 6\n",
      "detail 6\n",
      "conduct 6\n",
      "studi 6\n",
      "movielen 6\n",
      "1m 6\n",
      "compris 6\n",
      "movi 6\n",
      "titl 6\n",
      "goodread 6\n",
      "consist 6\n",
      "name 6\n",
      "book 6\n",
      "subsequ 6\n",
      "consid 6\n",
      "featur 6\n",
      "cast 6\n",
      "director 6\n",
      "ml 6\n",
      "author 6\n",
      "publish 6\n",
      "compar 6\n",
      "hit 6\n",
      "exhibit 6\n",
      "signific 6\n",
      "one 6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inverse_reg_porter = {}\n",
    "\n",
    "\n",
    "for i in range(len(termes_reg_porter)):\n",
    "    for term in termes_reg_porter[i]:\n",
    "        if term not in inverse_reg_porter:\n",
    "            inverse_reg_porter[term] = set()  \n",
    " \n",
    "        inverse_reg_porter[term].add(i + 1)\n",
    "\n",
    "\n",
    "inverse_reg_porter_output = \"\"\n",
    "for term, docs in inverse_reg_porter.items():\n",
    "    for doc in sorted(docs):\n",
    "        inverse_reg_porter_output += f\"{term} {doc}\\n\"\n",
    "\n",
    "\n",
    "print(inverse_reg_porter_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query 1\n",
      "query 2\n",
      "query 4\n",
      "query 5\n",
      "reform 1\n",
      "reform 4\n",
      "qr 1\n",
      "set 1\n",
      "set 3\n",
      "set 5\n",
      "techn 1\n",
      "techn 2\n",
      "techn 4\n",
      "techn 6\n",
      "us 1\n",
      "us 2\n",
      "us 3\n",
      "us 4\n",
      "us 5\n",
      "us 6\n",
      "transform 1\n",
      "origin 1\n",
      "search 1\n",
      "search 4\n",
      "search 5\n",
      "text 1\n",
      "text 3\n",
      "text 5\n",
      "bet 1\n",
      "align 1\n",
      "int 1\n",
      "int 4\n",
      "improv 1\n",
      "improv 2\n",
      "improv 3\n",
      "improv 4\n",
      "expery 1\n",
      "expery 3\n",
      "expery 4\n",
      "expery 5\n",
      "rec 1\n",
      "rec 4\n",
      "rec 5\n",
      "rec 6\n",
      "zero 1\n",
      "shot 1\n",
      "shot 6\n",
      "shown 1\n",
      "prom 1\n",
      "prom 6\n",
      "approach 1\n",
      "approach 2\n",
      "approach 3\n",
      "approach 5\n",
      "due 1\n",
      "abl 1\n",
      "abl 5\n",
      "exploit 1\n",
      "knowledg 1\n",
      "inh 1\n",
      "larg 1\n",
      "larg 2\n",
      "larg 3\n",
      "larg 4\n",
      "larg 5\n",
      "larg 6\n",
      "langu 1\n",
      "langu 2\n",
      "langu 3\n",
      "langu 4\n",
      "langu 5\n",
      "langu 6\n",
      "model 1\n",
      "model 2\n",
      "model 3\n",
      "model 4\n",
      "model 5\n",
      "model 6\n",
      "tak 1\n",
      "tak 3\n",
      "tak 5\n",
      "inspir 1\n",
      "inspir 3\n",
      "success 1\n",
      "success 4\n",
      "ensembl 1\n",
      "prompt 1\n",
      "prompt 2\n",
      "prompt 3\n",
      "prompt 4\n",
      "prompt 6\n",
      "strategies 1\n",
      "strategies 4\n",
      "strategies 5\n",
      "benefit 1\n",
      "many 1\n",
      "task 1\n",
      "task 2\n",
      "task 3\n",
      "task 5\n",
      "task 6\n",
      "investig 1\n",
      "help 1\n",
      "context 1\n",
      "propos 1\n",
      "propos 2\n",
      "propos 3\n",
      "propos 4\n",
      "propos 5\n",
      "bas 1\n",
      "bas 2\n",
      "bas 3\n",
      "bas 4\n",
      "bas 5\n",
      "bas 6\n",
      "genqrensembl 1\n",
      "lev 1\n",
      "lev 4\n",
      "lev 5\n",
      "paraphras 1\n",
      "instruct 1\n",
      "instruct 5\n",
      "gen 1\n",
      "gen 4\n",
      "gen 5\n",
      "gen 6\n",
      "multipl 1\n",
      "multipl 4\n",
      "multipl 6\n",
      "keyword 1\n",
      "ultim 1\n",
      "retriev 1\n",
      "retriev 4\n",
      "perform 1\n",
      "perform 2\n",
      "perform 4\n",
      "introduc 1\n",
      "introduc 5\n",
      "post 1\n",
      "vary 1\n",
      "vary 2\n",
      "vary 3\n",
      "vary 4\n",
      "genqrensemblerf 1\n",
      "incorp 1\n",
      "pseudo 1\n",
      "relev 1\n",
      "feedback 1\n",
      "feedback 4\n",
      "evalu 1\n",
      "evalu 4\n",
      "evalu 6\n",
      "four 1\n",
      "ir 1\n",
      "ir 4\n",
      "benchmark 1\n",
      "benchmark 2\n",
      "benchmark 4\n",
      "benchmark 5\n",
      "find 1\n",
      "find 3\n",
      "rel 1\n",
      "ndcg 1\n",
      "ndcg 2\n",
      "ndcg 4\n",
      "ndcg 6\n",
      "10 1\n",
      "10 2\n",
      "10 4\n",
      "18 1\n",
      "map 1\n",
      "upto 1\n",
      "24 1\n",
      "prevy 1\n",
      "prevy 2\n",
      "prevy 4\n",
      "stat 1\n",
      "stat 2\n",
      "stat 4\n",
      "art 1\n",
      "art 2\n",
      "art 4\n",
      "msmarco 1\n",
      "pass 1\n",
      "rank 1\n",
      "rank 2\n",
      "rank 5\n",
      "show 1\n",
      "show 2\n",
      "gain 1\n",
      "5 1\n",
      "5 6\n",
      "mrr 1\n",
      "mrr 6\n",
      "9 1\n",
      "docu 1\n",
      "docu 2\n",
      "docu 5\n",
      "llms 2\n",
      "llms 4\n",
      "llms 5\n",
      "llms 6\n",
      "direct 2\n",
      "direct 6\n",
      "fee 2\n",
      "candid 2\n",
      "interest 2\n",
      "pract 2\n",
      "problem 2\n",
      "problem 3\n",
      "problem 4\n",
      "howev 2\n",
      "research 2\n",
      "research 3\n",
      "found 2\n",
      "difficult 2\n",
      "outperform 2\n",
      "fin 2\n",
      "fin 3\n",
      "fin 5\n",
      "tun 2\n",
      "tun 3\n",
      "baselin 2\n",
      "dataset 2\n",
      "dataset 3\n",
      "dataset 5\n",
      "dataset 6\n",
      "analys 2\n",
      "analys 5\n",
      "pointw 2\n",
      "listw 2\n",
      "ex 2\n",
      "method 2\n",
      "method 4\n",
      "argu 2\n",
      "shelf 2\n",
      "ful 2\n",
      "understand 2\n",
      "understand 3\n",
      "understand 5\n",
      "challeng 2\n",
      "form 2\n",
      "form 5\n",
      "pap 2\n",
      "pap 4\n",
      "pap 5\n",
      "pap 6\n",
      "sign 2\n",
      "sign 3\n",
      "sign 4\n",
      "sign 6\n",
      "reduc 2\n",
      "reduc 3\n",
      "burd 2\n",
      "new 2\n",
      "cal 2\n",
      "pairw 2\n",
      "prp 2\n",
      "result 2\n",
      "result 3\n",
      "result 5\n",
      "result 6\n",
      "first 2\n",
      "first 4\n",
      "first 5\n",
      "lit 2\n",
      "achiev 2\n",
      "achiev 4\n",
      "achiev 5\n",
      "standard 2\n",
      "mod 2\n",
      "mod 4\n",
      "siz 2\n",
      "op 2\n",
      "op 6\n",
      "sourc 2\n",
      "sourc 6\n",
      "trec 2\n",
      "dl 2\n",
      "2019 2\n",
      "2020 2\n",
      "flan 2\n",
      "ul2 2\n",
      "20b 2\n",
      "paramet 2\n",
      "fav 2\n",
      "best 2\n",
      "blackbox 2\n",
      "commerc 2\n",
      "gpt 2\n",
      "gpt 6\n",
      "4 2\n",
      "50x 2\n",
      "estim 2\n",
      "llm 2\n",
      "llm 3\n",
      "llm 5\n",
      "llm 6\n",
      "solv 2\n",
      "instructgpt 2\n",
      "175b 2\n",
      "met 2\n",
      "met 6\n",
      "templ 2\n",
      "templ 3\n",
      "sev 2\n",
      "beir 2\n",
      "beir 4\n",
      "superv 2\n",
      "superv 5\n",
      "chatgpt 2\n",
      "2 2\n",
      "av 2\n",
      "furtherm 2\n",
      "furtherm 4\n",
      "efficy 2\n",
      "efficy 3\n",
      "poss 2\n",
      "competit 2\n",
      "ev 2\n",
      "linear 2\n",
      "complex 2\n",
      "complex 5\n",
      "manifest 3\n",
      "unparallel 3\n",
      "cap 3\n",
      "e 3\n",
      "g 3\n",
      "mult 3\n",
      "step 3\n",
      "reason 3\n",
      "input 3\n",
      "input 4\n",
      "input 5\n",
      "most 3\n",
      "limit 3\n",
      "limit 4\n",
      "plain 3\n",
      "could 3\n",
      "long 3\n",
      "contain 3\n",
      "noisy 3\n",
      "inform 3\n",
      "inform 4\n",
      "inform 5\n",
      "inform 6\n",
      "tim 3\n",
      "tim 4\n",
      "tim 6\n",
      "process 3\n",
      "process 4\n",
      "process 5\n",
      "process 6\n",
      "thu 3\n",
      "may 3\n",
      "enough 3\n",
      "recommend 3\n",
      "recommend 6\n",
      "system 3\n",
      "system 6\n",
      "requir 3\n",
      "immedy 3\n",
      "respons 3\n",
      "item 3\n",
      "item 6\n",
      "id 3\n",
      "fil 3\n",
      "discret 3\n",
      "allow 3\n",
      "allow 5\n",
      "giv 3\n",
      "giv 5\n",
      "nee 3\n",
      "nee 5\n",
      "extend 3\n",
      "bridg 3\n",
      "bridg 5\n",
      "word 3\n",
      "word 5\n",
      "unleash 3\n",
      "pow 3\n",
      "pow 5\n",
      "pow 6\n",
      "address 3\n",
      "distil 3\n",
      "spec 3\n",
      "continu 3\n",
      "vect 3\n",
      "inf 3\n",
      "also 3\n",
      "also 5\n",
      "design 3\n",
      "train 3\n",
      "train 5\n",
      "strategy 3\n",
      "attempt 3\n",
      "three 3\n",
      "real 3\n",
      "world 3\n",
      "demonst 3\n",
      "demonst 4\n",
      "demonst 6\n",
      "effect 3\n",
      "effect 4\n",
      "effect 5\n",
      "pod 3\n",
      "sequ 3\n",
      "sequ 5\n",
      "top 3\n",
      "top 6\n",
      "n 3\n",
      "although 3\n",
      "commun 3\n",
      "wel 4\n",
      "known 4\n",
      "aim 4\n",
      "aim 5\n",
      "enh 4\n",
      "enh 5\n",
      "singl 4\n",
      "complet 4\n",
      "rat 4\n",
      "autom 4\n",
      "oft 4\n",
      "redund 4\n",
      "expand 4\n",
      "pot 4\n",
      "pot 6\n",
      "constrain 4\n",
      "capt 4\n",
      "capt 5\n",
      "capt 6\n",
      "divers 4\n",
      "gencrf 4\n",
      "clust 4\n",
      "framework 4\n",
      "adapt 4\n",
      "differenty 4\n",
      "phas 4\n",
      "init 4\n",
      "custom 4\n",
      "group 4\n",
      "distinct 4\n",
      "repres 4\n",
      "repres 5\n",
      "expl 4\n",
      "expl 6\n",
      "combin 4\n",
      "combin 6\n",
      "innov 4\n",
      "weight 4\n",
      "aggreg 4\n",
      "optim 4\n",
      "cruc 4\n",
      "integr 4\n",
      "integr 5\n",
      "novel 4\n",
      "novel 5\n",
      "reward 4\n",
      "qerm 4\n",
      "refin 4\n",
      "loop 4\n",
      "empir 4\n",
      "surpass 4\n",
      "sota 4\n",
      "12 4\n",
      "boost 4\n",
      "adv 4\n",
      "adv 5\n",
      "field 4\n",
      "sess 5\n",
      "involv 5\n",
      "sery 5\n",
      "interact 5\n",
      "act 5\n",
      "fulfil 5\n",
      "cur 5\n",
      "typ 5\n",
      "priorit 5\n",
      "deep 5\n",
      "sem 5\n",
      "overlook 5\n",
      "graph 5\n",
      "structure 5\n",
      "foc 5\n",
      "structural 5\n",
      "neglect 5\n",
      "level 5\n",
      "symbol 5\n",
      "sgr 5\n",
      "concret 5\n",
      "gramm 5\n",
      "rul 5\n",
      "convert 5\n",
      "hist 5\n",
      "seamless 5\n",
      "moreov 5\n",
      "nat 5\n",
      "nat 6\n",
      "discrep 5\n",
      "pre 5\n",
      "corpor 5\n",
      "produc 5\n",
      "object 5\n",
      "structures 5\n",
      "within 5\n",
      "self 5\n",
      "learn 5\n",
      "includ 5\n",
      "link 5\n",
      "predict 5\n",
      "nod 5\n",
      "cont 5\n",
      "cont 6\n",
      "contrast 5\n",
      "en 5\n",
      "topolog 5\n",
      "coars 5\n",
      "grain 5\n",
      "comprehend 5\n",
      "two 5\n",
      "aol 5\n",
      "tiangong 5\n",
      "st 5\n",
      "confirm 5\n",
      "supery 5\n",
      "paradigm 5\n",
      "off 5\n",
      "methodolog 5\n",
      "gap 5\n",
      "tradit 5\n",
      "tradit 6\n",
      "modern 5\n",
      "describ 6\n",
      "play 6\n",
      "pivot 6\n",
      "rol 6\n",
      "provid 6\n",
      "sum 6\n",
      "view 6\n",
      "ess 6\n",
      "obtain 6\n",
      "man 6\n",
      "web 6\n",
      "scraping 6\n",
      "consum 6\n",
      "suscept 6\n",
      "dat 6\n",
      "inconsist 6\n",
      "year 6\n",
      "3 6\n",
      "lik 6\n",
      "alpac 6\n",
      "emerg 6\n",
      "tool 6\n",
      "detail 6\n",
      "conduc 6\n",
      "study 6\n",
      "moviel 6\n",
      "1m 6\n",
      "compr 6\n",
      "movy 6\n",
      "titl 6\n",
      "goodread 6\n",
      "consist 6\n",
      "nam 6\n",
      "book 6\n",
      "subsequ 6\n",
      "consid 6\n",
      "feat 6\n",
      "cast 6\n",
      "ml 6\n",
      "auth 6\n",
      "publ 6\n",
      "comp 6\n",
      "scraped 6\n",
      "hit 6\n",
      "exhibit 6\n",
      "on 6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inverse_reg_lancaster = {}\n",
    "\n",
    "\n",
    "for i in range(len(termes_reg_lancaster)):\n",
    "    for term in termes_reg_lancaster[i]:\n",
    "        if term not in inverse_reg_lancaster:\n",
    "            inverse_reg_lancaster[term] = set()  \n",
    " \n",
    "        inverse_reg_lancaster[term].add(i + 1)\n",
    "\n",
    "\n",
    "inverse_reg_lancaster_output = \"\"\n",
    "for term, docs in inverse_reg_lancaster.items():\n",
    "    for doc in sorted(docs):\n",
    "        inverse_reg_lancaster_output += f\"{term} {doc}\\n\"\n",
    "\n",
    "\n",
    "print(inverse_reg_lancaster_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query 1\n",
      "query 2\n",
      "query 4\n",
      "query 5\n",
      "reformulation(qr) 1\n",
      "set 1\n",
      "set 3\n",
      "set 5\n",
      "techn 1\n",
      "techn 2\n",
      "techn 4\n",
      "us 1\n",
      "us 2\n",
      "us 3\n",
      "us 4\n",
      "us 5\n",
      "us 6\n",
      "transform 1\n",
      "user’s 1\n",
      "origin 1\n",
      "search 1\n",
      "search 4\n",
      "search 5\n",
      "text 1\n",
      "text 3\n",
      "text 5\n",
      "bet 1\n",
      "align 1\n",
      "int 1\n",
      "int 4\n",
      "improv 1\n",
      "improv 2\n",
      "improv 3\n",
      "improv 4\n",
      "experience. 1\n",
      "recently, 1\n",
      "zero-shot 1\n",
      "qr 1\n",
      "shown 1\n",
      "prom 1\n",
      "approach 1\n",
      "approach 2\n",
      "approach 3\n",
      "approach 5\n",
      "due 1\n",
      "abl 1\n",
      "abl 5\n",
      "exploit 1\n",
      "knowledg 1\n",
      "inh 1\n",
      "larg 1\n",
      "larg 2\n",
      "larg 3\n",
      "larg 4\n",
      "larg 5\n",
      "larg 6\n",
      "langu 1\n",
      "langu 2\n",
      "langu 3\n",
      "langu 4\n",
      "langu 5\n",
      "langu 6\n",
      "models. 1\n",
      "models. 3\n",
      "tak 1\n",
      "tak 3\n",
      "tak 5\n",
      "inspir 1\n",
      "inspir 3\n",
      "success 1\n",
      "success 4\n",
      "ensembl 1\n",
      "prompt 1\n",
      "prompt 2\n",
      "prompt 3\n",
      "prompt 6\n",
      "strategies 1\n",
      "strategies 4\n",
      "strategies 5\n",
      "benefit 1\n",
      "many 1\n",
      "tasks, 1\n",
      "tasks, 2\n",
      "tasks, 3\n",
      "investig 1\n",
      "help 1\n",
      "reformulation. 1\n",
      "context, 1\n",
      "propos 1\n",
      "propos 2\n",
      "propos 3\n",
      "propos 4\n",
      "propos 5\n",
      "bas 1\n",
      "bas 2\n",
      "bas 4\n",
      "technique, 1\n",
      "genqrensembl 1\n",
      "lev 1\n",
      "lev 4\n",
      "lev 5\n",
      "paraphras 1\n",
      "instruct 1\n",
      "instruct 5\n",
      "gen 1\n",
      "gen 4\n",
      "gen 5\n",
      "gen 6\n",
      "multipl 1\n",
      "multipl 4\n",
      "multipl 6\n",
      "keyword 1\n",
      "ultim 1\n",
      "retriev 1\n",
      "retriev 4\n",
      "performance. 1\n",
      "introduc 1\n",
      "introduc 5\n",
      "post-retrieval 1\n",
      "variant, 1\n",
      "genqrensemblerf 1\n",
      "incorp 1\n",
      "pseudo 1\n",
      "relev 1\n",
      "feedback. 1\n",
      "evalu 1\n",
      "evalu 4\n",
      "evalu 6\n",
      "four 1\n",
      "ir 1\n",
      "benchmarks, 1\n",
      "find 1\n",
      "find 3\n",
      "reform 1\n",
      "reform 4\n",
      "rel 1\n",
      "ndcg@10 1\n",
      "18% 1\n",
      "map 1\n",
      "upto 1\n",
      "24% 1\n",
      "prevy 1\n",
      "prevy 2\n",
      "prevy 4\n",
      "state-of-art. 1\n",
      "msmarco 1\n",
      "pass 1\n",
      "rank 1\n",
      "rank 2\n",
      "rank 5\n",
      "task, 1\n",
      "task, 3\n",
      "show 1\n",
      "show 2\n",
      "gain 1\n",
      "5% 1\n",
      "mrr 1\n",
      "pseudo-relevance 1\n",
      "feedback, 1\n",
      "9% 1\n",
      "feedback 1\n",
      "feedback 4\n",
      "documents. 1\n",
      "docu 2\n",
      "model 2\n",
      "model 3\n",
      "model 4\n",
      "model 5\n",
      "model 6\n",
      "(llms) 2\n",
      "(llms) 4\n",
      "direct 2\n",
      "direct 6\n",
      "fee 2\n",
      "candid 2\n",
      "interest 2\n",
      "pract 2\n",
      "problem. 2\n",
      "however, 2\n",
      "research 2\n",
      "research 3\n",
      "found 2\n",
      "difficult 2\n",
      "outperform 2\n",
      "fine-tuned 2\n",
      "baselin 2\n",
      "benchmark 2\n",
      "benchmark 4\n",
      "benchmark 5\n",
      "datasets. 2\n",
      "analys 2\n",
      "analys 5\n",
      "pointw 2\n",
      "listw 2\n",
      "ex 2\n",
      "method 2\n",
      "method 4\n",
      "argu 2\n",
      "off-the-shelf 2\n",
      "llms 2\n",
      "llms 4\n",
      "llms 5\n",
      "llms 6\n",
      "ful 2\n",
      "understand 2\n",
      "understand 3\n",
      "challeng 2\n",
      "formulations. 2\n",
      "paper, 2\n",
      "paper, 4\n",
      "paper, 5\n",
      "paper, 6\n",
      "sign 2\n",
      "sign 3\n",
      "sign 4\n",
      "sign 6\n",
      "reduc 2\n",
      "reduc 3\n",
      "burd 2\n",
      "new 2\n",
      "cal 2\n",
      "pairw 2\n",
      "(prp). 2\n",
      "result 2\n",
      "result 3\n",
      "result 5\n",
      "result 6\n",
      "first 2\n",
      "first 4\n",
      "first 5\n",
      "lit 2\n",
      "achiev 2\n",
      "achiev 4\n",
      "achiev 5\n",
      "state-of-the-art 2\n",
      "state-of-the-art 4\n",
      "perform 2\n",
      "perform 4\n",
      "standard 2\n",
      "moderate-sized 2\n",
      "open-sourced 2\n",
      "open-sourced 6\n",
      "llms. 2\n",
      "llms. 5\n",
      "trec-dl 2\n",
      "2019 2\n",
      "2020, 2\n",
      "prp 2\n",
      "flan-ul2 2\n",
      "20b 2\n",
      "paramet 2\n",
      "fav 2\n",
      "best 2\n",
      "literature, 2\n",
      "blackbox 2\n",
      "commerc 2\n",
      "gpt-4 2\n",
      "50x 2\n",
      "(estimated) 2\n",
      "size, 2\n",
      "llm-based 2\n",
      "llm-based 3\n",
      "llm-based 6\n",
      "solutions, 2\n",
      "instructgpt 2\n",
      "175b 2\n",
      "parameters, 2\n",
      "10% 2\n",
      "metrics. 2\n",
      "metrics. 6\n",
      "templ 2\n",
      "templ 3\n",
      "sev 2\n",
      "beir 2\n",
      "beir 4\n",
      "superv 2\n",
      "chatgpt 2\n",
      "solv 2\n",
      "4.2% 2\n",
      "av 2\n",
      "ndcg@10. 2\n",
      "ndcg@10. 4\n",
      "furthermore, 2\n",
      "furthermore, 4\n",
      "vary 2\n",
      "vary 3\n",
      "vary 4\n",
      "efficy 2\n",
      "efficy 3\n",
      "poss 2\n",
      "competit 2\n",
      "ev 2\n",
      "linear 2\n",
      "complex 2\n",
      "complex 5\n",
      "(llm) 3\n",
      "manifest 3\n",
      "unparallel 3\n",
      "cap 3\n",
      "e.g., 3\n",
      "multi-step 3\n",
      "reasoning, 3\n",
      "input 3\n",
      "input 4\n",
      "input 5\n",
      "most 3\n",
      "limit 3\n",
      "limit 4\n",
      "plain 3\n",
      "text, 3\n",
      "could 3\n",
      "long 3\n",
      "contain 3\n",
      "noisy 3\n",
      "information. 3\n",
      "tim 3\n",
      "process, 3\n",
      "process, 5\n",
      "thu 3\n",
      "may 3\n",
      "enough 3\n",
      "recommend 3\n",
      "recommend 6\n",
      "system 3\n",
      "requir 3\n",
      "immedy 3\n",
      "response. 3\n",
      "models, 3\n",
      "item 3\n",
      "item 6\n",
      "id 3\n",
      "fil 3\n",
      "(i.e., 3\n",
      "discret 3\n",
      "prompt) 3\n",
      "allow 3\n",
      "allow 5\n",
      "giv 3\n",
      "giv 5\n",
      "nee 3\n",
      "extend 3\n",
      "fine-tuning 3\n",
      "bridg 3\n",
      "bridg 5\n",
      "user/item 3\n",
      "word 3\n",
      "unleash 3\n",
      "pow 3\n",
      "pow 5\n",
      "pow 6\n",
      "llm 3\n",
      "recommendation. 3\n",
      "address 3\n",
      "problems, 3\n",
      "distil 3\n",
      "spec 3\n",
      "task 3\n",
      "task 5\n",
      "continu 3\n",
      "vect 3\n",
      "inf 3\n",
      "time. 3\n",
      "time. 4\n",
      "also 3\n",
      "also 5\n",
      "design 3\n",
      "train 3\n",
      "strategy 3\n",
      "attempt 3\n",
      "expery 3\n",
      "expery 4\n",
      "expery 5\n",
      "three 3\n",
      "real-world 3\n",
      "dataset 3\n",
      "dataset 6\n",
      "demonst 3\n",
      "demonst 4\n",
      "demonst 6\n",
      "effect 3\n",
      "effect 4\n",
      "effect 5\n",
      "(pod) 3\n",
      "sequ 3\n",
      "sequ 5\n",
      "top-n 3\n",
      "tasks. 3\n",
      "tasks. 6\n",
      "although 3\n",
      "improved, 3\n",
      "limited. 3\n",
      "commun 3\n",
      "well-known 4\n",
      "problem 4\n",
      "inform 4\n",
      "inform 5\n",
      "inform 6\n",
      "(ir) 4\n",
      "aim 4\n",
      "aim 5\n",
      "enh 4\n",
      "enh 5\n",
      "singl 4\n",
      "complet 4\n",
      "rat 4\n",
      "autom 4\n",
      "mod 4\n",
      "user's 4\n",
      "user's 5\n",
      "query. 4\n",
      "rec 4\n",
      "rec 5\n",
      "rec 6\n",
      "reformulation, 4\n",
      "oft 4\n",
      "redund 4\n",
      "expansions, 4\n",
      "pot 4\n",
      "pot 6\n",
      "constrain 4\n",
      "capt 4\n",
      "capt 5\n",
      "capt 6\n",
      "divers 4\n",
      "intents. 4\n",
      "gencrf: 4\n",
      "clust 4\n",
      "framework 4\n",
      "adapt 4\n",
      "differentiated, 4\n",
      "well-generated 4\n",
      "phas 4\n",
      "gencrf 4\n",
      "init 4\n",
      "custom 4\n",
      "prompts, 4\n",
      "group 4\n",
      "distinct 4\n",
      "repres 4\n",
      "repres 5\n",
      "expl 4\n",
      "expl 6\n",
      "combin 4\n",
      "combin 6\n",
      "innov 4\n",
      "weight 4\n",
      "aggreg 4\n",
      "optim 4\n",
      "cruc 4\n",
      "integr 4\n",
      "integr 5\n",
      "novel 4\n",
      "novel 5\n",
      "reward 4\n",
      "(qerm) 4\n",
      "refin 4\n",
      "process 4\n",
      "process 6\n",
      "loops. 4\n",
      "empir 4\n",
      "performance, 4\n",
      "surpass 4\n",
      "sota 4\n",
      "12% 4\n",
      "llms, 4\n",
      "boost 4\n",
      "adv 4\n",
      "adv 5\n",
      "field 4\n",
      "retrieval. 4\n",
      "sess 5\n",
      "involv 5\n",
      "sery 5\n",
      "interact 5\n",
      "act 5\n",
      "fulfil 5\n",
      "need. 5\n",
      "cur 5\n",
      "typ 5\n",
      "priorit 5\n",
      "deep 5\n",
      "sem 5\n",
      "understanding, 5\n",
      "overlook 5\n",
      "graph 5\n",
      "structure 5\n",
      "interactions. 5\n",
      "foc 5\n",
      "structural 5\n",
      "information, 5\n",
      "documents, 5\n",
      "neglect 5\n",
      "word-level 5\n",
      "modeling. 5\n",
      "symbol 5\n",
      "(sgr), 5\n",
      "text-based 5\n",
      "graph-based 5\n",
      "(llms). 5\n",
      "concretely, 5\n",
      "gramm 5\n",
      "rul 5\n",
      "convert 5\n",
      "text. 5\n",
      "history, 5\n",
      "seamless 5\n",
      "llm. 5\n",
      "moreover, 5\n",
      "nat 5\n",
      "nat 6\n",
      "discrep 5\n",
      "pre-trained 5\n",
      "corpora, 5\n",
      "produc 5\n",
      "graph-to-text 5\n",
      "grammar, 5\n",
      "object 5\n",
      "llms' 5\n",
      "structures 5\n",
      "within 5\n",
      "format. 5\n",
      "this, 5\n",
      "self-supervised 5\n",
      "learn 5\n",
      "includ 5\n",
      "link 5\n",
      "prediction, 5\n",
      "nod 5\n",
      "cont 5\n",
      "cont 6\n",
      "generation, 5\n",
      "contrast 5\n",
      "learning, 5\n",
      "en 5\n",
      "topolog 5\n",
      "coarse-grained 5\n",
      "fine-grained. 5\n",
      "comprehend 5\n",
      "two 5\n",
      "datasets, 5\n",
      "aol 5\n",
      "tiangong-st, 5\n",
      "confirm 5\n",
      "supery 5\n",
      "approach. 5\n",
      "paradigm 5\n",
      "off 5\n",
      "methodolog 5\n",
      "gap 5\n",
      "tradit 5\n",
      "modern 5\n",
      "describ 6\n",
      "play 6\n",
      "pivot 6\n",
      "rol 6\n",
      "provid 6\n",
      "sum 6\n",
      "view 6\n",
      "ess 6\n",
      "systems. 6\n",
      "traditionally, 6\n",
      "obtain 6\n",
      "man 6\n",
      "web 6\n",
      "scraping 6\n",
      "techniques, 6\n",
      "time-consuming 6\n",
      "suscept 6\n",
      "dat 6\n",
      "inconsistencies. 6\n",
      "years, 6\n",
      "(llms), 6\n",
      "gpt-3.5, 6\n",
      "op 6\n",
      "sourc 6\n",
      "lik 6\n",
      "alpac 6\n",
      "emerg 6\n",
      "tool 6\n",
      "detail 6\n",
      "items. 6\n",
      "conduc 6\n",
      "study, 6\n",
      "moviel 6\n",
      "1m 6\n",
      "compr 6\n",
      "movy 6\n",
      "titl 6\n",
      "goodread 6\n",
      "consist 6\n",
      "nam 6\n",
      "book 6\n",
      "subsequently, 6\n",
      "llm, 6\n",
      "alpaca, 6\n",
      "few-shot 6\n",
      "consid 6\n",
      "feat 6\n",
      "cast 6\n",
      "ml 6\n",
      "auth 6\n",
      "publ 6\n",
      "dataset. 6\n",
      "comp 6\n",
      "scraped 6\n",
      "top 6\n",
      "hits, 6\n",
      "mrr, 6\n",
      "ndcg 6\n",
      "exhibit 6\n",
      "promise, 6\n",
      "on 6\n",
      "web-scraped 6\n",
      "descriptions. 6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inverse_split_lancaster = {}\n",
    "\n",
    "\n",
    "for i in range(len(termes_split_lancaster)):\n",
    "    for term in termes_split_lancaster[i]:\n",
    "        if term not in inverse_split_lancaster:\n",
    "            inverse_split_lancaster[term] = set()  \n",
    " \n",
    "        inverse_split_lancaster[term].add(i + 1)\n",
    "\n",
    "\n",
    "inverse_split_lancaster_output = \"\"\n",
    "for term, docs in inverse_split_lancaster.items():\n",
    "    for doc in sorted(docs):\n",
    "        inverse_split_lancaster_output += f\"{term} {doc}\\n\"\n",
    "\n",
    "\n",
    "print(inverse_split_lancaster_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving Files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved to descripteur_split.txt\n"
     ]
    }
   ],
   "source": [
    "output_file_path = 'descripteur_split.txt'\n",
    "\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(descripteur_split)\n",
    "\n",
    "print(f'file saved to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved to descripteur_reg.txt\n"
     ]
    }
   ],
   "source": [
    "output_file_path = 'descripteur_reg.txt'\n",
    "\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(descripteur_reg)\n",
    "\n",
    "print(f'file saved to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved to descripteur_split_porter.txt\n"
     ]
    }
   ],
   "source": [
    "output_file_path = 'descripteur_split_porter.txt'\n",
    "\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(descripteur_split_porter)\n",
    "\n",
    "print(f'file saved to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved to descripteur_reg_porter.txt\n"
     ]
    }
   ],
   "source": [
    "output_file_path = 'descripteur_reg_porter.txt'\n",
    "\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(descripteur_reg_porter)\n",
    "\n",
    "print(f'file saved to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved to descripteur_split_lancaster.txt\n"
     ]
    }
   ],
   "source": [
    "output_file_path = 'descripteur_split_lancaster.txt'\n",
    "\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(descripteur_split_lancaster)\n",
    "\n",
    "print(f'file saved to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved to descripteur_reg_lancaster.txt\n"
     ]
    }
   ],
   "source": [
    "output_file_path = 'descripteur_reg_lancaster.txt'\n",
    "\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(descripteur_reg_lancaster)\n",
    "\n",
    "print(f'file saved to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved to inverse_split.txt\n"
     ]
    }
   ],
   "source": [
    "output_file_path = 'inverse_split.txt'\n",
    "\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(inverse_split_output)\n",
    "\n",
    "print(f'file saved to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved to inverse_reg.txt\n"
     ]
    }
   ],
   "source": [
    "output_file_path = 'inverse_reg.txt'\n",
    "\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(inverse_reg_output)\n",
    "\n",
    "print(f'file saved to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved to inverse_split_porter.txt\n"
     ]
    }
   ],
   "source": [
    "output_file_path = 'inverse_split_porter.txt'\n",
    "\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(inverse_split_porter_output)\n",
    "\n",
    "print(f'file saved to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved to inverse_reg_porter.txt\n"
     ]
    }
   ],
   "source": [
    "output_file_path = 'inverse_reg_porter.txt'\n",
    "\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(inverse_reg_porter_output)\n",
    "\n",
    "print(f'file saved to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved to inverse_split_lancaster.txt\n"
     ]
    }
   ],
   "source": [
    "output_file_path = 'inverse_split_lancaster.txt'\n",
    "\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(inverse_split_lancaster_output)\n",
    "\n",
    "print(f'file saved to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved to inverse_reg_lancaster.txt\n"
     ]
    }
   ],
   "source": [
    "output_file_path = 'inverse_reg_lancaster.txt'\n",
    "\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(inverse_reg_lancaster_output)\n",
    "\n",
    "print(f'file saved to {output_file_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

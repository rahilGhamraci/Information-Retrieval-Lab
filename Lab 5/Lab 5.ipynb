{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import nltk \n",
    "Porter = nltk.PorterStemmer()\n",
    "Lancaster = nltk.LancasterStemmer() \n",
    "\n",
    "ExpReg = nltk.RegexpTokenizer('(?:[A-Za-z]\\.)+|[A-Za-z]+[\\-@]\\d+(?:\\.\\d+)?|\\d+[A-Za-z]+|\\d+(?:[\\.\\,\\-]\\d+)?%?|\\w+(?:[\\-/]\\w+)*') # \\d : équivalent à [0-9] \n",
    "StopWords = nltk.corpus.stopwords.words('english') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rsv(query,stemming,preprocessing):\n",
    "   \n",
    "    rsv_dict = {}\n",
    "    \n",
    "    # Iterate over the values and count frequencies  \n",
    "    \n",
    "    file_path = \"\"\n",
    "    if preprocessing == \"Split\":\n",
    "            match stemming:\n",
    "                case 'No Stemming':\n",
    "                    file_path = 'inverse_split.txt'\n",
    "                    query_terms = list(set([term for term in query.split() if term.lower() not in StopWords]))\n",
    "                    with open(file_path, 'r', encoding='utf-8') as file:              \n",
    "                        lines = file.readlines()\n",
    "                        for line in lines:\n",
    "                            parts = line.split()\n",
    "                            if parts[2] in  query_terms:\n",
    "\n",
    "                                if parts[2] in rsv_dict:                                                                        \n",
    "                                    rsv_dict[parts[2]] += parts[4]\n",
    "                                else:\n",
    "                                    rsv_dict[parts[2]] = parts[4]                       \n",
    "                         \n",
    "                case 'Porter':\n",
    "                    file_path = 'inverse_split_porter.txt'\n",
    "                    query_terms = list(set([Porter.stem(term) for term in query.split() if term.lower() not in StopWords]))\n",
    "                    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                        lines = file.readlines()\n",
    "                        for line in lines:\n",
    "                            parts = line.split()\n",
    "                            if parts[2] in  query_terms:\n",
    "\n",
    "                                if parts[2] in rsv_dict:\n",
    "                                    rsv_dict[parts[2]] += parts[4]\n",
    "                                else:\n",
    "\n",
    "                                    rsv_dict[parts[2]] = parts[4]\n",
    "                case 'Lancaster':\n",
    "                    file_path = 'inverse_split_lancaster.txt'\n",
    "                    query_terms = list(set([Lancaster.stem(term) for term in query.split() if term.lower() not in StopWords]))\n",
    "                    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                         \n",
    "                        lines = file.readlines()\n",
    "                        for line in lines:\n",
    "                            parts = line.split()\n",
    "                            if parts[2] in  query_terms:\n",
    "\n",
    "                                if parts[2] in rsv_dict:\n",
    "                                                                        \n",
    "                                    rsv_dict[parts[2]] += parts[4]\n",
    "                                else:\n",
    "\n",
    "                                    rsv_dict[parts[2]] = parts[4]\n",
    "    else:\n",
    "            match stemming:\n",
    "                case 'No Stemming':\n",
    "                    file_path = 'inverse_reg.txt'\n",
    "                    query_terms = list(set([term for term in ExpReg.tokenize(query) if term.lower() not in StopWords]))\n",
    "                    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                        lines = file.readlines()\n",
    "                        for line in lines:\n",
    "                            parts = line.split()\n",
    "                            if parts[2] in  query_terms:\n",
    "\n",
    "                                if parts[2] in rsv_dict:\n",
    "                                                                        \n",
    "                                    rsv_dict[parts[2]] += parts[4]\n",
    "                                else:\n",
    "\n",
    "                                    rsv_dict[parts[2]] = parts[4]\n",
    "                case 'Porter':\n",
    "                    file_path = 'inverse_reg_porter.txt'\n",
    "                    query_terms = list(set([Porter.stem(term) for term in ExpReg.tokenize(query) if term.lower() not in StopWords]))\n",
    "                    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                         \n",
    "                        lines = file.readlines()\n",
    "                        for line in lines:\n",
    "                            parts = line.split()\n",
    "\n",
    "                            if parts[1] in  query_terms:\n",
    "\n",
    "                                if parts[2] in rsv_dict:\n",
    "                                                                        \n",
    "                                    rsv_dict[parts[2]] += float(parts[4])\n",
    "                                else:\n",
    "\n",
    "                                    rsv_dict[parts[2]] = float(parts[4])\n",
    "                    \n",
    "                    rsv_dict = dict(sorted(rsv_dict.items(),key=lambda item:item[1],reverse=True))\n",
    "                case 'Lancaster':\n",
    "                    file_path = 'inverse_reg_lancaster.txt'\n",
    "                    query_terms = list(set([Lancaster.stem(term) for term in ExpReg.tokenize(query) if term.lower() not in StopWords]))\n",
    "                    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                        lines = file.readlines()\n",
    "                        for line in lines:\n",
    "                            parts = line.split()\n",
    "                            if parts[2] in  query_terms:\n",
    "\n",
    "                                if parts[2] in rsv_dict:\n",
    "                                                                        \n",
    "                                    rsv_dict[parts[2]] += parts[4]\n",
    "                                else:\n",
    "\n",
    "                                    rsv_dict[parts[2]] = parts[4]\n",
    "    return rsv_dict\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56d4859c48074c99a1686c10f9abb9bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Text(value='', description='Query:', layout=Layout(width='65%'), placeholder='Enter your query …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7893d2988bd4085baa5e38c8766ef51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Preprocessing:', layout=Layout(width='45%'), options=('Spl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce26a9d90604355b3aa6debe6cf36a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', description='Results:', layout=Layout(height='300px', width='100%'), placeholder='Results w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good one\n",
      "Porter\n",
      "Reg\n"
     ]
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "border_color = '#ccc'\n",
    "background_color = '#f9f9f9'\n",
    "container_background_color = '#f0f0f0'\n",
    "\n",
    "# Query input with adjusted width\n",
    "query_input = widgets.Text(\n",
    "    description='Query:',\n",
    "    placeholder='Enter your query here',\n",
    "    layout=widgets.Layout(width='65%')\n",
    ")\n",
    "\n",
    "# Submit button with adjusted width\n",
    "submit_button = widgets.Button(\n",
    "    description='Search',\n",
    "    layout=widgets.Layout(width='15%')\n",
    ")\n",
    "\n",
    "# Combine query input and submit button in a single line with styling\n",
    "query_container = widgets.HBox(\n",
    "    [query_input, submit_button],\n",
    "    layout=widgets.Layout(\n",
    "        border=f'2px solid {border_color}',\n",
    "        border_radius='10px',\n",
    "        padding='10px',\n",
    "        background_color=background_color,\n",
    "        width='80%'  # Adjust container width\n",
    "    )\n",
    ")\n",
    "\n",
    "# Dropdowns for preprocessing and stemming parameters\n",
    "preprocessing_options = ['Split', 'Reg']\n",
    "stemming_options = ['Porter', 'Lancaster', 'No Stemming']\n",
    "\n",
    "preprocessing_dropdown = widgets.Dropdown(\n",
    "    options=preprocessing_options,\n",
    "    description='Preprocessing:',\n",
    "    layout=widgets.Layout(width='45%')\n",
    ")\n",
    "\n",
    "stemming_dropdown = widgets.Dropdown(\n",
    "    options=stemming_options,\n",
    "    description='Stemming:',\n",
    "    layout=widgets.Layout(width='45%')\n",
    ")\n",
    "\n",
    "# Group preprocessing and stemming dropdowns in a container\n",
    "preprocessing_container = widgets.HBox(\n",
    "    [preprocessing_dropdown, stemming_dropdown],\n",
    "    layout=widgets.Layout(\n",
    "        border=f'2px solid {border_color}',\n",
    "        border_radius='10px',\n",
    "        padding='10px',\n",
    "        background_color=container_background_color,\n",
    "        justify_content='space-between',\n",
    "        width='80%'  # Adjust container width\n",
    "    )\n",
    ")\n",
    "\n",
    "# RadioButtons for file selection with toggle button\n",
    "file_options = ['DOCS per Term', 'Terms per Doc']\n",
    "file_selection = widgets.RadioButtons(\n",
    "    options=file_options,\n",
    "    description='File Type:',\n",
    "    layout=widgets.Layout(width='50%')\n",
    ")\n",
    "\n",
    "toggle_button = widgets.ToggleButton(\n",
    "    value=False,\n",
    "    description='Enable/Disable File Selection',\n",
    "    button_style='', \n",
    "    tooltip='Click to enable/disable the file selection widget',\n",
    "    layout=widgets.Layout(width='45%')\n",
    ")\n",
    "\n",
    "# Combine toggle button and file selection radio buttons\n",
    "file_selection_container = widgets.HBox(\n",
    "    [toggle_button, file_selection],\n",
    "    layout=widgets.Layout(\n",
    "        border=f'2px solid {border_color}',\n",
    "        border_radius='10px',\n",
    "        padding='10px',\n",
    "        background_color=background_color,\n",
    "        justify_content='space-between',\n",
    "        width='80%'  # Adjust container width\n",
    "    )\n",
    ")\n",
    "\n",
    "# Toggle function to enable/disable the file selection\n",
    "def on_toggle_button_change(change):\n",
    "    file_selection.disabled = not change['new']  \n",
    "\n",
    "toggle_button.observe(on_toggle_button_change, names='value')\n",
    "\n",
    "def is_file_selection_enabled():\n",
    "    return not file_selection.disabled\n",
    "\n",
    "# RadioButtons for model selection\n",
    "models_options = ['Scalar Product', 'Cosine Measure', 'Jaccard Measure']\n",
    "model_selection = widgets.RadioButtons(\n",
    "    options=models_options,\n",
    "    description='Vector space model:',\n",
    "    layout=widgets.Layout(width='80%')  # Adjust width to match other elements\n",
    ")\n",
    "\n",
    "# Group dropdowns and model selection in a single container\n",
    "dropdowns_container = widgets.VBox(\n",
    "    [preprocessing_container, file_selection_container, model_selection],\n",
    "    layout=widgets.Layout(\n",
    "        border=f'2px solid {border_color}',\n",
    "        border_radius='10px',\n",
    "        padding='15px',\n",
    "        background_color=background_color,\n",
    "        width='85%'  # Adjust container width\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# Create a text area to display results\n",
    "result_area = widgets.Textarea(\n",
    "    description='Results:',\n",
    "    placeholder='Results will be displayed here',\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(\n",
    "        width='100%',\n",
    "        height='300px',\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Function to handle button click\n",
    "def on_submit(b):\n",
    "    query = query_input.value\n",
    "    preprocessing = preprocessing_dropdown.value\n",
    "    stemming = stemming_dropdown.value\n",
    "    selected_file = file_selection.value\n",
    "    result_content = \"\"\n",
    "    if is_file_selection_enabled():\n",
    "        file_path = \"\"\n",
    "        if selected_file == \"Terms per Doc\":  # descriptive file\n",
    "            if preprocessing == \"Split\":\n",
    "                match stemming:\n",
    "                    case 'No Stemming':\n",
    "                        file_path = 'descripteur_split.txt'\n",
    "                    case 'Porter':\n",
    "                        file_path = 'descripteur_split_porter.txt'\n",
    "                    case 'Lancaster':\n",
    "                        file_path = 'descripteur_split_lancaster.txt'\n",
    "            else:\n",
    "                match stemming:\n",
    "                    case 'No Stemming':\n",
    "                        file_path = 'descripteur_reg.txt'\n",
    "                    case 'Porter':\n",
    "                        file_path = 'descripteur_reg_porter.txt'\n",
    "                    case 'Lancaster':\n",
    "                        file_path = 'descripteur_reg_lancaster.txt'\n",
    "        else:  # inverse file\n",
    "            if preprocessing == \"Split\":\n",
    "                match stemming:\n",
    "                    case 'No Stemming':\n",
    "                        file_path = 'inverse_split.txt'\n",
    "                    case 'Porter':\n",
    "                        file_path = 'inverse_split_porter.txt'\n",
    "                        query = Porter.stem(query)\n",
    "                    case 'Lancaster':\n",
    "                        file_path = 'inverse_split_lancaster.txt'\n",
    "                        query = Lancaster.stem(query)\n",
    "            else:\n",
    "                match stemming:\n",
    "                    case 'No Stemming':\n",
    "                        file_path = 'inverse_reg.txt'\n",
    "                    case 'Porter':\n",
    "                        file_path = 'inverse_reg_porter.txt'\n",
    "                        query = Porter.stem(query)\n",
    "                        mdict = rsv(query,'Porter','Reg')\n",
    "                        print(mdict)\n",
    "                        for doc,v in mdict.items():\n",
    "                            formatted_line = f\"{doc:<3} {v:<3}\\n\"\n",
    "                            result_content += formatted_line\n",
    "                    case 'Lancaster':\n",
    "                        file_path = 'inverse_reg_lancaster.txt'\n",
    "                        query = Lancaster.stem(query)\n",
    "\n",
    "        # Initialize result content with the correct header and numbered lines\n",
    "        line_counter = 1\n",
    "        if selected_file == \"Terms per Doc\":\n",
    "            result_content = \"N  Ndoc   Term           Freq   Weight  Positions\\n\"\n",
    "        \n",
    "            # Track terms and frequencies for the selected document\n",
    "            term_count = 0\n",
    "        \n",
    "        \n",
    "             # Filter the file content based on query and file type\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                lines = file.readlines()\n",
    "                for line in lines:\n",
    "                    parts = line.split()\n",
    "                    if parts[0] == query:\n",
    "                        # Format and add the numbered line to result_content\n",
    "                        formatted_line = f\"{line_counter:<3} {parts[0]:<5} {parts[1]:<15} {parts[2]:<5} {parts[3]:<10} {parts[4]:<10}\\n\"\n",
    "                        result_content += formatted_line\n",
    "                        line_counter += 1\n",
    "                        term_count += int(parts[2])  # Increment by term frequency\n",
    "                \n",
    "            # Append document vocabulary and size\n",
    "            result_content += f\"-------------------------------------------------------------------\"\n",
    "            result_content += f\"\\n# Doc vocabulary: {line_counter-1}               \"\n",
    "            result_content += f\"# Doc size: {term_count}\\n\"\n",
    "    \n",
    "        else:\n",
    "            result_content = \"N   Term            Ndoc   Freq   Weight\\n\"\n",
    "        \n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                lines = file.readlines()\n",
    "                for line in lines:\n",
    "                    parts = line.split()\n",
    "                    if parts[1] == query:\n",
    "                        formatted_line = f\"{parts[0]:<3} {parts[1]:<15} {parts[2]:<5} {parts[3]:<5} {parts[4]:<10}\\n\"\n",
    "                        result_content += formatted_line\n",
    "                        line_counter += 1\n",
    "\n",
    "  \n",
    "        if line_counter == 1:  # Only header is present\n",
    "            result_content += \"No matching results found.\"\n",
    "    \n",
    "    else:\n",
    "        my_dict = rsv(query,stemming,preprocessing)\n",
    "        #print(stemming)\n",
    "        #print(preprocessing)\n",
    "        for doc,v in my_dict.items():\n",
    "            formatted_line = f\"{doc:<3} {v:<3}\\n\"\n",
    "            result_content += formatted_line\n",
    "\n",
    "\n",
    "    result_area.value = result_content\n",
    "\n",
    "submit_button.on_click(on_submit)\n",
    "\n",
    "# Display all widgets\n",
    "display(query_container, dropdowns_container, result_area)\n",
    "#information retrieval\n",
    "#Large language models (LLM)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

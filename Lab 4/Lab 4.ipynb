{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "\n",
    "for i in range(6):\n",
    "    with open('..\\\\Collection\\\\D'+str(i+1)+'.txt', 'r', encoding='utf-8') as file:\n",
    "        documents.append(file.read())\n",
    "       \n",
    "\n",
    "print(len(documents))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Reformulation(QR) is a set of techniques used to transform a user’s original search query to a text that better aligns with the user’s intent and improves their search experience. Recently, zero-shot QR has been shown to be a promising approach due to its ability to exploit knowledge inherent in large language models. By taking inspiration from the success of ensemble prompting strategies which have benefited many tasks, we investigate if they can help improve query reformulation. In this context, we propose an ensemble based prompting technique, GenQREnsemble which leverages paraphrases of a zero-shot instruction to generate multiple sets of keywords ultimately improving retrieval performance. We further introduce its post-retrieval variant, GenQREnsembleRF to incorporate pseudo relevant feedback. On evaluations over four IR benchmarks, we find that GenQREnsemble generates better reformulations with relative nDCG@10 improvements up to 18% and MAP improvements upto 24% over the previous zero-shot state-of-art. On the MSMarco Passage Ranking task, GenQREnsembleRF shows relative gains of 5% MRR using pseudo-relevance feedback, and 9% nDCG@10 using relevant feedback documents.\n"
     ]
    }
   ],
   "source": [
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency(terms):\n",
    "\n",
    "    values = terms\n",
    "    \n",
    "    # Dictionary to store the frequency of each value\n",
    "    frequency_dict = {}\n",
    "    \n",
    "    # Iterate over the values and count frequencies\n",
    "    \n",
    "    for i in range(len(values)):\n",
    "        if values[i] in frequency_dict:\n",
    "            frequency_dict[values[i]] += 1\n",
    "        else:\n",
    "            frequency_dict[values[i]] = 1\n",
    "    \n",
    "    \n",
    "    return frequency_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "def poids(frequency,max_frequency,collection_frequency,n):\n",
    "\n",
    "    poids = (frequency / max_frequency) * (math.log10(1+ (n / collection_frequency)))\n",
    "    \n",
    "    return poids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positions(terms):\n",
    "    positions_dict = {}\n",
    "    \n",
    "    for i in range(len(terms)):\n",
    "        if terms[i] in positions_dict:\n",
    "            positions_dict[terms[i]].append(i + 1)\n",
    "        else:\n",
    "            positions_dict[terms[i]] = [i + 1]\n",
    "    \n",
    "    return positions_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spliting words using split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "StopWords = nltk.corpus.stopwords.words('english') \n",
    "\n",
    "# Initialize variables\n",
    "\n",
    "#list that containes the unique terms of each document using split\n",
    "termes_split = []\n",
    "\n",
    "#list that containes the unique terms along with their frecuencies of each document using split\n",
    "frequency_dict_split_documents = []\n",
    "\n",
    "#list that containes max frequency of each document using split\n",
    "max_frequency_dict_split_documents = []\n",
    "\n",
    "#list that containes the unique terms along with their frecuencies of all the collection using split\n",
    "document_frequency_dict_split = {}\n",
    "\n",
    "#to store the postions of each term in the document\n",
    "split_positions = []\n",
    "\n",
    "\n",
    "# Filtering out stopwords and calculating frequencies in one loop\n",
    "for i in range(6):\n",
    "    unique_stems = list(set([term for term in documents[i].split() if term.lower() not in StopWords]))\n",
    "    # Calculate positions\n",
    "    positions_dict = get_positions(documents[i].split())\n",
    "    split_positions.append(positions_dict)\n",
    "\n",
    "    filtered_terms = [term for term in documents[i].split() if term.lower() not in StopWords] # we need it to calculate frequencies\n",
    "    \n",
    "    termes_split.append(unique_stems)\n",
    "    \n",
    "    frequency_dict = frequency(filtered_terms)\n",
    "    frequency_dict_split_documents.append(frequency_dict)\n",
    "    max_frequency_dict_split_documents.append(max(frequency_dict.values()))\n",
    "    \n",
    "    # Calculate document frequency for each unique term in the whole collection\n",
    "    for term in unique_stems:\n",
    "        if term in document_frequency_dict_split:\n",
    "            document_frequency_dict_split[term] += 1\n",
    "        else:\n",
    "            document_frequency_dict_split[term] = 1\n",
    "\n",
    "n_split = len(termes_split)\n",
    "print(len(termes_split))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ranking': [1, 82],\n",
       " 'documents': [2, 15],\n",
       " 'using': [3, 76, 101, 163],\n",
       " 'Large': [4],\n",
       " 'Language': [5],\n",
       " 'Models': [6],\n",
       " '(LLMs)': [7],\n",
       " 'by': [8, 47, 75, 155, 183, 189],\n",
       " 'directly': [9],\n",
       " 'feeding': [10],\n",
       " 'the': [11, 17, 71, 88, 91, 113, 122, 127, 133, 164, 178],\n",
       " 'query': [12],\n",
       " 'and': [13, 22, 42, 50, 108, 176, 185, 206],\n",
       " 'candidate': [14],\n",
       " 'into': [16],\n",
       " 'prompt': [18, 166],\n",
       " 'is': [19, 130, 210],\n",
       " 'an': [20],\n",
       " 'interesting': [21],\n",
       " 'practical': [23],\n",
       " 'problem.': [24],\n",
       " 'However,': [25],\n",
       " 'researchers': [26],\n",
       " 'have': [27],\n",
       " 'found': [28],\n",
       " 'it': [29, 209],\n",
       " 'difficult': [30],\n",
       " 'to': [31, 68, 93, 203, 212],\n",
       " 'outperform': [32],\n",
       " 'fine-tuned': [33],\n",
       " 'baseline': [34],\n",
       " 'rankers': [35],\n",
       " 'on': [36, 73, 98, 112, 132, 168, 193],\n",
       " 'benchmark': [37],\n",
       " 'datasets.': [38],\n",
       " 'We': [39],\n",
       " 'analyze': [40],\n",
       " 'pointwise': [41, 186],\n",
       " 'listwise': [43],\n",
       " 'ranking': [44, 61, 96, 160],\n",
       " 'prompts': [45],\n",
       " 'used': [46],\n",
       " 'existing': [48],\n",
       " 'methods': [49],\n",
       " 'argue': [51],\n",
       " 'that': [52, 137, 208],\n",
       " 'off-the-shelf': [53],\n",
       " 'LLMs': [54, 74],\n",
       " 'do': [55],\n",
       " 'not': [56],\n",
       " 'fully': [57],\n",
       " 'understand': [58],\n",
       " 'these': [59],\n",
       " 'challenging': [60],\n",
       " 'formulations.': [62],\n",
       " 'In': [63],\n",
       " 'this': [64],\n",
       " 'paper,': [65],\n",
       " 'we': [66, 197],\n",
       " 'propose': [67, 198],\n",
       " 'significantly': [69],\n",
       " 'reduce': [70],\n",
       " 'burden': [72],\n",
       " 'a': [77],\n",
       " 'new': [78],\n",
       " 'technique': [79],\n",
       " 'called': [80],\n",
       " 'Pairwise': [81],\n",
       " 'Prompting': [83],\n",
       " '(PRP).': [84],\n",
       " 'Our': [85],\n",
       " 'results': [86, 215],\n",
       " 'are': [87],\n",
       " 'first': [89],\n",
       " 'in': [90, 126],\n",
       " 'literature': [92],\n",
       " 'achieve': [94, 213],\n",
       " 'state-of-the-art': [95],\n",
       " 'performance': [97],\n",
       " 'standard': [99],\n",
       " 'benchmarks': [100],\n",
       " 'moderate-sized': [102],\n",
       " 'open-sourced': [103],\n",
       " 'LLMs.': [104],\n",
       " 'On': [105],\n",
       " 'TREC-DL': [106],\n",
       " '2019': [107],\n",
       " '2020,': [109],\n",
       " 'PRP': [110, 172, 202],\n",
       " 'based': [111, 131],\n",
       " 'Flan-UL2': [114],\n",
       " 'model': [115, 141],\n",
       " 'with': [116, 121, 217],\n",
       " '20B': [117],\n",
       " 'parameters': [118],\n",
       " 'performs': [119],\n",
       " 'favorably': [120],\n",
       " 'previous': [123],\n",
       " 'best': [124],\n",
       " 'approach': [125],\n",
       " 'literature,': [128],\n",
       " 'which': [129, 151],\n",
       " 'blackbox': [134, 179],\n",
       " 'commercial': [135, 180],\n",
       " 'GPT-4': [136],\n",
       " 'has': [138, 152],\n",
       " '50x': [139],\n",
       " '(estimated)': [140],\n",
       " 'size,': [142],\n",
       " 'while': [143],\n",
       " 'outperforming': [144],\n",
       " 'other': [145],\n",
       " 'LLM-based': [146, 187],\n",
       " 'solutions,': [147],\n",
       " 'such': [148],\n",
       " 'as': [149],\n",
       " 'InstructGPT': [150],\n",
       " '175B': [153],\n",
       " 'parameters,': [154],\n",
       " 'over': [156],\n",
       " '10%': [157],\n",
       " 'for': [158],\n",
       " 'all': [159],\n",
       " 'metrics.': [161],\n",
       " 'By': [162],\n",
       " 'same': [165],\n",
       " 'template': [167],\n",
       " 'seven': [169],\n",
       " 'BEIR': [170],\n",
       " 'tasks,': [171],\n",
       " 'outperforms': [173, 177],\n",
       " 'supervised': [174],\n",
       " 'baselines': [175],\n",
       " 'ChatGPT': [181],\n",
       " 'solution': [182],\n",
       " '4.2%': [184],\n",
       " 'solutions': [188],\n",
       " 'more': [190],\n",
       " 'than': [191],\n",
       " '12-10%': [192],\n",
       " 'average': [194],\n",
       " 'NDCG@10.': [195],\n",
       " 'Furthermore,': [196],\n",
       " 'several': [199],\n",
       " 'variants': [200],\n",
       " 'of': [201],\n",
       " 'improve': [204],\n",
       " 'efficiency': [205],\n",
       " 'show': [207],\n",
       " 'possible': [211],\n",
       " 'competitive': [214],\n",
       " 'even': [216],\n",
       " 'linear': [218],\n",
       " 'complexity': [219]}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_positions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Large': 1, 'language': 1, 'models': 4, '(LLM)': 1, 'manifested': 1, 'unparalleled': 1, 'modeling': 1, 'capability': 1, 'various': 1, 'tasks,': 1, 'e.g.,': 1, 'multi-step': 1, 'reasoning,': 1, 'input': 1, 'mostly': 1, 'limited': 1, 'plain': 1, 'text,': 1, 'could': 2, 'long': 2, 'contain': 1, 'noisy': 1, 'information.': 1, 'Long': 1, 'text': 1, 'take': 1, 'time': 1, 'process,': 1, 'thus': 1, 'may': 2, 'efficient': 1, 'enough': 1, 'recommender': 1, 'systems': 1, 'require': 1, 'immediate': 1, 'response.': 1, 'LLM-based': 2, 'recommendation': 4, 'models,': 1, 'user': 1, 'item': 1, 'IDs': 3, 'usually': 2, 'filled': 1, 'template': 2, '(i.e.,': 1, 'discrete': 2, 'prompt)': 1, 'allow': 1, 'understand': 1, 'given': 1, 'task,': 1, 'need': 1, 'extensive': 1, 'fine-tuning': 1, 'bridge': 2, 'user/item': 1, 'words': 2, 'unleash': 1, 'power': 1, 'LLM': 1, 'recommendation.': 1, 'address': 1, 'problems,': 1, 'propose': 1, 'distill': 1, 'prompt': 2, 'specific': 1, 'task': 1, 'set': 1, 'continuous': 1, 'vectors': 1, 'reduce': 1, 'inference': 3, 'time.': 1, 'also': 1, 'design': 1, 'training': 3, 'strategy': 1, 'attempt': 1, 'improve': 2, 'efficiency': 4, 'models.': 2, 'Experimental': 1, 'results': 1, 'three': 1, 'real-world': 1, 'datasets': 1, 'demonstrate': 1, 'effectiveness': 1, 'PrOmpt': 1, 'Distillation': 1, '(POD)': 1, 'approach': 1, 'sequential': 1, 'top-N': 1, 'tasks.': 1, 'Although': 1, 'significantly': 1, 'improved,': 1, 'improvement': 1, 'limited.': 1, 'finding': 1, 'inspire': 1, 'researchers': 1, 'community': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(frequency_dict_split_documents[2])\n",
    "len(frequency_dict_split_documents[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "ExpReg = nltk.RegexpTokenizer('(?:[A-Za-z]\\.)+|[A-Za-z]+[\\-@]\\d+(?:\\.\\d+)?|\\d+[A-Za-z]+|\\d+(?:[\\.\\,\\-]\\d+)?%?|\\w+(?:[\\-/]\\w+)*') # \\d : équivalent à [0-9] \n",
    "StopWords = nltk.corpus.stopwords.words('english') \n",
    "\n",
    "\n",
    "# Initialize variables\n",
    "\n",
    "#list that containes the unique terms of each document using regx\n",
    "termes_reg = []\n",
    "\n",
    "#list that containes the unique terms along with their frecuencies of each document using regx\n",
    "frequency_dict_reg_documents = []\n",
    "\n",
    "#list that containes max frequency of each document using split\n",
    "max_frequency_dict_reg_documents = []\n",
    "\n",
    "#list that containes the unique terms along with their frecuencies of all the collection using regx\n",
    "document_frequency_dict_reg = {}\n",
    "\n",
    "reg_positions = []\n",
    "\n",
    "# Filtering out stopwords and calculating frequencies in one loop\n",
    "for i in range(6):\n",
    " \n",
    "\n",
    "    unique_stems = list(set([term for term in ExpReg.tokenize(documents[i]) if term.lower() not in StopWords]))\n",
    "\n",
    "    positions_dict = get_positions(ExpReg.tokenize(documents[i]))\n",
    "    reg_positions.append(positions_dict)\n",
    "\n",
    "    filtered_terms = [term for term in ExpReg.tokenize(documents[i])  if term.lower() not in StopWords]\n",
    "    termes_reg.append(unique_stems)\n",
    "    \n",
    "    # Calculating frequencies of unique_stems\n",
    "  \n",
    "    frequency_dict = frequency(filtered_terms)\n",
    "    frequency_dict_reg_documents.append(frequency_dict)\n",
    "    max_frequency_dict_reg_documents.append(max(frequency_dict.values()))\n",
    "    \n",
    "    # Calculating document frequencies for each unique term in the whole collection\n",
    "    for term in unique_stems:\n",
    "        if term in document_frequency_dict_reg:\n",
    "            document_frequency_dict_reg[term] += 1\n",
    "        else:\n",
    "            document_frequency_dict_reg[term] = 1\n",
    "\n",
    "n_reg = len(termes_reg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ranking': [1, 82],\n",
       " 'documents': [2, 15],\n",
       " 'using': [3, 76, 101, 163],\n",
       " 'Large': [4],\n",
       " 'Language': [5],\n",
       " 'Models': [6],\n",
       " 'LLMs': [7, 54, 74, 104],\n",
       " 'by': [8, 47, 75, 155, 183, 189],\n",
       " 'directly': [9],\n",
       " 'feeding': [10],\n",
       " 'the': [11, 17, 71, 88, 91, 113, 122, 127, 133, 164, 178],\n",
       " 'query': [12],\n",
       " 'and': [13, 22, 42, 50, 108, 176, 185, 206],\n",
       " 'candidate': [14],\n",
       " 'into': [16],\n",
       " 'prompt': [18, 166],\n",
       " 'is': [19, 130, 210],\n",
       " 'an': [20],\n",
       " 'interesting': [21],\n",
       " 'practical': [23],\n",
       " 'problem': [24],\n",
       " 'However': [25],\n",
       " 'researchers': [26],\n",
       " 'have': [27],\n",
       " 'found': [28],\n",
       " 'it': [29, 209],\n",
       " 'difficult': [30],\n",
       " 'to': [31, 68, 93, 203, 212],\n",
       " 'outperform': [32],\n",
       " 'fine-tuned': [33],\n",
       " 'baseline': [34],\n",
       " 'rankers': [35],\n",
       " 'on': [36, 73, 98, 112, 132, 168, 193],\n",
       " 'benchmark': [37],\n",
       " 'datasets': [38],\n",
       " 'We': [39],\n",
       " 'analyze': [40],\n",
       " 'pointwise': [41, 186],\n",
       " 'listwise': [43],\n",
       " 'ranking': [44, 61, 96, 160],\n",
       " 'prompts': [45],\n",
       " 'used': [46],\n",
       " 'existing': [48],\n",
       " 'methods': [49],\n",
       " 'argue': [51],\n",
       " 'that': [52, 137, 208],\n",
       " 'off-the-shelf': [53],\n",
       " 'do': [55],\n",
       " 'not': [56],\n",
       " 'fully': [57],\n",
       " 'understand': [58],\n",
       " 'these': [59],\n",
       " 'challenging': [60],\n",
       " 'formulations': [62],\n",
       " 'In': [63],\n",
       " 'this': [64],\n",
       " 'paper': [65],\n",
       " 'we': [66, 197],\n",
       " 'propose': [67, 198],\n",
       " 'significantly': [69],\n",
       " 'reduce': [70],\n",
       " 'burden': [72],\n",
       " 'a': [77],\n",
       " 'new': [78],\n",
       " 'technique': [79],\n",
       " 'called': [80],\n",
       " 'Pairwise': [81],\n",
       " 'Prompting': [83],\n",
       " 'PRP': [84, 110, 172, 202],\n",
       " 'Our': [85],\n",
       " 'results': [86, 215],\n",
       " 'are': [87],\n",
       " 'first': [89],\n",
       " 'in': [90, 126],\n",
       " 'literature': [92, 128],\n",
       " 'achieve': [94, 213],\n",
       " 'state-of-the-art': [95],\n",
       " 'performance': [97],\n",
       " 'standard': [99],\n",
       " 'benchmarks': [100],\n",
       " 'moderate-sized': [102],\n",
       " 'open-sourced': [103],\n",
       " 'On': [105],\n",
       " 'TREC-DL': [106],\n",
       " '2019': [107],\n",
       " '2020': [109],\n",
       " 'based': [111, 131],\n",
       " 'Flan-UL2': [114],\n",
       " 'model': [115, 141],\n",
       " 'with': [116, 121, 217],\n",
       " '20B': [117],\n",
       " 'parameters': [118, 154],\n",
       " 'performs': [119],\n",
       " 'favorably': [120],\n",
       " 'previous': [123],\n",
       " 'best': [124],\n",
       " 'approach': [125],\n",
       " 'which': [129, 151],\n",
       " 'blackbox': [134, 179],\n",
       " 'commercial': [135, 180],\n",
       " 'GPT-4': [136],\n",
       " 'has': [138, 152],\n",
       " '50x': [139],\n",
       " 'estimated': [140],\n",
       " 'size': [142],\n",
       " 'while': [143],\n",
       " 'outperforming': [144],\n",
       " 'other': [145],\n",
       " 'LLM-based': [146, 187],\n",
       " 'solutions': [147, 188],\n",
       " 'such': [148],\n",
       " 'as': [149],\n",
       " 'InstructGPT': [150],\n",
       " '175B': [153],\n",
       " 'over': [156],\n",
       " '10%': [157],\n",
       " 'for': [158],\n",
       " 'all': [159],\n",
       " 'metrics': [161],\n",
       " 'By': [162],\n",
       " 'same': [165],\n",
       " 'template': [167],\n",
       " 'seven': [169],\n",
       " 'BEIR': [170],\n",
       " 'tasks': [171],\n",
       " 'outperforms': [173, 177],\n",
       " 'supervised': [174],\n",
       " 'baselines': [175],\n",
       " 'ChatGPT': [181],\n",
       " 'solution': [182],\n",
       " '4.2%': [184],\n",
       " 'more': [190],\n",
       " 'than': [191],\n",
       " '12-10%': [192],\n",
       " 'average': [194],\n",
       " 'NDCG@10': [195],\n",
       " 'Furthermore': [196],\n",
       " 'several': [199],\n",
       " 'variants': [200],\n",
       " 'of': [201],\n",
       " 'improve': [204],\n",
       " 'efficiency': [205],\n",
       " 'show': [207],\n",
       " 'possible': [211],\n",
       " 'competitive': [214],\n",
       " 'even': [216],\n",
       " 'linear': [218],\n",
       " 'complexity': [219]}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_positions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "termes_split_porter = []\n",
    "termes_reg_porter = []\n",
    "Porter = nltk.PorterStemmer()\n",
    "\n",
    "#list that containes the unique terms along with their frecuencies of each document using split and porter\n",
    "frequency_dict_split_porter_documents = []\n",
    "\n",
    "#list that containes max frequency of each document using split and porter\n",
    "max_frequency_dict_split_porter_documents = []\n",
    "\n",
    "#list that containes the unique terms along with their frecuencies of all the collection using split and porter\n",
    "document_frequency_dict_split_porter = {}\n",
    "\n",
    "#list that containes the unique terms along with their frecuencies of each document using regx and porter\n",
    "frequency_dict_reg_porter_documents = []\n",
    "\n",
    "#list that containes max frequency of each document using regx and porter\n",
    "max_frequency_dict_reg_porter_documents = []\n",
    "\n",
    "#list that containes the unique terms along with their frecuencies of all the collection using regx and porter\n",
    "document_frequency_dict_reg_porter = {}\n",
    "\n",
    "split_porter_positions = []\n",
    "\n",
    "reg_porter_positions = []\n",
    "\n",
    "for i in range(6):\n",
    "    # Stemming and keeping only unique terms for `termes_split_porter`\n",
    "    unique_stems = list(set([Porter.stem(terme) for terme in documents[i].split() if terme.lower() not in StopWords]))\n",
    "    termes_split_porter.append(unique_stems)\n",
    "\n",
    "    positions_dict = get_positions([Porter.stem(terme) for terme in documents[i].split()])\n",
    "    split_porter_positions.append(positions_dict)\n",
    "    \n",
    "    # Calculating frequencies of unique_stems\n",
    "    filtered_terms = [Porter.stem(terme) for terme in documents[i].split() if terme.lower() not in StopWords]\n",
    "    frequency_dict = frequency(filtered_terms)\n",
    "    frequency_dict_split_porter_documents.append(frequency_dict)\n",
    "    max_frequency_dict_split_porter_documents.append(max(frequency_dict.values()))\n",
    "    \n",
    "    # Calculate document frequency for each unique term in the whole collection\n",
    "    for term in unique_stems:\n",
    "        if term in document_frequency_dict_split_porter:\n",
    "            document_frequency_dict_split_porter[term] += 1\n",
    "        else:\n",
    "            document_frequency_dict_split_porter[term] = 1\n",
    "   \n",
    "\n",
    "    # Stemming and keeping only unique terms for `termes_reg_porter`\n",
    "    unique_stems = list(set([Porter.stem(terme) for terme in ExpReg.tokenize(documents[i]) if terme.lower() not in StopWords]))\n",
    "    termes_reg_porter.append(unique_stems)\n",
    "\n",
    "    positions_dict = get_positions([Porter.stem(terme) for terme in ExpReg.tokenize(documents[i])])\n",
    "    reg_porter_positions.append(positions_dict)\n",
    "    \n",
    "    # Calculating frequencies of unique_stems\n",
    "    filtered_terms = [Porter.stem(terme) for terme in ExpReg.tokenize(documents[i])  if terme.lower() not in StopWords]\n",
    "    frequency_dict = frequency(filtered_terms)\n",
    "    frequency_dict_reg_porter_documents.append(frequency_dict)\n",
    "    max_frequency_dict_reg_porter_documents.append(max(frequency_dict.values()))\n",
    "    \n",
    "    # Calculate document frequency for each unique term\n",
    "    for term in unique_stems:\n",
    "        if term in document_frequency_dict_reg_porter:\n",
    "            document_frequency_dict_reg_porter[term] += 1\n",
    "        else:\n",
    "            document_frequency_dict_reg_porter[term] = 1\n",
    "   \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'session': [1, 96, 103],\n",
       " 'search': [2, 219],\n",
       " 'involv': [3],\n",
       " 'a': [4, 44, 88, 149, 157, 208],\n",
       " 'seri': [5],\n",
       " 'of': [6, 68, 78, 90, 159, 201],\n",
       " 'interact': [7, 33, 105],\n",
       " 'queri': [8],\n",
       " 'and': [9, 71, 107, 127, 170, 188, 196, 210, 221],\n",
       " 'action': [10],\n",
       " 'to': [11, 65, 94, 140, 144, 152, 174, 177, 184],\n",
       " 'fulfil': [12],\n",
       " 'user': [13],\n",
       " 's': [14],\n",
       " 'complex': [15],\n",
       " 'inform': [16, 41, 181],\n",
       " 'need': [17],\n",
       " 'current': [18],\n",
       " 'strategi': [19, 220],\n",
       " 'typic': [20],\n",
       " 'priorit': [21],\n",
       " 'sequenti': [22],\n",
       " 'model': [23, 53, 82],\n",
       " 'for': [24, 47, 113],\n",
       " 'deep': [25],\n",
       " 'semant': [26, 52],\n",
       " 'understand': [27],\n",
       " 'overlook': [28],\n",
       " 'the': [29, 50, 76, 114, 118, 128, 179, 199, 215],\n",
       " 'graph': [30, 60, 97, 146],\n",
       " 'structur': [31, 40, 147],\n",
       " 'in': [32, 54],\n",
       " 'while': [34],\n",
       " 'some': [35],\n",
       " 'approach': [36, 73, 203],\n",
       " 'focu': [37],\n",
       " 'on': [38, 124, 191],\n",
       " 'captur': [39, 145, 178],\n",
       " 'they': [42],\n",
       " 'use': [43, 133],\n",
       " 'gener': [45, 169, 171],\n",
       " 'represent': [46],\n",
       " 'document': [48],\n",
       " 'neglect': [49],\n",
       " 'word-level': [51],\n",
       " 'thi': [55, 100, 154],\n",
       " 'paper': [56],\n",
       " 'we': [57, 85, 131, 155],\n",
       " 'propos': [58],\n",
       " 'symbol': [59, 91, 129, 161],\n",
       " 'ranker': [61],\n",
       " 'sgr': [62],\n",
       " 'which': [63],\n",
       " 'aim': [64],\n",
       " 'take': [66],\n",
       " 'advantag': [67],\n",
       " 'both': [69],\n",
       " 'text-bas': [70],\n",
       " 'graph-bas': [72],\n",
       " 'by': [74],\n",
       " 'leverag': [75],\n",
       " 'power': [77],\n",
       " 'recent': [79],\n",
       " 'larg': [80],\n",
       " 'languag': [81, 130],\n",
       " 'llm': [83, 115, 122, 142, 176, 223],\n",
       " 'concret': [84],\n",
       " 'first': [86],\n",
       " 'introduc': [87, 156],\n",
       " 'set': [89, 158],\n",
       " 'grammar': [92, 136],\n",
       " 'rule': [93],\n",
       " 'convert': [95],\n",
       " 'into': [98],\n",
       " 'text': [99],\n",
       " 'allow': [101],\n",
       " 'integr': [102],\n",
       " 'histori': [104],\n",
       " 'process': [106],\n",
       " 'task': [108, 163],\n",
       " 'instruct': [109],\n",
       " 'seamlessli': [110],\n",
       " 'as': [111],\n",
       " 'input': [112],\n",
       " 'moreov': [116],\n",
       " 'given': [117],\n",
       " 'natur': [119],\n",
       " 'discrep': [120],\n",
       " 'between': [121, 217],\n",
       " 'pre-train': [123],\n",
       " 'textual': [125, 150],\n",
       " 'corpora': [126],\n",
       " 'produc': [132],\n",
       " 'our': [134, 137, 202, 204],\n",
       " 'graph-to-text': [135],\n",
       " 'object': [138],\n",
       " 'is': [139],\n",
       " 'enhanc': [141],\n",
       " 'abil': [143],\n",
       " 'within': [148],\n",
       " 'format': [151],\n",
       " 'achiev': [153],\n",
       " 'self-supervis': [160],\n",
       " 'learn': [162, 173],\n",
       " 'includ': [164],\n",
       " 'link': [165],\n",
       " 'predict': [166],\n",
       " 'node': [167],\n",
       " 'content': [168],\n",
       " 'contrast': [172],\n",
       " 'enabl': [175],\n",
       " 'topolog': [180],\n",
       " 'from': [182],\n",
       " 'coarse-grain': [183],\n",
       " 'fine-grain': [185],\n",
       " 'experi': [186],\n",
       " 'result': [187],\n",
       " 'comprehens': [189],\n",
       " 'analysi': [190],\n",
       " 'two': [192],\n",
       " 'benchmark': [193],\n",
       " 'dataset': [194],\n",
       " 'aol': [195],\n",
       " 'tiangong-st': [197],\n",
       " 'confirm': [198],\n",
       " 'superior': [200],\n",
       " 'paradigm': [205],\n",
       " 'also': [206],\n",
       " 'offer': [207],\n",
       " 'novel': [209],\n",
       " 'effect': [211],\n",
       " 'methodolog': [212],\n",
       " 'that': [213],\n",
       " 'bridg': [214],\n",
       " 'gap': [216],\n",
       " 'tradit': [218],\n",
       " 'modern': [222]}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_porter_positions[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(frequency_dict_reg_porter_documents[1]))\n",
    "frequency_dict_reg_porter_documents[1][termes_reg_porter[1][40]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "termes_split_lancaster = []\n",
    "termes_reg_lancaster = []\n",
    "Lancaster = nltk.LancasterStemmer() \n",
    "\n",
    "\n",
    "#list that containes the unique terms along with their frecuencies of each document using split and lancaster\n",
    "frequency_dict_split_lancaster_documents = []\n",
    "\n",
    "#list that containes max frequency of each document using split and lancaster\n",
    "max_frequency_dict_split_lancaster_documents = []\n",
    "\n",
    "#list that containes the unique terms along with their frecuencies of all the collection using split and lancaster\n",
    "document_frequency_dict_split_lancaster = {}\n",
    "\n",
    "#list that containes the unique terms along with their frecuencies of each document using regx and lancaster\n",
    "frequency_dict_reg_lancaster_documents = []\n",
    "\n",
    "#list that containes max frequency of each document using regx and lancaster\n",
    "max_frequency_dict_reg_lancaster_documents = []\n",
    "\n",
    "#list that containes the unique terms along with their frecuencies of all the collection using regx and lancaster\n",
    "document_frequency_dict_reg_lancaster = {}\n",
    "\n",
    "split_lancaster_positions = []\n",
    "\n",
    "reg_lancaster_positions = []\n",
    "\n",
    "for i in range(6):\n",
    "    # Stemming and keeping only unique terms for `termes_split_lancaster`\n",
    "    unique_stems = list(set([Lancaster.stem(terme) for terme in documents[i].split() if terme.lower() not in StopWords]))\n",
    "    termes_split_lancaster.append(unique_stems)\n",
    "\n",
    "    positions_dict = get_positions([Lancaster.stem(terme) for terme in documents[i].split()])\n",
    "    split_lancaster_positions.append(positions_dict)\n",
    "    \n",
    "    # Calculating frequencies of unique_stems\n",
    "    filtered_terms = [Lancaster.stem(terme) for terme in documents[i].split() if terme.lower() not in StopWords]\n",
    "    frequency_dict = frequency(filtered_terms)\n",
    "    frequency_dict_split_lancaster_documents.append(frequency_dict)\n",
    "    max_frequency_dict_split_lancaster_documents.append(max(frequency_dict.values()))\n",
    "    \n",
    "    # Calculate document frequency for each unique term\n",
    "    for term in unique_stems:\n",
    "        if term in document_frequency_dict_split_lancaster:\n",
    "            document_frequency_dict_split_lancaster[term] += 1\n",
    "        else:\n",
    "            document_frequency_dict_split_lancaster[term] = 1\n",
    "   \n",
    "\n",
    "    # Stemming and keeping only unique terms for `termes_reg_lancaster`\n",
    "    unique_stems = list(set([Lancaster.stem(terme) for terme in ExpReg.tokenize(documents[i])  if terme.lower() not in StopWords]))\n",
    "    termes_reg_lancaster.append(unique_stems)\n",
    "\n",
    "    positions_dict = get_positions([Lancaster.stem(terme) for terme in ExpReg.tokenize(documents[i])])\n",
    "    reg_lancaster_positions.append(positions_dict)\n",
    "    \n",
    "    # Calculating frequencies of unique_stems\n",
    "    filtered_terms = [Lancaster.stem(terme)for terme in ExpReg.tokenize(documents[i])  if terme.lower() not in StopWords]\n",
    "    frequency_dict = frequency(filtered_terms)\n",
    "    frequency_dict_reg_lancaster_documents.append(frequency_dict)\n",
    "    max_frequency_dict_reg_lancaster_documents.append(max(frequency_dict.values()))\n",
    "    \n",
    "    # Calculate document frequency for each unique term in the whole collection\n",
    "    for term in unique_stems:\n",
    "        if term in document_frequency_dict_reg_lancaster:\n",
    "            document_frequency_dict_reg_lancaster[term] += 1\n",
    "        else:\n",
    "            document_frequency_dict_reg_lancaster[term] = 1\n",
    "   \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rank': [1, 35, 44, 61, 82, 96, 160],\n",
       " 'docu': [2, 15],\n",
       " 'us': [3, 46, 76, 101, 163],\n",
       " 'larg': [4],\n",
       " 'langu': [5],\n",
       " 'model': [6, 115, 141],\n",
       " 'llms': [7, 54, 74, 104],\n",
       " 'by': [8, 47, 75, 155, 162, 183, 189],\n",
       " 'direct': [9],\n",
       " 'fee': [10],\n",
       " 'the': [11, 17, 71, 88, 91, 113, 122, 127, 133, 164, 178],\n",
       " 'query': [12],\n",
       " 'and': [13, 22, 42, 50, 108, 176, 185, 206],\n",
       " 'candid': [14],\n",
       " 'into': [16],\n",
       " 'prompt': [18, 45, 83, 166],\n",
       " 'is': [19, 130, 210],\n",
       " 'an': [20],\n",
       " 'interest': [21],\n",
       " 'pract': [23],\n",
       " 'problem': [24],\n",
       " 'howev': [25],\n",
       " 'research': [26],\n",
       " 'hav': [27],\n",
       " 'found': [28],\n",
       " 'it': [29, 209],\n",
       " 'difficult': [30],\n",
       " 'to': [31, 68, 93, 203, 212],\n",
       " 'outperform': [32, 144, 173, 177],\n",
       " 'fine-tuned': [33],\n",
       " 'baselin': [34, 175],\n",
       " 'on': [36, 73, 98, 105, 112, 132, 168, 193],\n",
       " 'benchmark': [37, 100],\n",
       " 'dataset': [38],\n",
       " 'we': [39, 66, 197],\n",
       " 'analys': [40],\n",
       " 'pointw': [41, 186],\n",
       " 'listw': [43],\n",
       " 'ex': [48],\n",
       " 'method': [49],\n",
       " 'argu': [51],\n",
       " 'that': [52, 137, 208],\n",
       " 'off-the-shelf': [53],\n",
       " 'do': [55],\n",
       " 'not': [56],\n",
       " 'ful': [57],\n",
       " 'understand': [58],\n",
       " 'thes': [59],\n",
       " 'challeng': [60],\n",
       " 'form': [62],\n",
       " 'in': [63, 90, 126],\n",
       " 'thi': [64],\n",
       " 'pap': [65],\n",
       " 'propos': [67, 198],\n",
       " 'sign': [69],\n",
       " 'reduc': [70],\n",
       " 'burd': [72],\n",
       " 'a': [77],\n",
       " 'new': [78],\n",
       " 'techn': [79],\n",
       " 'cal': [80],\n",
       " 'pairw': [81],\n",
       " 'prp': [84, 110, 172, 202],\n",
       " 'our': [85],\n",
       " 'result': [86, 215],\n",
       " 'ar': [87],\n",
       " 'first': [89],\n",
       " 'lit': [92, 128],\n",
       " 'achiev': [94, 213],\n",
       " 'state-of-the-art': [95],\n",
       " 'perform': [97, 119],\n",
       " 'standard': [99],\n",
       " 'moderate-sized': [102],\n",
       " 'open-sourced': [103],\n",
       " 'trec-dl': [106],\n",
       " '2019': [107],\n",
       " '2020': [109],\n",
       " 'bas': [111, 131],\n",
       " 'flan-ul2': [114],\n",
       " 'with': [116, 121, 217],\n",
       " '20b': [117],\n",
       " 'paramet': [118, 154],\n",
       " 'fav': [120],\n",
       " 'prevy': [123],\n",
       " 'best': [124],\n",
       " 'approach': [125],\n",
       " 'which': [129, 151],\n",
       " 'blackbox': [134, 179],\n",
       " 'commerc': [135, 180],\n",
       " 'gpt-4': [136],\n",
       " 'has': [138, 152],\n",
       " '50x': [139],\n",
       " 'estim': [140],\n",
       " 'siz': [142],\n",
       " 'whil': [143],\n",
       " 'oth': [145],\n",
       " 'llm-based': [146, 187],\n",
       " 'solv': [147, 182, 188],\n",
       " 'such': [148],\n",
       " 'as': [149],\n",
       " 'instructgpt': [150],\n",
       " '175b': [153],\n",
       " 'ov': [156],\n",
       " '10%': [157],\n",
       " 'for': [158],\n",
       " 'al': [159],\n",
       " 'met': [161],\n",
       " 'sam': [165],\n",
       " 'templ': [167],\n",
       " 'sev': [169, 199],\n",
       " 'beir': [170],\n",
       " 'task': [171],\n",
       " 'superv': [174],\n",
       " 'chatgpt': [181],\n",
       " '4.2%': [184],\n",
       " 'mor': [190],\n",
       " 'than': [191],\n",
       " '12-10%': [192],\n",
       " 'av': [194],\n",
       " 'ndcg@10': [195],\n",
       " 'furtherm': [196],\n",
       " 'vary': [200],\n",
       " 'of': [201],\n",
       " 'improv': [204],\n",
       " 'efficy': [205],\n",
       " 'show': [207],\n",
       " 'poss': [211],\n",
       " 'competit': [214],\n",
       " 'ev': [216],\n",
       " 'linear': [218],\n",
       " 'complex': [219]}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_lancaster_positions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'describ': 8,\n",
       " 'item': 2,\n",
       " 'play': 1,\n",
       " 'pivot': 1,\n",
       " 'rol': 1,\n",
       " 'provid': 1,\n",
       " 'cont': 1,\n",
       " 'inform': 1,\n",
       " 'sum': 1,\n",
       " 'capt': 1,\n",
       " 'pot': 1,\n",
       " 'view': 1,\n",
       " 'ess': 1,\n",
       " 'recommend': 1,\n",
       " 'system': 1,\n",
       " 'tradit': 1,\n",
       " 'obtain': 2,\n",
       " 'man': 1,\n",
       " 'web': 1,\n",
       " 'scraping': 1,\n",
       " 'techn': 1,\n",
       " 'time-consuming': 1,\n",
       " 'suscept': 1,\n",
       " 'dat': 1,\n",
       " 'inconsist': 1,\n",
       " 'rec': 1,\n",
       " 'year': 1,\n",
       " 'larg': 1,\n",
       " 'langu': 2,\n",
       " 'model': 1,\n",
       " 'llms': 3,\n",
       " 'gpt-3.5': 1,\n",
       " 'op': 1,\n",
       " 'sourc': 1,\n",
       " 'lik': 2,\n",
       " 'alpac': 2,\n",
       " 'emerg': 1,\n",
       " 'pow': 1,\n",
       " 'tool': 1,\n",
       " 'nat': 1,\n",
       " 'process': 1,\n",
       " 'task': 1,\n",
       " 'pap': 1,\n",
       " 'expl': 1,\n",
       " 'us': 3,\n",
       " 'gen': 4,\n",
       " 'detail': 2,\n",
       " 'conduc': 1,\n",
       " 'study': 1,\n",
       " 'moviel': 1,\n",
       " '1m': 1,\n",
       " 'dataset': 5,\n",
       " 'compr': 1,\n",
       " 'movy': 3,\n",
       " 'titl': 1,\n",
       " 'goodread': 2,\n",
       " 'consist': 1,\n",
       " 'nam': 3,\n",
       " 'book': 1,\n",
       " 'subsequ': 1,\n",
       " 'open-sourced': 1,\n",
       " 'llm': 1,\n",
       " 'prompt': 2,\n",
       " 'few-shot': 1,\n",
       " 'consid': 1,\n",
       " 'multipl': 1,\n",
       " 'feat': 1,\n",
       " 'cast': 1,\n",
       " 'direct': 1,\n",
       " 'ml': 1,\n",
       " 'auth': 1,\n",
       " 'publ': 1,\n",
       " 'comp': 2,\n",
       " 'scraped': 1,\n",
       " 'combin': 1,\n",
       " 'top': 1,\n",
       " 'hit': 1,\n",
       " 'mrr': 1,\n",
       " 'ndcg': 1,\n",
       " 'evalu': 1,\n",
       " 'met': 1,\n",
       " 'result': 2,\n",
       " 'demonst': 1,\n",
       " 'llm-based': 1,\n",
       " 'exhibit': 1,\n",
       " 'sign': 1,\n",
       " 'prom': 1,\n",
       " 'on': 1,\n",
       " 'web-scraped': 1}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(frequency_dict_reg_lancaster_documents[5]))\n",
    "frequency_dict_reg_lancaster_documents[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description file creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  task,  1 0.20068666377598746 [153]\n",
      "1  feedback  1 0.20068666377598746 [169]\n",
      "1  find  1 0.28169934667141894 [125]\n",
      "1  upto  1 0.28169934667141894 [141]\n",
      "1  techniques  1 0.20068666377598746 [7]\n",
      "1  documents.  1 0.28169934667141894 [170]\n",
      "1  Recently,  1 0.28169934667141894 [31]\n",
      "1  nDCG@10  2 0.5633986933428379 [133,166]\n",
      "1  success  1 0.28169934667141894 [59]\n",
      "1  text  1 0.20068666377598746 [18]\n",
      "1  propose  1 0.1141408936074021 [82]\n",
      "1  inspiration  1 0.28169934667141894 [56]\n",
      "1  MSMarco  1 0.28169934667141894 [150]\n",
      "1  state-of-art.  1 0.28169934667141894 [147]\n",
      "1  9%  1 0.28169934667141894 [165]\n",
      "1  zero-shot  3 0.8450980400142568 [32,94,146]\n",
      "1  technique,  1 0.28169934667141894 [87]\n",
      "1  prompting  2 0.4013733275519749 [62,86]\n",
      "1  ensemble  2 0.5633986933428379 [61,84]\n",
      "1  transform  1 0.28169934667141894 [10]\n",
      "1  set  1 0.15904041823988746 [5]\n",
      "1  previous  1 0.15904041823988746 [145]\n",
      "1  shown  1 0.28169934667141894 [36]\n",
      "1  intent  1 0.28169934667141894 [25]\n",
      "1  search  2 0.3180808364797749 [14,29]\n",
      "1  5%  1 0.28169934667141894 [159]\n",
      "1  better  2 0.5633986933428379 [20,129]\n",
      "1  MRR  1 0.28169934667141894 [160]\n",
      "1  feedback,  1 0.28169934667141894 [163]\n",
      "1  large  1 0.28169934667141894 [51]\n",
      "1  pseudo  1 0.28169934667141894 [115]\n",
      "1  retrieval  1 0.20068666377598746 [104]\n",
      "1  Ranking  1 0.20068666377598746 [152]\n",
      "1  performance.  1 0.28169934667141894 [105]\n",
      "1  many  1 0.28169934667141894 [67]\n",
      "1  relevant  2 0.5633986933428379 [116,168]\n",
      "1  experience.  1 0.28169934667141894 [30]\n",
      "1  introduce  1 0.20068666377598746 [108]\n",
      "1  post-retrieval  1 0.28169934667141894 [110]\n",
      "1  tasks,  1 0.15904041823988746 [68]\n",
      "1  18%  1 0.28169934667141894 [137]\n",
      "1  keywords  1 0.28169934667141894 [101]\n",
      "1  help  1 0.28169934667141894 [74]\n",
      "1  knowledge  1 0.28169934667141894 [48]\n",
      "1  investigate  1 0.28169934667141894 [70]\n",
      "1  improving  1 0.28169934667141894 [103]\n",
      "1  improves  1 0.28169934667141894 [27]\n",
      "1  strategies  1 0.15904041823988746 [63]\n",
      "1  approach  1 0.15904041823988746 [41]\n",
      "1  models.  1 0.20068666377598746 [53]\n",
      "1  generates  1 0.28169934667141894 [128]\n",
      "1  GenQREnsemble  2 0.5633986933428379 [88,127]\n",
      "1  QR  1 0.28169934667141894 [33]\n",
      "1  Query  1 0.20068666377598746 [1]\n",
      "1  language  1 0.13264666955734586 [52]\n",
      "1  based  1 0.15904041823988746 [85]\n",
      "1  IR  1 0.28169934667141894 [122]\n",
      "1  generate  1 0.15904041823988746 [97]\n",
      "1  using  2 0.2282817872148042 [161,167]\n",
      "1  due  1 0.28169934667141894 [42]\n",
      "1  context,  1 0.28169934667141894 [80]\n",
      "1  ultimately  1 0.28169934667141894 [102]\n",
      "1  ability  1 0.20068666377598746 [45]\n",
      "1  reformulations  1 0.28169934667141894 [130]\n",
      "1  benchmarks,  1 0.28169934667141894 [123]\n",
      "1  MAP  1 0.28169934667141894 [139]\n",
      "1  inherent  1 0.28169934667141894 [49]\n",
      "1  taking  1 0.28169934667141894 [55]\n",
      "1  instruction  1 0.20068666377598746 [95]\n",
      "1  exploit  1 0.28169934667141894 [47]\n",
      "1  24%  1 0.28169934667141894 [142]\n",
      "1  query  2 0.3180808364797749 [15,76]\n",
      "1  gains  1 0.28169934667141894 [157]\n",
      "1  GenQREnsembleRF  2 0.5633986933428379 [112,154]\n",
      "1  promising  1 0.28169934667141894 [40]\n",
      "1  benefited  1 0.28169934667141894 [66]\n",
      "1  Reformulation(QR)  1 0.28169934667141894 [2]\n",
      "1  evaluations  1 0.28169934667141894 [119]\n",
      "1  reformulation.  1 0.28169934667141894 [77]\n",
      "1  aligns  1 0.28169934667141894 [21]\n",
      "1  improve  1 0.13264666955734586 [75]\n",
      "1  sets  1 0.28169934667141894 [99]\n",
      "1  original  1 0.28169934667141894 [13]\n",
      "1  variant,  1 0.28169934667141894 [111]\n",
      "1  relative  2 0.5633986933428379 [132,156]\n",
      "1  pseudo-relevance  1 0.28169934667141894 [162]\n",
      "1  feedback.  1 0.28169934667141894 [117]\n",
      "1  Passage  1 0.28169934667141894 [151]\n",
      "1  multiple  1 0.15904041823988746 [98]\n",
      "1  used  1 0.15904041823988746 [8]\n",
      "1  user’s  2 0.5633986933428379 [12,24]\n",
      "1  improvements  2 0.5633986933428379 [134,140]\n",
      "1  incorporate  1 0.28169934667141894 [114]\n",
      "1  leverages  1 0.20068666377598746 [90]\n",
      "1  four  1 0.28169934667141894 [121]\n",
      "1  shows  1 0.28169934667141894 [155]\n",
      "1  paraphrases  1 0.28169934667141894 [91]\n",
      "2  technique  1 0.2112745100035642 [79]\n",
      "2  favorably  1 0.2112745100035642 [120]\n",
      "2  20B  1 0.2112745100035642 [117]\n",
      "2  commercial  2 0.4225490200071284 [135,180]\n",
      "2  template  1 0.1505149978319906 [167]\n",
      "2  solutions,  1 0.2112745100035642 [147]\n",
      "2  Flan-UL2  1 0.2112745100035642 [114]\n",
      "2  existing  1 0.2112745100035642 [48]\n",
      "2  significantly  1 0.11928031367991561 [69]\n",
      "2  propose  2 0.17121134041110314 [67,198]\n",
      "2  literature  1 0.2112745100035642 [92]\n",
      "2  candidate  1 0.2112745100035642 [14]\n",
      "2  linear  1 0.2112745100035642 [218]\n",
      "2  listwise  1 0.2112745100035642 [43]\n",
      "2  moderate-sized  1 0.2112745100035642 [102]\n",
      "2  baselines  1 0.2112745100035642 [175]\n",
      "2  parameters,  1 0.2112745100035642 [154]\n",
      "2  fine-tuned  1 0.2112745100035642 [33]\n",
      "2  first  1 0.11928031367991561 [89]\n",
      "2  solution  1 0.2112745100035642 [182]\n",
      "2  (PRP).  1 0.2112745100035642 [84]\n",
      "2  previous  1 0.11928031367991561 [123]\n",
      "2  PRP  3 0.6338235300106926 [110,172,202]\n",
      "2  average  1 0.2112745100035642 [194]\n",
      "2  competitive  1 0.2112745100035642 [214]\n",
      "2  model  2 0.4225490200071284 [115,141]\n",
      "2  open-sourced  1 0.1505149978319906 [103]\n",
      "2  rankers  1 0.2112745100035642 [35]\n",
      "2  outperforming  1 0.2112745100035642 [144]\n",
      "2  seven  1 0.2112745100035642 [169]\n",
      "2  standard  1 0.2112745100035642 [99]\n",
      "2  prompts  1 0.2112745100035642 [45]\n",
      "2  Language  1 0.0994850021680094 [5]\n",
      "2  Prompting  1 0.2112745100035642 [83]\n",
      "2  TREC-DL  1 0.2112745100035642 [106]\n",
      "2  formulations.  1 0.2112745100035642 [62]\n",
      "2  2019  1 0.2112745100035642 [107]\n",
      "2  10%  1 0.2112745100035642 [157]\n",
      "2  directly  1 0.2112745100035642 [9]\n",
      "2  Ranking  2 0.3010299956639812 [1,82]\n",
      "2  175B  1 0.2112745100035642 [153]\n",
      "2  complexity  1 0.2112745100035642 [219]\n",
      "2  BEIR  1 0.1505149978319906 [170]\n",
      "2  problem.  1 0.2112745100035642 [24]\n",
      "2  practical  1 0.2112745100035642 [23]\n",
      "2  several  1 0.2112745100035642 [199]\n",
      "2  documents  2 0.4225490200071284 [2,15]\n",
      "2  (estimated)  1 0.2112745100035642 [140]\n",
      "2  feeding  1 0.2112745100035642 [10]\n",
      "2  tasks,  1 0.11928031367991561 [171]\n",
      "2  ChatGPT  1 0.2112745100035642 [181]\n",
      "2  even  1 0.2112745100035642 [216]\n",
      "2  understand  1 0.1505149978319906 [58]\n",
      "2  paper,  1 0.0994850021680094 [65]\n",
      "2  argue  1 0.2112745100035642 [51]\n",
      "2  datasets.  1 0.2112745100035642 [38]\n",
      "2  off-the-shelf  1 0.2112745100035642 [53]\n",
      "2  approach  1 0.11928031367991561 [125]\n",
      "2  reduce  1 0.1505149978319906 [70]\n",
      "2  50x  1 0.2112745100035642 [139]\n",
      "2  metrics.  1 0.1505149978319906 [161]\n",
      "2  However,  1 0.2112745100035642 [25]\n",
      "2  ranking  4 0.8450980400142568 [44,61,96,160]\n",
      "2  Large  1 0.08560567020555157 [4]\n",
      "2  based  2 0.23856062735983122 [111,131]\n",
      "2  performs  1 0.2112745100035642 [119]\n",
      "2  LLM-based  2 0.23856062735983122 [146,187]\n",
      "2  using  4 0.3424226808222063 [3,76,101,163]\n",
      "2  Furthermore,  1 0.1505149978319906 [196]\n",
      "2  variants  1 0.2112745100035642 [200]\n",
      "2  show  1 0.2112745100035642 [207]\n",
      "2  outperforms  2 0.4225490200071284 [173,177]\n",
      "2  4.2%  1 0.2112745100035642 [184]\n",
      "2  (LLMs)  1 0.1505149978319906 [7]\n",
      "2  NDCG@10.  1 0.2112745100035642 [195]\n",
      "2  achieve  2 0.3010299956639812 [94,213]\n",
      "2  blackbox  2 0.4225490200071284 [134,179]\n",
      "2  Models  1 0.0994850021680094 [6]\n",
      "2  burden  1 0.2112745100035642 [72]\n",
      "2  difficult  1 0.2112745100035642 [30]\n",
      "2  performance  1 0.1505149978319906 [97]\n",
      "2  analyze  1 0.2112745100035642 [40]\n",
      "2  2020,  1 0.2112745100035642 [109]\n",
      "2  efficiency  1 0.1505149978319906 [205]\n",
      "2  query  1 0.11928031367991561 [12]\n",
      "2  outperform  1 0.2112745100035642 [32]\n",
      "2  benchmark  1 0.11928031367991561 [37]\n",
      "2  results  2 0.1989700043360188 [86,215]\n",
      "2  methods  1 0.1505149978319906 [49]\n",
      "2  interesting  1 0.2112745100035642 [21]\n",
      "2  LLMs  2 0.1989700043360188 [54,74]\n",
      "2  solutions  1 0.2112745100035642 [188]\n",
      "2  literature,  1 0.2112745100035642 [128]\n",
      "2  LLMs.  1 0.1505149978319906 [104]\n",
      "2  found  1 0.2112745100035642 [28]\n",
      "2  called  1 0.2112745100035642 [80]\n",
      "2  supervised  1 0.2112745100035642 [174]\n",
      "2  improve  1 0.0994850021680094 [204]\n",
      "2  baseline  1 0.2112745100035642 [34]\n",
      "2  fully  1 0.2112745100035642 [57]\n",
      "2  challenging  1 0.2112745100035642 [60]\n",
      "2  12-10%  1 0.2112745100035642 [192]\n",
      "2  prompt  2 0.3010299956639812 [18,166]\n",
      "2  GPT-4  1 0.2112745100035642 [136]\n",
      "2  new  1 0.2112745100035642 [78]\n",
      "2  parameters  1 0.2112745100035642 [118]\n",
      "2  state-of-the-art  1 0.1505149978319906 [95]\n",
      "2  researchers  1 0.1505149978319906 [26]\n",
      "2  InstructGPT  1 0.2112745100035642 [150]\n",
      "2  benchmarks  1 0.2112745100035642 [100]\n",
      "2  used  1 0.11928031367991561 [46]\n",
      "2  best  1 0.2112745100035642 [124]\n",
      "2  Pairwise  1 0.2112745100035642 [81]\n",
      "2  pointwise  2 0.4225490200071284 [41,186]\n",
      "2  size,  1 0.2112745100035642 [142]\n",
      "2  possible  1 0.2112745100035642 [211]\n",
      "3  text,  1 0.2112745100035642 [27]\n",
      "3  item  1 0.1505149978319906 [65]\n",
      "3  task,  1 0.1505149978319906 [84]\n",
      "3  design  1 0.2112745100035642 [147]\n",
      "3  continuous  1 0.2112745100035642 [129]\n",
      "3  long  2 0.4225490200071284 [32,41]\n",
      "3  template  2 0.3010299956639812 [72,99]\n",
      "3  PrOmpt  1 0.2112745100035642 [173]\n",
      "3  effectiveness  1 0.1505149978319906 [170]\n",
      "3  could  2 0.4225490200071284 [29,39]\n",
      "3  inspire  1 0.2112745100035642 [203]\n",
      "3  reasoning,  1 0.2112745100035642 [15]\n",
      "3  strategy  1 0.2112745100035642 [150]\n",
      "3  significantly  1 0.11928031367991561 [191]\n",
      "3  text  1 0.1505149978319906 [38]\n",
      "3  propose  1 0.08560567020555157 [115]\n",
      "3  enough  1 0.2112745100035642 [51]\n",
      "3  specific  1 0.2112745100035642 [123]\n",
      "3  usually  2 0.4225490200071284 [68,88]\n",
      "3  response.  1 0.2112745100035642 [58]\n",
      "3  power  1 0.1505149978319906 [105]\n",
      "3  time  1 0.2112745100035642 [42]\n",
      "3  information.  1 0.2112745100035642 [36]\n",
      "3  may  2 0.4225490200071284 [47,202]\n",
      "3  demonstrate  1 0.1505149978319906 [168]\n",
      "3  Although  1 0.2112745100035642 [185]\n",
      "3  set  1 0.11928031367991561 [127]\n",
      "3  datasets  1 0.2112745100035642 [167]\n",
      "3  user/item  1 0.2112745100035642 [95]\n",
      "3  tasks.  1 0.1505149978319906 [184]\n",
      "3  unleash  1 0.2112745100035642 [103]\n",
      "3  words  2 0.4225490200071284 [100,138]\n",
      "3  modeling  1 0.1505149978319906 [8]\n",
      "3  inference  3 0.6338235300106926 [143,196,212]\n",
      "3  allow  1 0.2112745100035642 [77]\n",
      "3  process,  1 0.1505149978319906 [44]\n",
      "3  e.g.,  1 0.2112745100035642 [13]\n",
      "3  time.  1 0.1505149978319906 [144]\n",
      "3  Distillation  1 0.2112745100035642 [174]\n",
      "3  mostly  1 0.2112745100035642 [23]\n",
      "3  attempt  1 0.2112745100035642 [153]\n",
      "3  input  1 0.1505149978319906 [18]\n",
      "3  systems  1 0.2112745100035642 [54]\n",
      "3  (LLM)  1 0.2112745100035642 [4]\n",
      "3  manifested  1 0.2112745100035642 [6]\n",
      "3  recommendation  4 0.6020599913279624 [61,180,183,216]\n",
      "3  models  4 0.8450980400142568 [3,21,79,87]\n",
      "3  unparalleled  1 0.2112745100035642 [7]\n",
      "3  address  1 0.2112745100035642 [111]\n",
      "3  models,  1 0.2112745100035642 [62]\n",
      "3  require  1 0.2112745100035642 [56]\n",
      "3  IDs  3 0.6338235300106926 [66,96,136]\n",
      "3  immediate  1 0.2112745100035642 [57]\n",
      "3  Long  1 0.2112745100035642 [37]\n",
      "3  problems,  1 0.2112745100035642 [113]\n",
      "3  tasks,  1 0.11928031367991561 [12]\n",
      "3  understand  1 0.1505149978319906 [81]\n",
      "3  fine-tuning  1 0.2112745100035642 [91]\n",
      "3  LLM  1 0.2112745100035642 [107]\n",
      "3  efficient  1 0.2112745100035642 [50]\n",
      "3  approach  1 0.11928031367991561 [176]\n",
      "3  take  1 0.1505149978319906 [40]\n",
      "3  reduce  1 0.1505149978319906 [141]\n",
      "3  models.  2 0.3010299956639812 [161,217]\n",
      "3  discrete  2 0.4225490200071284 [74,119]\n",
      "3  Large  1 0.08560567020555157 [1]\n",
      "3  various  1 0.1505149978319906 [11]\n",
      "3  language  1 0.0994850021680094 [2]\n",
      "3  limited  1 0.1505149978319906 [24]\n",
      "3  vectors  1 0.2112745100035642 [131]\n",
      "3  (POD)  1 0.2112745100035642 [175]\n",
      "3  LLM-based  2 0.23856062735983122 [60,215]\n",
      "3  recommendation.  1 0.2112745100035642 [109]\n",
      "3  real-world  1 0.2112745100035642 [166]\n",
      "3  task  1 0.1505149978319906 [124]\n",
      "3  improvement  1 0.2112745100035642 [194]\n",
      "3  extensive  1 0.2112745100035642 [90]\n",
      "3  contain  1 0.2112745100035642 [34]\n",
      "3  training  3 0.6338235300106926 [149,159,187]\n",
      "3  Experimental  1 0.2112745100035642 [162]\n",
      "3  need  1 0.2112745100035642 [89]\n",
      "3  also  1 0.1505149978319906 [146]\n",
      "3  user  1 0.2112745100035642 [63]\n",
      "3  community  1 0.2112745100035642 [207]\n",
      "3  sequential  1 0.1505149978319906 [179]\n",
      "3  improved,  1 0.2112745100035642 [192]\n",
      "3  efficiency  4 0.6020599913279624 [157,188,197,213]\n",
      "3  thus  1 0.2112745100035642 [46]\n",
      "3  results  1 0.0994850021680094 [163]\n",
      "3  finding  1 0.2112745100035642 [201]\n",
      "3  three  1 0.2112745100035642 [165]\n",
      "3  capability  1 0.2112745100035642 [9]\n",
      "3  filled  1 0.2112745100035642 [69]\n",
      "3  plain  1 0.2112745100035642 [26]\n",
      "3  limited.  1 0.2112745100035642 [199]\n",
      "3  noisy  1 0.2112745100035642 [35]\n",
      "3  improve  2 0.1989700043360188 [155,210]\n",
      "3  (i.e.,  1 0.2112745100035642 [73]\n",
      "3  given  1 0.1505149978319906 [83]\n",
      "3  multi-step  1 0.2112745100035642 [14]\n",
      "3  prompt  2 0.3010299956639812 [120,130]\n",
      "3  prompt)  1 0.2112745100035642 [75]\n",
      "3  recommender  1 0.2112745100035642 [53]\n",
      "3  researchers  1 0.1505149978319906 [204]\n",
      "3  distill  1 0.2112745100035642 [117]\n",
      "3  bridge  2 0.4225490200071284 [93,135]\n",
      "3  top-N  1 0.2112745100035642 [182]\n",
      "4  optimize  1 0.2112745100035642 [121]\n",
      "4  reformulation  2 0.4225490200071284 [2,156]\n",
      "4  feedback  1 0.1505149978319906 [139]\n",
      "4  retriever  1 0.2112745100035642 [174]\n",
      "4  performance,  1 0.2112745100035642 [152]\n",
      "4  represent  1 0.2112745100035642 [103]\n",
      "4  techniques  1 0.1505149978319906 [165]\n",
      "4  effectiveness  1 0.1505149978319906 [46]\n",
      "4  Retrieval.  1 0.2112745100035642 [182]\n",
      "4  significantly  1 0.11928031367991561 [172]\n",
      "4  propose  1 0.08560567020555157 [55]\n",
      "4  intentions  1 0.2112745100035642 [66]\n",
      "4  Generative  1 0.2112745100035642 [58]\n",
      "4  redundant  1 0.2112745100035642 [41]\n",
      "4  differentiated,  1 0.2112745100035642 [71]\n",
      "4  distinctly  1 0.2112745100035642 [102]\n",
      "4  clusters  1 0.2112745100035642 [97]\n",
      "4  demonstrate  1 0.1505149978319906 [147]\n",
      "4  first  1 0.11928031367991561 [80]\n",
      "4  SOTAs  1 0.2112745100035642 [157]\n",
      "4  previous  1 0.11928031367991561 [154]\n",
      "4  experiments  1 0.2112745100035642 [142]\n",
      "4  well-generated  1 0.2112745100035642 [72]\n",
      "4  advancing  1 0.2112745100035642 [177]\n",
      "4  (IR)  1 0.2112745100035642 [10]\n",
      "4  search  1 0.11928031367991561 [15]\n",
      "4  process  1 0.2112745100035642 [137]\n",
      "4  time.  1 0.1505149978319906 [81]\n",
      "4  prompts,  1 0.2112745100035642 [95]\n",
      "4  integrates  1 0.2112745100035642 [126]\n",
      "4  input  1 0.1505149978319906 [23]\n",
      "4  Language  1 0.0994850021680094 [29]\n",
      "4  rate  1 0.2112745100035642 [18]\n",
      "4  Clustering  1 0.2112745100035642 [59]\n",
      "4  explores  1 0.2112745100035642 [109]\n",
      "4  retrieval  2 0.3010299956639812 [76,122]\n",
      "4  groups  1 0.2112745100035642 [100]\n",
      "4  well-known  1 0.2112745100035642 [5]\n",
      "4  problem  1 0.2112745100035642 [6]\n",
      "4  combine  1 0.2112745100035642 [111]\n",
      "4  variable  1 0.2112745100035642 [87]\n",
      "4  leverage  1 0.2112745100035642 [27]\n",
      "4  adaptively  1 0.2112745100035642 [67]\n",
      "4  BEIR  1 0.1505149978319906 [145]\n",
      "4  crucially  1 0.2112745100035642 [125]\n",
      "4  achieves  1 0.2112745100035642 [150]\n",
      "4  Retrieval  1 0.2112745100035642 [9]\n",
      "4  automatically  1 0.2112745100035642 [20]\n",
      "4  capture  1 0.1505149978319906 [64]\n",
      "4  loops.  1 0.2112745100035642 [140]\n",
      "4  innovative  1 0.2112745100035642 [116]\n",
      "4  novel  1 0.1505149978319906 [128]\n",
      "4  Information  2 0.4225490200071284 [8,181]\n",
      "4  Reformulation  1 0.2112745100035642 [61]\n",
      "4  paper,  1 0.0994850021680094 [53]\n",
      "4  Empirical  1 0.2112745100035642 [141]\n",
      "4  initial  1 0.2112745100035642 [91]\n",
      "4  LLMs,  1 0.2112745100035642 [171]\n",
      "4  strategies  1 0.11928031367991561 [119]\n",
      "4  query.  1 0.2112745100035642 [24]\n",
      "4  boosting  1 0.2112745100035642 [173]\n",
      "4  refine  1 0.2112745100035642 [135]\n",
      "4  surpassing  1 0.2112745100035642 [153]\n",
      "4  Recent  1 0.2112745100035642 [25]\n",
      "4  (QERM)  1 0.2112745100035642 [133]\n",
      "4  intents.  2 0.4225490200071284 [50,105]\n",
      "4  single  1 0.2112745100035642 [14]\n",
      "4  GenCRF:  1 0.2112745100035642 [56]\n",
      "4  GenCRF  2 0.4225490200071284 [82,149]\n",
      "4  Query  2 0.3010299956639812 [1,129]\n",
      "4  nDCG@10.  1 0.2112745100035642 [163]\n",
      "4  Large  1 0.08560567020555157 [28]\n",
      "4  various  1 0.1505149978319906 [170]\n",
      "4  limited  1 0.1505149978319906 [39]\n",
      "4  capturing  1 0.1505149978319906 [48]\n",
      "4  based  1 0.11928031367991561 [68]\n",
      "4  Rewarding  1 0.2112745100035642 [131]\n",
      "4  generate  2 0.23856062735983122 [38,86]\n",
      "4  diverse  4 0.8450980400142568 [49,65,104,112]\n",
      "4  completion  1 0.2112745100035642 [17]\n",
      "4  intents  1 0.2112745100035642 [113]\n",
      "4  using  1 0.08560567020555157 [93]\n",
      "4  Furthermore,  1 0.1505149978319906 [106]\n",
      "4  user's  1 0.1505149978319906 [22]\n",
      "4  field  1 0.2112745100035642 [179]\n",
      "4  aggregation  1 0.2112745100035642 [118]\n",
      "4  (LLMs)  1 0.1505149978319906 [31]\n",
      "4  aimed  1 0.2112745100035642 [11]\n",
      "4  Models  1 0.0994850021680094 [30]\n",
      "4  performance  2 0.3010299956639812 [123,175]\n",
      "4  framework  1 0.2112745100035642 [108]\n",
      "4  query  4 0.47712125471966244 [34,92,114,155]\n",
      "4  expansions,  1 0.2112745100035642 [42]\n",
      "4  Evaluation  1 0.2112745100035642 [130]\n",
      "4  benchmark  1 0.11928031367991561 [146]\n",
      "4  adapted  1 0.2112745100035642 [168]\n",
      "4  methods  1 0.1505149978319906 [26]\n",
      "4  LLMs  1 0.0994850021680094 [84]\n",
      "4  Model  1 0.2112745100035642 [132]\n",
      "4  enhancing  1 0.2112745100035642 [13]\n",
      "4  constraining  1 0.2112745100035642 [44]\n",
      "4  often  1 0.2112745100035642 [37]\n",
      "4  improve  1 0.0994850021680094 [33]\n",
      "4  potentially  1 0.2112745100035642 [43]\n",
      "4  12%  1 0.2112745100035642 [161]\n",
      "4  phase  1 0.2112745100035642 [77]\n",
      "4  state-of-the-art  1 0.1505149978319906 [151]\n",
      "4  successful  1 0.2112745100035642 [16]\n",
      "4  multiple  1 0.11928031367991561 [70]\n",
      "4  Framework  1 0.2112745100035642 [62]\n",
      "4  customized  1 0.2112745100035642 [94]\n",
      "4  modifying  1 0.2112745100035642 [21]\n",
      "4  reformulation,  1 0.2112745100035642 [35]\n",
      "4  leverages  1 0.1505149978319906 [83]\n",
      "4  queries  2 0.3010299956639812 [73,88]\n",
      "4  weighted  1 0.2112745100035642 [117]\n",
      "5  analysis  1 0.28169934667141894 [189]\n",
      "5  graph-based  1 0.28169934667141894 [71]\n",
      "5  integrating  1 0.28169934667141894 [101]\n",
      "5  documents,  1 0.28169934667141894 [47]\n",
      "5  topological  1 0.28169934667141894 [179]\n",
      "5  discrepancy  1 0.28169934667141894 [119]\n",
      "5  representation  1 0.28169934667141894 [45]\n",
      "5  information,  1 0.28169934667141894 [40]\n",
      "5  understanding,  1 0.28169934667141894 [26]\n",
      "5  produce  1 0.28169934667141894 [131]\n",
      "5  superiority  1 0.28169934667141894 [199]\n",
      "5  methodology  1 0.28169934667141894 [211]\n",
      "5  propose  1 0.1141408936074021 [57]\n",
      "5  structures  1 0.28169934667141894 [146]\n",
      "5  inputs  1 0.28169934667141894 [111]\n",
      "5  Session  1 0.28169934667141894 [1]\n",
      "5  modern  1 0.28169934667141894 [221]\n",
      "5  natural  1 0.20068666377598746 [118]\n",
      "5  pre-trained  1 0.28169934667141894 [122]\n",
      "5  text.  1 0.28169934667141894 [98]\n",
      "5  recent  1 0.20068666377598746 [78]\n",
      "5  modeling.  1 0.28169934667141894 [52]\n",
      "5  traditional  1 0.28169934667141894 [217]\n",
      "5  power  1 0.20068666377598746 [76]\n",
      "5  text-based  1 0.28169934667141894 [69]\n",
      "5  semantic  2 0.5633986933428379 [25,51]\n",
      "5  first  1 0.15904041823988746 [85]\n",
      "5  set  2 0.3180808364797749 [88,157]\n",
      "5  content  1 0.28169934667141894 [167]\n",
      "5  Graph  1 0.28169934667141894 [59]\n",
      "5  enable  1 0.28169934667141894 [174]\n",
      "5  fulfill  1 0.28169934667141894 [12]\n",
      "5  Concretely,  1 0.28169934667141894 [83]\n",
      "5  prediction,  1 0.28169934667141894 [165]\n",
      "5  modeling  1 0.20068666377598746 [22]\n",
      "5  interactive  1 0.28169934667141894 [7]\n",
      "5  process,  1 0.20068666377598746 [105]\n",
      "5  prioritize  1 0.28169934667141894 [20]\n",
      "5  search  2 0.3180808364797749 [2,218]\n",
      "5  Symbolic  1 0.28169934667141894 [58]\n",
      "5  confirm  1 0.28169934667141894 [197]\n",
      "5  approach.  1 0.28169934667141894 [202]\n",
      "5  Language  1 0.13264666955734586 [80]\n",
      "5  history,  1 0.28169934667141894 [103]\n",
      "5  interactions.  1 0.28169934667141894 [32]\n",
      "5  involves  1 0.28169934667141894 [3]\n",
      "5  learning,  1 0.28169934667141894 [172]\n",
      "5  comprehensive  1 0.28169934667141894 [188]\n",
      "5  AOL  1 0.28169934667141894 [194]\n",
      "5  generative  1 0.28169934667141894 [170]\n",
      "5  advantage  1 0.28169934667141894 [66]\n",
      "5  complex  1 0.28169934667141894 [14]\n",
      "5  paradigm  1 0.28169934667141894 [204]\n",
      "5  format.  1 0.28169934667141894 [150]\n",
      "5  generation,  1 0.28169934667141894 [168]\n",
      "5  introduce  2 0.4013733275519749 [86,155]\n",
      "5  structure  1 0.28169934667141894 [30]\n",
      "5  capture  2 0.4013733275519749 [144,177]\n",
      "5  tasks  1 0.28169934667141894 [162]\n",
      "5  word-level  1 0.28169934667141894 [50]\n",
      "5  novel  1 0.20068666377598746 [208]\n",
      "5  focus  1 0.28169934667141894 [36]\n",
      "5  paper,  1 0.13264666955734586 [55]\n",
      "5  Ranker  1 0.28169934667141894 [60]\n",
      "5  rules  1 0.28169934667141894 [92]\n",
      "5  grammar  1 0.28169934667141894 [91]\n",
      "5  enhance  1 0.28169934667141894 [140]\n",
      "5  including  1 0.28169934667141894 [163]\n",
      "5  strategies  2 0.3180808364797749 [18,219]\n",
      "5  take  1 0.20068666377598746 [65]\n",
      "5  neglecting  1 0.28169934667141894 [48]\n",
      "5  Tiangong-ST,  1 0.28169934667141894 [196]\n",
      "5  structural  1 0.28169934667141894 [39]\n",
      "5  LLMs'  1 0.28169934667141894 [141]\n",
      "5  deep  1 0.28169934667141894 [24]\n",
      "5  approaches  2 0.5633986933428379 [35,72]\n",
      "5  Large  1 0.1141408936074021 [79]\n",
      "5  language  1 0.13264666955734586 [129]\n",
      "5  capturing  1 0.20068666377598746 [38]\n",
      "5  (SGR),  1 0.28169934667141894 [61]\n",
      "5  seamlessly  1 0.28169934667141894 [109]\n",
      "5  offers  1 0.28169934667141894 [206]\n",
      "5  datasets,  1 0.28169934667141894 [193]\n",
      "5  task  1 0.20068666377598746 [107]\n",
      "5  generalized  1 0.28169934667141894 [44]\n",
      "5  graph-to-text  1 0.28169934667141894 [134]\n",
      "5  typically  1 0.28169934667141894 [19]\n",
      "5  LLM.  1 0.28169934667141894 [114]\n",
      "5  using  1 0.1141408936074021 [132]\n",
      "5  leveraging  1 0.28169934667141894 [74]\n",
      "5  this,  1 0.28169934667141894 [153]\n",
      "5  coarse-grained  1 0.28169934667141894 [182]\n",
      "5  aims  1 0.28169934667141894 [63]\n",
      "5  user's  1 0.20068666377598746 [13]\n",
      "5  use  1 0.20068666377598746 [42]\n",
      "5  Experiment  1 0.28169934667141894 [185]\n",
      "5  grammar,  1 0.28169934667141894 [135]\n",
      "5  session  2 0.5633986933428379 [95,102]\n",
      "5  ability  1 0.20068666377598746 [142]\n",
      "5  (LLMs).  1 0.28169934667141894 [82]\n",
      "5  also  1 0.20068666377598746 [205]\n",
      "5  series  1 0.28169934667141894 [5]\n",
      "5  bridges  1 0.28169934667141894 [213]\n",
      "5  sequential  1 0.20068666377598746 [21]\n",
      "5  achieve  1 0.20068666377598746 [152]\n",
      "5  Models  1 0.13264666955734586 [81]\n",
      "5  Moreover,  1 0.28169934667141894 [115]\n",
      "5  instruction  1 0.20068666377598746 [108]\n",
      "5  effective  1 0.28169934667141894 [210]\n",
      "5  benchmark  1 0.15904041823988746 [192]\n",
      "5  results  1 0.13264666955734586 [186]\n",
      "5  objective  1 0.28169934667141894 [137]\n",
      "5  allows  1 0.28169934667141894 [100]\n",
      "5  two  1 0.28169934667141894 [191]\n",
      "5  learning  1 0.28169934667141894 [161]\n",
      "5  graph  3 0.8450980400142568 [29,96,145]\n",
      "5  LLMs  2 0.2652933391146917 [121,175]\n",
      "5  actions  1 0.28169934667141894 [10]\n",
      "5  corpora,  1 0.28169934667141894 [125]\n",
      "5  self-supervised  1 0.28169934667141894 [159]\n",
      "5  Current  1 0.28169934667141894 [17]\n",
      "5  LLMs.  1 0.20068666377598746 [222]\n",
      "5  convert  1 0.28169934667141894 [94]\n",
      "5  symbolic  3 0.8450980400142568 [90,128,160]\n",
      "5  interaction  1 0.28169934667141894 [104]\n",
      "5  contrastive  1 0.28169934667141894 [171]\n",
      "5  textual  2 0.5633986933428379 [124,149]\n",
      "5  given  1 0.20068666377598746 [116]\n",
      "5  link  1 0.28169934667141894 [164]\n",
      "5  within  1 0.28169934667141894 [147]\n",
      "5  need.  1 0.28169934667141894 [16]\n",
      "5  gap  1 0.28169934667141894 [215]\n",
      "5  information  2 0.5633986933428379 [15,180]\n",
      "5  node  1 0.28169934667141894 [166]\n",
      "5  queries  1 0.20068666377598746 [8]\n",
      "5  fine-grained.  1 0.28169934667141894 [184]\n",
      "5  overlooking  1 0.28169934667141894 [27]\n",
      "6  item  1 0.1505149978319906 [5]\n",
      "6  data  1 0.2112745100035642 [42]\n",
      "6  processing  1 0.2112745100035642 [68]\n",
      "6  ML  1 0.2112745100035642 [143]\n",
      "6  few-shot  1 0.2112745100035642 [120]\n",
      "6  exhibits  1 0.2112745100035642 [187]\n",
      "6  detailed  2 0.4225490200071284 [83,127]\n",
      "6  generated  1 0.2112745100035642 [158]\n",
      "6  dataset  3 0.6338235300106926 [98,124,144]\n",
      "6  compared  1 0.2112745100035642 [162]\n",
      "6  tools  1 0.2112745100035642 [64]\n",
      "6  manual  1 0.2112745100035642 [32]\n",
      "6  NDCG  1 0.2112745100035642 [175]\n",
      "6  emerged  1 0.2112745100035642 [61]\n",
      "6  natural  1 0.1505149978319906 [66]\n",
      "6  pivotal  1 0.2112745100035642 [8]\n",
      "6  recent  1 0.1505149978319906 [45]\n",
      "6  1M  1 0.2112745100035642 [97]\n",
      "6  prompting  1 0.1505149978319906 [121]\n",
      "6  description  3 0.6338235300106926 [2,159,185]\n",
      "6  powerful  1 0.2112745100035642 [63]\n",
      "6  potential  1 0.2112745100035642 [18]\n",
      "6  promise,  1 0.2112745100035642 [189]\n",
      "6  explored  1 0.2112745100035642 [75]\n",
      "6  tasks.  1 0.1505149978319906 [69]\n",
      "6  demonstrated  1 0.2112745100035642 [181]\n",
      "6  Goodreads  2 0.4225490200071284 [104,155]\n",
      "6  open-sourced  1 0.1505149978319906 [114]\n",
      "6  MovieLens  1 0.2112745100035642 [96]\n",
      "6  captivate  1 0.2112745100035642 [17]\n",
      "6  providing  1 0.2112745100035642 [11]\n",
      "6  concise  1 0.2112745100035642 [12]\n",
      "6  scraping  1 0.2112745100035642 [34]\n",
      "6  cast  1 0.2112745100035642 [138]\n",
      "6  role  1 0.2112745100035642 [9]\n",
      "6  study,  1 0.2112745100035642 [91]\n",
      "6  prompted  1 0.2112745100035642 [118]\n",
      "6  systems.  1 0.2112745100035642 [25]\n",
      "6  descriptions.  1 0.2112745100035642 [199]\n",
      "6  Language  1 0.0994850021680094 [48]\n",
      "6  plays  1 0.2112745100035642 [6]\n",
      "6  recommendation  1 0.1505149978319906 [24]\n",
      "6  generation  1 0.2112745100035642 [186]\n",
      "6  viewers  1 0.2112745100035642 [19]\n",
      "6  Top  1 0.2112745100035642 [171]\n",
      "6  Alpaca,  1 0.2112745100035642 [116]\n",
      "6  web-scraped  1 0.2112745100035642 [198]\n",
      "6  scraped  1 0.2112745100035642 [165]\n",
      "6  comparable  1 0.2112745100035642 [192]\n",
      "6  techniques,  1 0.2112745100035642 [35]\n",
      "6  Dataset  1 0.2112745100035642 [105]\n",
      "6  inconsistencies.  1 0.2112745100035642 [43]\n",
      "6  GPT-3.5,  1 0.2112745100035642 [53]\n",
      "6  author  1 0.2112745100035642 [150]\n",
      "6  web  1 0.2112745100035642 [33]\n",
      "6  paper,  1 0.0994850021680094 [72]\n",
      "6  time-consuming  1 0.2112745100035642 [38]\n",
      "6  MRR,  1 0.2112745100035642 [173]\n",
      "6  features  1 0.2112745100035642 [132]\n",
      "6  subsequently,  1 0.2112745100035642 [112]\n",
      "6  comprising  1 0.2112745100035642 [99]\n",
      "6  metrics.  1 0.1505149978319906 [178]\n",
      "6  summaries  1 0.2112745100035642 [15]\n",
      "6  like  2 0.4225490200071284 [58,133]\n",
      "6  ones  1 0.2112745100035642 [195]\n",
      "6  Large  1 0.08560567020555157 [47]\n",
      "6  Traditionally,  1 0.2112745100035642 [26]\n",
      "6  language  1 0.0994850021680094 [67]\n",
      "6  LLM-based  1 0.11928031367991561 [183]\n",
      "6  dataset.  1 0.2112745100035642 [156]\n",
      "6  essential  1 0.2112745100035642 [22]\n",
      "6  evaluation  1 0.2112745100035642 [177]\n",
      "6  names  3 0.6338235300106926 [108,135,147]\n",
      "6  generate  2 0.23856062735983122 [82,126]\n",
      "6  using  1 0.08560567020555157 [167]\n",
      "6  Alpaca  1 0.2112745100035642 [59]\n",
      "6  conduct  1 0.2112745100035642 [89]\n",
      "6  LLM,  1 0.2112745100035642 [115]\n",
      "6  (LLMs),  1 0.2112745100035642 [50]\n",
      "6  considering  1 0.2112745100035642 [130]\n",
      "6  use  1 0.1505149978319906 [79]\n",
      "6  books  1 0.2112745100035642 [110]\n",
      "6  obtained  2 0.4225490200071284 [30,196]\n",
      "6  consisting  1 0.2112745100035642 [106]\n",
      "6  directors  1 0.2112745100035642 [140]\n",
      "6  Models  1 0.0994850021680094 [49]\n",
      "6  descriptions  4 0.8450980400142568 [28,84,129,166]\n",
      "6  Hits,  1 0.2112745100035642 [172]\n",
      "6  items.  1 0.2112745100035642 [87]\n",
      "6  results  2 0.1989700043360188 [180,191]\n",
      "6  movie  3 0.6338235300106926 [100,128,184]\n",
      "6  publisher  1 0.2112745100035642 [152]\n",
      "6  LLMs  2 0.1989700043360188 [57,80]\n",
      "6  susceptible  1 0.2112745100035642 [40]\n",
      "6  combination  1 0.2112745100035642 [169]\n",
      "6  titles  1 0.2112745100035642 [101]\n",
      "6  informative  1 0.2112745100035642 [14]\n",
      "6  multiple  1 0.11928031367991561 [131]\n",
      "6  used  1 0.11928031367991561 [94]\n",
      "6  years,  1 0.2112745100035642 [46]\n",
      "6  open  1 0.2112745100035642 [55]\n",
      "6  significant  1 0.2112745100035642 [188]\n",
      "6  source  1 0.2112745100035642 [56]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "descripteur_split =\"\"\n",
    "\n",
    "\n",
    "for i in range(len(termes_split)):\n",
    "    for j in range(len(termes_split[i])):\n",
    "        frequency_term = frequency_dict_split_documents[i][termes_split[i][j]]\n",
    "        poids_term = poids(frequency_term,max_frequency_dict_split_documents[i],document_frequency_dict_split[termes_split[i][j]],n_split)\n",
    "        \n",
    "        term_positions = split_positions[i][termes_split[i][j]]\n",
    "        positions_string = \"[\" + \",\".join(str(pos) for pos in term_positions) + \"]\"\n",
    "\n",
    "        descripteur_split = descripteur_split + (str(i+1)+ \"  \" +termes_split[i][j]+ \"  \" +str(frequency_term)+\" \"+ str(poids_term)+\" \"+ positions_string+\"\\n\")\n",
    "\n",
    "print(descripteur_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  reformulation  1 0.20068666377598746 [80]\n",
      "1  feedback  3 0.6020599913279624 [120,166,172]\n",
      "1  technique  1 0.20068666377598746 [90]\n",
      "1  find  1 0.28169934667141894 [128]\n",
      "1  upto  1 0.28169934667141894 [144]\n",
      "1  techniques  1 0.15904041823988746 [8]\n",
      "1  nDCG@10  2 0.4013733275519749 [136,169]\n",
      "1  success  1 0.28169934667141894 [62]\n",
      "1  text  1 0.15904041823988746 [20]\n",
      "1  propose  1 0.1141408936074021 [85]\n",
      "1  inspiration  1 0.28169934667141894 [59]\n",
      "1  MSMarco  1 0.28169934667141894 [153]\n",
      "1  9%  1 0.28169934667141894 [168]\n",
      "1  zero-shot  3 0.8450980400142568 [35,97,149]\n",
      "1  prompting  2 0.4013733275519749 [65,89]\n",
      "1  ensemble  2 0.5633986933428379 [64,87]\n",
      "1  transform  1 0.28169934667141894 [11]\n",
      "1  set  1 0.15904041823988746 [6]\n",
      "1  previous  1 0.15904041823988746 [148]\n",
      "1  variant  1 0.28169934667141894 [114]\n",
      "1  shown  1 0.28169934667141894 [39]\n",
      "1  intent  1 0.28169934667141894 [28]\n",
      "1  state-of-art  1 0.28169934667141894 [150]\n",
      "1  search  2 0.3180808364797749 [16,32]\n",
      "1  5%  1 0.28169934667141894 [162]\n",
      "1  better  2 0.5633986933428379 [22,132]\n",
      "1  MRR  1 0.20068666377598746 [163]\n",
      "1  large  1 0.28169934667141894 [54]\n",
      "1  pseudo  1 0.28169934667141894 [118]\n",
      "1  retrieval  1 0.20068666377598746 [107]\n",
      "1  Ranking  1 0.20068666377598746 [155]\n",
      "1  many  1 0.28169934667141894 [70]\n",
      "1  models  1 0.20068666377598746 [56]\n",
      "1  relevant  2 0.5633986933428379 [119,171]\n",
      "1  documents  1 0.15904041823988746 [173]\n",
      "1  context  1 0.28169934667141894 [83]\n",
      "1  introduce  1 0.20068666377598746 [111]\n",
      "1  post-retrieval  1 0.28169934667141894 [113]\n",
      "1  tasks  1 0.1141408936074021 [71]\n",
      "1  18%  1 0.28169934667141894 [140]\n",
      "1  keywords  1 0.28169934667141894 [104]\n",
      "1  help  1 0.28169934667141894 [77]\n",
      "1  Reformulation  1 0.20068666377598746 [2]\n",
      "1  knowledge  1 0.28169934667141894 [51]\n",
      "1  investigate  1 0.28169934667141894 [73]\n",
      "1  improving  1 0.28169934667141894 [106]\n",
      "1  improves  1 0.28169934667141894 [30]\n",
      "1  strategies  1 0.15904041823988746 [66]\n",
      "1  approach  1 0.13264666955734586 [44]\n",
      "1  generates  1 0.28169934667141894 [131]\n",
      "1  GenQREnsemble  2 0.5633986933428379 [91,130]\n",
      "1  QR  2 0.5633986933428379 [3,36]\n",
      "1  Query  1 0.20068666377598746 [1]\n",
      "1  language  1 0.13264666955734586 [55]\n",
      "1  based  1 0.15904041823988746 [88]\n",
      "1  task  1 0.15904041823988746 [156]\n",
      "1  IR  1 0.20068666377598746 [125]\n",
      "1  generate  1 0.15904041823988746 [100]\n",
      "1  using  2 0.2282817872148042 [164,170]\n",
      "1  due  1 0.28169934667141894 [45]\n",
      "1  ultimately  1 0.28169934667141894 [105]\n",
      "1  ability  1 0.20068666377598746 [48]\n",
      "1  reformulations  1 0.28169934667141894 [133]\n",
      "1  user  2 0.2652933391146917 [13,26]\n",
      "1  experience  1 0.28169934667141894 [33]\n",
      "1  MAP  1 0.28169934667141894 [142]\n",
      "1  inherent  1 0.28169934667141894 [52]\n",
      "1  taking  1 0.28169934667141894 [58]\n",
      "1  instruction  1 0.20068666377598746 [98]\n",
      "1  exploit  1 0.28169934667141894 [50]\n",
      "1  performance  1 0.15904041823988746 [108]\n",
      "1  24%  1 0.28169934667141894 [145]\n",
      "1  query  2 0.3180808364797749 [17,79]\n",
      "1  gains  1 0.28169934667141894 [160]\n",
      "1  GenQREnsembleRF  2 0.5633986933428379 [115,157]\n",
      "1  promising  1 0.28169934667141894 [43]\n",
      "1  benefited  1 0.28169934667141894 [69]\n",
      "1  evaluations  1 0.28169934667141894 [122]\n",
      "1  aligns  1 0.28169934667141894 [23]\n",
      "1  improve  1 0.13264666955734586 [78]\n",
      "1  sets  1 0.28169934667141894 [102]\n",
      "1  original  1 0.28169934667141894 [15]\n",
      "1  relative  2 0.5633986933428379 [135,159]\n",
      "1  Recently  1 0.28169934667141894 [34]\n",
      "1  pseudo-relevance  1 0.28169934667141894 [165]\n",
      "1  Passage  1 0.28169934667141894 [154]\n",
      "1  benchmarks  1 0.20068666377598746 [126]\n",
      "1  multiple  1 0.15904041823988746 [101]\n",
      "1  used  1 0.15904041823988746 [9]\n",
      "1  improvements  2 0.5633986933428379 [137,143]\n",
      "1  incorporate  1 0.28169934667141894 [117]\n",
      "1  leverages  1 0.20068666377598746 [93]\n",
      "1  four  1 0.28169934667141894 [124]\n",
      "1  shows  1 0.28169934667141894 [158]\n",
      "1  paraphrases  1 0.28169934667141894 [94]\n",
      "2  technique  1 0.1505149978319906 [79]\n",
      "2  favorably  1 0.2112745100035642 [120]\n",
      "2  20B  1 0.2112745100035642 [117]\n",
      "2  commercial  2 0.4225490200071284 [135,180]\n",
      "2  template  1 0.1505149978319906 [167]\n",
      "2  Flan-UL2  1 0.2112745100035642 [114]\n",
      "2  existing  1 0.2112745100035642 [48]\n",
      "2  significantly  1 0.11928031367991561 [69]\n",
      "2  propose  2 0.17121134041110314 [67,198]\n",
      "2  literature  2 0.4225490200071284 [92,128]\n",
      "2  candidate  1 0.2112745100035642 [14]\n",
      "2  linear  1 0.2112745100035642 [218]\n",
      "2  listwise  1 0.2112745100035642 [43]\n",
      "2  formulations  1 0.2112745100035642 [62]\n",
      "2  moderate-sized  1 0.2112745100035642 [102]\n",
      "2  baselines  1 0.2112745100035642 [175]\n",
      "2  fine-tuned  1 0.2112745100035642 [33]\n",
      "2  first  1 0.11928031367991561 [89]\n",
      "2  datasets  1 0.11928031367991561 [38]\n",
      "2  solution  1 0.2112745100035642 [182]\n",
      "2  previous  1 0.11928031367991561 [123]\n",
      "2  PRP  4 0.8450980400142568 [84,110,172,202]\n",
      "2  average  1 0.2112745100035642 [194]\n",
      "2  paper  1 0.0994850021680094 [65]\n",
      "2  competitive  1 0.2112745100035642 [214]\n",
      "2  model  2 0.4225490200071284 [115,141]\n",
      "2  open-sourced  1 0.1505149978319906 [103]\n",
      "2  rankers  1 0.2112745100035642 [35]\n",
      "2  outperforming  1 0.2112745100035642 [144]\n",
      "2  seven  1 0.2112745100035642 [169]\n",
      "2  standard  1 0.2112745100035642 [99]\n",
      "2  prompts  1 0.1505149978319906 [45]\n",
      "2  Language  1 0.0994850021680094 [5]\n",
      "2  Prompting  1 0.2112745100035642 [83]\n",
      "2  TREC-DL  1 0.2112745100035642 [106]\n",
      "2  2019  1 0.2112745100035642 [107]\n",
      "2  10%  1 0.2112745100035642 [157]\n",
      "2  directly  1 0.2112745100035642 [9]\n",
      "2  Ranking  2 0.3010299956639812 [1,82]\n",
      "2  problem  1 0.1505149978319906 [24]\n",
      "2  175B  1 0.2112745100035642 [153]\n",
      "2  complexity  1 0.2112745100035642 [219]\n",
      "2  2020  1 0.2112745100035642 [109]\n",
      "2  BEIR  1 0.1505149978319906 [170]\n",
      "2  practical  1 0.2112745100035642 [23]\n",
      "2  several  1 0.2112745100035642 [199]\n",
      "2  size  1 0.2112745100035642 [142]\n",
      "2  documents  2 0.23856062735983122 [2,15]\n",
      "2  feeding  1 0.2112745100035642 [10]\n",
      "2  NDCG@10  1 0.2112745100035642 [195]\n",
      "2  tasks  1 0.08560567020555157 [171]\n",
      "2  ChatGPT  1 0.2112745100035642 [181]\n",
      "2  even  1 0.2112745100035642 [216]\n",
      "2  understand  1 0.1505149978319906 [58]\n",
      "2  argue  1 0.2112745100035642 [51]\n",
      "2  off-the-shelf  1 0.2112745100035642 [53]\n",
      "2  approach  1 0.0994850021680094 [125]\n",
      "2  reduce  1 0.1505149978319906 [70]\n",
      "2  50x  1 0.2112745100035642 [139]\n",
      "2  ranking  4 0.8450980400142568 [44,61,96,160]\n",
      "2  Large  1 0.08560567020555157 [4]\n",
      "2  based  2 0.23856062735983122 [111,131]\n",
      "2  performs  1 0.2112745100035642 [119]\n",
      "2  LLM-based  2 0.23856062735983122 [146,187]\n",
      "2  Furthermore  1 0.1505149978319906 [196]\n",
      "2  using  4 0.3424226808222063 [3,76,101,163]\n",
      "2  variants  1 0.2112745100035642 [200]\n",
      "2  show  1 0.2112745100035642 [207]\n",
      "2  4.2%  1 0.2112745100035642 [184]\n",
      "2  achieve  2 0.3010299956639812 [94,213]\n",
      "2  blackbox  2 0.4225490200071284 [134,179]\n",
      "2  Models  1 0.0994850021680094 [6]\n",
      "2  burden  1 0.2112745100035642 [72]\n",
      "2  difficult  1 0.2112745100035642 [30]\n",
      "2  performance  1 0.11928031367991561 [97]\n",
      "2  analyze  1 0.2112745100035642 [40]\n",
      "2  efficiency  1 0.1505149978319906 [205]\n",
      "2  query  1 0.11928031367991561 [12]\n",
      "2  outperform  1 0.2112745100035642 [32]\n",
      "2  benchmark  1 0.11928031367991561 [37]\n",
      "2  results  2 0.1989700043360188 [86,215]\n",
      "2  methods  1 0.1505149978319906 [49]\n",
      "2  interesting  1 0.2112745100035642 [21]\n",
      "2  LLMs  4 0.3979400086720376 [7,54,74,104]\n",
      "2  However  1 0.2112745100035642 [25]\n",
      "2  solutions  2 0.4225490200071284 [147,188]\n",
      "2  metrics  1 0.1505149978319906 [161]\n",
      "2  found  1 0.2112745100035642 [28]\n",
      "2  called  1 0.2112745100035642 [80]\n",
      "2  supervised  1 0.2112745100035642 [174]\n",
      "2  improve  1 0.0994850021680094 [204]\n",
      "2  baseline  1 0.2112745100035642 [34]\n",
      "2  fully  1 0.2112745100035642 [57]\n",
      "2  challenging  1 0.2112745100035642 [60]\n",
      "2  12-10%  1 0.2112745100035642 [192]\n",
      "2  prompt  2 0.3010299956639812 [18,166]\n",
      "2  GPT-4  1 0.2112745100035642 [136]\n",
      "2  new  1 0.2112745100035642 [78]\n",
      "2  estimated  1 0.2112745100035642 [140]\n",
      "2  parameters  2 0.4225490200071284 [118,154]\n",
      "2  state-of-the-art  1 0.1505149978319906 [95]\n",
      "2  researchers  1 0.1505149978319906 [26]\n",
      "2  InstructGPT  1 0.2112745100035642 [150]\n",
      "2  benchmarks  1 0.1505149978319906 [100]\n",
      "2  used  1 0.11928031367991561 [46]\n",
      "2  best  1 0.2112745100035642 [124]\n",
      "2  Pairwise  1 0.2112745100035642 [81]\n",
      "2  pointwise  2 0.4225490200071284 [41,186]\n",
      "2  outperforms  2 0.4225490200071284 [173,177]\n",
      "2  possible  1 0.2112745100035642 [211]\n",
      "3  item  1 0.08600857018970891 [65]\n",
      "3  design  1 0.1207282914306081 [147]\n",
      "3  continuous  1 0.1207282914306081 [129]\n",
      "3  long  2 0.2414565828612162 [32,41]\n",
      "3  template  2 0.17201714037941782 [72,99]\n",
      "3  PrOmpt  1 0.1207282914306081 [173]\n",
      "3  effectiveness  1 0.08600857018970891 [170]\n",
      "3  could  2 0.2414565828612162 [29,39]\n",
      "3  inspire  1 0.1207282914306081 [203]\n",
      "3  strategy  1 0.1207282914306081 [150]\n",
      "3  significantly  1 0.06816017924566606 [191]\n",
      "3  text  2 0.13632035849133212 [27,38]\n",
      "3  propose  1 0.048917525831743754 [115]\n",
      "3  enough  1 0.1207282914306081 [51]\n",
      "3  specific  1 0.1207282914306081 [123]\n",
      "3  response  1 0.1207282914306081 [58]\n",
      "3  usually  2 0.2414565828612162 [68,88]\n",
      "3  power  1 0.08600857018970891 [105]\n",
      "3  time  2 0.17201714037941782 [42,144]\n",
      "3  may  2 0.2414565828612162 [47,202]\n",
      "3  demonstrate  1 0.08600857018970891 [168]\n",
      "3  Although  1 0.1207282914306081 [185]\n",
      "3  set  1 0.06816017924566606 [127]\n",
      "3  datasets  1 0.06816017924566606 [167]\n",
      "3  user/item  1 0.1207282914306081 [95]\n",
      "3  unleash  1 0.1207282914306081 [103]\n",
      "3  words  2 0.2414565828612162 [100,138]\n",
      "3  modeling  1 0.08600857018970891 [8]\n",
      "3  inference  3 0.36218487429182433 [143,196,212]\n",
      "3  allow  1 0.1207282914306081 [77]\n",
      "3  reasoning  1 0.1207282914306081 [15]\n",
      "3  i.e.  1 0.1207282914306081 [73]\n",
      "3  process  1 0.06816017924566606 [44]\n",
      "3  Distillation  1 0.1207282914306081 [174]\n",
      "3  mostly  1 0.1207282914306081 [23]\n",
      "3  attempt  1 0.1207282914306081 [153]\n",
      "3  input  1 0.08600857018970891 [18]\n",
      "3  systems  1 0.08600857018970891 [54]\n",
      "3  manifested  1 0.1207282914306081 [6]\n",
      "3  e.g.  1 0.1207282914306081 [13]\n",
      "3  recommendation  5 0.43004285094854455 [61,109,180,183,216]\n",
      "3  models  7 0.6020599913279624 [3,21,62,79,87,161,217]\n",
      "3  unparalleled  1 0.1207282914306081 [7]\n",
      "3  address  1 0.1207282914306081 [111]\n",
      "3  require  1 0.1207282914306081 [56]\n",
      "3  IDs  3 0.36218487429182433 [66,96,136]\n",
      "3  immediate  1 0.1207282914306081 [57]\n",
      "3  Long  1 0.1207282914306081 [37]\n",
      "3  problems  1 0.1207282914306081 [113]\n",
      "3  tasks  2 0.09783505166348751 [12,184]\n",
      "3  understand  1 0.08600857018970891 [81]\n",
      "3  fine-tuning  1 0.1207282914306081 [91]\n",
      "3  LLM  2 0.13632035849133212 [4,107]\n",
      "3  efficient  1 0.1207282914306081 [50]\n",
      "3  approach  1 0.05684857266743394 [176]\n",
      "3  take  1 0.08600857018970891 [40]\n",
      "3  reduce  1 0.08600857018970891 [141]\n",
      "3  discrete  2 0.2414565828612162 [74,119]\n",
      "3  Large  1 0.048917525831743754 [1]\n",
      "3  various  1 0.08600857018970891 [11]\n",
      "3  language  1 0.05684857266743394 [2]\n",
      "3  limited  2 0.17201714037941782 [24,199]\n",
      "3  vectors  1 0.1207282914306081 [131]\n",
      "3  LLM-based  2 0.13632035849133212 [60,215]\n",
      "3  real-world  1 0.1207282914306081 [166]\n",
      "3  task  2 0.13632035849133212 [84,124]\n",
      "3  improvement  1 0.1207282914306081 [194]\n",
      "3  extensive  1 0.1207282914306081 [90]\n",
      "3  contain  1 0.1207282914306081 [34]\n",
      "3  training  3 0.36218487429182433 [149,159,187]\n",
      "3  Experimental  1 0.1207282914306081 [162]\n",
      "3  need  1 0.08600857018970891 [89]\n",
      "3  also  1 0.08600857018970891 [146]\n",
      "3  user  1 0.05684857266743394 [63]\n",
      "3  community  1 0.1207282914306081 [207]\n",
      "3  sequential  1 0.08600857018970891 [179]\n",
      "3  efficiency  4 0.34403428075883563 [157,188,197,213]\n",
      "3  thus  1 0.1207282914306081 [46]\n",
      "3  results  1 0.05684857266743394 [163]\n",
      "3  finding  1 0.1207282914306081 [201]\n",
      "3  three  1 0.1207282914306081 [165]\n",
      "3  improved  1 0.1207282914306081 [192]\n",
      "3  capability  1 0.1207282914306081 [9]\n",
      "3  filled  1 0.1207282914306081 [69]\n",
      "3  plain  1 0.1207282914306081 [26]\n",
      "3  POD  1 0.1207282914306081 [175]\n",
      "3  noisy  1 0.1207282914306081 [35]\n",
      "3  improve  2 0.11369714533486788 [155,210]\n",
      "3  given  1 0.08600857018970891 [83]\n",
      "3  multi-step  1 0.1207282914306081 [14]\n",
      "3  prompt  3 0.2580257105691267 [75,120,130]\n",
      "3  recommender  1 0.1207282914306081 [53]\n",
      "3  researchers  1 0.08600857018970891 [204]\n",
      "3  distill  1 0.1207282914306081 [117]\n",
      "3  information  1 0.08600857018970891 [36]\n",
      "3  bridge  2 0.2414565828612162 [93,135]\n",
      "3  top-N  1 0.1207282914306081 [182]\n",
      "4  optimize  1 0.16901960800285137 [122]\n",
      "4  reformulation  3 0.3612359947967774 [2,36,157]\n",
      "4  feedback  1 0.12041199826559248 [140]\n",
      "4  retriever  1 0.16901960800285137 [175]\n",
      "4  represent  1 0.16901960800285137 [104]\n",
      "4  techniques  1 0.09542425094393249 [166]\n",
      "4  effectiveness  1 0.12041199826559248 [47]\n",
      "4  nDCG@10  1 0.12041199826559248 [164]\n",
      "4  significantly  1 0.09542425094393249 [173]\n",
      "4  propose  1 0.06848453616444126 [56]\n",
      "4  intentions  1 0.16901960800285137 [67]\n",
      "4  Generative  1 0.16901960800285137 [59]\n",
      "4  redundant  1 0.16901960800285137 [42]\n",
      "4  time  1 0.12041199826559248 [82]\n",
      "4  distinctly  1 0.16901960800285137 [103]\n",
      "4  clusters  1 0.16901960800285137 [98]\n",
      "4  demonstrate  1 0.12041199826559248 [148]\n",
      "4  first  1 0.09542425094393249 [81]\n",
      "4  expansions  1 0.16901960800285137 [43]\n",
      "4  SOTAs  1 0.16901960800285137 [158]\n",
      "4  previous  1 0.09542425094393249 [155]\n",
      "4  paper  1 0.07958800173440753 [54]\n",
      "4  experiments  1 0.16901960800285137 [143]\n",
      "4  well-generated  1 0.16901960800285137 [73]\n",
      "4  advancing  1 0.16901960800285137 [178]\n",
      "4  search  1 0.09542425094393249 [15]\n",
      "4  process  1 0.09542425094393249 [138]\n",
      "4  integrates  1 0.16901960800285137 [127]\n",
      "4  input  1 0.12041199826559248 [24]\n",
      "4  prompts  1 0.12041199826559248 [96]\n",
      "4  Language  1 0.07958800173440753 [30]\n",
      "4  rate  1 0.16901960800285137 [18]\n",
      "4  Clustering  1 0.16901960800285137 [60]\n",
      "4  explores  1 0.16901960800285137 [110]\n",
      "4  retrieval  2 0.24082399653118497 [77,123]\n",
      "4  groups  1 0.16901960800285137 [101]\n",
      "4  well-known  1 0.16901960800285137 [5]\n",
      "4  problem  1 0.12041199826559248 [6]\n",
      "4  combine  1 0.16901960800285137 [112]\n",
      "4  variable  1 0.16901960800285137 [88]\n",
      "4  leverage  1 0.16901960800285137 [28]\n",
      "4  adaptively  1 0.16901960800285137 [68]\n",
      "4  BEIR  1 0.12041199826559248 [146]\n",
      "4  crucially  1 0.16901960800285137 [126]\n",
      "4  achieves  1 0.16901960800285137 [151]\n",
      "4  Retrieval  2 0.33803921600570275 [9,183]\n",
      "4  automatically  1 0.16901960800285137 [20]\n",
      "4  capture  1 0.12041199826559248 [65]\n",
      "4  innovative  1 0.16901960800285137 [117]\n",
      "4  novel  1 0.12041199826559248 [129]\n",
      "4  Information  2 0.33803921600570275 [8,182]\n",
      "4  Reformulation  1 0.12041199826559248 [62]\n",
      "4  Empirical  1 0.16901960800285137 [142]\n",
      "4  initial  1 0.16901960800285137 [92]\n",
      "4  strategies  1 0.09542425094393249 [120]\n",
      "4  boosting  1 0.16901960800285137 [174]\n",
      "4  refine  1 0.16901960800285137 [136]\n",
      "4  surpassing  1 0.16901960800285137 [154]\n",
      "4  Recent  1 0.16901960800285137 [26]\n",
      "4  single  1 0.16901960800285137 [14]\n",
      "4  GenCRF  3 0.5070588240085541 [57,83,150]\n",
      "4  Query  2 0.24082399653118497 [1,130]\n",
      "4  Large  1 0.06848453616444126 [29]\n",
      "4  various  1 0.12041199826559248 [171]\n",
      "4  limited  1 0.12041199826559248 [40]\n",
      "4  capturing  1 0.12041199826559248 [49]\n",
      "4  based  1 0.09542425094393249 [69]\n",
      "4  Rewarding  1 0.16901960800285137 [132]\n",
      "4  Furthermore  1 0.12041199826559248 [107]\n",
      "4  IR  1 0.12041199826559248 [10]\n",
      "4  generate  2 0.19084850188786498 [39,87]\n",
      "4  diverse  4 0.6760784320114055 [50,66,105,113]\n",
      "4  completion  1 0.16901960800285137 [17]\n",
      "4  intents  3 0.5070588240085541 [51,106,114]\n",
      "4  using  1 0.06848453616444126 [94]\n",
      "4  field  1 0.16901960800285137 [180]\n",
      "4  user  1 0.07958800173440753 [22]\n",
      "4  aggregation  1 0.16901960800285137 [119]\n",
      "4  aimed  1 0.16901960800285137 [11]\n",
      "4  Models  1 0.07958800173440753 [31]\n",
      "4  QERM  1 0.16901960800285137 [134]\n",
      "4  performance  3 0.28627275283179743 [124,153,176]\n",
      "4  framework  1 0.16901960800285137 [109]\n",
      "4  query  5 0.47712125471966244 [25,35,93,115,156]\n",
      "4  benchmark  1 0.09542425094393249 [147]\n",
      "4  Evaluation  1 0.16901960800285137 [131]\n",
      "4  adapted  1 0.16901960800285137 [169]\n",
      "4  differentiated  1 0.16901960800285137 [72]\n",
      "4  methods  1 0.12041199826559248 [27]\n",
      "4  LLMs  3 0.23876400520322255 [32,85,172]\n",
      "4  Model  1 0.16901960800285137 [133]\n",
      "4  enhancing  1 0.16901960800285137 [13]\n",
      "4  constraining  1 0.16901960800285137 [45]\n",
      "4  often  1 0.16901960800285137 [38]\n",
      "4  improve  1 0.07958800173440753 [34]\n",
      "4  potentially  1 0.16901960800285137 [44]\n",
      "4  loops  1 0.16901960800285137 [141]\n",
      "4  12%  1 0.16901960800285137 [162]\n",
      "4  phase  1 0.16901960800285137 [78]\n",
      "4  state-of-the-art  1 0.12041199826559248 [152]\n",
      "4  successful  1 0.16901960800285137 [16]\n",
      "4  multiple  1 0.09542425094393249 [71]\n",
      "4  Framework  1 0.16901960800285137 [63]\n",
      "4  customized  1 0.16901960800285137 [95]\n",
      "4  modifying  1 0.16901960800285137 [21]\n",
      "4  leverages  1 0.12041199826559248 [84]\n",
      "4  queries  2 0.24082399653118497 [74,89]\n",
      "4  weighted  1 0.16901960800285137 [118]\n",
      "5  analysis  1 0.16901960800285137 [190]\n",
      "5  graph-based  1 0.16901960800285137 [72]\n",
      "5  integrating  1 0.16901960800285137 [102]\n",
      "5  topological  1 0.16901960800285137 [180]\n",
      "5  discrepancy  1 0.16901960800285137 [120]\n",
      "5  representation  1 0.16901960800285137 [46]\n",
      "5  methodology  1 0.16901960800285137 [212]\n",
      "5  produce  1 0.16901960800285137 [132]\n",
      "5  superiority  1 0.16901960800285137 [200]\n",
      "5  fine-grained  1 0.16901960800285137 [185]\n",
      "5  propose  1 0.06848453616444126 [58]\n",
      "5  SGR  1 0.16901960800285137 [62]\n",
      "5  text  1 0.09542425094393249 [99]\n",
      "5  structures  1 0.16901960800285137 [147]\n",
      "5  inputs  1 0.16901960800285137 [112]\n",
      "5  Session  1 0.16901960800285137 [1]\n",
      "5  modern  1 0.16901960800285137 [222]\n",
      "5  natural  1 0.12041199826559248 [119]\n",
      "5  pre-trained  1 0.16901960800285137 [123]\n",
      "5  recent  1 0.12041199826559248 [79]\n",
      "5  traditional  1 0.16901960800285137 [218]\n",
      "5  power  1 0.12041199826559248 [77]\n",
      "5  text-based  1 0.16901960800285137 [70]\n",
      "5  semantic  2 0.33803921600570275 [26,52]\n",
      "5  first  1 0.09542425094393249 [86]\n",
      "5  set  2 0.19084850188786498 [89,158]\n",
      "5  content  1 0.16901960800285137 [168]\n",
      "5  datasets  1 0.09542425094393249 [194]\n",
      "5  Graph  1 0.16901960800285137 [60]\n",
      "5  history  1 0.16901960800285137 [104]\n",
      "5  enable  1 0.16901960800285137 [175]\n",
      "5  fulfill  1 0.16901960800285137 [12]\n",
      "5  Moreover  1 0.16901960800285137 [116]\n",
      "5  paper  1 0.07958800173440753 [56]\n",
      "5  modeling  2 0.24082399653118497 [23,53]\n",
      "5  interactive  1 0.16901960800285137 [7]\n",
      "5  format  1 0.16901960800285137 [151]\n",
      "5  prioritize  1 0.16901960800285137 [21]\n",
      "5  search  2 0.19084850188786498 [2,219]\n",
      "5  Symbolic  1 0.16901960800285137 [59]\n",
      "5  process  1 0.09542425094393249 [106]\n",
      "5  confirm  1 0.16901960800285137 [198]\n",
      "5  Tiangong-ST  1 0.16901960800285137 [197]\n",
      "5  Language  1 0.07958800173440753 [81]\n",
      "5  involves  1 0.16901960800285137 [3]\n",
      "5  corpora  1 0.16901960800285137 [126]\n",
      "5  comprehensive  1 0.16901960800285137 [189]\n",
      "5  generation  1 0.12041199826559248 [169]\n",
      "5  AOL  1 0.16901960800285137 [195]\n",
      "5  generative  1 0.16901960800285137 [171]\n",
      "5  advantage  1 0.16901960800285137 [67]\n",
      "5  complex  1 0.16901960800285137 [15]\n",
      "5  paradigm  1 0.16901960800285137 [205]\n",
      "5  documents  1 0.09542425094393249 [48]\n",
      "5  introduce  2 0.24082399653118497 [87,156]\n",
      "5  structure  1 0.16901960800285137 [31]\n",
      "5  capture  2 0.24082399653118497 [145,178]\n",
      "5  tasks  1 0.06848453616444126 [163]\n",
      "5  word-level  1 0.16901960800285137 [51]\n",
      "5  novel  1 0.12041199826559248 [209]\n",
      "5  focus  1 0.16901960800285137 [37]\n",
      "5  Ranker  1 0.16901960800285137 [61]\n",
      "5  rules  1 0.16901960800285137 [93]\n",
      "5  Concretely  1 0.16901960800285137 [84]\n",
      "5  grammar  2 0.33803921600570275 [92,136]\n",
      "5  LLM  1 0.09542425094393249 [115]\n",
      "5  enhance  1 0.16901960800285137 [141]\n",
      "5  including  1 0.16901960800285137 [164]\n",
      "5  strategies  2 0.19084850188786498 [19,220]\n",
      "5  approach  1 0.07958800173440753 [203]\n",
      "5  take  1 0.12041199826559248 [66]\n",
      "5  neglecting  1 0.16901960800285137 [49]\n",
      "5  interactions  1 0.16901960800285137 [33]\n",
      "5  structural  1 0.16901960800285137 [40]\n",
      "5  deep  1 0.16901960800285137 [25]\n",
      "5  approaches  2 0.33803921600570275 [36,73]\n",
      "5  Large  1 0.06848453616444126 [80]\n",
      "5  language  1 0.07958800173440753 [130]\n",
      "5  capturing  1 0.12041199826559248 [39]\n",
      "5  seamlessly  1 0.16901960800285137 [110]\n",
      "5  offers  1 0.16901960800285137 [207]\n",
      "5  task  1 0.09542425094393249 [108]\n",
      "5  generalized  1 0.16901960800285137 [45]\n",
      "5  graph-to-text  1 0.16901960800285137 [135]\n",
      "5  typically  1 0.16901960800285137 [20]\n",
      "5  using  1 0.06848453616444126 [133]\n",
      "5  leveraging  1 0.16901960800285137 [75]\n",
      "5  coarse-grained  1 0.16901960800285137 [183]\n",
      "5  aims  1 0.16901960800285137 [64]\n",
      "5  use  1 0.12041199826559248 [43]\n",
      "5  Experiment  1 0.16901960800285137 [186]\n",
      "5  session  2 0.33803921600570275 [96,103]\n",
      "5  ability  1 0.12041199826559248 [143]\n",
      "5  need  1 0.12041199826559248 [17]\n",
      "5  user  1 0.07958800173440753 [13]\n",
      "5  also  1 0.12041199826559248 [206]\n",
      "5  series  1 0.16901960800285137 [5]\n",
      "5  bridges  1 0.16901960800285137 [214]\n",
      "5  sequential  1 0.12041199826559248 [22]\n",
      "5  achieve  1 0.12041199826559248 [153]\n",
      "5  Models  1 0.07958800173440753 [82]\n",
      "5  instruction  1 0.12041199826559248 [109]\n",
      "5  prediction  1 0.16901960800285137 [166]\n",
      "5  benchmark  1 0.09542425094393249 [193]\n",
      "5  results  1 0.07958800173440753 [187]\n",
      "5  effective  1 0.16901960800285137 [211]\n",
      "5  objective  1 0.16901960800285137 [138]\n",
      "5  allows  1 0.16901960800285137 [101]\n",
      "5  two  1 0.16901960800285137 [192]\n",
      "5  learning  2 0.33803921600570275 [162,173]\n",
      "5  graph  3 0.5070588240085541 [30,97,146]\n",
      "5  LLMs  5 0.3979400086720376 [83,122,142,176,223]\n",
      "5  actions  1 0.16901960800285137 [10]\n",
      "5  self-supervised  1 0.16901960800285137 [160]\n",
      "5  understanding  1 0.16901960800285137 [27]\n",
      "5  Current  1 0.16901960800285137 [18]\n",
      "5  convert  1 0.16901960800285137 [95]\n",
      "5  symbolic  3 0.5070588240085541 [91,129,161]\n",
      "5  interaction  1 0.16901960800285137 [105]\n",
      "5  contrastive  1 0.16901960800285137 [172]\n",
      "5  textual  2 0.33803921600570275 [125,150]\n",
      "5  given  1 0.12041199826559248 [117]\n",
      "5  link  1 0.16901960800285137 [165]\n",
      "5  within  1 0.16901960800285137 [148]\n",
      "5  gap  1 0.16901960800285137 [216]\n",
      "5  information  3 0.3612359947967774 [16,41,181]\n",
      "5  node  1 0.16901960800285137 [167]\n",
      "5  queries  1 0.12041199826559248 [8]\n",
      "5  overlooking  1 0.16901960800285137 [28]\n",
      "6  item  1 0.12041199826559248 [5]\n",
      "6  data  1 0.16901960800285137 [42]\n",
      "6  processing  1 0.16901960800285137 [68]\n",
      "6  ML  1 0.16901960800285137 [143]\n",
      "6  techniques  1 0.09542425094393249 [35]\n",
      "6  few-shot  1 0.16901960800285137 [120]\n",
      "6  exhibits  1 0.16901960800285137 [187]\n",
      "6  detailed  2 0.33803921600570275 [83,127]\n",
      "6  generated  1 0.16901960800285137 [158]\n",
      "6  inconsistencies  1 0.16901960800285137 [43]\n",
      "6  dataset  4 0.6760784320114055 [98,124,144,156]\n",
      "6  compared  1 0.16901960800285137 [162]\n",
      "6  tools  1 0.16901960800285137 [64]\n",
      "6  manual  1 0.16901960800285137 [32]\n",
      "6  NDCG  1 0.16901960800285137 [175]\n",
      "6  emerged  1 0.16901960800285137 [61]\n",
      "6  natural  1 0.12041199826559248 [66]\n",
      "6  pivotal  1 0.16901960800285137 [8]\n",
      "6  recent  1 0.12041199826559248 [45]\n",
      "6  1M  1 0.16901960800285137 [97]\n",
      "6  prompting  1 0.12041199826559248 [121]\n",
      "6  description  3 0.5070588240085541 [2,159,185]\n",
      "6  powerful  1 0.16901960800285137 [63]\n",
      "6  potential  1 0.16901960800285137 [18]\n",
      "6  explored  1 0.16901960800285137 [75]\n",
      "6  paper  1 0.07958800173440753 [72]\n",
      "6  GPT-3.5  1 0.16901960800285137 [53]\n",
      "6  demonstrated  1 0.16901960800285137 [181]\n",
      "6  Goodreads  2 0.33803921600570275 [104,155]\n",
      "6  open-sourced  1 0.12041199826559248 [114]\n",
      "6  MovieLens  1 0.16901960800285137 [96]\n",
      "6  captivate  1 0.16901960800285137 [17]\n",
      "6  providing  1 0.16901960800285137 [11]\n",
      "6  items  1 0.16901960800285137 [87]\n",
      "6  concise  1 0.16901960800285137 [12]\n",
      "6  scraping  1 0.16901960800285137 [34]\n",
      "6  cast  1 0.16901960800285137 [138]\n",
      "6  role  1 0.16901960800285137 [9]\n",
      "6  promise  1 0.16901960800285137 [189]\n",
      "6  prompted  1 0.16901960800285137 [118]\n",
      "6  Language  1 0.07958800173440753 [48]\n",
      "6  systems  1 0.12041199826559248 [25]\n",
      "6  plays  1 0.16901960800285137 [6]\n",
      "6  MRR  1 0.12041199826559248 [173]\n",
      "6  recommendation  1 0.12041199826559248 [24]\n",
      "6  generation  1 0.12041199826559248 [186]\n",
      "6  viewers  1 0.16901960800285137 [19]\n",
      "6  Top  1 0.16901960800285137 [171]\n",
      "6  web-scraped  1 0.16901960800285137 [198]\n",
      "6  scraped  1 0.16901960800285137 [165]\n",
      "6  comparable  1 0.16901960800285137 [192]\n",
      "6  Dataset  1 0.16901960800285137 [105]\n",
      "6  author  1 0.16901960800285137 [150]\n",
      "6  tasks  1 0.06848453616444126 [69]\n",
      "6  web  1 0.16901960800285137 [33]\n",
      "6  LLM  1 0.09542425094393249 [115]\n",
      "6  time-consuming  1 0.16901960800285137 [38]\n",
      "6  subsequently  1 0.16901960800285137 [112]\n",
      "6  features  1 0.16901960800285137 [132]\n",
      "6  comprising  1 0.16901960800285137 [99]\n",
      "6  summaries  1 0.16901960800285137 [15]\n",
      "6  like  2 0.33803921600570275 [58,133]\n",
      "6  ones  1 0.16901960800285137 [195]\n",
      "6  Large  1 0.06848453616444126 [47]\n",
      "6  language  1 0.07958800173440753 [67]\n",
      "6  LLM-based  1 0.09542425094393249 [183]\n",
      "6  essential  1 0.16901960800285137 [22]\n",
      "6  evaluation  1 0.16901960800285137 [177]\n",
      "6  names  3 0.5070588240085541 [108,135,147]\n",
      "6  generate  2 0.19084850188786498 [82,126]\n",
      "6  using  1 0.06848453616444126 [167]\n",
      "6  Alpaca  2 0.33803921600570275 [59,116]\n",
      "6  conduct  1 0.16901960800285137 [89]\n",
      "6  considering  1 0.16901960800285137 [130]\n",
      "6  use  1 0.12041199826559248 [79]\n",
      "6  books  1 0.16901960800285137 [110]\n",
      "6  obtained  2 0.33803921600570275 [30,196]\n",
      "6  consisting  1 0.16901960800285137 [106]\n",
      "6  directors  1 0.16901960800285137 [140]\n",
      "6  Models  1 0.07958800173440753 [49]\n",
      "6  Traditionally  1 0.16901960800285137 [26]\n",
      "6  descriptions  5 0.8450980400142568 [28,84,129,166,199]\n",
      "6  results  2 0.15917600346881505 [180,191]\n",
      "6  movie  3 0.5070588240085541 [100,128,184]\n",
      "6  publisher  1 0.16901960800285137 [152]\n",
      "6  LLMs  3 0.23876400520322255 [50,57,80]\n",
      "6  metrics  1 0.12041199826559248 [178]\n",
      "6  susceptible  1 0.16901960800285137 [40]\n",
      "6  combination  1 0.16901960800285137 [169]\n",
      "6  Hits  1 0.16901960800285137 [172]\n",
      "6  titles  1 0.16901960800285137 [101]\n",
      "6  informative  1 0.16901960800285137 [14]\n",
      "6  multiple  1 0.09542425094393249 [131]\n",
      "6  used  1 0.09542425094393249 [94]\n",
      "6  years  1 0.16901960800285137 [46]\n",
      "6  study  1 0.16901960800285137 [91]\n",
      "6  open  1 0.16901960800285137 [55]\n",
      "6  significant  1 0.16901960800285137 [188]\n",
      "6  source  1 0.16901960800285137 [56]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "descripteur_reg =\"\"\n",
    "\n",
    "for i in range(len(termes_reg)):\n",
    "    for j in range(len(termes_reg[i])):\n",
    "        frequency_term = frequency_dict_reg_documents[i][termes_reg[i][j]]\n",
    "        poids_term = poids(frequency_term,max_frequency_dict_reg_documents[i],document_frequency_dict_reg[termes_reg[i][j]],n_reg)\n",
    "        \n",
    "        term_positions = reg_positions[i][termes_reg[i][j]]\n",
    "        positions_string = \"[\" + \",\".join(str(pos) for pos in term_positions) + \"]\"\n",
    "\n",
    "        descripteur_reg = descripteur_reg + (str(i+1)+ \"  \" +termes_reg[i][j]+ \"  \" +str(frequency_term)+\" \"+ str(poids_term)+\" \"+ positions_string +\"\\n\")\n",
    "\n",
    "\n",
    "print(descripteur_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  task,  1 0.12041199826559248 [153]\n",
      "1  investig  1 0.16901960800285137 [70]\n",
      "1  feedback  1 0.12041199826559248 [169]\n",
      "1  find  1 0.12041199826559248 [125]\n",
      "1  pseudo-relev  1 0.16901960800285137 [162]\n",
      "1  upto  1 0.16901960800285137 [141]\n",
      "1  documents.  1 0.16901960800285137 [170]\n",
      "1  ultim  1 0.16901960800285137 [102]\n",
      "1  success  1 0.12041199826559248 [59]\n",
      "1  text  1 0.12041199826559248 [18]\n",
      "1  instruct  1 0.12041199826559248 [95]\n",
      "1  state-of-art.  1 0.16901960800285137 [147]\n",
      "1  9%  1 0.16901960800285137 [165]\n",
      "1  msmarco  1 0.16901960800285137 [150]\n",
      "1  zero-shot  3 0.5070588240085541 [32,94,146]\n",
      "1  multipl  1 0.09542425094393249 [98]\n",
      "1  technique,  1 0.16901960800285137 [87]\n",
      "1  ensembl  2 0.33803921600570275 [61,84]\n",
      "1  rank  1 0.12041199826559248 [152]\n",
      "1  queri  3 0.23876400520322255 [1,15,76]\n",
      "1  transform  1 0.16901960800285137 [10]\n",
      "1  set  2 0.19084850188786498 [5,99]\n",
      "1  abil  1 0.12041199826559248 [45]\n",
      "1  shown  1 0.16901960800285137 [36]\n",
      "1  intent  1 0.12041199826559248 [25]\n",
      "1  search  2 0.19084850188786498 [14,29]\n",
      "1  5%  1 0.16901960800285137 [159]\n",
      "1  map  1 0.16901960800285137 [139]\n",
      "1  improv  5 0.3979400086720376 [27,75,103,134,140]\n",
      "1  better  2 0.33803921600570275 [20,129]\n",
      "1  feedback,  1 0.16901960800285137 [163]\n",
      "1  pseudo  1 0.16901960800285137 [115]\n",
      "1  recently,  1 0.16901960800285137 [31]\n",
      "1  performance.  1 0.16901960800285137 [105]\n",
      "1  techniqu  1 0.09542425094393249 [7]\n",
      "1  relev  2 0.33803921600570275 [116,168]\n",
      "1  experience.  1 0.16901960800285137 [30]\n",
      "1  qr  1 0.16901960800285137 [33]\n",
      "1  reformul  1 0.12041199826559248 [130]\n",
      "1  evalu  1 0.09542425094393249 [119]\n",
      "1  tasks,  1 0.09542425094393249 [68]\n",
      "1  incorpor  1 0.16901960800285137 [114]\n",
      "1  18%  1 0.16901960800285137 [137]\n",
      "1  mani  1 0.16901960800285137 [67]\n",
      "1  leverag  1 0.09542425094393249 [90]\n",
      "1  gain  1 0.16901960800285137 [157]\n",
      "1  help  1 0.16901960800285137 [74]\n",
      "1  base  1 0.09542425094393249 [85]\n",
      "1  reformulation(qr)  1 0.16901960800285137 [2]\n",
      "1  approach  1 0.07958800173440753 [41]\n",
      "1  take  1 0.09542425094393249 [55]\n",
      "1  genqrensemblerf  2 0.33803921600570275 [112,154]\n",
      "1  benefit  1 0.16901960800285137 [66]\n",
      "1  rel  2 0.33803921600570275 [132,156]\n",
      "1  models.  1 0.12041199826559248 [53]\n",
      "1  previou  1 0.09542425094393249 [145]\n",
      "1  genqrensembl  2 0.33803921600570275 [88,127]\n",
      "1  inspir  1 0.12041199826559248 [56]\n",
      "1  user’  2 0.33803921600570275 [12,24]\n",
      "1  gener  2 0.15917600346881505 [97,128]\n",
      "1  retriev  1 0.12041199826559248 [104]\n",
      "1  knowledg  1 0.16901960800285137 [48]\n",
      "1  passag  1 0.16901960800285137 [151]\n",
      "1  due  1 0.16901960800285137 [42]\n",
      "1  show  1 0.12041199826559248 [155]\n",
      "1  context,  1 0.16901960800285137 [80]\n",
      "1  ndcg@10  2 0.33803921600570275 [133,166]\n",
      "1  languag  1 0.06020599913279624 [52]\n",
      "1  use  3 0.20545360849332375 [8,161,167]\n",
      "1  promis  1 0.16901960800285137 [40]\n",
      "1  mrr  1 0.16901960800285137 [160]\n",
      "1  benchmarks,  1 0.16901960800285137 [123]\n",
      "1  inher  1 0.16901960800285137 [49]\n",
      "1  keyword  1 0.16901960800285137 [101]\n",
      "1  origin  1 0.16901960800285137 [13]\n",
      "1  exploit  1 0.16901960800285137 [47]\n",
      "1  24%  1 0.16901960800285137 [142]\n",
      "1  larg  1 0.06020599913279624 [51]\n",
      "1  paraphras  1 0.16901960800285137 [91]\n",
      "1  ir  1 0.16901960800285137 [122]\n",
      "1  reformulation.  1 0.16901960800285137 [77]\n",
      "1  align  1 0.16901960800285137 [21]\n",
      "1  introduc  1 0.12041199826559248 [108]\n",
      "1  variant,  1 0.16901960800285137 [111]\n",
      "1  strategi  1 0.07958800173440753 [63]\n",
      "1  prompt  2 0.15917600346881505 [62,86]\n",
      "1  propos  1 0.06848453616444126 [82]\n",
      "1  feedback.  1 0.16901960800285137 [117]\n",
      "1  post-retriev  1 0.16901960800285137 [110]\n",
      "1  four  1 0.16901960800285137 [121]\n",
      "2  effici  1 0.10034333188799373 [205]\n",
      "2  averag  1 0.14084967333570947 [194]\n",
      "2  baselin  2 0.28169934667141894 [34,175]\n",
      "2  solutions,  1 0.14084967333570947 [147]\n",
      "2  flan-ul2  1 0.14084967333570947 [114]\n",
      "2  beir  1 0.10034333188799373 [170]\n",
      "2  solut  2 0.28169934667141894 [182,188]\n",
      "2  linear  1 0.14084967333570947 [218]\n",
      "2  parameters,  1 0.14084967333570947 [154]\n",
      "2  rank  6 0.6020599913279624 [1,44,61,82,96,160]\n",
      "2  challeng  1 0.14084967333570947 [60]\n",
      "2  queri  1 0.06632333477867293 [12]\n",
      "2  first  1 0.07952020911994373 [89]\n",
      "2  pointwis  2 0.28169934667141894 [41,186]\n",
      "2  achiev  2 0.15904041823988746 [94,213]\n",
      "2  exist  1 0.14084967333570947 [48]\n",
      "2  model  3 0.17121134041110314 [6,115,141]\n",
      "2  variant  1 0.14084967333570947 [200]\n",
      "2  ranker  1 0.10034333188799373 [35]\n",
      "2  ndcg@10.  1 0.10034333188799373 [195]\n",
      "2  literatur  1 0.14084967333570947 [92]\n",
      "2  result  2 0.13264666955734586 [86,215]\n",
      "2  research  1 0.10034333188799373 [26]\n",
      "2  seven  1 0.14084967333570947 [169]\n",
      "2  commerci  2 0.28169934667141894 [135,180]\n",
      "2  directli  1 0.14084967333570947 [9]\n",
      "2  standard  1 0.14084967333570947 [99]\n",
      "2  chatgpt  1 0.14084967333570947 [181]\n",
      "2  (llms)  1 0.10034333188799373 [7]\n",
      "2  improv  1 0.06632333477867293 [204]\n",
      "2  2019  1 0.14084967333570947 [107]\n",
      "2  formulations.  1 0.14084967333570947 [62]\n",
      "2  (prp).  1 0.14084967333570947 [84]\n",
      "2  10%  1 0.14084967333570947 [157]\n",
      "2  open-sourc  1 0.10034333188799373 [103]\n",
      "2  paramet  1 0.14084967333570947 [118]\n",
      "2  interest  1 0.14084967333570947 [21]\n",
      "2  175b  1 0.14084967333570947 [153]\n",
      "2  listwis  1 0.14084967333570947 [43]\n",
      "2  llm  2 0.1141408936074021 [54,74]\n",
      "2  techniqu  1 0.07952020911994373 [79]\n",
      "2  perform  2 0.20068666377598746 [97,119]\n",
      "2  problem.  1 0.14084967333570947 [24]\n",
      "2  complex  1 0.10034333188799373 [219]\n",
      "2  prp  3 0.4225490200071284 [110,172,202]\n",
      "2  (estimated)  1 0.14084967333570947 [140]\n",
      "2  however,  1 0.14084967333570947 [25]\n",
      "2  llm-base  2 0.15904041823988746 [146,187]\n",
      "2  reduc  1 0.10034333188799373 [70]\n",
      "2  tasks,  1 0.07952020911994373 [171]\n",
      "2  even  1 0.14084967333570947 [216]\n",
      "2  understand  1 0.10034333188799373 [58]\n",
      "2  moderate-s  1 0.14084967333570947 [102]\n",
      "2  base  2 0.15904041823988746 [111,131]\n",
      "2  paper,  1 0.06632333477867293 [65]\n",
      "2  llms.  1 0.10034333188799373 [104]\n",
      "2  datasets.  1 0.14084967333570947 [38]\n",
      "2  analyz  1 0.14084967333570947 [40]\n",
      "2  significantli  1 0.07952020911994373 [69]\n",
      "2  off-the-shelf  1 0.14084967333570947 [53]\n",
      "2  approach  1 0.06632333477867293 [125]\n",
      "2  50x  1 0.14084967333570947 [139]\n",
      "2  gpt-4  1 0.14084967333570947 [136]\n",
      "2  pairwis  1 0.14084967333570947 [81]\n",
      "2  metrics.  1 0.10034333188799373 [161]\n",
      "2  argu  1 0.14084967333570947 [51]\n",
      "2  previou  1 0.07952020911994373 [123]\n",
      "2  possibl  1 0.14084967333570947 [211]\n",
      "2  furthermore,  1 0.10034333188799373 [196]\n",
      "2  fine-tun  1 0.10034333188799373 [33]\n",
      "2  trec-dl  1 0.14084967333570947 [106]\n",
      "2  show  1 0.10034333188799373 [207]\n",
      "2  languag  1 0.050171665943996864 [5]\n",
      "2  use  5 0.28535223401850524 [3,46,76,101,163]\n",
      "2  competit  1 0.14084967333570947 [214]\n",
      "2  favor  1 0.14084967333570947 [120]\n",
      "2  4.2%  1 0.14084967333570947 [184]\n",
      "2  blackbox  2 0.28169934667141894 [134,179]\n",
      "2  burden  1 0.14084967333570947 [72]\n",
      "2  difficult  1 0.14084967333570947 [30]\n",
      "2  2020,  1 0.14084967333570947 [109]\n",
      "2  method  1 0.10034333188799373 [49]\n",
      "2  practic  1 0.14084967333570947 [23]\n",
      "2  outperform  4 0.5633986933428379 [32,144,173,177]\n",
      "2  larg  1 0.050171665943996864 [4]\n",
      "2  benchmark  2 0.15904041823988746 [37,100]\n",
      "2  templat  1 0.10034333188799373 [167]\n",
      "2  call  1 0.14084967333570947 [80]\n",
      "2  instructgpt  1 0.14084967333570947 [150]\n",
      "2  sever  1 0.14084967333570947 [199]\n",
      "2  literature,  1 0.14084967333570947 [128]\n",
      "2  found  1 0.14084967333570947 [28]\n",
      "2  feed  1 0.14084967333570947 [10]\n",
      "2  supervis  1 0.14084967333570947 [174]\n",
      "2  12-10%  1 0.14084967333570947 [192]\n",
      "2  document  2 0.28169934667141894 [2,15]\n",
      "2  prompt  4 0.2652933391146917 [18,45,83,166]\n",
      "2  new  1 0.14084967333570947 [78]\n",
      "2  fulli  1 0.14084967333570947 [57]\n",
      "2  propos  2 0.1141408936074021 [67,198]\n",
      "2  state-of-the-art  1 0.10034333188799373 [95]\n",
      "2  best  1 0.14084967333570947 [124]\n",
      "2  20b  1 0.14084967333570947 [117]\n",
      "2  candid  1 0.14084967333570947 [14]\n",
      "2  size,  1 0.14084967333570947 [142]\n",
      "3  text,  1 0.16901960800285137 [27]\n",
      "3  item  1 0.12041199826559248 [65]\n",
      "3  task,  1 0.12041199826559248 [84]\n",
      "3  effici  5 0.6020599913279624 [50,157,188,197,213]\n",
      "3  design  1 0.16901960800285137 [147]\n",
      "3  find  1 0.12041199826559248 [201]\n",
      "3  long  3 0.5070588240085541 [32,37,41]\n",
      "3  manifest  1 0.16901960800285137 [6]\n",
      "3  could  2 0.33803921600570275 [29,39]\n",
      "3  reasoning,  1 0.16901960800285137 [15]\n",
      "3  dataset  1 0.12041199826559248 [167]\n",
      "3  text  1 0.12041199826559248 [38]\n",
      "3  enough  1 0.16901960800285137 [51]\n",
      "3  system  1 0.16901960800285137 [54]\n",
      "3  bridg  2 0.24082399653118497 [93,135]\n",
      "3  response.  1 0.16901960800285137 [58]\n",
      "3  power  1 0.09542425094393249 [105]\n",
      "3  time  1 0.16901960800285137 [42]\n",
      "3  information.  1 0.16901960800285137 [36]\n",
      "3  may  2 0.33803921600570275 [47,202]\n",
      "3  set  1 0.09542425094393249 [127]\n",
      "3  fill  1 0.16901960800285137 [69]\n",
      "3  limit  1 0.12041199826559248 [24]\n",
      "3  user/item  1 0.16901960800285137 [95]\n",
      "3  tasks.  1 0.12041199826559248 [184]\n",
      "3  unleash  1 0.16901960800285137 [103]\n",
      "3  model  5 0.3424226808222063 [3,8,21,79,87]\n",
      "3  specif  1 0.16901960800285137 [123]\n",
      "3  result  1 0.07958800173440753 [163]\n",
      "3  allow  1 0.12041199826559248 [77]\n",
      "3  research  1 0.12041199826559248 [204]\n",
      "3  process,  1 0.12041199826559248 [44]\n",
      "3  e.g.,  1 0.16901960800285137 [13]\n",
      "3  requir  1 0.16901960800285137 [56]\n",
      "3  time.  1 0.12041199826559248 [144]\n",
      "3  top-n  1 0.16901960800285137 [182]\n",
      "3  recommend  5 0.6020599913279624 [53,61,180,183,216]\n",
      "3  unparallel  1 0.16901960800285137 [7]\n",
      "3  attempt  1 0.16901960800285137 [153]\n",
      "3  noisi  1 0.16901960800285137 [35]\n",
      "3  input  1 0.09542425094393249 [18]\n",
      "3  improv  3 0.23876400520322255 [155,194,210]\n",
      "3  capabl  1 0.16901960800285137 [9]\n",
      "3  although  1 0.16901960800285137 [185]\n",
      "3  mostli  1 0.16901960800285137 [23]\n",
      "3  variou  1 0.12041199826559248 [11]\n",
      "3  thu  1 0.16901960800285137 [46]\n",
      "3  discret  2 0.33803921600570275 [74,119]\n",
      "3  distil  2 0.33803921600570275 [117,174]\n",
      "3  llm  1 0.06848453616444126 [107]\n",
      "3  address  1 0.16901960800285137 [111]\n",
      "3  models,  1 0.16901960800285137 [62]\n",
      "3  sequenti  1 0.12041199826559248 [179]\n",
      "3  commun  1 0.16901960800285137 [207]\n",
      "3  problems,  1 0.16901960800285137 [113]\n",
      "3  (pod)  1 0.16901960800285137 [175]\n",
      "3  llm-base  2 0.19084850188786498 [60,215]\n",
      "3  tasks,  1 0.09542425094393249 [12]\n",
      "3  extens  1 0.16901960800285137 [90]\n",
      "3  reduc  1 0.12041199826559248 [141]\n",
      "3  understand  1 0.12041199826559248 [81]\n",
      "3  immedi  1 0.16901960800285137 [57]\n",
      "3  usual  2 0.33803921600570275 [68,88]\n",
      "3  vector  1 0.16901960800285137 [131]\n",
      "3  significantli  1 0.09542425094393249 [191]\n",
      "3  approach  1 0.07958800173440753 [176]\n",
      "3  take  1 0.09542425094393249 [40]\n",
      "3  experiment  1 0.16901960800285137 [162]\n",
      "3  models.  2 0.24082399653118497 [161,217]\n",
      "3  word  2 0.33803921600570275 [100,138]\n",
      "3  infer  3 0.5070588240085541 [143,196,212]\n",
      "3  recommendation.  1 0.16901960800285137 [109]\n",
      "3  real-world  1 0.16901960800285137 [166]\n",
      "3  inspir  1 0.12041199826559248 [203]\n",
      "3  fine-tun  1 0.12041199826559248 [91]\n",
      "3  task  1 0.12041199826559248 [124]\n",
      "3  contain  1 0.16901960800285137 [34]\n",
      "3  languag  1 0.06020599913279624 [2]\n",
      "3  continu  1 0.16901960800285137 [129]\n",
      "3  also  1 0.12041199826559248 [146]\n",
      "3  need  1 0.16901960800285137 [89]\n",
      "3  user  1 0.16901960800285137 [63]\n",
      "3  improved,  1 0.16901960800285137 [192]\n",
      "3  id  3 0.5070588240085541 [66,96,136]\n",
      "3  larg  1 0.06020599913279624 [1]\n",
      "3  train  3 0.5070588240085541 [149,159,187]\n",
      "3  templat  2 0.24082399653118497 [72,99]\n",
      "3  three  1 0.16901960800285137 [165]\n",
      "3  plain  1 0.16901960800285137 [26]\n",
      "3  limited.  1 0.16901960800285137 [199]\n",
      "3  (i.e.,  1 0.16901960800285137 [73]\n",
      "3  given  1 0.12041199826559248 [83]\n",
      "3  strategi  1 0.07958800173440753 [150]\n",
      "3  multi-step  1 0.16901960800285137 [14]\n",
      "3  prompt  3 0.23876400520322255 [120,130,173]\n",
      "3  prompt)  1 0.16901960800285137 [75]\n",
      "3  propos  1 0.06848453616444126 [115]\n",
      "3  effect  1 0.09542425094393249 [170]\n",
      "3  demonstr  1 0.09542425094393249 [168]\n",
      "3  (llm)  1 0.16901960800285137 [4]\n",
      "4  complet  1 0.1056372550017821 [17]\n",
      "4  optim  1 0.1056372550017821 [121]\n",
      "4  feedback  1 0.0752574989159953 [139]\n",
      "4  performance,  1 0.1056372550017821 [152]\n",
      "4  experi  1 0.0752574989159953 [142]\n",
      "4  integr  1 0.0752574989159953 [126]\n",
      "4  beir  1 0.0752574989159953 [145]\n",
      "4  success  1 0.0752574989159953 [16]\n",
      "4  gencrf:  1 0.1056372550017821 [56]\n",
      "4  custom  1 0.1056372550017821 [94]\n",
      "4  recent  1 0.059640156839957804 [25]\n",
      "4  multipl  1 0.059640156839957804 [70]\n",
      "4  differentiated,  1 0.1056372550017821 [71]\n",
      "4  queri  8 0.3979400086720376 [1,34,73,88,92,114,129,155]\n",
      "4  first  1 0.059640156839957804 [80]\n",
      "4  limit  1 0.0752574989159953 [39]\n",
      "4  crucial  1 0.1056372550017821 [125]\n",
      "4  achiev  1 0.059640156839957804 [150]\n",
      "4  redund  1 0.1056372550017821 [41]\n",
      "4  (ir)  1 0.1056372550017821 [10]\n",
      "4  model  2 0.08560567020555157 [30,132]\n",
      "4  divers  4 0.4225490200071284 [49,65,104,112]\n",
      "4  llms,  1 0.1056372550017821 [171]\n",
      "4  gencrf  2 0.2112745100035642 [82,149]\n",
      "4  ndcg@10.  1 0.0752574989159953 [163]\n",
      "4  enhanc  1 0.0752574989159953 [13]\n",
      "4  intent  2 0.1505149978319906 [66,113]\n",
      "4  search  1 0.059640156839957804 [15]\n",
      "4  process  1 0.0752574989159953 [137]\n",
      "4  time.  1 0.0752574989159953 [81]\n",
      "4  prompts,  1 0.1056372550017821 [95]\n",
      "4  input  1 0.059640156839957804 [23]\n",
      "4  (llms)  1 0.0752574989159953 [31]\n",
      "4  improv  1 0.0497425010840047 [33]\n",
      "4  variou  1 0.0752574989159953 [170]\n",
      "4  rate  1 0.1056372550017821 [18]\n",
      "4  well-known  1 0.1056372550017821 [5]\n",
      "4  problem  1 0.1056372550017821 [6]\n",
      "4  explor  1 0.0752574989159953 [109]\n",
      "4  llm  1 0.042802835102775785 [84]\n",
      "4  perform  2 0.1505149978319906 [123,175]\n",
      "4  adapt  2 0.2112745100035642 [67,168]\n",
      "4  group  1 0.1056372550017821 [100]\n",
      "4  techniqu  1 0.059640156839957804 [165]\n",
      "4  constrain  1 0.1056372550017821 [44]\n",
      "4  captur  2 0.1505149978319906 [48,64]\n",
      "4  advanc  1 0.1056372550017821 [177]\n",
      "4  sota  1 0.1056372550017821 [157]\n",
      "4  modifi  1 0.1056372550017821 [21]\n",
      "4  reformul  3 0.22577249674798588 [2,61,156]\n",
      "4  evalu  1 0.059640156839957804 [130]\n",
      "4  loops.  1 0.1056372550017821 [140]\n",
      "4  leverag  2 0.11928031367991561 [27,83]\n",
      "4  novel  1 0.0752574989159953 [128]\n",
      "4  base  1 0.059640156839957804 [68]\n",
      "4  paper,  1 0.0497425010840047 [53]\n",
      "4  innov  1 0.1056372550017821 [116]\n",
      "4  significantli  1 0.059640156839957804 [172]\n",
      "4  query.  1 0.1056372550017821 [24]\n",
      "4  potenti  1 0.0752574989159953 [43]\n",
      "4  well-gener  1 0.1056372550017821 [72]\n",
      "4  intents.  2 0.2112745100035642 [50,105]\n",
      "4  (qerm)  1 0.1056372550017821 [133]\n",
      "4  boost  1 0.1056372550017821 [173]\n",
      "4  previou  1 0.059640156839957804 [154]\n",
      "4  combin  1 0.0752574989159953 [111]\n",
      "4  furthermore,  1 0.0752574989159953 [106]\n",
      "4  gener  3 0.14922750325201412 [38,58,86]\n",
      "4  retriev  4 0.3010299956639812 [9,76,122,174]\n",
      "4  reward  1 0.1056372550017821 [131]\n",
      "4  inform  2 0.11928031367991561 [8,181]\n",
      "4  languag  1 0.03762874945799765 [29]\n",
      "4  use  1 0.042802835102775785 [93]\n",
      "4  empir  1 0.1056372550017821 [141]\n",
      "4  user'  1 0.0752574989159953 [22]\n",
      "4  singl  1 0.1056372550017821 [14]\n",
      "4  field  1 0.1056372550017821 [179]\n",
      "4  surpass  1 0.1056372550017821 [153]\n",
      "4  variabl  1 0.1056372550017821 [87]\n",
      "4  repres  1 0.1056372550017821 [103]\n",
      "4  method  1 0.0752574989159953 [26]\n",
      "4  framework  2 0.2112745100035642 [62,108]\n",
      "4  benchmark  1 0.059640156839957804 [146]\n",
      "4  larg  1 0.03762874945799765 [28]\n",
      "4  expansions,  1 0.1056372550017821 [42]\n",
      "4  aggreg  1 0.1056372550017821 [118]\n",
      "4  retrieval.  1 0.1056372550017821 [182]\n",
      "4  often  1 0.1056372550017821 [37]\n",
      "4  distinctli  1 0.1056372550017821 [102]\n",
      "4  refin  1 0.1056372550017821 [135]\n",
      "4  strategi  1 0.0497425010840047 [119]\n",
      "4  automat  1 0.1056372550017821 [20]\n",
      "4  12%  1 0.1056372550017821 [161]\n",
      "4  propos  1 0.042802835102775785 [55]\n",
      "4  phase  1 0.1056372550017821 [77]\n",
      "4  state-of-the-art  1 0.0752574989159953 [151]\n",
      "4  aim  1 0.0752574989159953 [11]\n",
      "4  effect  1 0.059640156839957804 [46]\n",
      "4  initi  1 0.1056372550017821 [91]\n",
      "4  reformulation,  1 0.1056372550017821 [35]\n",
      "4  cluster  2 0.2112745100035642 [59,97]\n",
      "4  demonstr  1 0.059640156839957804 [147]\n",
      "4  weight  1 0.1056372550017821 [117]\n",
      "5  semant  2 0.4225490200071284 [25,51]\n",
      "5  interact  2 0.4225490200071284 [7,104]\n",
      "5  methodolog  1 0.2112745100035642 [211]\n",
      "5  experi  1 0.1505149978319906 [185]\n",
      "5  integr  1 0.1505149978319906 [101]\n",
      "5  represent  1 0.2112745100035642 [45]\n",
      "5  documents,  1 0.2112745100035642 [47]\n",
      "5  advantag  1 0.2112745100035642 [66]\n",
      "5  information,  1 0.2112745100035642 [40]\n",
      "5  understanding,  1 0.2112745100035642 [26]\n",
      "5  instruct  1 0.1505149978319906 [108]\n",
      "5  modern  1 0.2112745100035642 [221]\n",
      "5  object  1 0.2112745100035642 [137]\n",
      "5  bridg  1 0.1505149978319906 [213]\n",
      "5  text.  1 0.2112745100035642 [98]\n",
      "5  recent  1 0.11928031367991561 [78]\n",
      "5  modeling.  1 0.2112745100035642 [52]\n",
      "5  analysi  1 0.2112745100035642 [189]\n",
      "5  power  1 0.11928031367991561 [76]\n",
      "5  superior  1 0.2112745100035642 [199]\n",
      "5  queri  1 0.0994850021680094 [8]\n",
      "5  first  1 0.11928031367991561 [85]\n",
      "5  set  2 0.23856062735983122 [88,157]\n",
      "5  content  1 0.2112745100035642 [167]\n",
      "5  abil  1 0.1505149978319906 [142]\n",
      "5  llm.  1 0.2112745100035642 [114]\n",
      "5  current  1 0.2112745100035642 [17]\n",
      "5  achiev  1 0.11928031367991561 [152]\n",
      "5  aol  1 0.2112745100035642 [194]\n",
      "5  model  2 0.17121134041110314 [22,81]\n",
      "5  prediction,  1 0.2112745100035642 [165]\n",
      "5  ranker  1 0.1505149978319906 [60]\n",
      "5  tradit  1 0.2112745100035642 [217]\n",
      "5  enhanc  1 0.1505149978319906 [140]\n",
      "5  result  1 0.0994850021680094 [186]\n",
      "5  allow  1 0.1505149978319906 [100]\n",
      "5  process,  1 0.1505149978319906 [105]\n",
      "5  search  2 0.23856062735983122 [2,218]\n",
      "5  confirm  1 0.2112745100035642 [197]\n",
      "5  concretely,  1 0.2112745100035642 [83]\n",
      "5  input  1 0.11928031367991561 [111]\n",
      "5  learn  1 0.2112745100035642 [161]\n",
      "5  approach.  1 0.2112745100035642 [202]\n",
      "5  history,  1 0.2112745100035642 [103]\n",
      "5  interactions.  1 0.2112745100035642 [32]\n",
      "5  focu  1 0.2112745100035642 [36]\n",
      "5  learning,  1 0.2112745100035642 [172]\n",
      "5  offer  1 0.2112745100035642 [206]\n",
      "5  typic  1 0.2112745100035642 [19]\n",
      "5  llm  2 0.17121134041110314 [121,175]\n",
      "5  complex  1 0.1505149978319906 [14]\n",
      "5  sequenti  1 0.1505149978319906 [21]\n",
      "5  discrep  1 0.2112745100035642 [119]\n",
      "5  paradigm  1 0.2112745100035642 [204]\n",
      "5  captur  3 0.45154499349597177 [38,144,177]\n",
      "5  pre-train  1 0.2112745100035642 [122]\n",
      "5  produc  1 0.2112745100035642 [131]\n",
      "5  format.  1 0.2112745100035642 [150]\n",
      "5  generation,  1 0.2112745100035642 [168]\n",
      "5  word-level  1 0.2112745100035642 [50]\n",
      "5  leverag  1 0.11928031367991561 [74]\n",
      "5  novel  1 0.1505149978319906 [208]\n",
      "5  paper,  1 0.0994850021680094 [55]\n",
      "5  grammar  1 0.2112745100035642 [91]\n",
      "5  action  1 0.2112745100035642 [10]\n",
      "5  llms.  1 0.1505149978319906 [222]\n",
      "5  text-bas  1 0.2112745100035642 [69]\n",
      "5  approach  2 0.1989700043360188 [35,72]\n",
      "5  take  1 0.11928031367991561 [65]\n",
      "5  self-supervis  1 0.2112745100035642 [159]\n",
      "5  comprehens  1 0.2112745100035642 [188]\n",
      "5  deep  1 0.2112745100035642 [24]\n",
      "5  fulfil  1 0.2112745100035642 [12]\n",
      "5  gener  2 0.1989700043360188 [44,170]\n",
      "5  datasets,  1 0.2112745100035642 [193]\n",
      "5  task  2 0.3010299956639812 [107,162]\n",
      "5  topolog  1 0.2112745100035642 [179]\n",
      "5  graph-to-text  1 0.2112745100035642 [134]\n",
      "5  this,  1 0.2112745100035642 [153]\n",
      "5  overlook  1 0.2112745100035642 [27]\n",
      "5  enabl  1 0.2112745100035642 [174]\n",
      "5  inform  2 0.23856062735983122 [15,180]\n",
      "5  priorit  1 0.2112745100035642 [20]\n",
      "5  use  2 0.17121134041110314 [42,132]\n",
      "5  languag  2 0.1505149978319906 [80,129]\n",
      "5  user'  1 0.1505149978319906 [13]\n",
      "5  rule  1 0.2112745100035642 [92]\n",
      "5  grammar,  1 0.2112745100035642 [135]\n",
      "5  session  3 0.6338235300106926 [1,95,102]\n",
      "5  includ  1 0.2112745100035642 [163]\n",
      "5  contrast  1 0.2112745100035642 [171]\n",
      "5  also  1 0.1505149978319906 [205]\n",
      "5  benchmark  1 0.11928031367991561 [192]\n",
      "5  larg  1 0.0752574989159953 [79]\n",
      "5  seamlessli  1 0.2112745100035642 [109]\n",
      "5  two  1 0.2112745100035642 [191]\n",
      "5  graph  4 0.8450980400142568 [29,59,96,145]\n",
      "5  graph-bas  1 0.2112745100035642 [71]\n",
      "5  moreover,  1 0.2112745100035642 [115]\n",
      "5  coarse-grain  1 0.2112745100035642 [182]\n",
      "5  corpora,  1 0.2112745100035642 [125]\n",
      "5  (sgr),  1 0.2112745100035642 [61]\n",
      "5  convert  1 0.2112745100035642 [94]\n",
      "5  fine-grained.  1 0.2112745100035642 [184]\n",
      "5  neglect  1 0.2112745100035642 [48]\n",
      "5  textual  2 0.4225490200071284 [124,149]\n",
      "5  introduc  2 0.3010299956639812 [86,155]\n",
      "5  given  1 0.1505149978319906 [116]\n",
      "5  link  1 0.2112745100035642 [164]\n",
      "5  symbol  4 0.8450980400142568 [58,90,128,160]\n",
      "5  strategi  2 0.1989700043360188 [18,219]\n",
      "5  tiangong-st,  1 0.2112745100035642 [196]\n",
      "5  seri  1 0.2112745100035642 [5]\n",
      "5  structur  3 0.6338235300106926 [30,39,146]\n",
      "5  natur  1 0.1505149978319906 [118]\n",
      "5  propos  1 0.08560567020555157 [57]\n",
      "5  aim  1 0.1505149978319906 [63]\n",
      "5  within  1 0.2112745100035642 [147]\n",
      "5  need.  1 0.2112745100035642 [16]\n",
      "5  effect  1 0.11928031367991561 [210]\n",
      "5  gap  1 0.2112745100035642 [215]\n",
      "5  node  1 0.2112745100035642 [166]\n",
      "5  (llms).  1 0.2112745100035642 [82]\n",
      "5  involv  1 0.2112745100035642 [3]\n",
      "5  llms'  1 0.2112745100035642 [141]\n",
      "6  item  1 0.08600857018970891 [5]\n",
      "6  data  1 0.1207282914306081 [42]\n",
      "6  1m  1 0.1207282914306081 [97]\n",
      "6  consid  1 0.1207282914306081 [130]\n",
      "6  few-shot  1 0.1207282914306081 [120]\n",
      "6  scrape  2 0.2414565828612162 [34,165]\n",
      "6  book  1 0.1207282914306081 [110]\n",
      "6  dataset  4 0.34403428075883563 [98,105,124,144]\n",
      "6  titl  1 0.1207282914306081 [101]\n",
      "6  movi  3 0.36218487429182433 [100,128,184]\n",
      "6  manual  1 0.1207282914306081 [32]\n",
      "6  ndcg  1 0.1207282914306081 [175]\n",
      "6  gpt-3.5,  1 0.1207282914306081 [53]\n",
      "6  emerg  1 0.1207282914306081 [61]\n",
      "6  recent  1 0.06816017924566606 [45]\n",
      "6  concis  1 0.1207282914306081 [12]\n",
      "6  multipl  1 0.06816017924566606 [131]\n",
      "6  power  1 0.06816017924566606 [63]\n",
      "6  alpaca  1 0.1207282914306081 [59]\n",
      "6  llm,  1 0.1207282914306081 [115]\n",
      "6  viewer  1 0.1207282914306081 [19]\n",
      "6  promise,  1 0.1207282914306081 [189]\n",
      "6  tasks.  1 0.08600857018970891 [69]\n",
      "6  model  1 0.048917525831743754 [49]\n",
      "6  suscept  1 0.1207282914306081 [40]\n",
      "6  compris  1 0.1207282914306081 [99]\n",
      "6  result  2 0.11369714533486788 [180,191]\n",
      "6  process  1 0.08600857018970891 [68]\n",
      "6  obtain  2 0.2414565828612162 [30,196]\n",
      "6  cast  1 0.1207282914306081 [138]\n",
      "6  role  1 0.1207282914306081 [9]\n",
      "6  time-consum  1 0.1207282914306081 [38]\n",
      "6  study,  1 0.1207282914306081 [91]\n",
      "6  recommend  1 0.08600857018970891 [24]\n",
      "6  signific  1 0.1207282914306081 [188]\n",
      "6  publish  1 0.1207282914306081 [152]\n",
      "6  systems.  1 0.1207282914306081 [25]\n",
      "6  descriptions.  1 0.1207282914306081 [199]\n",
      "6  captiv  1 0.1207282914306081 [17]\n",
      "6  essenti  1 0.1207282914306081 [22]\n",
      "6  (llms),  1 0.1207282914306081 [50]\n",
      "6  open-sourc  1 0.08600857018970891 [114]\n",
      "6  director  1 0.1207282914306081 [140]\n",
      "6  provid  1 0.1207282914306081 [11]\n",
      "6  explor  1 0.08600857018970891 [75]\n",
      "6  llm  2 0.09783505166348751 [57,80]\n",
      "6  featur  1 0.1207282914306081 [132]\n",
      "6  techniques,  1 0.1207282914306081 [35]\n",
      "6  consist  1 0.1207282914306081 [106]\n",
      "6  inconsistencies.  1 0.1207282914306081 [43]\n",
      "6  detail  2 0.2414565828612162 [83,127]\n",
      "6  author  1 0.1207282914306081 [150]\n",
      "6  evalu  1 0.06816017924566606 [177]\n",
      "6  llm-base  1 0.06816017924566606 [183]\n",
      "6  web  1 0.1207282914306081 [33]\n",
      "6  pivot  1 0.1207282914306081 [8]\n",
      "6  sourc  1 0.1207282914306081 [56]\n",
      "6  movielen  1 0.1207282914306081 [96]\n",
      "6  paper,  1 0.05684857266743394 [72]\n",
      "6  hits,  1 0.1207282914306081 [172]\n",
      "6  exhibit  1 0.1207282914306081 [187]\n",
      "6  traditionally,  1 0.1207282914306081 [26]\n",
      "6  subsequently,  1 0.1207282914306081 [112]\n",
      "6  potenti  1 0.08600857018970891 [18]\n",
      "6  metrics.  1 0.08600857018970891 [178]\n",
      "6  top  1 0.1207282914306081 [171]\n",
      "6  like  2 0.2414565828612162 [58,133]\n",
      "6  combin  1 0.08600857018970891 [169]\n",
      "6  dataset.  1 0.1207282914306081 [156]\n",
      "6  gener  4 0.22739429066973577 [82,126,158,186]\n",
      "6  conduct  1 0.1207282914306081 [89]\n",
      "6  inform  1 0.06816017924566606 [14]\n",
      "6  languag  2 0.08600857018970891 [48,67]\n",
      "6  use  3 0.14675257749523127 [79,94,167]\n",
      "6  mrr,  1 0.1207282914306081 [173]\n",
      "6  goodread  2 0.2414565828612162 [104,155]\n",
      "6  items.  1 0.1207282914306081 [87]\n",
      "6  larg  1 0.043004285094854454 [47]\n",
      "6  tool  1 0.1207282914306081 [64]\n",
      "6  compar  2 0.2414565828612162 [162,192]\n",
      "6  alpaca,  1 0.1207282914306081 [116]\n",
      "6  name  3 0.36218487429182433 [108,135,147]\n",
      "6  one  1 0.1207282914306081 [195]\n",
      "6  web-scrap  1 0.1207282914306081 [198]\n",
      "6  prompt  2 0.11369714533486788 [118,121]\n",
      "6  natur  1 0.08600857018970891 [66]\n",
      "6  ml  1 0.1207282914306081 [143]\n",
      "6  descript  7 0.8450980400142568 [2,28,84,129,159,166,185]\n",
      "6  years,  1 0.1207282914306081 [46]\n",
      "6  open  1 0.1207282914306081 [55]\n",
      "6  play  1 0.1207282914306081 [6]\n",
      "6  summari  1 0.1207282914306081 [15]\n",
      "6  demonstr  1 0.06816017924566606 [181]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "descripteur_split_porter =\"\"\n",
    "\n",
    "for i in range(len(termes_split_porter)):\n",
    "    \n",
    "    for j in range(len(termes_split_porter[i])):\n",
    "\n",
    "        term = termes_split_porter[i][j]\n",
    "        #print(str(i) + \" \" +str(j)+ \" \" +term +\"\\n\")\n",
    "\n",
    "        frequency_term = frequency_dict_split_porter_documents[i][term]\n",
    "        max_frequancy = max_frequency_dict_split_porter_documents[i]\n",
    "        frequency_in_collection = document_frequency_dict_split_porter[term]\n",
    "\n",
    "        poids_term = poids(frequency_term,max_frequancy,frequency_in_collection,n_split)\n",
    "\n",
    "        term_positions = split_porter_positions[i][termes_split_porter[i][j]]\n",
    "        positions_string = \"[\" + \",\".join(str(pos) for pos in term_positions) + \"]\"\n",
    "\n",
    "        descripteur_split_porter = descripteur_split_porter + (str(i+1)+ \"  \" +termes_split_porter[i][j]+ \"  \" +str(frequency_term)+\" \"+ str(poids_term)+\" \"+positions_string+\"\\n\")\n",
    "\n",
    "\n",
    "print(descripteur_split_porter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['effici', 'averag', 'baselin', 'flan-ul2', 'beir', 'solut', 'dataset', 'linear', 'rank', 'challeng', 'queri', 'first', 'pointwis', 'achiev', 'exist', 'paper', 'model', 'variant', 'ranker', 'metric', 'literatur', 'result', 'research', 'seven', 'commerci', 'directli', 'standard', 'chatgpt', 'furthermor', 'improv', 'estim', '2019', '10%', 'open-sourc', 'problem', 'paramet', 'interest', '2020', 'listwis', '175b', 'llm', 'techniqu', 'perform', 'complex', 'size', 'howev', 'formul', 'prp', 'llm-base', 'reduc', 'even', 'understand', 'moderate-s', 'base', 'analyz', 'significantli', 'off-the-shelf', 'approach', '50x', 'gpt-4', 'pairwis', 'argu', 'previou', 'possibl', 'fine-tun', 'task', 'trec-dl', 'show', 'ndcg@10', 'languag', 'use', 'competit', 'favor', '4.2%', 'blackbox', 'burden', 'difficult', 'method', 'practic', 'outperform', 'larg', 'benchmark', 'templat', 'call', 'instructgpt', 'sever', 'found', 'feed', 'supervis', '12-10%', 'document', 'prompt', 'new', 'fulli', 'propos', 'state-of-the-art', 'best', '20b', 'candid']\n"
     ]
    }
   ],
   "source": [
    "print(termes_reg_porter[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  investig  1 0.16901960800285137 [73]\n",
      "1  feedback  3 0.3612359947967774 [120,166,172]\n",
      "1  experi  1 0.09542425094393249 [33]\n",
      "1  find  1 0.12041199826559248 [128]\n",
      "1  pseudo-relev  1 0.16901960800285137 [165]\n",
      "1  upto  1 0.16901960800285137 [144]\n",
      "1  ultim  1 0.16901960800285137 [105]\n",
      "1  success  1 0.12041199826559248 [62]\n",
      "1  text  1 0.09542425094393249 [20]\n",
      "1  instruct  1 0.12041199826559248 [98]\n",
      "1  recent  1 0.07958800173440753 [34]\n",
      "1  9%  1 0.16901960800285137 [168]\n",
      "1  msmarco  1 0.16901960800285137 [153]\n",
      "1  zero-shot  3 0.5070588240085541 [35,97,149]\n",
      "1  multipl  1 0.09542425094393249 [101]\n",
      "1  ensembl  2 0.33803921600570275 [64,87]\n",
      "1  rank  1 0.12041199826559248 [155]\n",
      "1  queri  3 0.23876400520322255 [1,17,79]\n",
      "1  transform  1 0.16901960800285137 [11]\n",
      "1  set  2 0.19084850188786498 [6,102]\n",
      "1  abil  1 0.12041199826559248 [48]\n",
      "1  model  1 0.06020599913279624 [56]\n",
      "1  variant  1 0.12041199826559248 [114]\n",
      "1  shown  1 0.16901960800285137 [39]\n",
      "1  intent  1 0.12041199826559248 [28]\n",
      "1  state-of-art  1 0.16901960800285137 [150]\n",
      "1  search  2 0.19084850188786498 [16,32]\n",
      "1  5%  1 0.16901960800285137 [162]\n",
      "1  map  1 0.16901960800285137 [142]\n",
      "1  better  2 0.33803921600570275 [22,132]\n",
      "1  improv  5 0.3979400086720376 [30,78,106,137,143]\n",
      "1  pseudo  1 0.16901960800285137 [118]\n",
      "1  techniqu  2 0.15917600346881505 [8,90]\n",
      "1  perform  1 0.09542425094393249 [108]\n",
      "1  relev  2 0.33803921600570275 [119,171]\n",
      "1  qr  2 0.33803921600570275 [3,36]\n",
      "1  context  1 0.16901960800285137 [83]\n",
      "1  reformul  3 0.3612359947967774 [2,80,133]\n",
      "1  evalu  1 0.09542425094393249 [122]\n",
      "1  incorpor  1 0.16901960800285137 [117]\n",
      "1  18%  1 0.16901960800285137 [140]\n",
      "1  mani  1 0.16901960800285137 [70]\n",
      "1  leverag  1 0.09542425094393249 [93]\n",
      "1  gain  1 0.16901960800285137 [160]\n",
      "1  help  1 0.16901960800285137 [77]\n",
      "1  base  1 0.09542425094393249 [88]\n",
      "1  approach  1 0.07958800173440753 [44]\n",
      "1  take  1 0.09542425094393249 [58]\n",
      "1  genqrensemblerf  2 0.33803921600570275 [115,157]\n",
      "1  benefit  1 0.16901960800285137 [69]\n",
      "1  rel  2 0.33803921600570275 [135,159]\n",
      "1  previou  1 0.09542425094393249 [148]\n",
      "1  genqrensembl  2 0.33803921600570275 [91,130]\n",
      "1  inspir  1 0.12041199826559248 [59]\n",
      "1  gener  2 0.15917600346881505 [100,131]\n",
      "1  retriev  1 0.12041199826559248 [107]\n",
      "1  task  2 0.13696907232888253 [71,156]\n",
      "1  knowledg  1 0.16901960800285137 [51]\n",
      "1  passag  1 0.16901960800285137 [154]\n",
      "1  due  1 0.16901960800285137 [45]\n",
      "1  show  1 0.12041199826559248 [158]\n",
      "1  ndcg@10  2 0.19084850188786498 [136,169]\n",
      "1  languag  1 0.06020599913279624 [55]\n",
      "1  use  3 0.20545360849332375 [9,164,170]\n",
      "1  promis  1 0.12041199826559248 [43]\n",
      "1  mrr  1 0.12041199826559248 [163]\n",
      "1  user  2 0.15917600346881505 [13,26]\n",
      "1  inher  1 0.16901960800285137 [52]\n",
      "1  keyword  1 0.16901960800285137 [104]\n",
      "1  origin  1 0.16901960800285137 [15]\n",
      "1  exploit  1 0.16901960800285137 [50]\n",
      "1  24%  1 0.16901960800285137 [145]\n",
      "1  benchmark  1 0.07958800173440753 [126]\n",
      "1  larg  1 0.06020599913279624 [54]\n",
      "1  paraphras  1 0.16901960800285137 [94]\n",
      "1  ir  1 0.12041199826559248 [125]\n",
      "1  align  1 0.16901960800285137 [23]\n",
      "1  introduc  1 0.12041199826559248 [111]\n",
      "1  strategi  1 0.07958800173440753 [66]\n",
      "1  document  1 0.09542425094393249 [173]\n",
      "1  prompt  2 0.13696907232888253 [65,89]\n",
      "1  propos  1 0.06848453616444126 [85]\n",
      "1  post-retriev  1 0.16901960800285137 [113]\n",
      "1  four  1 0.16901960800285137 [124]\n",
      "2  effici  1 0.10034333188799373 [205]\n",
      "2  averag  1 0.14084967333570947 [194]\n",
      "2  baselin  2 0.28169934667141894 [34,175]\n",
      "2  flan-ul2  1 0.14084967333570947 [114]\n",
      "2  beir  1 0.10034333188799373 [170]\n",
      "2  solut  3 0.4225490200071284 [147,182,188]\n",
      "2  dataset  1 0.06632333477867293 [38]\n",
      "2  linear  1 0.14084967333570947 [218]\n",
      "2  rank  6 0.6020599913279624 [1,44,61,82,96,160]\n",
      "2  challeng  1 0.14084967333570947 [60]\n",
      "2  queri  1 0.06632333477867293 [12]\n",
      "2  first  1 0.07952020911994373 [89]\n",
      "2  pointwis  2 0.28169934667141894 [41,186]\n",
      "2  achiev  2 0.15904041823988746 [94,213]\n",
      "2  exist  1 0.14084967333570947 [48]\n",
      "2  paper  1 0.06632333477867293 [65]\n",
      "2  model  3 0.1505149978319906 [6,115,141]\n",
      "2  variant  1 0.10034333188799373 [200]\n",
      "2  ranker  1 0.10034333188799373 [35]\n",
      "2  metric  1 0.10034333188799373 [161]\n",
      "2  literatur  2 0.28169934667141894 [92,128]\n",
      "2  result  2 0.13264666955734586 [86,215]\n",
      "2  research  1 0.10034333188799373 [26]\n",
      "2  seven  1 0.14084967333570947 [169]\n",
      "2  commerci  2 0.28169934667141894 [135,180]\n",
      "2  directli  1 0.14084967333570947 [9]\n",
      "2  standard  1 0.14084967333570947 [99]\n",
      "2  chatgpt  1 0.14084967333570947 [181]\n",
      "2  furthermor  1 0.10034333188799373 [196]\n",
      "2  improv  1 0.06632333477867293 [204]\n",
      "2  estim  1 0.14084967333570947 [140]\n",
      "2  2019  1 0.14084967333570947 [107]\n",
      "2  10%  1 0.14084967333570947 [157]\n",
      "2  open-sourc  1 0.10034333188799373 [103]\n",
      "2  problem  1 0.07952020911994373 [24]\n",
      "2  paramet  2 0.28169934667141894 [118,154]\n",
      "2  interest  1 0.14084967333570947 [21]\n",
      "2  2020  1 0.14084967333570947 [109]\n",
      "2  listwis  1 0.14084967333570947 [43]\n",
      "2  175b  1 0.14084967333570947 [153]\n",
      "2  llm  4 0.2282817872148042 [7,54,74,104]\n",
      "2  techniqu  1 0.06632333477867293 [79]\n",
      "2  perform  2 0.15904041823988746 [97,119]\n",
      "2  complex  1 0.10034333188799373 [219]\n",
      "2  size  1 0.14084967333570947 [142]\n",
      "2  howev  1 0.14084967333570947 [25]\n",
      "2  formul  1 0.14084967333570947 [62]\n",
      "2  prp  4 0.5633986933428379 [84,110,172,202]\n",
      "2  llm-base  2 0.15904041823988746 [146,187]\n",
      "2  reduc  1 0.10034333188799373 [70]\n",
      "2  even  1 0.14084967333570947 [216]\n",
      "2  understand  1 0.07952020911994373 [58]\n",
      "2  moderate-s  1 0.14084967333570947 [102]\n",
      "2  base  2 0.15904041823988746 [111,131]\n",
      "2  analyz  1 0.14084967333570947 [40]\n",
      "2  significantli  1 0.07952020911994373 [69]\n",
      "2  off-the-shelf  1 0.14084967333570947 [53]\n",
      "2  approach  1 0.06632333477867293 [125]\n",
      "2  50x  1 0.14084967333570947 [139]\n",
      "2  gpt-4  1 0.14084967333570947 [136]\n",
      "2  pairwis  1 0.14084967333570947 [81]\n",
      "2  argu  1 0.14084967333570947 [51]\n",
      "2  previou  1 0.07952020911994373 [123]\n",
      "2  possibl  1 0.14084967333570947 [211]\n",
      "2  fine-tun  1 0.10034333188799373 [33]\n",
      "2  task  1 0.05707044680370105 [171]\n",
      "2  trec-dl  1 0.14084967333570947 [106]\n",
      "2  show  1 0.10034333188799373 [207]\n",
      "2  ndcg@10  1 0.07952020911994373 [195]\n",
      "2  languag  1 0.050171665943996864 [5]\n",
      "2  use  5 0.28535223401850524 [3,46,76,101,163]\n",
      "2  competit  1 0.14084967333570947 [214]\n",
      "2  favor  1 0.14084967333570947 [120]\n",
      "2  4.2%  1 0.14084967333570947 [184]\n",
      "2  blackbox  2 0.28169934667141894 [134,179]\n",
      "2  burden  1 0.14084967333570947 [72]\n",
      "2  difficult  1 0.14084967333570947 [30]\n",
      "2  method  1 0.10034333188799373 [49]\n",
      "2  practic  1 0.14084967333570947 [23]\n",
      "2  outperform  4 0.5633986933428379 [32,144,173,177]\n",
      "2  larg  1 0.050171665943996864 [4]\n",
      "2  benchmark  2 0.13264666955734586 [37,100]\n",
      "2  templat  1 0.10034333188799373 [167]\n",
      "2  call  1 0.14084967333570947 [80]\n",
      "2  instructgpt  1 0.14084967333570947 [150]\n",
      "2  sever  1 0.14084967333570947 [199]\n",
      "2  found  1 0.14084967333570947 [28]\n",
      "2  feed  1 0.14084967333570947 [10]\n",
      "2  supervis  1 0.14084967333570947 [174]\n",
      "2  12-10%  1 0.14084967333570947 [192]\n",
      "2  document  2 0.15904041823988746 [2,15]\n",
      "2  prompt  4 0.2282817872148042 [18,45,83,166]\n",
      "2  new  1 0.14084967333570947 [78]\n",
      "2  fulli  1 0.14084967333570947 [57]\n",
      "2  propos  2 0.1141408936074021 [67,198]\n",
      "2  state-of-the-art  1 0.10034333188799373 [95]\n",
      "2  best  1 0.14084967333570947 [124]\n",
      "2  20b  1 0.14084967333570947 [117]\n",
      "2  candid  1 0.14084967333570947 [14]\n",
      "3  item  1 0.0752574989159953 [65]\n",
      "3  effici  5 0.3762874945799765 [50,157,188,197,213]\n",
      "3  design  1 0.1056372550017821 [147]\n",
      "3  pod  1 0.1056372550017821 [175]\n",
      "3  find  1 0.0752574989159953 [201]\n",
      "3  long  3 0.3169117650053463 [32,37,41]\n",
      "3  manifest  1 0.1056372550017821 [6]\n",
      "3  could  2 0.2112745100035642 [29,39]\n",
      "3  dataset  1 0.0497425010840047 [167]\n",
      "3  text  2 0.11928031367991561 [27,38]\n",
      "3  enough  1 0.1056372550017821 [51]\n",
      "3  system  1 0.0752574989159953 [54]\n",
      "3  bridg  2 0.1505149978319906 [93,135]\n",
      "3  power  1 0.059640156839957804 [105]\n",
      "3  time  2 0.1505149978319906 [42,144]\n",
      "3  may  2 0.2112745100035642 [47,202]\n",
      "3  set  1 0.059640156839957804 [127]\n",
      "3  fill  1 0.1056372550017821 [69]\n",
      "3  limit  2 0.1505149978319906 [24,199]\n",
      "3  user/item  1 0.1056372550017821 [95]\n",
      "3  unleash  1 0.1056372550017821 [103]\n",
      "3  model  8 0.3010299956639812 [3,8,21,62,79,87,161,217]\n",
      "3  specif  1 0.1056372550017821 [123]\n",
      "3  result  1 0.0497425010840047 [163]\n",
      "3  allow  1 0.0752574989159953 [77]\n",
      "3  i.e.  1 0.1056372550017821 [73]\n",
      "3  reason  1 0.1056372550017821 [15]\n",
      "3  research  1 0.0752574989159953 [204]\n",
      "3  process  1 0.0497425010840047 [44]\n",
      "3  requir  1 0.1056372550017821 [56]\n",
      "3  top-n  1 0.1056372550017821 [182]\n",
      "3  recommend  6 0.45154499349597177 [53,61,109,180,183,216]\n",
      "3  unparallel  1 0.1056372550017821 [7]\n",
      "3  attempt  1 0.1056372550017821 [153]\n",
      "3  noisi  1 0.1056372550017821 [35]\n",
      "3  input  1 0.059640156839957804 [18]\n",
      "3  improv  4 0.1989700043360188 [155,192,194,210]\n",
      "3  capabl  1 0.1056372550017821 [9]\n",
      "3  although  1 0.1056372550017821 [185]\n",
      "3  mostli  1 0.1056372550017821 [23]\n",
      "3  variou  1 0.0752574989159953 [11]\n",
      "3  thu  1 0.1056372550017821 [46]\n",
      "3  e.g.  1 0.1056372550017821 [13]\n",
      "3  problem  1 0.059640156839957804 [113]\n",
      "3  discret  2 0.2112745100035642 [74,119]\n",
      "3  distil  2 0.2112745100035642 [117,174]\n",
      "3  llm  2 0.08560567020555157 [4,107]\n",
      "3  address  1 0.1056372550017821 [111]\n",
      "3  sequenti  1 0.0752574989159953 [179]\n",
      "3  commun  1 0.1056372550017821 [207]\n",
      "3  llm-base  2 0.11928031367991561 [60,215]\n",
      "3  reduc  1 0.0752574989159953 [141]\n",
      "3  extens  1 0.1056372550017821 [90]\n",
      "3  understand  1 0.059640156839957804 [81]\n",
      "3  immedi  1 0.1056372550017821 [57]\n",
      "3  usual  2 0.2112745100035642 [68,88]\n",
      "3  respons  1 0.1056372550017821 [58]\n",
      "3  vector  1 0.1056372550017821 [131]\n",
      "3  significantli  1 0.059640156839957804 [191]\n",
      "3  approach  1 0.0497425010840047 [176]\n",
      "3  take  1 0.059640156839957804 [40]\n",
      "3  experiment  1 0.1056372550017821 [162]\n",
      "3  word  2 0.2112745100035642 [100,138]\n",
      "3  infer  3 0.3169117650053463 [143,196,212]\n",
      "3  real-world  1 0.1056372550017821 [166]\n",
      "3  inspir  1 0.0752574989159953 [203]\n",
      "3  fine-tun  1 0.0752574989159953 [91]\n",
      "3  task  4 0.17121134041110314 [12,84,124,184]\n",
      "3  contain  1 0.1056372550017821 [34]\n",
      "3  inform  1 0.0497425010840047 [36]\n",
      "3  languag  1 0.03762874945799765 [2]\n",
      "3  continu  1 0.1056372550017821 [129]\n",
      "3  also  1 0.0752574989159953 [146]\n",
      "3  need  1 0.0752574989159953 [89]\n",
      "3  user  1 0.0497425010840047 [63]\n",
      "3  id  3 0.3169117650053463 [66,96,136]\n",
      "3  larg  1 0.03762874945799765 [1]\n",
      "3  train  3 0.3169117650053463 [149,159,187]\n",
      "3  templat  2 0.1505149978319906 [72,99]\n",
      "3  three  1 0.1056372550017821 [165]\n",
      "3  plain  1 0.1056372550017821 [26]\n",
      "3  given  1 0.0752574989159953 [83]\n",
      "3  strategi  1 0.0497425010840047 [150]\n",
      "3  multi-step  1 0.1056372550017821 [14]\n",
      "3  prompt  4 0.17121134041110314 [75,120,130,173]\n",
      "3  propos  1 0.042802835102775785 [115]\n",
      "3  effect  1 0.059640156839957804 [170]\n",
      "3  demonstr  1 0.059640156839957804 [168]\n",
      "4  complet  1 0.09389978222380631 [17]\n",
      "4  optim  1 0.09389978222380631 [122]\n",
      "4  feedback  1 0.06689555459199582 [140]\n",
      "4  experi  1 0.05301347274662915 [143]\n",
      "4  integr  1 0.06689555459199582 [127]\n",
      "4  beir  1 0.06689555459199582 [146]\n",
      "4  success  1 0.06689555459199582 [16]\n",
      "4  custom  1 0.09389978222380631 [95]\n",
      "4  qerm  1 0.09389978222380631 [134]\n",
      "4  recent  1 0.04421555651911529 [26]\n",
      "4  multipl  1 0.05301347274662915 [71]\n",
      "4  time  1 0.06689555459199582 [82]\n",
      "4  loop  1 0.09389978222380631 [141]\n",
      "4  queri  9 0.3979400086720376 [1,25,35,74,89,93,115,130,156]\n",
      "4  first  1 0.05301347274662915 [81]\n",
      "4  limit  1 0.06689555459199582 [40]\n",
      "4  crucial  1 0.09389978222380631 [126]\n",
      "4  achiev  1 0.05301347274662915 [151]\n",
      "4  redund  1 0.09389978222380631 [42]\n",
      "4  paper  1 0.04421555651911529 [54]\n",
      "4  model  2 0.06689555459199582 [31,133]\n",
      "4  divers  4 0.37559912889522523 [50,66,105,113]\n",
      "4  gencrf  3 0.28169934667141894 [57,83,150]\n",
      "4  enhanc  1 0.06689555459199582 [13]\n",
      "4  intent  4 0.2675822183679833 [51,67,106,114]\n",
      "4  search  1 0.05301347274662915 [15]\n",
      "4  process  1 0.04421555651911529 [138]\n",
      "4  input  1 0.05301347274662915 [24]\n",
      "4  furthermor  1 0.06689555459199582 [107]\n",
      "4  improv  1 0.04421555651911529 [34]\n",
      "4  variou  1 0.06689555459199582 [171]\n",
      "4  differenti  1 0.09389978222380631 [72]\n",
      "4  rate  1 0.09389978222380631 [18]\n",
      "4  well-known  1 0.09389978222380631 [5]\n",
      "4  problem  1 0.05301347274662915 [6]\n",
      "4  explor  1 0.06689555459199582 [110]\n",
      "4  llm  3 0.1141408936074021 [32,85,172]\n",
      "4  perform  3 0.15904041823988746 [124,153,176]\n",
      "4  adapt  2 0.18779956444761262 [68,169]\n",
      "4  expans  1 0.09389978222380631 [43]\n",
      "4  group  1 0.09389978222380631 [101]\n",
      "4  techniqu  1 0.04421555651911529 [166]\n",
      "4  constrain  1 0.09389978222380631 [45]\n",
      "4  captur  2 0.13379110918399165 [49,65]\n",
      "4  advanc  1 0.09389978222380631 [178]\n",
      "4  sota  1 0.09389978222380631 [158]\n",
      "4  modifi  1 0.09389978222380631 [21]\n",
      "4  reformul  4 0.2675822183679833 [2,36,62,157]\n",
      "4  evalu  1 0.05301347274662915 [131]\n",
      "4  leverag  2 0.1060269454932583 [28,84]\n",
      "4  novel  1 0.06689555459199582 [129]\n",
      "4  base  1 0.05301347274662915 [69]\n",
      "4  innov  1 0.09389978222380631 [117]\n",
      "4  significantli  1 0.05301347274662915 [173]\n",
      "4  potenti  1 0.06689555459199582 [44]\n",
      "4  well-gener  1 0.09389978222380631 [73]\n",
      "4  boost  1 0.09389978222380631 [174]\n",
      "4  previou  1 0.05301347274662915 [155]\n",
      "4  combin  1 0.06689555459199582 [112]\n",
      "4  gener  3 0.13264666955734586 [39,59,87]\n",
      "4  retriev  5 0.3344777729599791 [9,77,123,175,183]\n",
      "4  reward  1 0.09389978222380631 [132]\n",
      "4  inform  2 0.08843111303823058 [8,182]\n",
      "4  languag  1 0.03344777729599791 [30]\n",
      "4  use  1 0.0380469645358007 [94]\n",
      "4  empir  1 0.09389978222380631 [142]\n",
      "4  ndcg@10  1 0.05301347274662915 [164]\n",
      "4  field  1 0.09389978222380631 [180]\n",
      "4  singl  1 0.09389978222380631 [14]\n",
      "4  user  1 0.04421555651911529 [22]\n",
      "4  surpass  1 0.09389978222380631 [154]\n",
      "4  variabl  1 0.09389978222380631 [88]\n",
      "4  repres  1 0.09389978222380631 [104]\n",
      "4  method  1 0.06689555459199582 [27]\n",
      "4  framework  2 0.18779956444761262 [63,109]\n",
      "4  benchmark  1 0.04421555651911529 [147]\n",
      "4  larg  1 0.03344777729599791 [29]\n",
      "4  aggreg  1 0.09389978222380631 [119]\n",
      "4  often  1 0.09389978222380631 [38]\n",
      "4  ir  1 0.06689555459199582 [10]\n",
      "4  distinctli  1 0.09389978222380631 [103]\n",
      "4  refin  1 0.09389978222380631 [136]\n",
      "4  strategi  1 0.04421555651911529 [120]\n",
      "4  automat  1 0.09389978222380631 [20]\n",
      "4  prompt  1 0.0380469645358007 [96]\n",
      "4  12%  1 0.09389978222380631 [162]\n",
      "4  propos  1 0.0380469645358007 [56]\n",
      "4  phase  1 0.09389978222380631 [78]\n",
      "4  state-of-the-art  1 0.06689555459199582 [152]\n",
      "4  aim  1 0.06689555459199582 [11]\n",
      "4  effect  1 0.05301347274662915 [47]\n",
      "4  initi  1 0.09389978222380631 [92]\n",
      "4  cluster  2 0.18779956444761262 [60,98]\n",
      "4  demonstr  1 0.05301347274662915 [148]\n",
      "4  weight  1 0.09389978222380631 [118]\n",
      "5  semant  2 0.28169934667141894 [26,52]\n",
      "5  interact  3 0.4225490200071284 [7,33,105]\n",
      "5  methodolog  1 0.14084967333570947 [212]\n",
      "5  experi  1 0.07952020911994373 [186]\n",
      "5  integr  1 0.10034333188799373 [102]\n",
      "5  represent  1 0.14084967333570947 [46]\n",
      "5  advantag  1 0.14084967333570947 [67]\n",
      "5  dataset  1 0.06632333477867293 [194]\n",
      "5  text  1 0.07952020911994373 [99]\n",
      "5  instruct  1 0.10034333188799373 [109]\n",
      "5  modern  1 0.14084967333570947 [222]\n",
      "5  object  1 0.14084967333570947 [138]\n",
      "5  bridg  1 0.10034333188799373 [214]\n",
      "5  recent  1 0.06632333477867293 [79]\n",
      "5  analysi  1 0.14084967333570947 [190]\n",
      "5  power  1 0.07952020911994373 [77]\n",
      "5  superior  1 0.14084967333570947 [200]\n",
      "5  queri  1 0.06632333477867293 [8]\n",
      "5  first  1 0.07952020911994373 [86]\n",
      "5  set  2 0.15904041823988746 [89,158]\n",
      "5  content  1 0.14084967333570947 [168]\n",
      "5  abil  1 0.10034333188799373 [143]\n",
      "5  fine-grain  1 0.14084967333570947 [185]\n",
      "5  current  1 0.14084967333570947 [18]\n",
      "5  concret  1 0.14084967333570947 [84]\n",
      "5  achiev  1 0.07952020911994373 [153]\n",
      "5  paper  1 0.06632333477867293 [56]\n",
      "5  aol  1 0.14084967333570947 [195]\n",
      "5  model  3 0.1505149978319906 [23,53,82]\n",
      "5  ranker  1 0.10034333188799373 [61]\n",
      "5  tradit  1 0.10034333188799373 [218]\n",
      "5  format  1 0.14084967333570947 [151]\n",
      "5  enhanc  1 0.10034333188799373 [141]\n",
      "5  result  1 0.06632333477867293 [187]\n",
      "5  allow  1 0.10034333188799373 [101]\n",
      "5  search  2 0.15904041823988746 [2,219]\n",
      "5  process  1 0.06632333477867293 [106]\n",
      "5  confirm  1 0.14084967333570947 [198]\n",
      "5  input  1 0.07952020911994373 [112]\n",
      "5  learn  2 0.28169934667141894 [162,173]\n",
      "5  focu  1 0.14084967333570947 [37]\n",
      "5  corpora  1 0.14084967333570947 [126]\n",
      "5  offer  1 0.14084967333570947 [207]\n",
      "5  typic  1 0.14084967333570947 [20]\n",
      "5  llm  6 0.3424226808222063 [83,115,122,142,176,223]\n",
      "5  complex  1 0.10034333188799373 [15]\n",
      "5  sequenti  1 0.10034333188799373 [22]\n",
      "5  discrep  1 0.14084967333570947 [120]\n",
      "5  paradigm  1 0.14084967333570947 [205]\n",
      "5  captur  3 0.3010299956639812 [39,145,178]\n",
      "5  pre-train  1 0.14084967333570947 [123]\n",
      "5  produc  1 0.14084967333570947 [132]\n",
      "5  word-level  1 0.14084967333570947 [51]\n",
      "5  understand  1 0.07952020911994373 [27]\n",
      "5  leverag  1 0.07952020911994373 [75]\n",
      "5  novel  1 0.10034333188799373 [209]\n",
      "5  predict  1 0.14084967333570947 [166]\n",
      "5  tiangong-st  1 0.14084967333570947 [197]\n",
      "5  grammar  2 0.28169934667141894 [92,136]\n",
      "5  action  1 0.14084967333570947 [10]\n",
      "5  text-bas  1 0.14084967333570947 [70]\n",
      "5  approach  3 0.1989700043360188 [36,73,203]\n",
      "5  take  1 0.07952020911994373 [66]\n",
      "5  self-supervis  1 0.14084967333570947 [160]\n",
      "5  comprehens  1 0.14084967333570947 [189]\n",
      "5  deep  1 0.14084967333570947 [25]\n",
      "5  fulfil  1 0.14084967333570947 [12]\n",
      "5  gener  3 0.1989700043360188 [45,169,171]\n",
      "5  task  2 0.1141408936074021 [108,163]\n",
      "5  topolog  1 0.14084967333570947 [180]\n",
      "5  graph-to-text  1 0.14084967333570947 [135]\n",
      "5  overlook  1 0.14084967333570947 [28]\n",
      "5  enabl  1 0.14084967333570947 [175]\n",
      "5  inform  3 0.1989700043360188 [16,41,181]\n",
      "5  priorit  1 0.14084967333570947 [21]\n",
      "5  use  2 0.1141408936074021 [43,133]\n",
      "5  languag  2 0.10034333188799373 [81,130]\n",
      "5  rule  1 0.14084967333570947 [93]\n",
      "5  includ  1 0.14084967333570947 [164]\n",
      "5  session  3 0.4225490200071284 [1,96,103]\n",
      "5  contrast  1 0.14084967333570947 [172]\n",
      "5  need  1 0.10034333188799373 [17]\n",
      "5  user  1 0.06632333477867293 [13]\n",
      "5  also  1 0.10034333188799373 [206]\n",
      "5  histori  1 0.14084967333570947 [104]\n",
      "5  benchmark  1 0.06632333477867293 [193]\n",
      "5  larg  1 0.050171665943996864 [80]\n",
      "5  seamlessli  1 0.14084967333570947 [110]\n",
      "5  two  1 0.14084967333570947 [192]\n",
      "5  graph  4 0.5633986933428379 [30,60,97,146]\n",
      "5  sgr  1 0.14084967333570947 [62]\n",
      "5  graph-bas  1 0.14084967333570947 [72]\n",
      "5  coarse-grain  1 0.14084967333570947 [183]\n",
      "5  convert  1 0.14084967333570947 [95]\n",
      "5  moreov  1 0.14084967333570947 [116]\n",
      "5  neglect  1 0.14084967333570947 [49]\n",
      "5  textual  2 0.28169934667141894 [125,150]\n",
      "5  introduc  2 0.20068666377598746 [87,156]\n",
      "5  given  1 0.10034333188799373 [117]\n",
      "5  link  1 0.14084967333570947 [165]\n",
      "5  symbol  4 0.5633986933428379 [59,91,129,161]\n",
      "5  strategi  2 0.13264666955734586 [19,220]\n",
      "5  document  1 0.07952020911994373 [48]\n",
      "5  seri  1 0.14084967333570947 [5]\n",
      "5  structur  3 0.4225490200071284 [31,40,147]\n",
      "5  natur  1 0.10034333188799373 [119]\n",
      "5  propos  1 0.05707044680370105 [58]\n",
      "5  aim  1 0.10034333188799373 [64]\n",
      "5  within  1 0.14084967333570947 [148]\n",
      "5  effect  1 0.07952020911994373 [211]\n",
      "5  gap  1 0.14084967333570947 [216]\n",
      "5  node  1 0.14084967333570947 [167]\n",
      "5  involv  1 0.14084967333570947 [3]\n",
      "6  item  2 0.1505149978319906 [5,87]\n",
      "6  data  1 0.1056372550017821 [42]\n",
      "6  1m  1 0.1056372550017821 [97]\n",
      "6  gpt-3.5  1 0.1056372550017821 [53]\n",
      "6  consid  1 0.1056372550017821 [130]\n",
      "6  few-shot  1 0.1056372550017821 [120]\n",
      "6  inconsist  1 0.1056372550017821 [43]\n",
      "6  scrape  2 0.2112745100035642 [34,165]\n",
      "6  book  1 0.1056372550017821 [110]\n",
      "6  dataset  5 0.2487125054200235 [98,105,124,144,156]\n",
      "6  titl  1 0.1056372550017821 [101]\n",
      "6  movi  3 0.3169117650053463 [100,128,184]\n",
      "6  manual  1 0.1056372550017821 [32]\n",
      "6  ndcg  1 0.1056372550017821 [175]\n",
      "6  emerg  1 0.1056372550017821 [61]\n",
      "6  system  1 0.0752574989159953 [25]\n",
      "6  recent  1 0.0497425010840047 [45]\n",
      "6  concis  1 0.1056372550017821 [12]\n",
      "6  multipl  1 0.059640156839957804 [131]\n",
      "6  power  1 0.059640156839957804 [63]\n",
      "6  alpaca  2 0.2112745100035642 [59,116]\n",
      "6  viewer  1 0.1056372550017821 [19]\n",
      "6  paper  1 0.0497425010840047 [72]\n",
      "6  model  1 0.03762874945799765 [49]\n",
      "6  subsequ  1 0.1056372550017821 [112]\n",
      "6  tradit  1 0.0752574989159953 [26]\n",
      "6  suscept  1 0.1056372550017821 [40]\n",
      "6  compris  1 0.1056372550017821 [99]\n",
      "6  metric  1 0.0752574989159953 [178]\n",
      "6  result  2 0.0994850021680094 [180,191]\n",
      "6  process  1 0.0497425010840047 [68]\n",
      "6  obtain  2 0.2112745100035642 [30,196]\n",
      "6  cast  1 0.1056372550017821 [138]\n",
      "6  role  1 0.1056372550017821 [9]\n",
      "6  time-consum  1 0.1056372550017821 [38]\n",
      "6  recommend  1 0.0752574989159953 [24]\n",
      "6  signific  1 0.1056372550017821 [188]\n",
      "6  publish  1 0.1056372550017821 [152]\n",
      "6  captiv  1 0.1056372550017821 [17]\n",
      "6  essenti  1 0.1056372550017821 [22]\n",
      "6  open-sourc  1 0.0752574989159953 [114]\n",
      "6  director  1 0.1056372550017821 [140]\n",
      "6  provid  1 0.1056372550017821 [11]\n",
      "6  explor  1 0.0752574989159953 [75]\n",
      "6  techniqu  1 0.0497425010840047 [35]\n",
      "6  llm  4 0.17121134041110314 [50,57,80,115]\n",
      "6  featur  1 0.1056372550017821 [132]\n",
      "6  consist  1 0.1056372550017821 [106]\n",
      "6  detail  2 0.2112745100035642 [83,127]\n",
      "6  author  1 0.1056372550017821 [150]\n",
      "6  evalu  1 0.059640156839957804 [177]\n",
      "6  llm-base  1 0.059640156839957804 [183]\n",
      "6  web  1 0.1056372550017821 [33]\n",
      "6  pivot  1 0.1056372550017821 [8]\n",
      "6  sourc  1 0.1056372550017821 [56]\n",
      "6  movielen  1 0.1056372550017821 [96]\n",
      "6  year  1 0.1056372550017821 [46]\n",
      "6  exhibit  1 0.1056372550017821 [187]\n",
      "6  potenti  1 0.0752574989159953 [18]\n",
      "6  top  1 0.1056372550017821 [171]\n",
      "6  like  2 0.2112745100035642 [58,133]\n",
      "6  combin  1 0.0752574989159953 [169]\n",
      "6  gener  4 0.1989700043360188 [82,126,158,186]\n",
      "6  task  1 0.042802835102775785 [69]\n",
      "6  conduct  1 0.1056372550017821 [89]\n",
      "6  inform  1 0.0497425010840047 [14]\n",
      "6  languag  2 0.0752574989159953 [48,67]\n",
      "6  use  3 0.12840850530832737 [79,94,167]\n",
      "6  mrr  1 0.0752574989159953 [173]\n",
      "6  promis  1 0.0752574989159953 [189]\n",
      "6  goodread  2 0.2112745100035642 [104,155]\n",
      "6  larg  1 0.03762874945799765 [47]\n",
      "6  tool  1 0.1056372550017821 [64]\n",
      "6  compar  2 0.2112745100035642 [162,192]\n",
      "6  studi  1 0.1056372550017821 [91]\n",
      "6  name  3 0.3169117650053463 [108,135,147]\n",
      "6  one  1 0.1056372550017821 [195]\n",
      "6  web-scrap  1 0.1056372550017821 [198]\n",
      "6  prompt  2 0.08560567020555157 [118,121]\n",
      "6  natur  1 0.0752574989159953 [66]\n",
      "6  ml  1 0.1056372550017821 [143]\n",
      "6  descript  8 0.8450980400142568 [2,28,84,129,159,166,185,199]\n",
      "6  hit  1 0.1056372550017821 [172]\n",
      "6  open  1 0.1056372550017821 [55]\n",
      "6  play  1 0.1056372550017821 [6]\n",
      "6  summari  1 0.1056372550017821 [15]\n",
      "6  demonstr  1 0.059640156839957804 [181]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "descripteur_reg_porter =\"\"\n",
    "\n",
    "for i in range(len(termes_reg_porter)):\n",
    "    \n",
    "    for j in range(len(termes_reg_porter[i])):\n",
    "\n",
    "        term = termes_reg_porter[i][j]\n",
    "        #print(str(i) + \" \" +str(j)+ \" \" +term +\"\\n\")\n",
    "\n",
    "        frequency_term = frequency_dict_reg_porter_documents[i][term]\n",
    "        max_frequancy = max_frequency_dict_reg_porter_documents[i]\n",
    "        frequency_in_collection = document_frequency_dict_reg_porter[term]\n",
    "\n",
    "        poids_term = poids(frequency_term,max_frequancy,frequency_in_collection,n_reg)\n",
    "\n",
    "        term_positions = reg_porter_positions[i][termes_reg_porter[i][j]]\n",
    "        positions_string = \"[\" + \",\".join(str(pos) for pos in term_positions) + \"]\"\n",
    "\n",
    "        descripteur_reg_porter = descripteur_reg_porter + (str(i+1)+ \"  \" +termes_reg_porter[i][j]+ \"  \" +str(frequency_term)+\" \"+ str(poids_term)+\" \"+positions_string+\"\\n\")\n",
    "\n",
    "\n",
    "print(descripteur_reg_porter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  task,  1 0.12041199826559248 [153]\n",
      "1  pass  1 0.16901960800285137 [151]\n",
      "1  investig  1 0.16901960800285137 [70]\n",
      "1  feedback  1 0.12041199826559248 [169]\n",
      "1  find  1 0.12041199826559248 [125]\n",
      "1  techn  1 0.09542425094393249 [7]\n",
      "1  upto  1 0.16901960800285137 [141]\n",
      "1  documents.  1 0.16901960800285137 [170]\n",
      "1  ultim  1 0.16901960800285137 [102]\n",
      "1  success  1 0.12041199826559248 [59]\n",
      "1  text  1 0.09542425094393249 [18]\n",
      "1  instruct  1 0.12041199826559248 [95]\n",
      "1  state-of-art.  1 0.16901960800285137 [147]\n",
      "1  9%  1 0.16901960800285137 [165]\n",
      "1  msmarco  1 0.16901960800285137 [150]\n",
      "1  zero-shot  3 0.5070588240085541 [32,94,146]\n",
      "1  multipl  1 0.09542425094393249 [98]\n",
      "1  technique,  1 0.16901960800285137 [87]\n",
      "1  ensembl  2 0.33803921600570275 [61,84]\n",
      "1  rank  1 0.09542425094393249 [152]\n",
      "1  transform  1 0.16901960800285137 [10]\n",
      "1  prom  1 0.16901960800285137 [40]\n",
      "1  set  2 0.19084850188786498 [5,99]\n",
      "1  shown  1 0.16901960800285137 [36]\n",
      "1  inh  1 0.16901960800285137 [49]\n",
      "1  us  3 0.1806179973983887 [8,161,167]\n",
      "1  search  2 0.19084850188786498 [14,29]\n",
      "1  5%  1 0.16901960800285137 [159]\n",
      "1  map  1 0.16901960800285137 [139]\n",
      "1  improv  5 0.3979400086720376 [27,75,103,134,140]\n",
      "1  feedback,  1 0.16901960800285137 [163]\n",
      "1  pseudo  1 0.16901960800285137 [115]\n",
      "1  recently,  1 0.16901960800285137 [31]\n",
      "1  many  1 0.16901960800285137 [67]\n",
      "1  bas  1 0.09542425094393249 [85]\n",
      "1  performance.  1 0.16901960800285137 [105]\n",
      "1  tak  1 0.09542425094393249 [55]\n",
      "1  relev  2 0.33803921600570275 [116,168]\n",
      "1  experience.  1 0.16901960800285137 [30]\n",
      "1  qr  1 0.16901960800285137 [33]\n",
      "1  langu  1 0.06020599913279624 [52]\n",
      "1  lev  1 0.09542425094393249 [90]\n",
      "1  evalu  1 0.09542425094393249 [119]\n",
      "1  post-retrieval  1 0.16901960800285137 [110]\n",
      "1  tasks,  1 0.09542425094393249 [68]\n",
      "1  18%  1 0.16901960800285137 [137]\n",
      "1  gain  1 0.16901960800285137 [157]\n",
      "1  help  1 0.16901960800285137 [74]\n",
      "1  reformulation(qr)  1 0.16901960800285137 [2]\n",
      "1  strategies  1 0.09542425094393249 [63]\n",
      "1  approach  1 0.07958800173440753 [41]\n",
      "1  genqrensemblerf  2 0.33803921600570275 [112,154]\n",
      "1  benefit  1 0.16901960800285137 [66]\n",
      "1  rel  2 0.33803921600570275 [132,156]\n",
      "1  models.  1 0.12041199826559248 [53]\n",
      "1  abl  1 0.12041199826559248 [45]\n",
      "1  genqrensembl  2 0.33803921600570275 [88,127]\n",
      "1  prevy  1 0.09542425094393249 [145]\n",
      "1  inspir  1 0.12041199826559248 [56]\n",
      "1  retriev  1 0.12041199826559248 [104]\n",
      "1  int  1 0.12041199826559248 [25]\n",
      "1  knowledg  1 0.16901960800285137 [48]\n",
      "1  due  1 0.16901960800285137 [42]\n",
      "1  show  1 0.12041199826559248 [155]\n",
      "1  context,  1 0.16901960800285137 [80]\n",
      "1  ndcg@10  2 0.33803921600570275 [133,166]\n",
      "1  mrr  1 0.16901960800285137 [160]\n",
      "1  benchmarks,  1 0.16901960800285137 [123]\n",
      "1  keyword  1 0.16901960800285137 [101]\n",
      "1  origin  1 0.16901960800285137 [13]\n",
      "1  exploit  1 0.16901960800285137 [47]\n",
      "1  24%  1 0.16901960800285137 [142]\n",
      "1  query  3 0.23876400520322255 [1,15,76]\n",
      "1  larg  1 0.06020599913279624 [51]\n",
      "1  reform  1 0.12041199826559248 [130]\n",
      "1  bet  2 0.33803921600570275 [20,129]\n",
      "1  paraphras  1 0.16901960800285137 [91]\n",
      "1  ir  1 0.16901960800285137 [122]\n",
      "1  reformulation.  1 0.16901960800285137 [77]\n",
      "1  align  1 0.16901960800285137 [21]\n",
      "1  introduc  1 0.12041199826559248 [108]\n",
      "1  variant,  1 0.16901960800285137 [111]\n",
      "1  prompt  2 0.15917600346881505 [62,86]\n",
      "1  incorp  1 0.16901960800285137 [114]\n",
      "1  propos  1 0.06848453616444126 [82]\n",
      "1  gen  2 0.15917600346881505 [97,128]\n",
      "1  pseudo-relevance  1 0.16901960800285137 [162]\n",
      "1  feedback.  1 0.16901960800285137 [117]\n",
      "1  user’s  2 0.33803921600570275 [12,24]\n",
      "1  four  1 0.16901960800285137 [121]\n",
      "2  pairw  1 0.1207282914306081 [81]\n",
      "2  efficy  1 0.08600857018970891 [205]\n",
      "2  baselin  2 0.2414565828612162 [34,175]\n",
      "2  docu  2 0.2414565828612162 [2,15]\n",
      "2  techn  1 0.06816017924566606 [79]\n",
      "2  solutions,  1 0.1207282914306081 [147]\n",
      "2  flan-ul2  1 0.1207282914306081 [114]\n",
      "2  beir  1 0.08600857018970891 [170]\n",
      "2  linear  1 0.1207282914306081 [218]\n",
      "2  moderate-sized  1 0.1207282914306081 [102]\n",
      "2  parameters,  1 0.1207282914306081 [154]\n",
      "2  direct  1 0.08600857018970891 [9]\n",
      "2  solv  2 0.2414565828612162 [182,188]\n",
      "2  listw  1 0.1207282914306081 [43]\n",
      "2  rank  7 0.47712125471966244 [1,35,44,61,82,96,160]\n",
      "2  challeng  1 0.1207282914306081 [60]\n",
      "2  fine-tuned  1 0.1207282914306081 [33]\n",
      "2  first  1 0.06816017924566606 [89]\n",
      "2  cal  1 0.1207282914306081 [80]\n",
      "2  achiev  2 0.13632035849133212 [94,213]\n",
      "2  llm-based  2 0.13632035849133212 [146,187]\n",
      "2  model  3 0.14675257749523127 [6,115,141]\n",
      "2  open-sourced  1 0.08600857018970891 [103]\n",
      "2  ndcg@10.  1 0.08600857018970891 [195]\n",
      "2  us  5 0.21502142547427228 [3,46,76,101,163]\n",
      "2  result  2 0.11369714533486788 [86,215]\n",
      "2  ev  1 0.1207282914306081 [216]\n",
      "2  research  1 0.08600857018970891 [26]\n",
      "2  standard  1 0.1207282914306081 [99]\n",
      "2  chatgpt  1 0.1207282914306081 [181]\n",
      "2  (llms)  1 0.08600857018970891 [7]\n",
      "2  improv  1 0.05684857266743394 [204]\n",
      "2  2019  1 0.1207282914306081 [107]\n",
      "2  formulations.  1 0.1207282914306081 [62]\n",
      "2  (prp).  1 0.1207282914306081 [84]\n",
      "2  10%  1 0.1207282914306081 [157]\n",
      "2  paramet  1 0.1207282914306081 [118]\n",
      "2  bas  2 0.13632035849133212 [111,131]\n",
      "2  pointw  2 0.2414565828612162 [41,186]\n",
      "2  interest  1 0.1207282914306081 [21]\n",
      "2  175b  1 0.1207282914306081 [153]\n",
      "2  perform  2 0.17201714037941782 [97,119]\n",
      "2  problem.  1 0.1207282914306081 [24]\n",
      "2  complex  1 0.08600857018970891 [219]\n",
      "2  fee  1 0.1207282914306081 [10]\n",
      "2  lit  1 0.1207282914306081 [92]\n",
      "2  langu  1 0.043004285094854454 [5]\n",
      "2  prp  3 0.36218487429182433 [110,172,202]\n",
      "2  (estimated)  1 0.1207282914306081 [140]\n",
      "2  analys  1 0.08600857018970891 [40]\n",
      "2  however,  1 0.1207282914306081 [25]\n",
      "2  reduc  1 0.08600857018970891 [70]\n",
      "2  tasks,  1 0.06816017924566606 [171]\n",
      "2  understand  1 0.08600857018970891 [58]\n",
      "2  superv  1 0.1207282914306081 [174]\n",
      "2  paper,  1 0.05684857266743394 [65]\n",
      "2  commerc  2 0.2414565828612162 [135,180]\n",
      "2  llms.  1 0.08600857018970891 [104]\n",
      "2  datasets.  1 0.1207282914306081 [38]\n",
      "2  templ  1 0.08600857018970891 [167]\n",
      "2  off-the-shelf  1 0.1207282914306081 [53]\n",
      "2  approach  1 0.05684857266743394 [125]\n",
      "2  50x  1 0.1207282914306081 [139]\n",
      "2  gpt-4  1 0.1207282914306081 [136]\n",
      "2  metrics.  1 0.08600857018970891 [161]\n",
      "2  argu  1 0.1207282914306081 [51]\n",
      "2  vary  1 0.06816017924566606 [200]\n",
      "2  furthermore,  1 0.08600857018970891 [196]\n",
      "2  prevy  1 0.06816017924566606 [123]\n",
      "2  trec-dl  1 0.1207282914306081 [106]\n",
      "2  show  1 0.08600857018970891 [207]\n",
      "2  pract  1 0.1207282914306081 [23]\n",
      "2  competit  1 0.1207282914306081 [214]\n",
      "2  sev  2 0.2414565828612162 [169,199]\n",
      "2  4.2%  1 0.1207282914306081 [184]\n",
      "2  blackbox  2 0.2414565828612162 [134,179]\n",
      "2  llms  2 0.11369714533486788 [54,74]\n",
      "2  difficult  1 0.1207282914306081 [30]\n",
      "2  2020,  1 0.1207282914306081 [109]\n",
      "2  method  1 0.08600857018970891 [49]\n",
      "2  query  1 0.05684857266743394 [12]\n",
      "2  larg  1 0.043004285094854454 [4]\n",
      "2  outperform  4 0.4829131657224324 [32,144,173,177]\n",
      "2  benchmark  2 0.13632035849133212 [37,100]\n",
      "2  instructgpt  1 0.1207282914306081 [150]\n",
      "2  av  1 0.1207282914306081 [194]\n",
      "2  ful  1 0.1207282914306081 [57]\n",
      "2  literature,  1 0.1207282914306081 [128]\n",
      "2  found  1 0.1207282914306081 [28]\n",
      "2  burd  1 0.1207282914306081 [72]\n",
      "2  fav  1 0.1207282914306081 [120]\n",
      "2  poss  1 0.1207282914306081 [211]\n",
      "2  12-10%  1 0.1207282914306081 [192]\n",
      "2  prompt  4 0.22739429066973577 [18,45,83,166]\n",
      "2  new  1 0.1207282914306081 [78]\n",
      "2  propos  2 0.09783505166348751 [67,198]\n",
      "2  state-of-the-art  1 0.08600857018970891 [95]\n",
      "2  best  1 0.1207282914306081 [124]\n",
      "2  20b  1 0.1207282914306081 [117]\n",
      "2  sign  1 0.05684857266743394 [69]\n",
      "2  candid  1 0.1207282914306081 [14]\n",
      "2  size,  1 0.1207282914306081 [142]\n",
      "2  ex  1 0.1207282914306081 [48]\n",
      "3  text,  1 0.16901960800285137 [27]\n",
      "3  item  1 0.12041199826559248 [65]\n",
      "3  task,  1 0.12041199826559248 [84]\n",
      "3  design  1 0.16901960800285137 [147]\n",
      "3  efficy  5 0.6020599913279624 [50,157,188,197,213]\n",
      "3  find  1 0.12041199826559248 [201]\n",
      "3  long  3 0.5070588240085541 [32,37,41]\n",
      "3  manifest  1 0.16901960800285137 [6]\n",
      "3  could  2 0.33803921600570275 [29,39]\n",
      "3  reasoning,  1 0.16901960800285137 [15]\n",
      "3  strategy  1 0.16901960800285137 [150]\n",
      "3  dataset  1 0.12041199826559248 [167]\n",
      "3  text  1 0.09542425094393249 [38]\n",
      "3  enough  1 0.16901960800285137 [51]\n",
      "3  extend  1 0.16901960800285137 [90]\n",
      "3  system  1 0.16901960800285137 [54]\n",
      "3  bridg  2 0.24082399653118497 [93,135]\n",
      "3  response.  1 0.16901960800285137 [58]\n",
      "3  information.  1 0.16901960800285137 [36]\n",
      "3  may  2 0.33803921600570275 [47,202]\n",
      "3  set  1 0.09542425094393249 [127]\n",
      "3  limit  1 0.12041199826559248 [24]\n",
      "3  user/item  1 0.16901960800285137 [95]\n",
      "3  tasks.  1 0.12041199826559248 [184]\n",
      "3  llm-based  2 0.19084850188786498 [60,215]\n",
      "3  unleash  1 0.16901960800285137 [103]\n",
      "3  model  5 0.3424226808222063 [3,8,21,79,87]\n",
      "3  fil  1 0.16901960800285137 [69]\n",
      "3  us  3 0.1806179973983887 [63,68,88]\n",
      "3  result  1 0.07958800173440753 [163]\n",
      "3  allow  1 0.12041199826559248 [77]\n",
      "3  research  1 0.12041199826559248 [204]\n",
      "3  process,  1 0.12041199826559248 [44]\n",
      "3  e.g.,  1 0.16901960800285137 [13]\n",
      "3  requir  1 0.16901960800285137 [56]\n",
      "3  time.  1 0.12041199826559248 [144]\n",
      "3  top-n  1 0.16901960800285137 [182]\n",
      "3  recommend  5 0.6020599913279624 [53,61,180,183,216]\n",
      "3  unparallel  1 0.16901960800285137 [7]\n",
      "3  attempt  1 0.16901960800285137 [153]\n",
      "3  input  1 0.09542425094393249 [18]\n",
      "3  improv  3 0.23876400520322255 [155,194,210]\n",
      "3  although  1 0.16901960800285137 [185]\n",
      "3  thu  1 0.16901960800285137 [46]\n",
      "3  expery  1 0.09542425094393249 [162]\n",
      "3  tak  1 0.09542425094393249 [40]\n",
      "3  discret  2 0.33803921600570275 [74,119]\n",
      "3  distil  2 0.33803921600570275 [117,174]\n",
      "3  llm  1 0.16901960800285137 [107]\n",
      "3  address  1 0.16901960800285137 [111]\n",
      "3  models,  1 0.16901960800285137 [62]\n",
      "3  langu  1 0.06020599913279624 [2]\n",
      "3  commun  1 0.16901960800285137 [207]\n",
      "3  problems,  1 0.16901960800285137 [113]\n",
      "3  (pod)  1 0.16901960800285137 [175]\n",
      "3  tasks,  1 0.09542425094393249 [12]\n",
      "3  reduc  1 0.12041199826559248 [141]\n",
      "3  understand  1 0.12041199826559248 [81]\n",
      "3  inf  3 0.5070588240085541 [143,196,212]\n",
      "3  fine-tuning  1 0.16901960800285137 [91]\n",
      "3  nee  1 0.16901960800285137 [89]\n",
      "3  templ  2 0.24082399653118497 [72,99]\n",
      "3  approach  1 0.07958800173440753 [176]\n",
      "3  models.  2 0.24082399653118497 [161,217]\n",
      "3  word  2 0.33803921600570275 [100,138]\n",
      "3  vary  1 0.09542425094393249 [11]\n",
      "3  recommendation.  1 0.16901960800285137 [109]\n",
      "3  real-world  1 0.16901960800285137 [166]\n",
      "3  inspir  1 0.12041199826559248 [203]\n",
      "3  sequ  1 0.12041199826559248 [179]\n",
      "3  task  1 0.12041199826559248 [124]\n",
      "3  contain  1 0.16901960800285137 [34]\n",
      "3  pow  1 0.09542425094393249 [105]\n",
      "3  continu  1 0.16901960800285137 [129]\n",
      "3  also  1 0.12041199826559248 [146]\n",
      "3  vect  1 0.16901960800285137 [131]\n",
      "3  cap  1 0.16901960800285137 [9]\n",
      "3  most  1 0.16901960800285137 [23]\n",
      "3  immedy  1 0.16901960800285137 [57]\n",
      "3  improved,  1 0.16901960800285137 [192]\n",
      "3  id  3 0.5070588240085541 [66,96,136]\n",
      "3  larg  1 0.06020599913279624 [1]\n",
      "3  train  3 0.5070588240085541 [149,159,187]\n",
      "3  three  1 0.16901960800285137 [165]\n",
      "3  plain  1 0.16901960800285137 [26]\n",
      "3  limited.  1 0.16901960800285137 [199]\n",
      "3  tim  1 0.16901960800285137 [42]\n",
      "3  noisy  1 0.16901960800285137 [35]\n",
      "3  (i.e.,  1 0.16901960800285137 [73]\n",
      "3  giv  1 0.12041199826559248 [83]\n",
      "3  multi-step  1 0.16901960800285137 [14]\n",
      "3  prompt  3 0.23876400520322255 [120,130,173]\n",
      "3  prompt)  1 0.16901960800285137 [75]\n",
      "3  spec  1 0.16901960800285137 [123]\n",
      "3  propos  1 0.06848453616444126 [115]\n",
      "3  effect  1 0.09542425094393249 [170]\n",
      "3  sign  1 0.07958800173440753 [191]\n",
      "3  demonst  1 0.09542425094393249 [168]\n",
      "3  (llm)  1 0.16901960800285137 [4]\n",
      "4  complet  1 0.1056372550017821 [17]\n",
      "4  optim  1 0.1056372550017821 [121]\n",
      "4  feedback  1 0.0752574989159953 [139]\n",
      "4  performance,  1 0.1056372550017821 [152]\n",
      "4  integr  1 0.0752574989159953 [126]\n",
      "4  techn  1 0.059640156839957804 [165]\n",
      "4  phas  1 0.1056372550017821 [77]\n",
      "4  beir  1 0.0752574989159953 [145]\n",
      "4  success  1 0.0752574989159953 [16]\n",
      "4  gencrf:  1 0.1056372550017821 [56]\n",
      "4  custom  1 0.1056372550017821 [94]\n",
      "4  multipl  1 0.059640156839957804 [70]\n",
      "4  differentiated,  1 0.1056372550017821 [71]\n",
      "4  first  1 0.059640156839957804 [80]\n",
      "4  rat  1 0.1056372550017821 [18]\n",
      "4  limit  1 0.0752574989159953 [39]\n",
      "4  achiev  1 0.059640156839957804 [150]\n",
      "4  redund  1 0.1056372550017821 [41]\n",
      "4  oft  1 0.1056372550017821 [37]\n",
      "4  (ir)  1 0.1056372550017821 [10]\n",
      "4  model  2 0.08560567020555157 [30,132]\n",
      "4  divers  4 0.4225490200071284 [49,65,104,112]\n",
      "4  well-generated  1 0.1056372550017821 [72]\n",
      "4  llms,  1 0.1056372550017821 [171]\n",
      "4  gencrf  2 0.2112745100035642 [82,149]\n",
      "4  ndcg@10.  1 0.0752574989159953 [163]\n",
      "4  us  1 0.03762874945799765 [93]\n",
      "4  search  1 0.059640156839957804 [15]\n",
      "4  process  1 0.0752574989159953 [137]\n",
      "4  time.  1 0.0752574989159953 [81]\n",
      "4  prompts,  1 0.1056372550017821 [95]\n",
      "4  input  1 0.059640156839957804 [23]\n",
      "4  (llms)  1 0.0752574989159953 [31]\n",
      "4  improv  1 0.0497425010840047 [33]\n",
      "4  mod  1 0.1056372550017821 [21]\n",
      "4  rec  1 0.059640156839957804 [25]\n",
      "4  well-known  1 0.1056372550017821 [5]\n",
      "4  problem  1 0.1056372550017821 [6]\n",
      "4  bas  1 0.059640156839957804 [68]\n",
      "4  expery  1 0.059640156839957804 [142]\n",
      "4  perform  2 0.1505149978319906 [123,175]\n",
      "4  adapt  2 0.2112745100035642 [67,168]\n",
      "4  group  1 0.1056372550017821 [100]\n",
      "4  adv  1 0.0752574989159953 [177]\n",
      "4  constrain  1 0.1056372550017821 [44]\n",
      "4  cruc  1 0.1056372550017821 [125]\n",
      "4  langu  1 0.03762874945799765 [29]\n",
      "4  sota  1 0.1056372550017821 [157]\n",
      "4  lev  2 0.11928031367991561 [27,83]\n",
      "4  evalu  1 0.059640156839957804 [130]\n",
      "4  loops.  1 0.1056372550017821 [140]\n",
      "4  novel  1 0.0752574989159953 [128]\n",
      "4  paper,  1 0.0497425010840047 [53]\n",
      "4  innov  1 0.1056372550017821 [116]\n",
      "4  strategies  1 0.059640156839957804 [119]\n",
      "4  query.  1 0.1056372550017821 [24]\n",
      "4  pot  1 0.0752574989159953 [43]\n",
      "4  boost  1 0.1056372550017821 [173]\n",
      "4  intents.  2 0.2112745100035642 [50,105]\n",
      "4  (qerm)  1 0.1056372550017821 [133]\n",
      "4  vary  2 0.11928031367991561 [87,170]\n",
      "4  combin  1 0.0752574989159953 [111]\n",
      "4  furthermore,  1 0.0752574989159953 [106]\n",
      "4  prevy  1 0.059640156839957804 [154]\n",
      "4  retriev  4 0.3010299956639812 [9,76,122,174]\n",
      "4  int  2 0.1505149978319906 [66,113]\n",
      "4  capt  2 0.11928031367991561 [48,64]\n",
      "4  autom  1 0.1056372550017821 [20]\n",
      "4  clust  2 0.2112745100035642 [59,97]\n",
      "4  reward  1 0.1056372550017821 [131]\n",
      "4  inform  2 0.11928031367991561 [8,181]\n",
      "4  empir  1 0.1056372550017821 [141]\n",
      "4  user's  1 0.0752574989159953 [22]\n",
      "4  field  1 0.1056372550017821 [179]\n",
      "4  singl  1 0.1056372550017821 [14]\n",
      "4  surpass  1 0.1056372550017821 [153]\n",
      "4  repres  1 0.0752574989159953 [103]\n",
      "4  llms  1 0.0497425010840047 [84]\n",
      "4  enh  1 0.0752574989159953 [13]\n",
      "4  method  1 0.0752574989159953 [26]\n",
      "4  framework  2 0.2112745100035642 [62,108]\n",
      "4  query  8 0.3979400086720376 [1,34,73,88,92,114,129,155]\n",
      "4  larg  1 0.03762874945799765 [28]\n",
      "4  expansions,  1 0.1056372550017821 [42]\n",
      "4  reform  3 0.22577249674798588 [2,61,156]\n",
      "4  benchmark  1 0.059640156839957804 [146]\n",
      "4  init  1 0.1056372550017821 [91]\n",
      "4  aggreg  1 0.1056372550017821 [118]\n",
      "4  retrieval.  1 0.1056372550017821 [182]\n",
      "4  distinct  1 0.1056372550017821 [102]\n",
      "4  expl  1 0.0752574989159953 [109]\n",
      "4  refin  1 0.1056372550017821 [135]\n",
      "4  12%  1 0.1056372550017821 [161]\n",
      "4  propos  1 0.042802835102775785 [55]\n",
      "4  gen  3 0.14922750325201412 [38,58,86]\n",
      "4  state-of-the-art  1 0.0752574989159953 [151]\n",
      "4  aim  1 0.0752574989159953 [11]\n",
      "4  effect  1 0.059640156839957804 [46]\n",
      "4  sign  1 0.0497425010840047 [172]\n",
      "4  reformulation,  1 0.1056372550017821 [35]\n",
      "4  demonst  1 0.059640156839957804 [147]\n",
      "4  weight  1 0.1056372550017821 [117]\n",
      "5  seamless  1 0.2112745100035642 [109]\n",
      "5  interact  2 0.4225490200071284 [7,104]\n",
      "5  graph-based  1 0.2112745100035642 [71]\n",
      "5  methodolog  1 0.2112745100035642 [211]\n",
      "5  foc  1 0.2112745100035642 [36]\n",
      "5  integr  1 0.1505149978319906 [101]\n",
      "5  documents,  1 0.2112745100035642 [47]\n",
      "5  information,  1 0.2112745100035642 [40]\n",
      "5  understanding,  1 0.2112745100035642 [26]\n",
      "5  text  2 0.23856062735983122 [124,149]\n",
      "5  gramm  1 0.2112745100035642 [91]\n",
      "5  instruct  1 0.1505149978319906 [108]\n",
      "5  structures  1 0.2112745100035642 [146]\n",
      "5  modern  1 0.2112745100035642 [221]\n",
      "5  object  1 0.2112745100035642 [137]\n",
      "5  nod  1 0.2112745100035642 [166]\n",
      "5  act  1 0.2112745100035642 [10]\n",
      "5  pre-trained  1 0.2112745100035642 [122]\n",
      "5  bridg  1 0.1505149978319906 [213]\n",
      "5  text.  1 0.2112745100035642 [98]\n",
      "5  modeling.  1 0.2112745100035642 [52]\n",
      "5  text-based  1 0.2112745100035642 [69]\n",
      "5  rul  1 0.2112745100035642 [92]\n",
      "5  rank  1 0.11928031367991561 [60]\n",
      "5  first  1 0.11928031367991561 [85]\n",
      "5  set  2 0.23856062735983122 [88,157]\n",
      "5  llm.  1 0.2112745100035642 [114]\n",
      "5  achiev  1 0.11928031367991561 [152]\n",
      "5  aol  1 0.2112745100035642 [194]\n",
      "5  model  2 0.17121134041110314 [22,81]\n",
      "5  prediction,  1 0.2112745100035642 [165]\n",
      "5  tradit  1 0.2112745100035642 [217]\n",
      "5  us  2 0.1505149978319906 [42,132]\n",
      "5  result  1 0.0994850021680094 [186]\n",
      "5  allow  1 0.1505149978319906 [100]\n",
      "5  process,  1 0.1505149978319906 [105]\n",
      "5  search  2 0.23856062735983122 [2,218]\n",
      "5  confirm  1 0.2112745100035642 [197]\n",
      "5  concretely,  1 0.2112745100035642 [83]\n",
      "5  en  1 0.2112745100035642 [174]\n",
      "5  input  1 0.11928031367991561 [111]\n",
      "5  learn  1 0.2112745100035642 [161]\n",
      "5  approach.  1 0.2112745100035642 [202]\n",
      "5  history,  1 0.2112745100035642 [103]\n",
      "5  interactions.  1 0.2112745100035642 [32]\n",
      "5  rec  1 0.11928031367991561 [78]\n",
      "5  learning,  1 0.2112745100035642 [172]\n",
      "5  expery  1 0.11928031367991561 [185]\n",
      "5  tak  1 0.11928031367991561 [65]\n",
      "5  adv  1 0.1505149978319906 [66]\n",
      "5  complex  1 0.1505149978319906 [14]\n",
      "5  discrep  1 0.2112745100035642 [119]\n",
      "5  supery  1 0.2112745100035642 [199]\n",
      "5  paradigm  1 0.2112745100035642 [204]\n",
      "5  langu  2 0.1505149978319906 [80,129]\n",
      "5  produc  1 0.2112745100035642 [131]\n",
      "5  analys  1 0.1505149978319906 [189]\n",
      "5  format.  1 0.2112745100035642 [150]\n",
      "5  generation,  1 0.2112745100035642 [168]\n",
      "5  lev  1 0.11928031367991561 [74]\n",
      "5  structure  1 0.2112745100035642 [30]\n",
      "5  word-level  1 0.2112745100035642 [50]\n",
      "5  novel  1 0.1505149978319906 [208]\n",
      "5  paper,  1 0.0994850021680094 [55]\n",
      "5  llms.  1 0.1505149978319906 [222]\n",
      "5  sess  3 0.6338235300106926 [1,95,102]\n",
      "5  sem  2 0.4225490200071284 [25,51]\n",
      "5  strategies  2 0.23856062735983122 [18,219]\n",
      "5  comprehend  1 0.2112745100035642 [188]\n",
      "5  approach  2 0.1989700043360188 [35,72]\n",
      "5  abl  1 0.1505149978319906 [142]\n",
      "5  structural  1 0.2112745100035642 [39]\n",
      "5  deep  1 0.2112745100035642 [24]\n",
      "5  fulfil  1 0.2112745100035642 [12]\n",
      "5  sequ  1 0.1505149978319906 [21]\n",
      "5  datasets,  1 0.2112745100035642 [193]\n",
      "5  capt  3 0.35784094103974684 [38,144,177]\n",
      "5  task  2 0.3010299956639812 [107,162]\n",
      "5  graph-to-text  1 0.2112745100035642 [134]\n",
      "5  topolog  1 0.2112745100035642 [179]\n",
      "5  cont  1 0.1505149978319906 [167]\n",
      "5  off  1 0.2112745100035642 [206]\n",
      "5  this,  1 0.2112745100035642 [153]\n",
      "5  overlook  1 0.2112745100035642 [27]\n",
      "5  coarse-grained  1 0.2112745100035642 [182]\n",
      "5  inform  2 0.23856062735983122 [15,180]\n",
      "5  priorit  1 0.2112745100035642 [20]\n",
      "5  user's  1 0.1505149978319906 [13]\n",
      "5  pow  1 0.11928031367991561 [76]\n",
      "5  grammar,  1 0.2112745100035642 [135]\n",
      "5  includ  1 0.2112745100035642 [163]\n",
      "5  contrast  1 0.2112745100035642 [171]\n",
      "5  also  1 0.1505149978319906 [205]\n",
      "5  repres  1 0.1505149978319906 [45]\n",
      "5  llms  2 0.1989700043360188 [121,175]\n",
      "5  enh  1 0.1505149978319906 [140]\n",
      "5  query  1 0.0994850021680094 [8]\n",
      "5  larg  1 0.0752574989159953 [79]\n",
      "5  benchmark  1 0.11928031367991561 [192]\n",
      "5  two  1 0.2112745100035642 [191]\n",
      "5  sery  1 0.2112745100035642 [5]\n",
      "5  graph  4 0.8450980400142568 [29,59,96,145]\n",
      "5  moreover,  1 0.2112745100035642 [115]\n",
      "5  corpora,  1 0.2112745100035642 [125]\n",
      "5  nat  1 0.1505149978319906 [118]\n",
      "5  self-supervised  1 0.2112745100035642 [159]\n",
      "5  (sgr),  1 0.2112745100035642 [61]\n",
      "5  convert  1 0.2112745100035642 [94]\n",
      "5  fine-grained.  1 0.2112745100035642 [184]\n",
      "5  neglect  1 0.2112745100035642 [48]\n",
      "5  typ  1 0.2112745100035642 [19]\n",
      "5  introduc  2 0.3010299956639812 [86,155]\n",
      "5  link  1 0.2112745100035642 [164]\n",
      "5  symbol  4 0.8450980400142568 [58,90,128,160]\n",
      "5  tiangong-st,  1 0.2112745100035642 [196]\n",
      "5  giv  1 0.1505149978319906 [116]\n",
      "5  cur  1 0.2112745100035642 [17]\n",
      "5  propos  1 0.08560567020555157 [57]\n",
      "5  gen  2 0.1989700043360188 [44,170]\n",
      "5  aim  1 0.1505149978319906 [63]\n",
      "5  within  1 0.2112745100035642 [147]\n",
      "5  need.  1 0.2112745100035642 [16]\n",
      "5  effect  1 0.11928031367991561 [210]\n",
      "5  gap  1 0.2112745100035642 [215]\n",
      "5  (llms).  1 0.2112745100035642 [82]\n",
      "5  involv  1 0.2112745100035642 [3]\n",
      "5  llms'  1 0.2112745100035642 [141]\n",
      "6  item  1 0.08600857018970891 [5]\n",
      "6  1m  1 0.1207282914306081 [97]\n",
      "6  consid  1 0.1207282914306081 [130]\n",
      "6  few-shot  1 0.1207282914306081 [120]\n",
      "6  book  1 0.1207282914306081 [110]\n",
      "6  dataset  4 0.34403428075883563 [98,105,124,144]\n",
      "6  titl  1 0.1207282914306081 [101]\n",
      "6  ndcg  1 0.1207282914306081 [175]\n",
      "6  gpt-3.5,  1 0.1207282914306081 [53]\n",
      "6  emerg  1 0.1207282914306081 [61]\n",
      "6  alpac  1 0.1207282914306081 [59]\n",
      "6  multipl  1 0.06816017924566606 [131]\n",
      "6  lik  2 0.2414565828612162 [58,133]\n",
      "6  direct  1 0.08600857018970891 [140]\n",
      "6  llm,  1 0.1207282914306081 [115]\n",
      "6  movy  3 0.36218487429182433 [100,128,184]\n",
      "6  promise,  1 0.1207282914306081 [189]\n",
      "6  tasks.  1 0.08600857018970891 [69]\n",
      "6  llm-based  1 0.06816017924566606 [183]\n",
      "6  model  1 0.048917525831743754 [49]\n",
      "6  open-sourced  1 0.08600857018970891 [114]\n",
      "6  suscept  1 0.1207282914306081 [40]\n",
      "6  us  3 0.12901285528456335 [79,94,167]\n",
      "6  result  2 0.11369714533486788 [180,191]\n",
      "6  conduc  1 0.1207282914306081 [89]\n",
      "6  process  1 0.08600857018970891 [68]\n",
      "6  scraping  1 0.1207282914306081 [34]\n",
      "6  obtain  2 0.2414565828612162 [30,196]\n",
      "6  cast  1 0.1207282914306081 [138]\n",
      "6  study,  1 0.1207282914306081 [91]\n",
      "6  recommend  1 0.08600857018970891 [24]\n",
      "6  systems.  1 0.1207282914306081 [25]\n",
      "6  descriptions.  1 0.1207282914306081 [199]\n",
      "6  publ  1 0.1207282914306081 [152]\n",
      "6  rec  1 0.06816017924566606 [45]\n",
      "6  (llms),  1 0.1207282914306081 [50]\n",
      "6  ess  1 0.1207282914306081 [22]\n",
      "6  man  1 0.1207282914306081 [32]\n",
      "6  provid  1 0.1207282914306081 [11]\n",
      "6  web-scraped  1 0.1207282914306081 [198]\n",
      "6  scraped  1 0.1207282914306081 [165]\n",
      "6  techniques,  1 0.1207282914306081 [35]\n",
      "6  langu  2 0.08600857018970891 [48,67]\n",
      "6  consist  1 0.1207282914306081 [106]\n",
      "6  describ  7 0.8450980400142568 [2,28,84,129,159,166,185]\n",
      "6  inconsistencies.  1 0.1207282914306081 [43]\n",
      "6  detail  2 0.2414565828612162 [83,127]\n",
      "6  evalu  1 0.06816017924566606 [177]\n",
      "6  feat  1 0.1207282914306081 [132]\n",
      "6  web  1 0.1207282914306081 [33]\n",
      "6  pivot  1 0.1207282914306081 [8]\n",
      "6  sourc  1 0.1207282914306081 [56]\n",
      "6  rol  1 0.1207282914306081 [9]\n",
      "6  paper,  1 0.05684857266743394 [72]\n",
      "6  hits,  1 0.1207282914306081 [172]\n",
      "6  time-consuming  1 0.1207282914306081 [38]\n",
      "6  exhibit  1 0.1207282914306081 [187]\n",
      "6  traditionally,  1 0.1207282914306081 [26]\n",
      "6  op  1 0.1207282914306081 [55]\n",
      "6  pot  1 0.08600857018970891 [18]\n",
      "6  subsequently,  1 0.1207282914306081 [112]\n",
      "6  metrics.  1 0.08600857018970891 [178]\n",
      "6  top  1 0.1207282914306081 [171]\n",
      "6  combin  1 0.08600857018970891 [169]\n",
      "6  dataset.  1 0.1207282914306081 [156]\n",
      "6  on  1 0.1207282914306081 [122,195]\n",
      "6  capt  1 0.06816017924566606 [17]\n",
      "6  cont  1 0.08600857018970891 [12]\n",
      "6  nam  3 0.36218487429182433 [108,135,147]\n",
      "6  dat  1 0.1207282914306081 [42]\n",
      "6  inform  1 0.06816017924566606 [14]\n",
      "6  sum  1 0.1207282914306081 [15]\n",
      "6  mrr,  1 0.1207282914306081 [173]\n",
      "6  pow  1 0.06816017924566606 [63]\n",
      "6  goodread  2 0.2414565828612162 [104,155]\n",
      "6  compr  1 0.1207282914306081 [99]\n",
      "6  moviel  1 0.1207282914306081 [96]\n",
      "6  llms  2 0.11369714533486788 [57,80]\n",
      "6  items.  1 0.1207282914306081 [87]\n",
      "6  larg  1 0.043004285094854454 [47]\n",
      "6  tool  1 0.1207282914306081 [64]\n",
      "6  nat  1 0.08600857018970891 [66]\n",
      "6  alpaca,  1 0.1207282914306081 [116]\n",
      "6  expl  1 0.08600857018970891 [75]\n",
      "6  auth  1 0.1207282914306081 [150]\n",
      "6  comp  2 0.2414565828612162 [162,192]\n",
      "6  prompt  2 0.11369714533486788 [118,121]\n",
      "6  view  1 0.1207282914306081 [19]\n",
      "6  gen  4 0.22739429066973577 [82,126,158,186]\n",
      "6  ml  1 0.1207282914306081 [143]\n",
      "6  years,  1 0.1207282914306081 [46]\n",
      "6  sign  1 0.05684857266743394 [188]\n",
      "6  play  1 0.1207282914306081 [6]\n",
      "6  demonst  1 0.06816017924566606 [181]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "descripteur_split_lancaster =\"\"\n",
    "\n",
    "for i in range(len(termes_split_lancaster)):\n",
    "    for j in range(len(termes_split_lancaster[i])):\n",
    "               \n",
    "        term = termes_split_lancaster[i][j]\n",
    "        frequency_term = frequency_dict_split_lancaster_documents[i][term]\n",
    "        max_frequancy = max_frequency_dict_split_lancaster_documents[i]\n",
    "        frequency_in_collection = document_frequency_dict_split_lancaster[term]\n",
    "\n",
    "        poids_term = poids(frequency_term,max_frequancy,frequency_in_collection,n_split)\n",
    "\n",
    "        term_positions = split_lancaster_positions[i][termes_split_lancaster[i][j]]\n",
    "        positions_string = \"[\" + \",\".join(str(pos) for pos in term_positions) + \"]\"\n",
    "\n",
    "        descripteur_split_lancaster = descripteur_split_lancaster + (str(i+1)+ \"  \" +termes_split_lancaster[i][j]+ \"  \" +str(frequency_term)+\" \"+ str(poids_term)+\" \"+positions_string+\"\\n\")\n",
    "\n",
    "\n",
    "print(descripteur_split_lancaster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  pass  1 0.16901960800285137 [154]\n",
      "1  investig  1 0.16901960800285137 [73]\n",
      "1  feedback  3 0.3612359947967774 [120,166,172]\n",
      "1  find  1 0.12041199826559248 [128]\n",
      "1  docu  1 0.09542425094393249 [173]\n",
      "1  techn  2 0.15917600346881505 [8,90]\n",
      "1  upto  1 0.16901960800285137 [144]\n",
      "1  ultim  1 0.16901960800285137 [105]\n",
      "1  success  1 0.12041199826559248 [62]\n",
      "1  text  1 0.09542425094393249 [20]\n",
      "1  instruct  1 0.12041199826559248 [98]\n",
      "1  9%  1 0.16901960800285137 [168]\n",
      "1  msmarco  1 0.16901960800285137 [153]\n",
      "1  zero-shot  3 0.5070588240085541 [35,97,149]\n",
      "1  multipl  1 0.09542425094393249 [101]\n",
      "1  ensembl  2 0.33803921600570275 [64,87]\n",
      "1  rank  1 0.09542425094393249 [155]\n",
      "1  prom  1 0.12041199826559248 [43]\n",
      "1  transform  1 0.16901960800285137 [11]\n",
      "1  set  2 0.19084850188786498 [6,102]\n",
      "1  model  1 0.06020599913279624 [56]\n",
      "1  shown  1 0.16901960800285137 [39]\n",
      "1  inh  1 0.16901960800285137 [52]\n",
      "1  us  5 0.3010299956639812 [9,13,26,164,170]\n",
      "1  state-of-art  1 0.16901960800285137 [150]\n",
      "1  search  2 0.19084850188786498 [16,32]\n",
      "1  5%  1 0.16901960800285137 [162]\n",
      "1  map  1 0.16901960800285137 [142]\n",
      "1  improv  5 0.3979400086720376 [30,78,106,137,143]\n",
      "1  rec  1 0.07958800173440753 [34]\n",
      "1  pseudo  1 0.16901960800285137 [118]\n",
      "1  many  1 0.16901960800285137 [70]\n",
      "1  expery  1 0.07958800173440753 [33]\n",
      "1  bas  1 0.09542425094393249 [88]\n",
      "1  tak  1 0.09542425094393249 [58]\n",
      "1  perform  1 0.09542425094393249 [108]\n",
      "1  relev  2 0.33803921600570275 [119,171]\n",
      "1  qr  2 0.33803921600570275 [3,36]\n",
      "1  langu  1 0.06020599913279624 [55]\n",
      "1  context  1 0.16901960800285137 [83]\n",
      "1  lev  1 0.09542425094393249 [93]\n",
      "1  evalu  1 0.09542425094393249 [122]\n",
      "1  post-retrieval  1 0.16901960800285137 [113]\n",
      "1  18%  1 0.16901960800285137 [140]\n",
      "1  gain  1 0.16901960800285137 [160]\n",
      "1  help  1 0.16901960800285137 [77]\n",
      "1  strategies  1 0.09542425094393249 [66]\n",
      "1  approach  1 0.07958800173440753 [44]\n",
      "1  genqrensemblerf  2 0.33803921600570275 [115,157]\n",
      "1  benefit  1 0.16901960800285137 [69]\n",
      "1  rel  2 0.33803921600570275 [135,159]\n",
      "1  abl  1 0.12041199826559248 [48]\n",
      "1  genqrensembl  2 0.33803921600570275 [91,130]\n",
      "1  vary  1 0.07958800173440753 [114]\n",
      "1  prevy  1 0.09542425094393249 [148]\n",
      "1  inspir  1 0.12041199826559248 [59]\n",
      "1  retriev  1 0.12041199826559248 [107]\n",
      "1  int  1 0.12041199826559248 [28]\n",
      "1  task  2 0.13696907232888253 [71,156]\n",
      "1  knowledg  1 0.16901960800285137 [51]\n",
      "1  due  1 0.16901960800285137 [45]\n",
      "1  show  1 0.12041199826559248 [158]\n",
      "1  ndcg@10  2 0.19084850188786498 [136,169]\n",
      "1  mrr  1 0.12041199826559248 [163]\n",
      "1  keyword  1 0.16901960800285137 [104]\n",
      "1  origin  1 0.16901960800285137 [15]\n",
      "1  exploit  1 0.16901960800285137 [50]\n",
      "1  24%  1 0.16901960800285137 [145]\n",
      "1  query  3 0.23876400520322255 [1,17,79]\n",
      "1  larg  1 0.06020599913279624 [54]\n",
      "1  benchmark  1 0.07958800173440753 [126]\n",
      "1  reform  3 0.3612359947967774 [2,80,133]\n",
      "1  bet  2 0.33803921600570275 [22,132]\n",
      "1  paraphras  1 0.16901960800285137 [94]\n",
      "1  ir  1 0.12041199826559248 [125]\n",
      "1  align  1 0.16901960800285137 [23]\n",
      "1  introduc  1 0.12041199826559248 [111]\n",
      "1  prompt  2 0.13696907232888253 [65,89]\n",
      "1  incorp  1 0.16901960800285137 [117]\n",
      "1  propos  1 0.06848453616444126 [85]\n",
      "1  gen  2 0.15917600346881505 [100,131]\n",
      "1  pseudo-relevance  1 0.16901960800285137 [165]\n",
      "1  four  1 0.16901960800285137 [124]\n",
      "2  pairw  1 0.1207282914306081 [81]\n",
      "2  efficy  1 0.08600857018970891 [205]\n",
      "2  baselin  2 0.2414565828612162 [34,175]\n",
      "2  docu  2 0.13632035849133212 [2,15]\n",
      "2  techn  1 0.05684857266743394 [79]\n",
      "2  flan-ul2  1 0.1207282914306081 [114]\n",
      "2  beir  1 0.08600857018970891 [170]\n",
      "2  dataset  1 0.05684857266743394 [38]\n",
      "2  linear  1 0.1207282914306081 [218]\n",
      "2  moderate-sized  1 0.1207282914306081 [102]\n",
      "2  direct  1 0.08600857018970891 [9]\n",
      "2  solv  3 0.36218487429182433 [147,182,188]\n",
      "2  listw  1 0.1207282914306081 [43]\n",
      "2  rank  7 0.47712125471966244 [1,35,44,61,82,96,160]\n",
      "2  challeng  1 0.1207282914306081 [60]\n",
      "2  fine-tuned  1 0.1207282914306081 [33]\n",
      "2  first  1 0.06816017924566606 [89]\n",
      "2  cal  1 0.1207282914306081 [80]\n",
      "2  achiev  2 0.13632035849133212 [94,213]\n",
      "2  llm-based  2 0.13632035849133212 [146,187]\n",
      "2  model  3 0.12901285528456335 [6,115,141]\n",
      "2  open-sourced  1 0.08600857018970891 [103]\n",
      "2  us  5 0.21502142547427228 [3,46,76,101,163]\n",
      "2  result  2 0.11369714533486788 [86,215]\n",
      "2  ev  1 0.1207282914306081 [216]\n",
      "2  research  1 0.08600857018970891 [26]\n",
      "2  standard  1 0.1207282914306081 [99]\n",
      "2  chatgpt  1 0.1207282914306081 [181]\n",
      "2  improv  1 0.05684857266743394 [204]\n",
      "2  estim  1 0.1207282914306081 [140]\n",
      "2  2019  1 0.1207282914306081 [107]\n",
      "2  10%  1 0.1207282914306081 [157]\n",
      "2  problem  1 0.06816017924566606 [24]\n",
      "2  paramet  2 0.2414565828612162 [118,154]\n",
      "2  bas  2 0.13632035849133212 [111,131]\n",
      "2  pointw  2 0.2414565828612162 [41,186]\n",
      "2  interest  1 0.1207282914306081 [21]\n",
      "2  2020  1 0.1207282914306081 [109]\n",
      "2  175b  1 0.1207282914306081 [153]\n",
      "2  perform  2 0.13632035849133212 [97,119]\n",
      "2  complex  1 0.08600857018970891 [219]\n",
      "2  fee  1 0.1207282914306081 [10]\n",
      "2  lit  2 0.2414565828612162 [92,128]\n",
      "2  howev  1 0.1207282914306081 [25]\n",
      "2  langu  1 0.043004285094854454 [5]\n",
      "2  prp  4 0.4829131657224324 [84,110,172,202]\n",
      "2  analys  1 0.08600857018970891 [40]\n",
      "2  reduc  1 0.08600857018970891 [70]\n",
      "2  understand  1 0.06816017924566606 [58]\n",
      "2  superv  1 0.1207282914306081 [174]\n",
      "2  commerc  2 0.2414565828612162 [135,180]\n",
      "2  furtherm  1 0.08600857018970891 [196]\n",
      "2  templ  1 0.08600857018970891 [167]\n",
      "2  off-the-shelf  1 0.1207282914306081 [53]\n",
      "2  approach  1 0.05684857266743394 [125]\n",
      "2  50x  1 0.1207282914306081 [139]\n",
      "2  gpt-4  1 0.1207282914306081 [136]\n",
      "2  argu  1 0.1207282914306081 [51]\n",
      "2  vary  1 0.05684857266743394 [200]\n",
      "2  met  1 0.08600857018970891 [161]\n",
      "2  prevy  1 0.06816017924566606 [123]\n",
      "2  task  1 0.048917525831743754 [171]\n",
      "2  trec-dl  1 0.1207282914306081 [106]\n",
      "2  pap  1 0.05684857266743394 [65]\n",
      "2  show  1 0.08600857018970891 [207]\n",
      "2  ndcg@10  1 0.06816017924566606 [195]\n",
      "2  pract  1 0.1207282914306081 [23]\n",
      "2  competit  1 0.1207282914306081 [214]\n",
      "2  sev  2 0.2414565828612162 [169,199]\n",
      "2  4.2%  1 0.1207282914306081 [184]\n",
      "2  blackbox  2 0.2414565828612162 [134,179]\n",
      "2  llms  4 0.22739429066973577 [7,54,74,104]\n",
      "2  difficult  1 0.1207282914306081 [30]\n",
      "2  method  1 0.08600857018970891 [49]\n",
      "2  query  1 0.05684857266743394 [12]\n",
      "2  larg  1 0.043004285094854454 [4]\n",
      "2  outperform  4 0.4829131657224324 [32,144,173,177]\n",
      "2  benchmark  2 0.11369714533486788 [37,100]\n",
      "2  instructgpt  1 0.1207282914306081 [150]\n",
      "2  av  1 0.1207282914306081 [194]\n",
      "2  ful  1 0.1207282914306081 [57]\n",
      "2  found  1 0.1207282914306081 [28]\n",
      "2  burd  1 0.1207282914306081 [72]\n",
      "2  siz  1 0.1207282914306081 [142]\n",
      "2  form  1 0.08600857018970891 [62]\n",
      "2  fav  1 0.1207282914306081 [120]\n",
      "2  poss  1 0.1207282914306081 [211]\n",
      "2  12-10%  1 0.1207282914306081 [192]\n",
      "2  prompt  4 0.19567010332697501 [18,45,83,166]\n",
      "2  new  1 0.1207282914306081 [78]\n",
      "2  propos  2 0.09783505166348751 [67,198]\n",
      "2  state-of-the-art  1 0.08600857018970891 [95]\n",
      "2  best  1 0.1207282914306081 [124]\n",
      "2  20b  1 0.1207282914306081 [117]\n",
      "2  sign  1 0.05684857266743394 [69]\n",
      "2  candid  1 0.1207282914306081 [14]\n",
      "2  ex  1 0.1207282914306081 [48]\n",
      "3  item  1 0.0752574989159953 [65]\n",
      "3  design  1 0.1056372550017821 [147]\n",
      "3  efficy  5 0.3762874945799765 [50,157,188,197,213]\n",
      "3  pod  1 0.1056372550017821 [175]\n",
      "3  find  1 0.0752574989159953 [201]\n",
      "3  long  3 0.3169117650053463 [32,37,41]\n",
      "3  manifest  1 0.1056372550017821 [6]\n",
      "3  could  2 0.2112745100035642 [29,39]\n",
      "3  strategy  1 0.1056372550017821 [150]\n",
      "3  dataset  1 0.0497425010840047 [167]\n",
      "3  text  2 0.11928031367991561 [27,38]\n",
      "3  enough  1 0.1056372550017821 [51]\n",
      "3  extend  1 0.1056372550017821 [90]\n",
      "3  system  1 0.0752574989159953 [54]\n",
      "3  bridg  2 0.1505149978319906 [93,135]\n",
      "3  may  2 0.2112745100035642 [47,202]\n",
      "3  set  1 0.059640156839957804 [127]\n",
      "3  limit  2 0.1505149978319906 [24,199]\n",
      "3  user/item  1 0.1056372550017821 [95]\n",
      "3  llm-based  2 0.11928031367991561 [60,215]\n",
      "3  unleash  1 0.1056372550017821 [103]\n",
      "3  model  8 0.3010299956639812 [3,8,21,62,79,87,161,217]\n",
      "3  fil  1 0.1056372550017821 [69]\n",
      "3  us  3 0.11288624837399294 [63,68,88]\n",
      "3  result  1 0.0497425010840047 [163]\n",
      "3  allow  1 0.0752574989159953 [77]\n",
      "3  i.e.  1 0.1056372550017821 [73]\n",
      "3  reason  1 0.1056372550017821 [15]\n",
      "3  research  1 0.0752574989159953 [204]\n",
      "3  process  1 0.0497425010840047 [44]\n",
      "3  requir  1 0.1056372550017821 [56]\n",
      "3  top-n  1 0.1056372550017821 [182]\n",
      "3  recommend  6 0.45154499349597177 [53,61,109,180,183,216]\n",
      "3  unparallel  1 0.1056372550017821 [7]\n",
      "3  attempt  1 0.1056372550017821 [153]\n",
      "3  input  1 0.059640156839957804 [18]\n",
      "3  improv  4 0.1989700043360188 [155,192,194,210]\n",
      "3  although  1 0.1056372550017821 [185]\n",
      "3  thu  1 0.1056372550017821 [46]\n",
      "3  e.g.  1 0.1056372550017821 [13]\n",
      "3  problem  1 0.059640156839957804 [113]\n",
      "3  expery  1 0.0497425010840047 [162]\n",
      "3  tak  1 0.059640156839957804 [40]\n",
      "3  discret  2 0.2112745100035642 [74,119]\n",
      "3  distil  2 0.2112745100035642 [117,174]\n",
      "3  llm  2 0.11928031367991561 [4,107]\n",
      "3  address  1 0.1056372550017821 [111]\n",
      "3  langu  1 0.03762874945799765 [2]\n",
      "3  commun  1 0.1056372550017821 [207]\n",
      "3  reduc  1 0.0752574989159953 [141]\n",
      "3  understand  1 0.059640156839957804 [81]\n",
      "3  inf  3 0.3169117650053463 [143,196,212]\n",
      "3  fine-tuning  1 0.1056372550017821 [91]\n",
      "3  nee  1 0.0752574989159953 [89]\n",
      "3  respons  1 0.1056372550017821 [58]\n",
      "3  templ  2 0.1505149978319906 [72,99]\n",
      "3  approach  1 0.0497425010840047 [176]\n",
      "3  word  2 0.2112745100035642 [100,138]\n",
      "3  vary  1 0.0497425010840047 [11]\n",
      "3  real-world  1 0.1056372550017821 [166]\n",
      "3  inspir  1 0.0752574989159953 [203]\n",
      "3  sequ  1 0.0752574989159953 [179]\n",
      "3  task  4 0.17121134041110314 [12,84,124,184]\n",
      "3  contain  1 0.1056372550017821 [34]\n",
      "3  inform  1 0.0497425010840047 [36]\n",
      "3  pow  1 0.059640156839957804 [105]\n",
      "3  continu  1 0.1056372550017821 [129]\n",
      "3  also  1 0.0752574989159953 [146]\n",
      "3  vect  1 0.1056372550017821 [131]\n",
      "3  cap  1 0.1056372550017821 [9]\n",
      "3  most  1 0.1056372550017821 [23]\n",
      "3  immedy  1 0.1056372550017821 [57]\n",
      "3  id  3 0.3169117650053463 [66,96,136]\n",
      "3  larg  1 0.03762874945799765 [1]\n",
      "3  train  3 0.3169117650053463 [149,159,187]\n",
      "3  three  1 0.1056372550017821 [165]\n",
      "3  plain  1 0.1056372550017821 [26]\n",
      "3  tim  2 0.1505149978319906 [42,144]\n",
      "3  noisy  1 0.1056372550017821 [35]\n",
      "3  giv  1 0.0752574989159953 [83]\n",
      "3  multi-step  1 0.1056372550017821 [14]\n",
      "3  prompt  4 0.17121134041110314 [75,120,130,173]\n",
      "3  spec  1 0.1056372550017821 [123]\n",
      "3  propos  1 0.042802835102775785 [115]\n",
      "3  effect  1 0.059640156839957804 [170]\n",
      "3  sign  1 0.0497425010840047 [191]\n",
      "3  demonst  1 0.059640156839957804 [168]\n",
      "4  complet  1 0.09389978222380631 [17]\n",
      "4  optim  1 0.09389978222380631 [122]\n",
      "4  feedback  1 0.06689555459199582 [140]\n",
      "4  integr  1 0.06689555459199582 [127]\n",
      "4  techn  1 0.04421555651911529 [166]\n",
      "4  phas  1 0.09389978222380631 [78]\n",
      "4  beir  1 0.06689555459199582 [146]\n",
      "4  success  1 0.06689555459199582 [16]\n",
      "4  custom  1 0.09389978222380631 [95]\n",
      "4  qerm  1 0.09389978222380631 [134]\n",
      "4  multipl  1 0.05301347274662915 [71]\n",
      "4  loop  1 0.09389978222380631 [141]\n",
      "4  first  1 0.05301347274662915 [81]\n",
      "4  rat  1 0.09389978222380631 [18]\n",
      "4  limit  1 0.06689555459199582 [40]\n",
      "4  achiev  1 0.05301347274662915 [151]\n",
      "4  redund  1 0.09389978222380631 [42]\n",
      "4  oft  1 0.09389978222380631 [38]\n",
      "4  model  2 0.06689555459199582 [31,133]\n",
      "4  differenty  1 0.09389978222380631 [72]\n",
      "4  divers  4 0.37559912889522523 [50,66,105,113]\n",
      "4  well-generated  1 0.09389978222380631 [73]\n",
      "4  gencrf  3 0.28169934667141894 [57,83,150]\n",
      "4  us  2 0.06689555459199582 [22,94]\n",
      "4  search  1 0.05301347274662915 [15]\n",
      "4  process  1 0.04421555651911529 [138]\n",
      "4  input  1 0.05301347274662915 [24]\n",
      "4  improv  1 0.04421555651911529 [34]\n",
      "4  mod  1 0.09389978222380631 [21]\n",
      "4  rec  1 0.04421555651911529 [26]\n",
      "4  well-known  1 0.09389978222380631 [5]\n",
      "4  problem  1 0.05301347274662915 [6]\n",
      "4  bas  1 0.05301347274662915 [69]\n",
      "4  expery  1 0.04421555651911529 [143]\n",
      "4  perform  3 0.15904041823988746 [124,153,176]\n",
      "4  adapt  2 0.18779956444761262 [68,169]\n",
      "4  group  1 0.09389978222380631 [101]\n",
      "4  adv  1 0.06689555459199582 [178]\n",
      "4  constrain  1 0.09389978222380631 [45]\n",
      "4  cruc  1 0.09389978222380631 [126]\n",
      "4  langu  1 0.03344777729599791 [30]\n",
      "4  sota  1 0.09389978222380631 [158]\n",
      "4  lev  2 0.1060269454932583 [28,84]\n",
      "4  evalu  1 0.05301347274662915 [131]\n",
      "4  expand  1 0.09389978222380631 [43]\n",
      "4  novel  1 0.06689555459199582 [129]\n",
      "4  furtherm  1 0.06689555459199582 [107]\n",
      "4  innov  1 0.09389978222380631 [117]\n",
      "4  strategies  1 0.05301347274662915 [120]\n",
      "4  pot  1 0.06689555459199582 [44]\n",
      "4  boost  1 0.09389978222380631 [174]\n",
      "4  vary  2 0.08843111303823058 [88,171]\n",
      "4  combin  1 0.06689555459199582 [112]\n",
      "4  prevy  1 0.05301347274662915 [155]\n",
      "4  retriev  5 0.3344777729599791 [9,77,123,175,183]\n",
      "4  int  4 0.2675822183679833 [51,67,106,114]\n",
      "4  capt  2 0.1060269454932583 [49,65]\n",
      "4  autom  1 0.09389978222380631 [20]\n",
      "4  pap  1 0.04421555651911529 [54]\n",
      "4  clust  2 0.18779956444761262 [60,98]\n",
      "4  reward  1 0.09389978222380631 [132]\n",
      "4  inform  2 0.08843111303823058 [8,182]\n",
      "4  empir  1 0.09389978222380631 [142]\n",
      "4  ndcg@10  1 0.05301347274662915 [164]\n",
      "4  field  1 0.09389978222380631 [180]\n",
      "4  singl  1 0.09389978222380631 [14]\n",
      "4  surpass  1 0.09389978222380631 [154]\n",
      "4  repres  1 0.06689555459199582 [104]\n",
      "4  llms  3 0.13264666955734586 [32,85,172]\n",
      "4  enh  1 0.06689555459199582 [13]\n",
      "4  method  1 0.06689555459199582 [27]\n",
      "4  framework  2 0.18779956444761262 [63,109]\n",
      "4  query  9 0.3979400086720376 [1,25,35,74,89,93,115,130,156]\n",
      "4  larg  1 0.03344777729599791 [29]\n",
      "4  benchmark  1 0.04421555651911529 [147]\n",
      "4  reform  4 0.2675822183679833 [2,36,62,157]\n",
      "4  init  1 0.09389978222380631 [92]\n",
      "4  aggreg  1 0.09389978222380631 [119]\n",
      "4  distinct  1 0.09389978222380631 [103]\n",
      "4  ir  1 0.06689555459199582 [10]\n",
      "4  expl  1 0.06689555459199582 [110]\n",
      "4  tim  1 0.06689555459199582 [82]\n",
      "4  refin  1 0.09389978222380631 [136]\n",
      "4  prompt  1 0.0380469645358007 [96]\n",
      "4  12%  1 0.09389978222380631 [162]\n",
      "4  propos  1 0.0380469645358007 [56]\n",
      "4  gen  3 0.13264666955734586 [39,59,87]\n",
      "4  state-of-the-art  1 0.06689555459199582 [152]\n",
      "4  aim  1 0.06689555459199582 [11]\n",
      "4  effect  1 0.05301347274662915 [47]\n",
      "4  sign  1 0.04421555651911529 [173]\n",
      "4  demonst  1 0.05301347274662915 [148]\n",
      "4  weight  1 0.09389978222380631 [118]\n",
      "5  seamless  1 0.16901960800285137 [110]\n",
      "5  interact  3 0.5070588240085541 [7,33,105]\n",
      "5  graph-based  1 0.16901960800285137 [72]\n",
      "5  methodolog  1 0.16901960800285137 [212]\n",
      "5  foc  1 0.16901960800285137 [37]\n",
      "5  integr  1 0.12041199826559248 [102]\n",
      "5  docu  1 0.09542425094393249 [48]\n",
      "5  fine-grained  1 0.16901960800285137 [185]\n",
      "5  dataset  1 0.07958800173440753 [194]\n",
      "5  text  3 0.28627275283179743 [99,125,150]\n",
      "5  gramm  2 0.33803921600570275 [92,136]\n",
      "5  instruct  1 0.12041199826559248 [109]\n",
      "5  structures  1 0.16901960800285137 [147]\n",
      "5  modern  1 0.16901960800285137 [222]\n",
      "5  object  1 0.16901960800285137 [138]\n",
      "5  nod  1 0.16901960800285137 [167]\n",
      "5  act  1 0.16901960800285137 [10]\n",
      "5  pre-trained  1 0.16901960800285137 [123]\n",
      "5  bridg  1 0.12041199826559248 [214]\n",
      "5  text-based  1 0.16901960800285137 [70]\n",
      "5  rul  1 0.16901960800285137 [93]\n",
      "5  rank  1 0.09542425094393249 [61]\n",
      "5  first  1 0.09542425094393249 [86]\n",
      "5  set  2 0.19084850188786498 [89,158]\n",
      "5  concret  1 0.16901960800285137 [84]\n",
      "5  achiev  1 0.09542425094393249 [153]\n",
      "5  aol  1 0.16901960800285137 [195]\n",
      "5  model  3 0.1806179973983887 [23,53,82]\n",
      "5  tradit  1 0.12041199826559248 [218]\n",
      "5  hist  1 0.16901960800285137 [104]\n",
      "5  us  3 0.1806179973983887 [13,43,133]\n",
      "5  result  1 0.07958800173440753 [187]\n",
      "5  allow  1 0.12041199826559248 [101]\n",
      "5  search  2 0.19084850188786498 [2,219]\n",
      "5  process  1 0.07958800173440753 [106]\n",
      "5  confirm  1 0.16901960800285137 [198]\n",
      "5  en  1 0.16901960800285137 [175]\n",
      "5  input  1 0.09542425094393249 [112]\n",
      "5  learn  2 0.33803921600570275 [162,173]\n",
      "5  corpor  1 0.16901960800285137 [126]\n",
      "5  rec  1 0.07958800173440753 [79]\n",
      "5  expery  1 0.07958800173440753 [186]\n",
      "5  tak  1 0.09542425094393249 [66]\n",
      "5  llm  1 0.09542425094393249 [115]\n",
      "5  adv  1 0.12041199826559248 [67]\n",
      "5  complex  1 0.12041199826559248 [15]\n",
      "5  discrep  1 0.16901960800285137 [120]\n",
      "5  paradigm  1 0.16901960800285137 [205]\n",
      "5  langu  2 0.12041199826559248 [81,130]\n",
      "5  produc  1 0.16901960800285137 [132]\n",
      "5  analys  1 0.12041199826559248 [190]\n",
      "5  lev  1 0.09542425094393249 [75]\n",
      "5  structure  1 0.16901960800285137 [31]\n",
      "5  word-level  1 0.16901960800285137 [51]\n",
      "5  understand  1 0.09542425094393249 [27]\n",
      "5  nee  1 0.12041199826559248 [17]\n",
      "5  novel  1 0.12041199826559248 [209]\n",
      "5  predict  1 0.16901960800285137 [166]\n",
      "5  tiangong-st  1 0.16901960800285137 [197]\n",
      "5  sess  3 0.5070588240085541 [1,96,103]\n",
      "5  sem  2 0.33803921600570275 [26,52]\n",
      "5  strategies  2 0.19084850188786498 [19,220]\n",
      "5  comprehend  1 0.16901960800285137 [189]\n",
      "5  approach  3 0.23876400520322255 [36,73,203]\n",
      "5  abl  1 0.12041199826559248 [143]\n",
      "5  structural  1 0.16901960800285137 [40]\n",
      "5  deep  1 0.16901960800285137 [25]\n",
      "5  fulfil  1 0.16901960800285137 [12]\n",
      "5  sequ  1 0.12041199826559248 [22]\n",
      "5  capt  3 0.28627275283179743 [39,145,178]\n",
      "5  task  2 0.13696907232888253 [108,163]\n",
      "5  graph-to-text  1 0.16901960800285137 [135]\n",
      "5  topolog  1 0.16901960800285137 [180]\n",
      "5  pap  1 0.07958800173440753 [56]\n",
      "5  cont  1 0.12041199826559248 [168]\n",
      "5  off  1 0.16901960800285137 [207]\n",
      "5  overlook  1 0.16901960800285137 [28]\n",
      "5  coarse-grained  1 0.16901960800285137 [183]\n",
      "5  inform  3 0.23876400520322255 [16,41,181]\n",
      "5  priorit  1 0.16901960800285137 [21]\n",
      "5  pow  1 0.09542425094393249 [77]\n",
      "5  includ  1 0.16901960800285137 [164]\n",
      "5  contrast  1 0.16901960800285137 [172]\n",
      "5  also  1 0.12041199826559248 [206]\n",
      "5  repres  1 0.12041199826559248 [46]\n",
      "5  llms  5 0.3979400086720376 [83,122,142,176,223]\n",
      "5  enh  1 0.12041199826559248 [141]\n",
      "5  query  1 0.07958800173440753 [8]\n",
      "5  larg  1 0.06020599913279624 [80]\n",
      "5  benchmark  1 0.07958800173440753 [193]\n",
      "5  two  1 0.16901960800285137 [192]\n",
      "5  sery  1 0.16901960800285137 [5]\n",
      "5  graph  4 0.6760784320114055 [30,60,97,146]\n",
      "5  sgr  1 0.16901960800285137 [62]\n",
      "5  nat  1 0.12041199826559248 [119]\n",
      "5  self-supervised  1 0.16901960800285137 [160]\n",
      "5  convert  1 0.16901960800285137 [95]\n",
      "5  moreov  1 0.16901960800285137 [116]\n",
      "5  neglect  1 0.16901960800285137 [49]\n",
      "5  typ  1 0.16901960800285137 [20]\n",
      "5  form  1 0.12041199826559248 [151]\n",
      "5  introduc  2 0.24082399653118497 [87,156]\n",
      "5  link  1 0.16901960800285137 [165]\n",
      "5  symbol  4 0.6760784320114055 [59,91,129,161]\n",
      "5  giv  1 0.12041199826559248 [117]\n",
      "5  cur  1 0.16901960800285137 [18]\n",
      "5  propos  1 0.06848453616444126 [58]\n",
      "5  gen  3 0.23876400520322255 [45,169,171]\n",
      "5  aim  1 0.12041199826559248 [64]\n",
      "5  within  1 0.16901960800285137 [148]\n",
      "5  effect  1 0.09542425094393249 [211]\n",
      "5  gap  1 0.16901960800285137 [216]\n",
      "5  involv  1 0.16901960800285137 [3]\n",
      "5  supery  1 0.16901960800285137 [200]\n",
      "6  item  2 0.1505149978319906 [5,87]\n",
      "6  1m  1 0.1056372550017821 [97]\n",
      "6  gpt-3.5  1 0.1056372550017821 [53]\n",
      "6  techn  1 0.0497425010840047 [35]\n",
      "6  consid  1 0.1056372550017821 [130]\n",
      "6  few-shot  1 0.1056372550017821 [120]\n",
      "6  inconsist  1 0.1056372550017821 [43]\n",
      "6  book  1 0.1056372550017821 [110]\n",
      "6  dataset  5 0.2487125054200235 [98,105,124,144,156]\n",
      "6  titl  1 0.1056372550017821 [101]\n",
      "6  ndcg  1 0.1056372550017821 [175]\n",
      "6  emerg  1 0.1056372550017821 [61]\n",
      "6  system  1 0.0752574989159953 [25]\n",
      "6  alpac  2 0.2112745100035642 [59,116]\n",
      "6  multipl  1 0.059640156839957804 [131]\n",
      "6  lik  2 0.2112745100035642 [58,133]\n",
      "6  direct  1 0.0752574989159953 [140]\n",
      "6  movy  3 0.3169117650053463 [100,128,184]\n",
      "6  prom  1 0.0752574989159953 [189]\n",
      "6  llm-based  1 0.059640156839957804 [183]\n",
      "6  model  1 0.03762874945799765 [49]\n",
      "6  subsequ  1 0.1056372550017821 [112]\n",
      "6  tradit  1 0.0752574989159953 [26]\n",
      "6  suscept  1 0.1056372550017821 [40]\n",
      "6  open-sourced  1 0.0752574989159953 [114]\n",
      "6  us  3 0.11288624837399294 [79,94,167]\n",
      "6  result  2 0.0994850021680094 [180,191]\n",
      "6  conduc  1 0.1056372550017821 [89]\n",
      "6  process  1 0.0497425010840047 [68]\n",
      "6  scraping  1 0.1056372550017821 [34]\n",
      "6  obtain  2 0.2112745100035642 [30,196]\n",
      "6  cast  1 0.1056372550017821 [138]\n",
      "6  recommend  1 0.0752574989159953 [24]\n",
      "6  publ  1 0.1056372550017821 [152]\n",
      "6  rec  1 0.0497425010840047 [45]\n",
      "6  ess  1 0.1056372550017821 [22]\n",
      "6  man  1 0.1056372550017821 [32]\n",
      "6  provid  1 0.1056372550017821 [11]\n",
      "6  llm  1 0.059640156839957804 [115]\n",
      "6  web-scraped  1 0.1056372550017821 [198]\n",
      "6  scraped  1 0.1056372550017821 [165]\n",
      "6  consist  1 0.1056372550017821 [106]\n",
      "6  langu  2 0.0752574989159953 [48,67]\n",
      "6  describ  8 0.8450980400142568 [2,28,84,129,159,166,185,199]\n",
      "6  detail  2 0.2112745100035642 [83,127]\n",
      "6  evalu  1 0.059640156839957804 [177]\n",
      "6  feat  1 0.1056372550017821 [132]\n",
      "6  web  1 0.1056372550017821 [33]\n",
      "6  pivot  1 0.1056372550017821 [8]\n",
      "6  sourc  1 0.1056372550017821 [56]\n",
      "6  year  1 0.1056372550017821 [46]\n",
      "6  rol  1 0.1056372550017821 [9]\n",
      "6  time-consuming  1 0.1056372550017821 [38]\n",
      "6  exhibit  1 0.1056372550017821 [187]\n",
      "6  op  1 0.1056372550017821 [55]\n",
      "6  pot  1 0.0752574989159953 [18]\n",
      "6  top  1 0.1056372550017821 [171]\n",
      "6  combin  1 0.0752574989159953 [169]\n",
      "6  met  1 0.0752574989159953 [178]\n",
      "6  on  1 0.1056372550017821 [122,195]\n",
      "6  capt  1 0.059640156839957804 [17]\n",
      "6  task  1 0.042802835102775785 [69]\n",
      "6  pap  1 0.0497425010840047 [72]\n",
      "6  cont  1 0.0752574989159953 [12]\n",
      "6  nam  3 0.3169117650053463 [108,135,147]\n",
      "6  dat  1 0.1056372550017821 [42]\n",
      "6  inform  1 0.0497425010840047 [14]\n",
      "6  mrr  1 0.0752574989159953 [173]\n",
      "6  sum  1 0.1056372550017821 [15]\n",
      "6  pow  1 0.059640156839957804 [63]\n",
      "6  goodread  2 0.2112745100035642 [104,155]\n",
      "6  compr  1 0.1056372550017821 [99]\n",
      "6  moviel  1 0.1056372550017821 [96]\n",
      "6  llms  3 0.14922750325201412 [50,57,80]\n",
      "6  larg  1 0.03762874945799765 [47]\n",
      "6  tool  1 0.1056372550017821 [64]\n",
      "6  nat  1 0.0752574989159953 [66]\n",
      "6  expl  1 0.0752574989159953 [75]\n",
      "6  auth  1 0.1056372550017821 [150]\n",
      "6  comp  2 0.2112745100035642 [162,192]\n",
      "6  prompt  2 0.08560567020555157 [118,121]\n",
      "6  view  1 0.1056372550017821 [19]\n",
      "6  gen  4 0.1989700043360188 [82,126,158,186]\n",
      "6  ml  1 0.1056372550017821 [143]\n",
      "6  study  1 0.1056372550017821 [91]\n",
      "6  hit  1 0.1056372550017821 [172]\n",
      "6  sign  1 0.0497425010840047 [188]\n",
      "6  play  1 0.1056372550017821 [6]\n",
      "6  demonst  1 0.059640156839957804 [181]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "descripteur_reg_lancaster =\"\"\n",
    "\n",
    "for i in range(len(termes_reg_lancaster)):\n",
    "    for j in range(len(termes_reg_lancaster[i])):\n",
    "\n",
    "        term = termes_reg_lancaster[i][j]\n",
    "        frequency_term = frequency_dict_reg_lancaster_documents[i][term]\n",
    "        max_frequancy = max_frequency_dict_reg_lancaster_documents[i]\n",
    "        frequency_in_collection = document_frequency_dict_reg_lancaster[term]\n",
    "\n",
    "        poids_term = poids(frequency_term,max_frequancy,frequency_in_collection,n_reg)\n",
    "\n",
    "        term_positions = reg_lancaster_positions[i][termes_reg_lancaster[i][j]]\n",
    "        positions_string = \"[\" + \",\".join(str(pos) for pos in term_positions) + \"]\"\n",
    "\n",
    "        descripteur_reg_lancaster= descripteur_reg_lancaster + (str(i+1)+ \"  \" +termes_reg_lancaster[i][j]+ \"  \" +str(frequency_term)+\" \"+ str(poids_term)+\" \"+positions_string+\"\\n\")\n",
    "\n",
    "\n",
    "print(descripteur_reg_lancaster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inverse file creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  task,  1  1  0.20068666377598746\n",
      "2  task,  3  1  0.1505149978319906\n",
      "1  feedback  1  1  0.20068666377598746\n",
      "2  feedback  4  1  0.1505149978319906\n",
      "1  find  1  1  0.28169934667141894\n",
      "1  upto  1  1  0.28169934667141894\n",
      "1  techniques  1  1  0.20068666377598746\n",
      "2  techniques  4  1  0.1505149978319906\n",
      "1  documents.  1  1  0.28169934667141894\n",
      "1  Recently,  1  1  0.28169934667141894\n",
      "1  nDCG@10  1  2  0.5633986933428379\n",
      "1  success  1  1  0.28169934667141894\n",
      "1  text  1  1  0.20068666377598746\n",
      "2  text  3  1  0.1505149978319906\n",
      "1  propose  1  1  0.1141408936074021\n",
      "2  propose  2  2  0.17121134041110314\n",
      "3  propose  3  1  0.08560567020555157\n",
      "4  propose  4  1  0.08560567020555157\n",
      "5  propose  5  1  0.1141408936074021\n",
      "1  inspiration  1  1  0.28169934667141894\n",
      "1  MSMarco  1  1  0.28169934667141894\n",
      "1  state-of-art.  1  1  0.28169934667141894\n",
      "1  9%  1  1  0.28169934667141894\n",
      "1  zero-shot  1  3  0.8450980400142568\n",
      "1  technique,  1  1  0.28169934667141894\n",
      "1  prompting  1  2  0.4013733275519749\n",
      "2  prompting  6  1  0.1505149978319906\n",
      "1  ensemble  1  2  0.5633986933428379\n",
      "1  transform  1  1  0.28169934667141894\n",
      "1  set  1  1  0.15904041823988746\n",
      "2  set  3  1  0.11928031367991561\n",
      "3  set  5  2  0.3180808364797749\n",
      "1  previous  1  1  0.15904041823988746\n",
      "2  previous  2  1  0.11928031367991561\n",
      "3  previous  4  1  0.11928031367991561\n",
      "1  shown  1  1  0.28169934667141894\n",
      "1  intent  1  1  0.28169934667141894\n",
      "1  search  1  2  0.3180808364797749\n",
      "2  search  4  1  0.11928031367991561\n",
      "3  search  5  2  0.3180808364797749\n",
      "1  5%  1  1  0.28169934667141894\n",
      "1  better  1  2  0.5633986933428379\n",
      "1  MRR  1  1  0.28169934667141894\n",
      "1  feedback,  1  1  0.28169934667141894\n",
      "1  large  1  1  0.28169934667141894\n",
      "1  pseudo  1  1  0.28169934667141894\n",
      "1  retrieval  1  1  0.20068666377598746\n",
      "2  retrieval  4  2  0.3010299956639812\n",
      "1  Ranking  1  1  0.20068666377598746\n",
      "2  Ranking  2  2  0.3010299956639812\n",
      "1  performance.  1  1  0.28169934667141894\n",
      "1  many  1  1  0.28169934667141894\n",
      "1  relevant  1  2  0.5633986933428379\n",
      "1  experience.  1  1  0.28169934667141894\n",
      "1  introduce  1  1  0.20068666377598746\n",
      "2  introduce  5  2  0.4013733275519749\n",
      "1  post-retrieval  1  1  0.28169934667141894\n",
      "1  tasks,  1  1  0.15904041823988746\n",
      "2  tasks,  2  1  0.11928031367991561\n",
      "3  tasks,  3  1  0.11928031367991561\n",
      "1  18%  1  1  0.28169934667141894\n",
      "1  keywords  1  1  0.28169934667141894\n",
      "1  help  1  1  0.28169934667141894\n",
      "1  knowledge  1  1  0.28169934667141894\n",
      "1  investigate  1  1  0.28169934667141894\n",
      "1  improving  1  1  0.28169934667141894\n",
      "1  improves  1  1  0.28169934667141894\n",
      "1  strategies  1  1  0.15904041823988746\n",
      "2  strategies  4  1  0.11928031367991561\n",
      "3  strategies  5  2  0.3180808364797749\n",
      "1  approach  1  1  0.15904041823988746\n",
      "2  approach  2  1  0.11928031367991561\n",
      "3  approach  3  1  0.11928031367991561\n",
      "1  models.  1  1  0.20068666377598746\n",
      "2  models.  3  2  0.3010299956639812\n",
      "1  generates  1  1  0.28169934667141894\n",
      "1  GenQREnsemble  1  2  0.5633986933428379\n",
      "1  QR  1  1  0.28169934667141894\n",
      "1  Query  1  1  0.20068666377598746\n",
      "2  Query  4  2  0.3010299956639812\n",
      "1  language  1  1  0.13264666955734586\n",
      "2  language  3  1  0.0994850021680094\n",
      "3  language  5  1  0.13264666955734586\n",
      "4  language  6  1  0.0994850021680094\n",
      "1  based  1  1  0.15904041823988746\n",
      "2  based  2  2  0.23856062735983122\n",
      "3  based  4  1  0.11928031367991561\n",
      "1  IR  1  1  0.28169934667141894\n",
      "1  generate  1  1  0.15904041823988746\n",
      "2  generate  4  2  0.23856062735983122\n",
      "3  generate  6  2  0.23856062735983122\n",
      "1  using  1  2  0.2282817872148042\n",
      "2  using  2  4  0.3424226808222063\n",
      "3  using  4  1  0.08560567020555157\n",
      "4  using  5  1  0.1141408936074021\n",
      "5  using  6  1  0.08560567020555157\n",
      "1  due  1  1  0.28169934667141894\n",
      "1  context,  1  1  0.28169934667141894\n",
      "1  ultimately  1  1  0.28169934667141894\n",
      "1  ability  1  1  0.20068666377598746\n",
      "2  ability  5  1  0.20068666377598746\n",
      "1  reformulations  1  1  0.28169934667141894\n",
      "1  benchmarks,  1  1  0.28169934667141894\n",
      "1  MAP  1  1  0.28169934667141894\n",
      "1  inherent  1  1  0.28169934667141894\n",
      "1  taking  1  1  0.28169934667141894\n",
      "1  instruction  1  1  0.20068666377598746\n",
      "2  instruction  5  1  0.20068666377598746\n",
      "1  exploit  1  1  0.28169934667141894\n",
      "1  24%  1  1  0.28169934667141894\n",
      "1  query  1  2  0.3180808364797749\n",
      "2  query  2  1  0.11928031367991561\n",
      "3  query  4  4  0.47712125471966244\n",
      "1  gains  1  1  0.28169934667141894\n",
      "1  GenQREnsembleRF  1  2  0.5633986933428379\n",
      "1  promising  1  1  0.28169934667141894\n",
      "1  benefited  1  1  0.28169934667141894\n",
      "1  Reformulation(QR)  1  1  0.28169934667141894\n",
      "1  evaluations  1  1  0.28169934667141894\n",
      "1  reformulation.  1  1  0.28169934667141894\n",
      "1  aligns  1  1  0.28169934667141894\n",
      "1  improve  1  1  0.13264666955734586\n",
      "2  improve  2  1  0.0994850021680094\n",
      "3  improve  3  2  0.1989700043360188\n",
      "4  improve  4  1  0.0994850021680094\n",
      "1  sets  1  1  0.28169934667141894\n",
      "1  original  1  1  0.28169934667141894\n",
      "1  variant,  1  1  0.28169934667141894\n",
      "1  relative  1  2  0.5633986933428379\n",
      "1  pseudo-relevance  1  1  0.28169934667141894\n",
      "1  feedback.  1  1  0.28169934667141894\n",
      "1  Passage  1  1  0.28169934667141894\n",
      "1  multiple  1  1  0.15904041823988746\n",
      "2  multiple  4  1  0.11928031367991561\n",
      "3  multiple  6  1  0.11928031367991561\n",
      "1  used  1  1  0.15904041823988746\n",
      "2  used  2  1  0.11928031367991561\n",
      "3  used  6  1  0.11928031367991561\n",
      "1  user’s  1  2  0.5633986933428379\n",
      "1  improvements  1  2  0.5633986933428379\n",
      "1  incorporate  1  1  0.28169934667141894\n",
      "1  leverages  1  1  0.20068666377598746\n",
      "2  leverages  4  1  0.1505149978319906\n",
      "1  four  1  1  0.28169934667141894\n",
      "1  shows  1  1  0.28169934667141894\n",
      "1  paraphrases  1  1  0.28169934667141894\n",
      "1  technique  2  1  0.2112745100035642\n",
      "1  favorably  2  1  0.2112745100035642\n",
      "1  20B  2  1  0.2112745100035642\n",
      "1  commercial  2  2  0.4225490200071284\n",
      "1  template  2  1  0.1505149978319906\n",
      "2  template  3  2  0.3010299956639812\n",
      "1  solutions,  2  1  0.2112745100035642\n",
      "1  Flan-UL2  2  1  0.2112745100035642\n",
      "1  existing  2  1  0.2112745100035642\n",
      "1  significantly  2  1  0.11928031367991561\n",
      "2  significantly  3  1  0.11928031367991561\n",
      "3  significantly  4  1  0.11928031367991561\n",
      "1  literature  2  1  0.2112745100035642\n",
      "1  candidate  2  1  0.2112745100035642\n",
      "1  linear  2  1  0.2112745100035642\n",
      "1  listwise  2  1  0.2112745100035642\n",
      "1  moderate-sized  2  1  0.2112745100035642\n",
      "1  baselines  2  1  0.2112745100035642\n",
      "1  parameters,  2  1  0.2112745100035642\n",
      "1  fine-tuned  2  1  0.2112745100035642\n",
      "1  first  2  1  0.11928031367991561\n",
      "2  first  4  1  0.11928031367991561\n",
      "3  first  5  1  0.15904041823988746\n",
      "1  solution  2  1  0.2112745100035642\n",
      "1  (PRP).  2  1  0.2112745100035642\n",
      "1  PRP  2  3  0.6338235300106926\n",
      "1  average  2  1  0.2112745100035642\n",
      "1  competitive  2  1  0.2112745100035642\n",
      "1  model  2  2  0.4225490200071284\n",
      "1  open-sourced  2  1  0.1505149978319906\n",
      "2  open-sourced  6  1  0.1505149978319906\n",
      "1  rankers  2  1  0.2112745100035642\n",
      "1  outperforming  2  1  0.2112745100035642\n",
      "1  seven  2  1  0.2112745100035642\n",
      "1  standard  2  1  0.2112745100035642\n",
      "1  prompts  2  1  0.2112745100035642\n",
      "1  Language  2  1  0.0994850021680094\n",
      "2  Language  4  1  0.0994850021680094\n",
      "3  Language  5  1  0.13264666955734586\n",
      "4  Language  6  1  0.0994850021680094\n",
      "1  Prompting  2  1  0.2112745100035642\n",
      "1  TREC-DL  2  1  0.2112745100035642\n",
      "1  formulations.  2  1  0.2112745100035642\n",
      "1  2019  2  1  0.2112745100035642\n",
      "1  10%  2  1  0.2112745100035642\n",
      "1  directly  2  1  0.2112745100035642\n",
      "1  175B  2  1  0.2112745100035642\n",
      "1  complexity  2  1  0.2112745100035642\n",
      "1  BEIR  2  1  0.1505149978319906\n",
      "2  BEIR  4  1  0.1505149978319906\n",
      "1  problem.  2  1  0.2112745100035642\n",
      "1  practical  2  1  0.2112745100035642\n",
      "1  several  2  1  0.2112745100035642\n",
      "1  documents  2  2  0.4225490200071284\n",
      "1  (estimated)  2  1  0.2112745100035642\n",
      "1  feeding  2  1  0.2112745100035642\n",
      "1  ChatGPT  2  1  0.2112745100035642\n",
      "1  even  2  1  0.2112745100035642\n",
      "1  understand  2  1  0.1505149978319906\n",
      "2  understand  3  1  0.1505149978319906\n",
      "1  paper,  2  1  0.0994850021680094\n",
      "2  paper,  4  1  0.0994850021680094\n",
      "3  paper,  5  1  0.13264666955734586\n",
      "4  paper,  6  1  0.0994850021680094\n",
      "1  argue  2  1  0.2112745100035642\n",
      "1  datasets.  2  1  0.2112745100035642\n",
      "1  off-the-shelf  2  1  0.2112745100035642\n",
      "1  reduce  2  1  0.1505149978319906\n",
      "2  reduce  3  1  0.1505149978319906\n",
      "1  50x  2  1  0.2112745100035642\n",
      "1  metrics.  2  1  0.1505149978319906\n",
      "2  metrics.  6  1  0.1505149978319906\n",
      "1  However,  2  1  0.2112745100035642\n",
      "1  ranking  2  4  0.8450980400142568\n",
      "1  Large  2  1  0.08560567020555157\n",
      "2  Large  3  1  0.08560567020555157\n",
      "3  Large  4  1  0.08560567020555157\n",
      "4  Large  5  1  0.1141408936074021\n",
      "5  Large  6  1  0.08560567020555157\n",
      "1  performs  2  1  0.2112745100035642\n",
      "1  LLM-based  2  2  0.23856062735983122\n",
      "2  LLM-based  3  2  0.23856062735983122\n",
      "3  LLM-based  6  1  0.11928031367991561\n",
      "1  Furthermore,  2  1  0.1505149978319906\n",
      "2  Furthermore,  4  1  0.1505149978319906\n",
      "1  variants  2  1  0.2112745100035642\n",
      "1  show  2  1  0.2112745100035642\n",
      "1  outperforms  2  2  0.4225490200071284\n",
      "1  4.2%  2  1  0.2112745100035642\n",
      "1  (LLMs)  2  1  0.1505149978319906\n",
      "2  (LLMs)  4  1  0.1505149978319906\n",
      "1  NDCG@10.  2  1  0.2112745100035642\n",
      "1  achieve  2  2  0.3010299956639812\n",
      "2  achieve  5  1  0.20068666377598746\n",
      "1  blackbox  2  2  0.4225490200071284\n",
      "1  Models  2  1  0.0994850021680094\n",
      "2  Models  4  1  0.0994850021680094\n",
      "3  Models  5  1  0.13264666955734586\n",
      "4  Models  6  1  0.0994850021680094\n",
      "1  burden  2  1  0.2112745100035642\n",
      "1  difficult  2  1  0.2112745100035642\n",
      "1  performance  2  1  0.1505149978319906\n",
      "2  performance  4  2  0.3010299956639812\n",
      "1  analyze  2  1  0.2112745100035642\n",
      "1  2020,  2  1  0.2112745100035642\n",
      "1  efficiency  2  1  0.1505149978319906\n",
      "2  efficiency  3  4  0.6020599913279624\n",
      "1  outperform  2  1  0.2112745100035642\n",
      "1  benchmark  2  1  0.11928031367991561\n",
      "2  benchmark  4  1  0.11928031367991561\n",
      "3  benchmark  5  1  0.15904041823988746\n",
      "1  results  2  2  0.1989700043360188\n",
      "2  results  3  1  0.0994850021680094\n",
      "3  results  5  1  0.13264666955734586\n",
      "4  results  6  2  0.1989700043360188\n",
      "1  methods  2  1  0.1505149978319906\n",
      "2  methods  4  1  0.1505149978319906\n",
      "1  interesting  2  1  0.2112745100035642\n",
      "1  LLMs  2  2  0.1989700043360188\n",
      "2  LLMs  4  1  0.0994850021680094\n",
      "3  LLMs  5  2  0.2652933391146917\n",
      "4  LLMs  6  2  0.1989700043360188\n",
      "1  solutions  2  1  0.2112745100035642\n",
      "1  literature,  2  1  0.2112745100035642\n",
      "1  LLMs.  2  1  0.1505149978319906\n",
      "2  LLMs.  5  1  0.20068666377598746\n",
      "1  found  2  1  0.2112745100035642\n",
      "1  called  2  1  0.2112745100035642\n",
      "1  supervised  2  1  0.2112745100035642\n",
      "1  baseline  2  1  0.2112745100035642\n",
      "1  fully  2  1  0.2112745100035642\n",
      "1  challenging  2  1  0.2112745100035642\n",
      "1  12-10%  2  1  0.2112745100035642\n",
      "1  prompt  2  2  0.3010299956639812\n",
      "2  prompt  3  2  0.3010299956639812\n",
      "1  GPT-4  2  1  0.2112745100035642\n",
      "1  new  2  1  0.2112745100035642\n",
      "1  parameters  2  1  0.2112745100035642\n",
      "1  state-of-the-art  2  1  0.1505149978319906\n",
      "2  state-of-the-art  4  1  0.1505149978319906\n",
      "1  researchers  2  1  0.1505149978319906\n",
      "2  researchers  3  1  0.1505149978319906\n",
      "1  InstructGPT  2  1  0.2112745100035642\n",
      "1  benchmarks  2  1  0.2112745100035642\n",
      "1  best  2  1  0.2112745100035642\n",
      "1  Pairwise  2  1  0.2112745100035642\n",
      "1  pointwise  2  2  0.4225490200071284\n",
      "1  size,  2  1  0.2112745100035642\n",
      "1  possible  2  1  0.2112745100035642\n",
      "1  text,  3  1  0.2112745100035642\n",
      "1  item  3  1  0.1505149978319906\n",
      "2  item  6  1  0.1505149978319906\n",
      "1  design  3  1  0.2112745100035642\n",
      "1  continuous  3  1  0.2112745100035642\n",
      "1  long  3  2  0.4225490200071284\n",
      "1  PrOmpt  3  1  0.2112745100035642\n",
      "1  effectiveness  3  1  0.1505149978319906\n",
      "2  effectiveness  4  1  0.1505149978319906\n",
      "1  could  3  2  0.4225490200071284\n",
      "1  inspire  3  1  0.2112745100035642\n",
      "1  reasoning,  3  1  0.2112745100035642\n",
      "1  strategy  3  1  0.2112745100035642\n",
      "1  enough  3  1  0.2112745100035642\n",
      "1  specific  3  1  0.2112745100035642\n",
      "1  usually  3  2  0.4225490200071284\n",
      "1  response.  3  1  0.2112745100035642\n",
      "1  power  3  1  0.1505149978319906\n",
      "2  power  5  1  0.20068666377598746\n",
      "1  time  3  1  0.2112745100035642\n",
      "1  information.  3  1  0.2112745100035642\n",
      "1  may  3  2  0.4225490200071284\n",
      "1  demonstrate  3  1  0.1505149978319906\n",
      "2  demonstrate  4  1  0.1505149978319906\n",
      "1  Although  3  1  0.2112745100035642\n",
      "1  datasets  3  1  0.2112745100035642\n",
      "1  user/item  3  1  0.2112745100035642\n",
      "1  tasks.  3  1  0.1505149978319906\n",
      "2  tasks.  6  1  0.1505149978319906\n",
      "1  unleash  3  1  0.2112745100035642\n",
      "1  words  3  2  0.4225490200071284\n",
      "1  modeling  3  1  0.1505149978319906\n",
      "2  modeling  5  1  0.20068666377598746\n",
      "1  inference  3  3  0.6338235300106926\n",
      "1  allow  3  1  0.2112745100035642\n",
      "1  process,  3  1  0.1505149978319906\n",
      "2  process,  5  1  0.20068666377598746\n",
      "1  e.g.,  3  1  0.2112745100035642\n",
      "1  time.  3  1  0.1505149978319906\n",
      "2  time.  4  1  0.1505149978319906\n",
      "1  Distillation  3  1  0.2112745100035642\n",
      "1  mostly  3  1  0.2112745100035642\n",
      "1  attempt  3  1  0.2112745100035642\n",
      "1  input  3  1  0.1505149978319906\n",
      "2  input  4  1  0.1505149978319906\n",
      "1  systems  3  1  0.2112745100035642\n",
      "1  (LLM)  3  1  0.2112745100035642\n",
      "1  manifested  3  1  0.2112745100035642\n",
      "1  recommendation  3  4  0.6020599913279624\n",
      "2  recommendation  6  1  0.1505149978319906\n",
      "1  models  3  4  0.8450980400142568\n",
      "1  unparalleled  3  1  0.2112745100035642\n",
      "1  address  3  1  0.2112745100035642\n",
      "1  models,  3  1  0.2112745100035642\n",
      "1  require  3  1  0.2112745100035642\n",
      "1  IDs  3  3  0.6338235300106926\n",
      "1  immediate  3  1  0.2112745100035642\n",
      "1  Long  3  1  0.2112745100035642\n",
      "1  problems,  3  1  0.2112745100035642\n",
      "1  fine-tuning  3  1  0.2112745100035642\n",
      "1  LLM  3  1  0.2112745100035642\n",
      "1  efficient  3  1  0.2112745100035642\n",
      "1  take  3  1  0.1505149978319906\n",
      "2  take  5  1  0.20068666377598746\n",
      "1  discrete  3  2  0.4225490200071284\n",
      "1  various  3  1  0.1505149978319906\n",
      "2  various  4  1  0.1505149978319906\n",
      "1  limited  3  1  0.1505149978319906\n",
      "2  limited  4  1  0.1505149978319906\n",
      "1  vectors  3  1  0.2112745100035642\n",
      "1  (POD)  3  1  0.2112745100035642\n",
      "1  recommendation.  3  1  0.2112745100035642\n",
      "1  real-world  3  1  0.2112745100035642\n",
      "1  task  3  1  0.1505149978319906\n",
      "2  task  5  1  0.20068666377598746\n",
      "1  improvement  3  1  0.2112745100035642\n",
      "1  extensive  3  1  0.2112745100035642\n",
      "1  contain  3  1  0.2112745100035642\n",
      "1  training  3  3  0.6338235300106926\n",
      "1  Experimental  3  1  0.2112745100035642\n",
      "1  need  3  1  0.2112745100035642\n",
      "1  also  3  1  0.1505149978319906\n",
      "2  also  5  1  0.20068666377598746\n",
      "1  user  3  1  0.2112745100035642\n",
      "1  community  3  1  0.2112745100035642\n",
      "1  sequential  3  1  0.1505149978319906\n",
      "2  sequential  5  1  0.20068666377598746\n",
      "1  improved,  3  1  0.2112745100035642\n",
      "1  thus  3  1  0.2112745100035642\n",
      "1  finding  3  1  0.2112745100035642\n",
      "1  three  3  1  0.2112745100035642\n",
      "1  capability  3  1  0.2112745100035642\n",
      "1  filled  3  1  0.2112745100035642\n",
      "1  plain  3  1  0.2112745100035642\n",
      "1  limited.  3  1  0.2112745100035642\n",
      "1  noisy  3  1  0.2112745100035642\n",
      "1  (i.e.,  3  1  0.2112745100035642\n",
      "1  given  3  1  0.1505149978319906\n",
      "2  given  5  1  0.20068666377598746\n",
      "1  multi-step  3  1  0.2112745100035642\n",
      "1  prompt)  3  1  0.2112745100035642\n",
      "1  recommender  3  1  0.2112745100035642\n",
      "1  distill  3  1  0.2112745100035642\n",
      "1  bridge  3  2  0.4225490200071284\n",
      "1  top-N  3  1  0.2112745100035642\n",
      "1  optimize  4  1  0.2112745100035642\n",
      "1  reformulation  4  2  0.4225490200071284\n",
      "1  retriever  4  1  0.2112745100035642\n",
      "1  performance,  4  1  0.2112745100035642\n",
      "1  represent  4  1  0.2112745100035642\n",
      "1  Retrieval.  4  1  0.2112745100035642\n",
      "1  intentions  4  1  0.2112745100035642\n",
      "1  Generative  4  1  0.2112745100035642\n",
      "1  redundant  4  1  0.2112745100035642\n",
      "1  differentiated,  4  1  0.2112745100035642\n",
      "1  distinctly  4  1  0.2112745100035642\n",
      "1  clusters  4  1  0.2112745100035642\n",
      "1  SOTAs  4  1  0.2112745100035642\n",
      "1  experiments  4  1  0.2112745100035642\n",
      "1  well-generated  4  1  0.2112745100035642\n",
      "1  advancing  4  1  0.2112745100035642\n",
      "1  (IR)  4  1  0.2112745100035642\n",
      "1  process  4  1  0.2112745100035642\n",
      "1  prompts,  4  1  0.2112745100035642\n",
      "1  integrates  4  1  0.2112745100035642\n",
      "1  rate  4  1  0.2112745100035642\n",
      "1  Clustering  4  1  0.2112745100035642\n",
      "1  explores  4  1  0.2112745100035642\n",
      "1  groups  4  1  0.2112745100035642\n",
      "1  well-known  4  1  0.2112745100035642\n",
      "1  problem  4  1  0.2112745100035642\n",
      "1  combine  4  1  0.2112745100035642\n",
      "1  variable  4  1  0.2112745100035642\n",
      "1  leverage  4  1  0.2112745100035642\n",
      "1  adaptively  4  1  0.2112745100035642\n",
      "1  crucially  4  1  0.2112745100035642\n",
      "1  achieves  4  1  0.2112745100035642\n",
      "1  Retrieval  4  1  0.2112745100035642\n",
      "1  automatically  4  1  0.2112745100035642\n",
      "1  capture  4  1  0.1505149978319906\n",
      "2  capture  5  2  0.4013733275519749\n",
      "1  loops.  4  1  0.2112745100035642\n",
      "1  innovative  4  1  0.2112745100035642\n",
      "1  novel  4  1  0.1505149978319906\n",
      "2  novel  5  1  0.20068666377598746\n",
      "1  Information  4  2  0.4225490200071284\n",
      "1  Reformulation  4  1  0.2112745100035642\n",
      "1  Empirical  4  1  0.2112745100035642\n",
      "1  initial  4  1  0.2112745100035642\n",
      "1  LLMs,  4  1  0.2112745100035642\n",
      "1  query.  4  1  0.2112745100035642\n",
      "1  boosting  4  1  0.2112745100035642\n",
      "1  refine  4  1  0.2112745100035642\n",
      "1  surpassing  4  1  0.2112745100035642\n",
      "1  Recent  4  1  0.2112745100035642\n",
      "1  (QERM)  4  1  0.2112745100035642\n",
      "1  intents.  4  2  0.4225490200071284\n",
      "1  single  4  1  0.2112745100035642\n",
      "1  GenCRF:  4  1  0.2112745100035642\n",
      "1  GenCRF  4  2  0.4225490200071284\n",
      "1  nDCG@10.  4  1  0.2112745100035642\n",
      "1  capturing  4  1  0.1505149978319906\n",
      "2  capturing  5  1  0.20068666377598746\n",
      "1  Rewarding  4  1  0.2112745100035642\n",
      "1  diverse  4  4  0.8450980400142568\n",
      "1  completion  4  1  0.2112745100035642\n",
      "1  intents  4  1  0.2112745100035642\n",
      "1  user's  4  1  0.1505149978319906\n",
      "2  user's  5  1  0.20068666377598746\n",
      "1  field  4  1  0.2112745100035642\n",
      "1  aggregation  4  1  0.2112745100035642\n",
      "1  aimed  4  1  0.2112745100035642\n",
      "1  framework  4  1  0.2112745100035642\n",
      "1  expansions,  4  1  0.2112745100035642\n",
      "1  Evaluation  4  1  0.2112745100035642\n",
      "1  adapted  4  1  0.2112745100035642\n",
      "1  Model  4  1  0.2112745100035642\n",
      "1  enhancing  4  1  0.2112745100035642\n",
      "1  constraining  4  1  0.2112745100035642\n",
      "1  often  4  1  0.2112745100035642\n",
      "1  potentially  4  1  0.2112745100035642\n",
      "1  12%  4  1  0.2112745100035642\n",
      "1  phase  4  1  0.2112745100035642\n",
      "1  successful  4  1  0.2112745100035642\n",
      "1  Framework  4  1  0.2112745100035642\n",
      "1  customized  4  1  0.2112745100035642\n",
      "1  modifying  4  1  0.2112745100035642\n",
      "1  reformulation,  4  1  0.2112745100035642\n",
      "1  queries  4  2  0.3010299956639812\n",
      "2  queries  5  1  0.20068666377598746\n",
      "1  weighted  4  1  0.2112745100035642\n",
      "1  analysis  5  1  0.28169934667141894\n",
      "1  graph-based  5  1  0.28169934667141894\n",
      "1  integrating  5  1  0.28169934667141894\n",
      "1  documents,  5  1  0.28169934667141894\n",
      "1  topological  5  1  0.28169934667141894\n",
      "1  discrepancy  5  1  0.28169934667141894\n",
      "1  representation  5  1  0.28169934667141894\n",
      "1  information,  5  1  0.28169934667141894\n",
      "1  understanding,  5  1  0.28169934667141894\n",
      "1  produce  5  1  0.28169934667141894\n",
      "1  superiority  5  1  0.28169934667141894\n",
      "1  methodology  5  1  0.28169934667141894\n",
      "1  structures  5  1  0.28169934667141894\n",
      "1  inputs  5  1  0.28169934667141894\n",
      "1  Session  5  1  0.28169934667141894\n",
      "1  modern  5  1  0.28169934667141894\n",
      "1  natural  5  1  0.20068666377598746\n",
      "2  natural  6  1  0.1505149978319906\n",
      "1  pre-trained  5  1  0.28169934667141894\n",
      "1  text.  5  1  0.28169934667141894\n",
      "1  recent  5  1  0.20068666377598746\n",
      "2  recent  6  1  0.1505149978319906\n",
      "1  modeling.  5  1  0.28169934667141894\n",
      "1  traditional  5  1  0.28169934667141894\n",
      "1  text-based  5  1  0.28169934667141894\n",
      "1  semantic  5  2  0.5633986933428379\n",
      "1  content  5  1  0.28169934667141894\n",
      "1  Graph  5  1  0.28169934667141894\n",
      "1  enable  5  1  0.28169934667141894\n",
      "1  fulfill  5  1  0.28169934667141894\n",
      "1  Concretely,  5  1  0.28169934667141894\n",
      "1  prediction,  5  1  0.28169934667141894\n",
      "1  interactive  5  1  0.28169934667141894\n",
      "1  prioritize  5  1  0.28169934667141894\n",
      "1  Symbolic  5  1  0.28169934667141894\n",
      "1  confirm  5  1  0.28169934667141894\n",
      "1  approach.  5  1  0.28169934667141894\n",
      "1  history,  5  1  0.28169934667141894\n",
      "1  interactions.  5  1  0.28169934667141894\n",
      "1  involves  5  1  0.28169934667141894\n",
      "1  learning,  5  1  0.28169934667141894\n",
      "1  comprehensive  5  1  0.28169934667141894\n",
      "1  AOL  5  1  0.28169934667141894\n",
      "1  generative  5  1  0.28169934667141894\n",
      "1  advantage  5  1  0.28169934667141894\n",
      "1  complex  5  1  0.28169934667141894\n",
      "1  paradigm  5  1  0.28169934667141894\n",
      "1  format.  5  1  0.28169934667141894\n",
      "1  generation,  5  1  0.28169934667141894\n",
      "1  structure  5  1  0.28169934667141894\n",
      "1  tasks  5  1  0.28169934667141894\n",
      "1  word-level  5  1  0.28169934667141894\n",
      "1  focus  5  1  0.28169934667141894\n",
      "1  Ranker  5  1  0.28169934667141894\n",
      "1  rules  5  1  0.28169934667141894\n",
      "1  grammar  5  1  0.28169934667141894\n",
      "1  enhance  5  1  0.28169934667141894\n",
      "1  including  5  1  0.28169934667141894\n",
      "1  neglecting  5  1  0.28169934667141894\n",
      "1  Tiangong-ST,  5  1  0.28169934667141894\n",
      "1  structural  5  1  0.28169934667141894\n",
      "1  LLMs'  5  1  0.28169934667141894\n",
      "1  deep  5  1  0.28169934667141894\n",
      "1  approaches  5  2  0.5633986933428379\n",
      "1  (SGR),  5  1  0.28169934667141894\n",
      "1  seamlessly  5  1  0.28169934667141894\n",
      "1  offers  5  1  0.28169934667141894\n",
      "1  datasets,  5  1  0.28169934667141894\n",
      "1  generalized  5  1  0.28169934667141894\n",
      "1  graph-to-text  5  1  0.28169934667141894\n",
      "1  typically  5  1  0.28169934667141894\n",
      "1  LLM.  5  1  0.28169934667141894\n",
      "1  leveraging  5  1  0.28169934667141894\n",
      "1  this,  5  1  0.28169934667141894\n",
      "1  coarse-grained  5  1  0.28169934667141894\n",
      "1  aims  5  1  0.28169934667141894\n",
      "1  use  5  1  0.20068666377598746\n",
      "2  use  6  1  0.1505149978319906\n",
      "1  Experiment  5  1  0.28169934667141894\n",
      "1  grammar,  5  1  0.28169934667141894\n",
      "1  session  5  2  0.5633986933428379\n",
      "1  (LLMs).  5  1  0.28169934667141894\n",
      "1  series  5  1  0.28169934667141894\n",
      "1  bridges  5  1  0.28169934667141894\n",
      "1  Moreover,  5  1  0.28169934667141894\n",
      "1  effective  5  1  0.28169934667141894\n",
      "1  objective  5  1  0.28169934667141894\n",
      "1  allows  5  1  0.28169934667141894\n",
      "1  two  5  1  0.28169934667141894\n",
      "1  learning  5  1  0.28169934667141894\n",
      "1  graph  5  3  0.8450980400142568\n",
      "1  actions  5  1  0.28169934667141894\n",
      "1  corpora,  5  1  0.28169934667141894\n",
      "1  self-supervised  5  1  0.28169934667141894\n",
      "1  Current  5  1  0.28169934667141894\n",
      "1  convert  5  1  0.28169934667141894\n",
      "1  symbolic  5  3  0.8450980400142568\n",
      "1  interaction  5  1  0.28169934667141894\n",
      "1  contrastive  5  1  0.28169934667141894\n",
      "1  textual  5  2  0.5633986933428379\n",
      "1  link  5  1  0.28169934667141894\n",
      "1  within  5  1  0.28169934667141894\n",
      "1  need.  5  1  0.28169934667141894\n",
      "1  gap  5  1  0.28169934667141894\n",
      "1  information  5  2  0.5633986933428379\n",
      "1  node  5  1  0.28169934667141894\n",
      "1  fine-grained.  5  1  0.28169934667141894\n",
      "1  overlooking  5  1  0.28169934667141894\n",
      "1  data  6  1  0.2112745100035642\n",
      "1  processing  6  1  0.2112745100035642\n",
      "1  ML  6  1  0.2112745100035642\n",
      "1  few-shot  6  1  0.2112745100035642\n",
      "1  exhibits  6  1  0.2112745100035642\n",
      "1  detailed  6  2  0.4225490200071284\n",
      "1  generated  6  1  0.2112745100035642\n",
      "1  dataset  6  3  0.6338235300106926\n",
      "1  compared  6  1  0.2112745100035642\n",
      "1  tools  6  1  0.2112745100035642\n",
      "1  manual  6  1  0.2112745100035642\n",
      "1  NDCG  6  1  0.2112745100035642\n",
      "1  emerged  6  1  0.2112745100035642\n",
      "1  pivotal  6  1  0.2112745100035642\n",
      "1  1M  6  1  0.2112745100035642\n",
      "1  description  6  3  0.6338235300106926\n",
      "1  powerful  6  1  0.2112745100035642\n",
      "1  potential  6  1  0.2112745100035642\n",
      "1  promise,  6  1  0.2112745100035642\n",
      "1  explored  6  1  0.2112745100035642\n",
      "1  demonstrated  6  1  0.2112745100035642\n",
      "1  Goodreads  6  2  0.4225490200071284\n",
      "1  MovieLens  6  1  0.2112745100035642\n",
      "1  captivate  6  1  0.2112745100035642\n",
      "1  providing  6  1  0.2112745100035642\n",
      "1  concise  6  1  0.2112745100035642\n",
      "1  scraping  6  1  0.2112745100035642\n",
      "1  cast  6  1  0.2112745100035642\n",
      "1  role  6  1  0.2112745100035642\n",
      "1  study,  6  1  0.2112745100035642\n",
      "1  prompted  6  1  0.2112745100035642\n",
      "1  systems.  6  1  0.2112745100035642\n",
      "1  descriptions.  6  1  0.2112745100035642\n",
      "1  plays  6  1  0.2112745100035642\n",
      "1  generation  6  1  0.2112745100035642\n",
      "1  viewers  6  1  0.2112745100035642\n",
      "1  Top  6  1  0.2112745100035642\n",
      "1  Alpaca,  6  1  0.2112745100035642\n",
      "1  web-scraped  6  1  0.2112745100035642\n",
      "1  scraped  6  1  0.2112745100035642\n",
      "1  comparable  6  1  0.2112745100035642\n",
      "1  techniques,  6  1  0.2112745100035642\n",
      "1  Dataset  6  1  0.2112745100035642\n",
      "1  inconsistencies.  6  1  0.2112745100035642\n",
      "1  GPT-3.5,  6  1  0.2112745100035642\n",
      "1  author  6  1  0.2112745100035642\n",
      "1  web  6  1  0.2112745100035642\n",
      "1  time-consuming  6  1  0.2112745100035642\n",
      "1  MRR,  6  1  0.2112745100035642\n",
      "1  features  6  1  0.2112745100035642\n",
      "1  subsequently,  6  1  0.2112745100035642\n",
      "1  comprising  6  1  0.2112745100035642\n",
      "1  summaries  6  1  0.2112745100035642\n",
      "1  like  6  2  0.4225490200071284\n",
      "1  ones  6  1  0.2112745100035642\n",
      "1  Traditionally,  6  1  0.2112745100035642\n",
      "1  dataset.  6  1  0.2112745100035642\n",
      "1  essential  6  1  0.2112745100035642\n",
      "1  evaluation  6  1  0.2112745100035642\n",
      "1  names  6  3  0.6338235300106926\n",
      "1  Alpaca  6  1  0.2112745100035642\n",
      "1  conduct  6  1  0.2112745100035642\n",
      "1  LLM,  6  1  0.2112745100035642\n",
      "1  (LLMs),  6  1  0.2112745100035642\n",
      "1  considering  6  1  0.2112745100035642\n",
      "1  books  6  1  0.2112745100035642\n",
      "1  obtained  6  2  0.4225490200071284\n",
      "1  consisting  6  1  0.2112745100035642\n",
      "1  directors  6  1  0.2112745100035642\n",
      "1  descriptions  6  4  0.8450980400142568\n",
      "1  Hits,  6  1  0.2112745100035642\n",
      "1  items.  6  1  0.2112745100035642\n",
      "1  movie  6  3  0.6338235300106926\n",
      "1  publisher  6  1  0.2112745100035642\n",
      "1  susceptible  6  1  0.2112745100035642\n",
      "1  combination  6  1  0.2112745100035642\n",
      "1  titles  6  1  0.2112745100035642\n",
      "1  informative  6  1  0.2112745100035642\n",
      "1  years,  6  1  0.2112745100035642\n",
      "1  open  6  1  0.2112745100035642\n",
      "1  significant  6  1  0.2112745100035642\n",
      "1  source  6  1  0.2112745100035642\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inverse_split = {}\n",
    "\n",
    "# Loop over each document's terms\n",
    "for i in range(len(termes_split)):\n",
    "    seen_terms = set()  # Track terms already processed for the current document\n",
    "    \n",
    "    for term in termes_split[i]:\n",
    "        # Ensure we only process each term once per document\n",
    "        if (term, i) not in seen_terms:\n",
    "            seen_terms.add((term, i))  # Mark term as processed for this document\n",
    "            \n",
    "            if term not in inverse_split:\n",
    "                inverse_split[term] = []  # Initialize list for storing details\n",
    "            \n",
    "            # Calculate frequency and weight for the term in the current document\n",
    "            frequency_term = frequency_dict_split_documents[i][term]\n",
    "            poids_term = poids(frequency_term, max_frequency_dict_split_documents[i], document_frequency_dict_split[term], n_split)\n",
    "            \n",
    "            # Store the document number, frequency, and weight\n",
    "            inverse_split[term].append((i + 1, frequency_term, poids_term))\n",
    "\n",
    "# Prepare output for the inverse split\n",
    "inverse_split_output = \"\"\n",
    "for term, docs in inverse_split.items():\n",
    "    for idx, doc_info in enumerate(docs, 1):\n",
    "        doc_num, frequency_term, poids_term = doc_info\n",
    "        inverse_split_output += f\"{idx}  {term}  {doc_num}  {frequency_term}  {poids_term}\\n\"\n",
    "\n",
    "print(inverse_split_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  reformulation  1  1  0.20068666377598746\n",
      "2  reformulation  4  3  0.3612359947967774\n",
      "1  feedback  1  3  0.6020599913279624\n",
      "2  feedback  4  1  0.12041199826559248\n",
      "1  technique  1  1  0.20068666377598746\n",
      "2  technique  2  1  0.1505149978319906\n",
      "1  find  1  1  0.28169934667141894\n",
      "1  upto  1  1  0.28169934667141894\n",
      "1  techniques  1  1  0.15904041823988746\n",
      "2  techniques  4  1  0.09542425094393249\n",
      "3  techniques  6  1  0.09542425094393249\n",
      "1  nDCG@10  1  2  0.4013733275519749\n",
      "2  nDCG@10  4  1  0.12041199826559248\n",
      "1  success  1  1  0.28169934667141894\n",
      "1  text  1  1  0.15904041823988746\n",
      "2  text  3  2  0.13632035849133212\n",
      "3  text  5  1  0.09542425094393249\n",
      "1  propose  1  1  0.1141408936074021\n",
      "2  propose  2  2  0.17121134041110314\n",
      "3  propose  3  1  0.048917525831743754\n",
      "4  propose  4  1  0.06848453616444126\n",
      "5  propose  5  1  0.06848453616444126\n",
      "1  inspiration  1  1  0.28169934667141894\n",
      "1  MSMarco  1  1  0.28169934667141894\n",
      "1  9%  1  1  0.28169934667141894\n",
      "1  zero-shot  1  3  0.8450980400142568\n",
      "1  prompting  1  2  0.4013733275519749\n",
      "2  prompting  6  1  0.12041199826559248\n",
      "1  ensemble  1  2  0.5633986933428379\n",
      "1  transform  1  1  0.28169934667141894\n",
      "1  set  1  1  0.15904041823988746\n",
      "2  set  3  1  0.06816017924566606\n",
      "3  set  5  2  0.19084850188786498\n",
      "1  previous  1  1  0.15904041823988746\n",
      "2  previous  2  1  0.11928031367991561\n",
      "3  previous  4  1  0.09542425094393249\n",
      "1  variant  1  1  0.28169934667141894\n",
      "1  shown  1  1  0.28169934667141894\n",
      "1  intent  1  1  0.28169934667141894\n",
      "1  state-of-art  1  1  0.28169934667141894\n",
      "1  search  1  2  0.3180808364797749\n",
      "2  search  4  1  0.09542425094393249\n",
      "3  search  5  2  0.19084850188786498\n",
      "1  5%  1  1  0.28169934667141894\n",
      "1  better  1  2  0.5633986933428379\n",
      "1  MRR  1  1  0.20068666377598746\n",
      "2  MRR  6  1  0.12041199826559248\n",
      "1  large  1  1  0.28169934667141894\n",
      "1  pseudo  1  1  0.28169934667141894\n",
      "1  retrieval  1  1  0.20068666377598746\n",
      "2  retrieval  4  2  0.24082399653118497\n",
      "1  Ranking  1  1  0.20068666377598746\n",
      "2  Ranking  2  2  0.3010299956639812\n",
      "1  many  1  1  0.28169934667141894\n",
      "1  models  1  1  0.20068666377598746\n",
      "2  models  3  7  0.6020599913279624\n",
      "1  relevant  1  2  0.5633986933428379\n",
      "1  documents  1  1  0.15904041823988746\n",
      "2  documents  2  2  0.23856062735983122\n",
      "3  documents  5  1  0.09542425094393249\n",
      "1  context  1  1  0.28169934667141894\n",
      "1  introduce  1  1  0.20068666377598746\n",
      "2  introduce  5  2  0.24082399653118497\n",
      "1  post-retrieval  1  1  0.28169934667141894\n",
      "1  tasks  1  1  0.1141408936074021\n",
      "2  tasks  2  1  0.08560567020555157\n",
      "3  tasks  3  2  0.09783505166348751\n",
      "4  tasks  5  1  0.06848453616444126\n",
      "5  tasks  6  1  0.06848453616444126\n",
      "1  18%  1  1  0.28169934667141894\n",
      "1  keywords  1  1  0.28169934667141894\n",
      "1  help  1  1  0.28169934667141894\n",
      "1  Reformulation  1  1  0.20068666377598746\n",
      "2  Reformulation  4  1  0.12041199826559248\n",
      "1  knowledge  1  1  0.28169934667141894\n",
      "1  investigate  1  1  0.28169934667141894\n",
      "1  improving  1  1  0.28169934667141894\n",
      "1  improves  1  1  0.28169934667141894\n",
      "1  strategies  1  1  0.15904041823988746\n",
      "2  strategies  4  1  0.09542425094393249\n",
      "3  strategies  5  2  0.19084850188786498\n",
      "1  approach  1  1  0.13264666955734586\n",
      "2  approach  2  1  0.0994850021680094\n",
      "3  approach  3  1  0.05684857266743394\n",
      "4  approach  5  1  0.07958800173440753\n",
      "1  generates  1  1  0.28169934667141894\n",
      "1  GenQREnsemble  1  2  0.5633986933428379\n",
      "1  QR  1  2  0.5633986933428379\n",
      "1  Query  1  1  0.20068666377598746\n",
      "2  Query  4  2  0.24082399653118497\n",
      "1  language  1  1  0.13264666955734586\n",
      "2  language  3  1  0.05684857266743394\n",
      "3  language  5  1  0.07958800173440753\n",
      "4  language  6  1  0.07958800173440753\n",
      "1  based  1  1  0.15904041823988746\n",
      "2  based  2  2  0.23856062735983122\n",
      "3  based  4  1  0.09542425094393249\n",
      "1  task  1  1  0.15904041823988746\n",
      "2  task  3  2  0.13632035849133212\n",
      "3  task  5  1  0.09542425094393249\n",
      "1  IR  1  1  0.20068666377598746\n",
      "2  IR  4  1  0.12041199826559248\n",
      "1  generate  1  1  0.15904041823988746\n",
      "2  generate  4  2  0.19084850188786498\n",
      "3  generate  6  2  0.19084850188786498\n",
      "1  using  1  2  0.2282817872148042\n",
      "2  using  2  4  0.3424226808222063\n",
      "3  using  4  1  0.06848453616444126\n",
      "4  using  5  1  0.06848453616444126\n",
      "5  using  6  1  0.06848453616444126\n",
      "1  due  1  1  0.28169934667141894\n",
      "1  ultimately  1  1  0.28169934667141894\n",
      "1  ability  1  1  0.20068666377598746\n",
      "2  ability  5  1  0.12041199826559248\n",
      "1  reformulations  1  1  0.28169934667141894\n",
      "1  user  1  2  0.2652933391146917\n",
      "2  user  3  1  0.05684857266743394\n",
      "3  user  4  1  0.07958800173440753\n",
      "4  user  5  1  0.07958800173440753\n",
      "1  experience  1  1  0.28169934667141894\n",
      "1  MAP  1  1  0.28169934667141894\n",
      "1  inherent  1  1  0.28169934667141894\n",
      "1  taking  1  1  0.28169934667141894\n",
      "1  instruction  1  1  0.20068666377598746\n",
      "2  instruction  5  1  0.12041199826559248\n",
      "1  exploit  1  1  0.28169934667141894\n",
      "1  performance  1  1  0.15904041823988746\n",
      "2  performance  2  1  0.11928031367991561\n",
      "3  performance  4  3  0.28627275283179743\n",
      "1  24%  1  1  0.28169934667141894\n",
      "1  query  1  2  0.3180808364797749\n",
      "2  query  2  1  0.11928031367991561\n",
      "3  query  4  5  0.47712125471966244\n",
      "1  gains  1  1  0.28169934667141894\n",
      "1  GenQREnsembleRF  1  2  0.5633986933428379\n",
      "1  promising  1  1  0.28169934667141894\n",
      "1  benefited  1  1  0.28169934667141894\n",
      "1  evaluations  1  1  0.28169934667141894\n",
      "1  aligns  1  1  0.28169934667141894\n",
      "1  improve  1  1  0.13264666955734586\n",
      "2  improve  2  1  0.0994850021680094\n",
      "3  improve  3  2  0.11369714533486788\n",
      "4  improve  4  1  0.07958800173440753\n",
      "1  sets  1  1  0.28169934667141894\n",
      "1  original  1  1  0.28169934667141894\n",
      "1  relative  1  2  0.5633986933428379\n",
      "1  Recently  1  1  0.28169934667141894\n",
      "1  pseudo-relevance  1  1  0.28169934667141894\n",
      "1  Passage  1  1  0.28169934667141894\n",
      "1  benchmarks  1  1  0.20068666377598746\n",
      "2  benchmarks  2  1  0.1505149978319906\n",
      "1  multiple  1  1  0.15904041823988746\n",
      "2  multiple  4  1  0.09542425094393249\n",
      "3  multiple  6  1  0.09542425094393249\n",
      "1  used  1  1  0.15904041823988746\n",
      "2  used  2  1  0.11928031367991561\n",
      "3  used  6  1  0.09542425094393249\n",
      "1  improvements  1  2  0.5633986933428379\n",
      "1  incorporate  1  1  0.28169934667141894\n",
      "1  leverages  1  1  0.20068666377598746\n",
      "2  leverages  4  1  0.12041199826559248\n",
      "1  four  1  1  0.28169934667141894\n",
      "1  shows  1  1  0.28169934667141894\n",
      "1  paraphrases  1  1  0.28169934667141894\n",
      "1  favorably  2  1  0.2112745100035642\n",
      "1  20B  2  1  0.2112745100035642\n",
      "1  commercial  2  2  0.4225490200071284\n",
      "1  template  2  1  0.1505149978319906\n",
      "2  template  3  2  0.17201714037941782\n",
      "1  Flan-UL2  2  1  0.2112745100035642\n",
      "1  existing  2  1  0.2112745100035642\n",
      "1  significantly  2  1  0.11928031367991561\n",
      "2  significantly  3  1  0.06816017924566606\n",
      "3  significantly  4  1  0.09542425094393249\n",
      "1  literature  2  2  0.4225490200071284\n",
      "1  candidate  2  1  0.2112745100035642\n",
      "1  linear  2  1  0.2112745100035642\n",
      "1  listwise  2  1  0.2112745100035642\n",
      "1  formulations  2  1  0.2112745100035642\n",
      "1  moderate-sized  2  1  0.2112745100035642\n",
      "1  baselines  2  1  0.2112745100035642\n",
      "1  fine-tuned  2  1  0.2112745100035642\n",
      "1  first  2  1  0.11928031367991561\n",
      "2  first  4  1  0.09542425094393249\n",
      "3  first  5  1  0.09542425094393249\n",
      "1  datasets  2  1  0.11928031367991561\n",
      "2  datasets  3  1  0.06816017924566606\n",
      "3  datasets  5  1  0.09542425094393249\n",
      "1  solution  2  1  0.2112745100035642\n",
      "1  PRP  2  4  0.8450980400142568\n",
      "1  average  2  1  0.2112745100035642\n",
      "1  paper  2  1  0.0994850021680094\n",
      "2  paper  4  1  0.07958800173440753\n",
      "3  paper  5  1  0.07958800173440753\n",
      "4  paper  6  1  0.07958800173440753\n",
      "1  competitive  2  1  0.2112745100035642\n",
      "1  model  2  2  0.4225490200071284\n",
      "1  open-sourced  2  1  0.1505149978319906\n",
      "2  open-sourced  6  1  0.12041199826559248\n",
      "1  rankers  2  1  0.2112745100035642\n",
      "1  outperforming  2  1  0.2112745100035642\n",
      "1  seven  2  1  0.2112745100035642\n",
      "1  standard  2  1  0.2112745100035642\n",
      "1  prompts  2  1  0.1505149978319906\n",
      "2  prompts  4  1  0.12041199826559248\n",
      "1  Language  2  1  0.0994850021680094\n",
      "2  Language  4  1  0.07958800173440753\n",
      "3  Language  5  1  0.07958800173440753\n",
      "4  Language  6  1  0.07958800173440753\n",
      "1  Prompting  2  1  0.2112745100035642\n",
      "1  TREC-DL  2  1  0.2112745100035642\n",
      "1  2019  2  1  0.2112745100035642\n",
      "1  10%  2  1  0.2112745100035642\n",
      "1  directly  2  1  0.2112745100035642\n",
      "1  problem  2  1  0.1505149978319906\n",
      "2  problem  4  1  0.12041199826559248\n",
      "1  175B  2  1  0.2112745100035642\n",
      "1  complexity  2  1  0.2112745100035642\n",
      "1  2020  2  1  0.2112745100035642\n",
      "1  BEIR  2  1  0.1505149978319906\n",
      "2  BEIR  4  1  0.12041199826559248\n",
      "1  practical  2  1  0.2112745100035642\n",
      "1  several  2  1  0.2112745100035642\n",
      "1  size  2  1  0.2112745100035642\n",
      "1  feeding  2  1  0.2112745100035642\n",
      "1  NDCG@10  2  1  0.2112745100035642\n",
      "1  ChatGPT  2  1  0.2112745100035642\n",
      "1  even  2  1  0.2112745100035642\n",
      "1  understand  2  1  0.1505149978319906\n",
      "2  understand  3  1  0.08600857018970891\n",
      "1  argue  2  1  0.2112745100035642\n",
      "1  off-the-shelf  2  1  0.2112745100035642\n",
      "1  reduce  2  1  0.1505149978319906\n",
      "2  reduce  3  1  0.08600857018970891\n",
      "1  50x  2  1  0.2112745100035642\n",
      "1  ranking  2  4  0.8450980400142568\n",
      "1  Large  2  1  0.08560567020555157\n",
      "2  Large  3  1  0.048917525831743754\n",
      "3  Large  4  1  0.06848453616444126\n",
      "4  Large  5  1  0.06848453616444126\n",
      "5  Large  6  1  0.06848453616444126\n",
      "1  performs  2  1  0.2112745100035642\n",
      "1  LLM-based  2  2  0.23856062735983122\n",
      "2  LLM-based  3  2  0.13632035849133212\n",
      "3  LLM-based  6  1  0.09542425094393249\n",
      "1  Furthermore  2  1  0.1505149978319906\n",
      "2  Furthermore  4  1  0.12041199826559248\n",
      "1  variants  2  1  0.2112745100035642\n",
      "1  show  2  1  0.2112745100035642\n",
      "1  4.2%  2  1  0.2112745100035642\n",
      "1  achieve  2  2  0.3010299956639812\n",
      "2  achieve  5  1  0.12041199826559248\n",
      "1  blackbox  2  2  0.4225490200071284\n",
      "1  Models  2  1  0.0994850021680094\n",
      "2  Models  4  1  0.07958800173440753\n",
      "3  Models  5  1  0.07958800173440753\n",
      "4  Models  6  1  0.07958800173440753\n",
      "1  burden  2  1  0.2112745100035642\n",
      "1  difficult  2  1  0.2112745100035642\n",
      "1  analyze  2  1  0.2112745100035642\n",
      "1  efficiency  2  1  0.1505149978319906\n",
      "2  efficiency  3  4  0.34403428075883563\n",
      "1  outperform  2  1  0.2112745100035642\n",
      "1  benchmark  2  1  0.11928031367991561\n",
      "2  benchmark  4  1  0.09542425094393249\n",
      "3  benchmark  5  1  0.09542425094393249\n",
      "1  results  2  2  0.1989700043360188\n",
      "2  results  3  1  0.05684857266743394\n",
      "3  results  5  1  0.07958800173440753\n",
      "4  results  6  2  0.15917600346881505\n",
      "1  methods  2  1  0.1505149978319906\n",
      "2  methods  4  1  0.12041199826559248\n",
      "1  interesting  2  1  0.2112745100035642\n",
      "1  LLMs  2  4  0.3979400086720376\n",
      "2  LLMs  4  3  0.23876400520322255\n",
      "3  LLMs  5  5  0.3979400086720376\n",
      "4  LLMs  6  3  0.23876400520322255\n",
      "1  However  2  1  0.2112745100035642\n",
      "1  solutions  2  2  0.4225490200071284\n",
      "1  metrics  2  1  0.1505149978319906\n",
      "2  metrics  6  1  0.12041199826559248\n",
      "1  found  2  1  0.2112745100035642\n",
      "1  called  2  1  0.2112745100035642\n",
      "1  supervised  2  1  0.2112745100035642\n",
      "1  baseline  2  1  0.2112745100035642\n",
      "1  fully  2  1  0.2112745100035642\n",
      "1  challenging  2  1  0.2112745100035642\n",
      "1  12-10%  2  1  0.2112745100035642\n",
      "1  prompt  2  2  0.3010299956639812\n",
      "2  prompt  3  3  0.2580257105691267\n",
      "1  GPT-4  2  1  0.2112745100035642\n",
      "1  new  2  1  0.2112745100035642\n",
      "1  estimated  2  1  0.2112745100035642\n",
      "1  parameters  2  2  0.4225490200071284\n",
      "1  state-of-the-art  2  1  0.1505149978319906\n",
      "2  state-of-the-art  4  1  0.12041199826559248\n",
      "1  researchers  2  1  0.1505149978319906\n",
      "2  researchers  3  1  0.08600857018970891\n",
      "1  InstructGPT  2  1  0.2112745100035642\n",
      "1  best  2  1  0.2112745100035642\n",
      "1  Pairwise  2  1  0.2112745100035642\n",
      "1  pointwise  2  2  0.4225490200071284\n",
      "1  outperforms  2  2  0.4225490200071284\n",
      "1  possible  2  1  0.2112745100035642\n",
      "1  item  3  1  0.08600857018970891\n",
      "2  item  6  1  0.12041199826559248\n",
      "1  design  3  1  0.1207282914306081\n",
      "1  continuous  3  1  0.1207282914306081\n",
      "1  long  3  2  0.2414565828612162\n",
      "1  PrOmpt  3  1  0.1207282914306081\n",
      "1  effectiveness  3  1  0.08600857018970891\n",
      "2  effectiveness  4  1  0.12041199826559248\n",
      "1  could  3  2  0.2414565828612162\n",
      "1  inspire  3  1  0.1207282914306081\n",
      "1  strategy  3  1  0.1207282914306081\n",
      "1  enough  3  1  0.1207282914306081\n",
      "1  specific  3  1  0.1207282914306081\n",
      "1  response  3  1  0.1207282914306081\n",
      "1  usually  3  2  0.2414565828612162\n",
      "1  power  3  1  0.08600857018970891\n",
      "2  power  5  1  0.12041199826559248\n",
      "1  time  3  2  0.17201714037941782\n",
      "2  time  4  1  0.12041199826559248\n",
      "1  may  3  2  0.2414565828612162\n",
      "1  demonstrate  3  1  0.08600857018970891\n",
      "2  demonstrate  4  1  0.12041199826559248\n",
      "1  Although  3  1  0.1207282914306081\n",
      "1  user/item  3  1  0.1207282914306081\n",
      "1  unleash  3  1  0.1207282914306081\n",
      "1  words  3  2  0.2414565828612162\n",
      "1  modeling  3  1  0.08600857018970891\n",
      "2  modeling  5  2  0.24082399653118497\n",
      "1  inference  3  3  0.36218487429182433\n",
      "1  allow  3  1  0.1207282914306081\n",
      "1  reasoning  3  1  0.1207282914306081\n",
      "1  i.e.  3  1  0.1207282914306081\n",
      "1  process  3  1  0.06816017924566606\n",
      "2  process  4  1  0.09542425094393249\n",
      "3  process  5  1  0.09542425094393249\n",
      "1  Distillation  3  1  0.1207282914306081\n",
      "1  mostly  3  1  0.1207282914306081\n",
      "1  attempt  3  1  0.1207282914306081\n",
      "1  input  3  1  0.08600857018970891\n",
      "2  input  4  1  0.12041199826559248\n",
      "1  systems  3  1  0.08600857018970891\n",
      "2  systems  6  1  0.12041199826559248\n",
      "1  manifested  3  1  0.1207282914306081\n",
      "1  e.g.  3  1  0.1207282914306081\n",
      "1  recommendation  3  5  0.43004285094854455\n",
      "2  recommendation  6  1  0.12041199826559248\n",
      "1  unparalleled  3  1  0.1207282914306081\n",
      "1  address  3  1  0.1207282914306081\n",
      "1  require  3  1  0.1207282914306081\n",
      "1  IDs  3  3  0.36218487429182433\n",
      "1  immediate  3  1  0.1207282914306081\n",
      "1  Long  3  1  0.1207282914306081\n",
      "1  problems  3  1  0.1207282914306081\n",
      "1  fine-tuning  3  1  0.1207282914306081\n",
      "1  LLM  3  2  0.13632035849133212\n",
      "2  LLM  5  1  0.09542425094393249\n",
      "3  LLM  6  1  0.09542425094393249\n",
      "1  efficient  3  1  0.1207282914306081\n",
      "1  take  3  1  0.08600857018970891\n",
      "2  take  5  1  0.12041199826559248\n",
      "1  discrete  3  2  0.2414565828612162\n",
      "1  various  3  1  0.08600857018970891\n",
      "2  various  4  1  0.12041199826559248\n",
      "1  limited  3  2  0.17201714037941782\n",
      "2  limited  4  1  0.12041199826559248\n",
      "1  vectors  3  1  0.1207282914306081\n",
      "1  real-world  3  1  0.1207282914306081\n",
      "1  improvement  3  1  0.1207282914306081\n",
      "1  extensive  3  1  0.1207282914306081\n",
      "1  contain  3  1  0.1207282914306081\n",
      "1  training  3  3  0.36218487429182433\n",
      "1  Experimental  3  1  0.1207282914306081\n",
      "1  need  3  1  0.08600857018970891\n",
      "2  need  5  1  0.12041199826559248\n",
      "1  also  3  1  0.08600857018970891\n",
      "2  also  5  1  0.12041199826559248\n",
      "1  community  3  1  0.1207282914306081\n",
      "1  sequential  3  1  0.08600857018970891\n",
      "2  sequential  5  1  0.12041199826559248\n",
      "1  thus  3  1  0.1207282914306081\n",
      "1  finding  3  1  0.1207282914306081\n",
      "1  three  3  1  0.1207282914306081\n",
      "1  improved  3  1  0.1207282914306081\n",
      "1  capability  3  1  0.1207282914306081\n",
      "1  filled  3  1  0.1207282914306081\n",
      "1  plain  3  1  0.1207282914306081\n",
      "1  POD  3  1  0.1207282914306081\n",
      "1  noisy  3  1  0.1207282914306081\n",
      "1  given  3  1  0.08600857018970891\n",
      "2  given  5  1  0.12041199826559248\n",
      "1  multi-step  3  1  0.1207282914306081\n",
      "1  recommender  3  1  0.1207282914306081\n",
      "1  distill  3  1  0.1207282914306081\n",
      "1  information  3  1  0.08600857018970891\n",
      "2  information  5  3  0.3612359947967774\n",
      "1  bridge  3  2  0.2414565828612162\n",
      "1  top-N  3  1  0.1207282914306081\n",
      "1  optimize  4  1  0.16901960800285137\n",
      "1  retriever  4  1  0.16901960800285137\n",
      "1  represent  4  1  0.16901960800285137\n",
      "1  intentions  4  1  0.16901960800285137\n",
      "1  Generative  4  1  0.16901960800285137\n",
      "1  redundant  4  1  0.16901960800285137\n",
      "1  distinctly  4  1  0.16901960800285137\n",
      "1  clusters  4  1  0.16901960800285137\n",
      "1  expansions  4  1  0.16901960800285137\n",
      "1  SOTAs  4  1  0.16901960800285137\n",
      "1  experiments  4  1  0.16901960800285137\n",
      "1  well-generated  4  1  0.16901960800285137\n",
      "1  advancing  4  1  0.16901960800285137\n",
      "1  integrates  4  1  0.16901960800285137\n",
      "1  rate  4  1  0.16901960800285137\n",
      "1  Clustering  4  1  0.16901960800285137\n",
      "1  explores  4  1  0.16901960800285137\n",
      "1  groups  4  1  0.16901960800285137\n",
      "1  well-known  4  1  0.16901960800285137\n",
      "1  combine  4  1  0.16901960800285137\n",
      "1  variable  4  1  0.16901960800285137\n",
      "1  leverage  4  1  0.16901960800285137\n",
      "1  adaptively  4  1  0.16901960800285137\n",
      "1  crucially  4  1  0.16901960800285137\n",
      "1  achieves  4  1  0.16901960800285137\n",
      "1  Retrieval  4  2  0.33803921600570275\n",
      "1  automatically  4  1  0.16901960800285137\n",
      "1  capture  4  1  0.12041199826559248\n",
      "2  capture  5  2  0.24082399653118497\n",
      "1  innovative  4  1  0.16901960800285137\n",
      "1  novel  4  1  0.12041199826559248\n",
      "2  novel  5  1  0.12041199826559248\n",
      "1  Information  4  2  0.33803921600570275\n",
      "1  Empirical  4  1  0.16901960800285137\n",
      "1  initial  4  1  0.16901960800285137\n",
      "1  boosting  4  1  0.16901960800285137\n",
      "1  refine  4  1  0.16901960800285137\n",
      "1  surpassing  4  1  0.16901960800285137\n",
      "1  Recent  4  1  0.16901960800285137\n",
      "1  single  4  1  0.16901960800285137\n",
      "1  GenCRF  4  3  0.5070588240085541\n",
      "1  capturing  4  1  0.12041199826559248\n",
      "2  capturing  5  1  0.12041199826559248\n",
      "1  Rewarding  4  1  0.16901960800285137\n",
      "1  diverse  4  4  0.6760784320114055\n",
      "1  completion  4  1  0.16901960800285137\n",
      "1  intents  4  3  0.5070588240085541\n",
      "1  field  4  1  0.16901960800285137\n",
      "1  aggregation  4  1  0.16901960800285137\n",
      "1  aimed  4  1  0.16901960800285137\n",
      "1  QERM  4  1  0.16901960800285137\n",
      "1  framework  4  1  0.16901960800285137\n",
      "1  Evaluation  4  1  0.16901960800285137\n",
      "1  adapted  4  1  0.16901960800285137\n",
      "1  differentiated  4  1  0.16901960800285137\n",
      "1  Model  4  1  0.16901960800285137\n",
      "1  enhancing  4  1  0.16901960800285137\n",
      "1  constraining  4  1  0.16901960800285137\n",
      "1  often  4  1  0.16901960800285137\n",
      "1  potentially  4  1  0.16901960800285137\n",
      "1  loops  4  1  0.16901960800285137\n",
      "1  12%  4  1  0.16901960800285137\n",
      "1  phase  4  1  0.16901960800285137\n",
      "1  successful  4  1  0.16901960800285137\n",
      "1  Framework  4  1  0.16901960800285137\n",
      "1  customized  4  1  0.16901960800285137\n",
      "1  modifying  4  1  0.16901960800285137\n",
      "1  queries  4  2  0.24082399653118497\n",
      "2  queries  5  1  0.12041199826559248\n",
      "1  weighted  4  1  0.16901960800285137\n",
      "1  analysis  5  1  0.16901960800285137\n",
      "1  graph-based  5  1  0.16901960800285137\n",
      "1  integrating  5  1  0.16901960800285137\n",
      "1  topological  5  1  0.16901960800285137\n",
      "1  discrepancy  5  1  0.16901960800285137\n",
      "1  representation  5  1  0.16901960800285137\n",
      "1  methodology  5  1  0.16901960800285137\n",
      "1  produce  5  1  0.16901960800285137\n",
      "1  superiority  5  1  0.16901960800285137\n",
      "1  fine-grained  5  1  0.16901960800285137\n",
      "1  SGR  5  1  0.16901960800285137\n",
      "1  structures  5  1  0.16901960800285137\n",
      "1  inputs  5  1  0.16901960800285137\n",
      "1  Session  5  1  0.16901960800285137\n",
      "1  modern  5  1  0.16901960800285137\n",
      "1  natural  5  1  0.12041199826559248\n",
      "2  natural  6  1  0.12041199826559248\n",
      "1  pre-trained  5  1  0.16901960800285137\n",
      "1  recent  5  1  0.12041199826559248\n",
      "2  recent  6  1  0.12041199826559248\n",
      "1  traditional  5  1  0.16901960800285137\n",
      "1  text-based  5  1  0.16901960800285137\n",
      "1  semantic  5  2  0.33803921600570275\n",
      "1  content  5  1  0.16901960800285137\n",
      "1  Graph  5  1  0.16901960800285137\n",
      "1  history  5  1  0.16901960800285137\n",
      "1  enable  5  1  0.16901960800285137\n",
      "1  fulfill  5  1  0.16901960800285137\n",
      "1  Moreover  5  1  0.16901960800285137\n",
      "1  interactive  5  1  0.16901960800285137\n",
      "1  format  5  1  0.16901960800285137\n",
      "1  prioritize  5  1  0.16901960800285137\n",
      "1  Symbolic  5  1  0.16901960800285137\n",
      "1  confirm  5  1  0.16901960800285137\n",
      "1  Tiangong-ST  5  1  0.16901960800285137\n",
      "1  involves  5  1  0.16901960800285137\n",
      "1  corpora  5  1  0.16901960800285137\n",
      "1  comprehensive  5  1  0.16901960800285137\n",
      "1  generation  5  1  0.12041199826559248\n",
      "2  generation  6  1  0.12041199826559248\n",
      "1  AOL  5  1  0.16901960800285137\n",
      "1  generative  5  1  0.16901960800285137\n",
      "1  advantage  5  1  0.16901960800285137\n",
      "1  complex  5  1  0.16901960800285137\n",
      "1  paradigm  5  1  0.16901960800285137\n",
      "1  structure  5  1  0.16901960800285137\n",
      "1  word-level  5  1  0.16901960800285137\n",
      "1  focus  5  1  0.16901960800285137\n",
      "1  Ranker  5  1  0.16901960800285137\n",
      "1  rules  5  1  0.16901960800285137\n",
      "1  Concretely  5  1  0.16901960800285137\n",
      "1  grammar  5  2  0.33803921600570275\n",
      "1  enhance  5  1  0.16901960800285137\n",
      "1  including  5  1  0.16901960800285137\n",
      "1  neglecting  5  1  0.16901960800285137\n",
      "1  interactions  5  1  0.16901960800285137\n",
      "1  structural  5  1  0.16901960800285137\n",
      "1  deep  5  1  0.16901960800285137\n",
      "1  approaches  5  2  0.33803921600570275\n",
      "1  seamlessly  5  1  0.16901960800285137\n",
      "1  offers  5  1  0.16901960800285137\n",
      "1  generalized  5  1  0.16901960800285137\n",
      "1  graph-to-text  5  1  0.16901960800285137\n",
      "1  typically  5  1  0.16901960800285137\n",
      "1  leveraging  5  1  0.16901960800285137\n",
      "1  coarse-grained  5  1  0.16901960800285137\n",
      "1  aims  5  1  0.16901960800285137\n",
      "1  use  5  1  0.12041199826559248\n",
      "2  use  6  1  0.12041199826559248\n",
      "1  Experiment  5  1  0.16901960800285137\n",
      "1  session  5  2  0.33803921600570275\n",
      "1  series  5  1  0.16901960800285137\n",
      "1  bridges  5  1  0.16901960800285137\n",
      "1  prediction  5  1  0.16901960800285137\n",
      "1  effective  5  1  0.16901960800285137\n",
      "1  objective  5  1  0.16901960800285137\n",
      "1  allows  5  1  0.16901960800285137\n",
      "1  two  5  1  0.16901960800285137\n",
      "1  learning  5  2  0.33803921600570275\n",
      "1  graph  5  3  0.5070588240085541\n",
      "1  actions  5  1  0.16901960800285137\n",
      "1  self-supervised  5  1  0.16901960800285137\n",
      "1  understanding  5  1  0.16901960800285137\n",
      "1  Current  5  1  0.16901960800285137\n",
      "1  convert  5  1  0.16901960800285137\n",
      "1  symbolic  5  3  0.5070588240085541\n",
      "1  interaction  5  1  0.16901960800285137\n",
      "1  contrastive  5  1  0.16901960800285137\n",
      "1  textual  5  2  0.33803921600570275\n",
      "1  link  5  1  0.16901960800285137\n",
      "1  within  5  1  0.16901960800285137\n",
      "1  gap  5  1  0.16901960800285137\n",
      "1  node  5  1  0.16901960800285137\n",
      "1  overlooking  5  1  0.16901960800285137\n",
      "1  data  6  1  0.16901960800285137\n",
      "1  processing  6  1  0.16901960800285137\n",
      "1  ML  6  1  0.16901960800285137\n",
      "1  few-shot  6  1  0.16901960800285137\n",
      "1  exhibits  6  1  0.16901960800285137\n",
      "1  detailed  6  2  0.33803921600570275\n",
      "1  generated  6  1  0.16901960800285137\n",
      "1  inconsistencies  6  1  0.16901960800285137\n",
      "1  dataset  6  4  0.6760784320114055\n",
      "1  compared  6  1  0.16901960800285137\n",
      "1  tools  6  1  0.16901960800285137\n",
      "1  manual  6  1  0.16901960800285137\n",
      "1  NDCG  6  1  0.16901960800285137\n",
      "1  emerged  6  1  0.16901960800285137\n",
      "1  pivotal  6  1  0.16901960800285137\n",
      "1  1M  6  1  0.16901960800285137\n",
      "1  description  6  3  0.5070588240085541\n",
      "1  powerful  6  1  0.16901960800285137\n",
      "1  potential  6  1  0.16901960800285137\n",
      "1  explored  6  1  0.16901960800285137\n",
      "1  GPT-3.5  6  1  0.16901960800285137\n",
      "1  demonstrated  6  1  0.16901960800285137\n",
      "1  Goodreads  6  2  0.33803921600570275\n",
      "1  MovieLens  6  1  0.16901960800285137\n",
      "1  captivate  6  1  0.16901960800285137\n",
      "1  providing  6  1  0.16901960800285137\n",
      "1  items  6  1  0.16901960800285137\n",
      "1  concise  6  1  0.16901960800285137\n",
      "1  scraping  6  1  0.16901960800285137\n",
      "1  cast  6  1  0.16901960800285137\n",
      "1  role  6  1  0.16901960800285137\n",
      "1  promise  6  1  0.16901960800285137\n",
      "1  prompted  6  1  0.16901960800285137\n",
      "1  plays  6  1  0.16901960800285137\n",
      "1  viewers  6  1  0.16901960800285137\n",
      "1  Top  6  1  0.16901960800285137\n",
      "1  web-scraped  6  1  0.16901960800285137\n",
      "1  scraped  6  1  0.16901960800285137\n",
      "1  comparable  6  1  0.16901960800285137\n",
      "1  Dataset  6  1  0.16901960800285137\n",
      "1  author  6  1  0.16901960800285137\n",
      "1  web  6  1  0.16901960800285137\n",
      "1  time-consuming  6  1  0.16901960800285137\n",
      "1  subsequently  6  1  0.16901960800285137\n",
      "1  features  6  1  0.16901960800285137\n",
      "1  comprising  6  1  0.16901960800285137\n",
      "1  summaries  6  1  0.16901960800285137\n",
      "1  like  6  2  0.33803921600570275\n",
      "1  ones  6  1  0.16901960800285137\n",
      "1  essential  6  1  0.16901960800285137\n",
      "1  evaluation  6  1  0.16901960800285137\n",
      "1  names  6  3  0.5070588240085541\n",
      "1  Alpaca  6  2  0.33803921600570275\n",
      "1  conduct  6  1  0.16901960800285137\n",
      "1  considering  6  1  0.16901960800285137\n",
      "1  books  6  1  0.16901960800285137\n",
      "1  obtained  6  2  0.33803921600570275\n",
      "1  consisting  6  1  0.16901960800285137\n",
      "1  directors  6  1  0.16901960800285137\n",
      "1  Traditionally  6  1  0.16901960800285137\n",
      "1  descriptions  6  5  0.8450980400142568\n",
      "1  movie  6  3  0.5070588240085541\n",
      "1  publisher  6  1  0.16901960800285137\n",
      "1  susceptible  6  1  0.16901960800285137\n",
      "1  combination  6  1  0.16901960800285137\n",
      "1  Hits  6  1  0.16901960800285137\n",
      "1  titles  6  1  0.16901960800285137\n",
      "1  informative  6  1  0.16901960800285137\n",
      "1  years  6  1  0.16901960800285137\n",
      "1  study  6  1  0.16901960800285137\n",
      "1  open  6  1  0.16901960800285137\n",
      "1  significant  6  1  0.16901960800285137\n",
      "1  source  6  1  0.16901960800285137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inverse_reg = {}\n",
    "\n",
    "for i in range(len(termes_reg)):\n",
    "    seen_terms = set()  # Track terms processed in the current document\n",
    "\n",
    "    for term in termes_reg[i]:\n",
    "        # Ensure each term-doc pair is processed once\n",
    "        if (term, i) not in seen_terms:\n",
    "            seen_terms.add((term, i))\n",
    "\n",
    "            if term not in inverse_reg:\n",
    "                inverse_reg[term] = []  # Initialize list for storing details\n",
    "            \n",
    "            frequency_term = frequency_dict_reg_documents[i][term]\n",
    "            poids_term = poids(frequency_term, max_frequency_dict_reg_documents[i], document_frequency_dict_reg[term], n_reg)\n",
    "            \n",
    "            inverse_reg[term].append((i + 1, frequency_term, poids_term))\n",
    "\n",
    "# Prepare output for the inverse split\n",
    "inverse_reg_output = \"\"\n",
    "for term, docs in inverse_reg.items():\n",
    "    for idx, doc_info in enumerate(docs, 1):\n",
    "        doc_num, frequency_term, poids_term = doc_info\n",
    "        inverse_reg_output += f\"{idx}  {term}  {doc_num}  {frequency_term}  {poids_term}\\n\"\n",
    "\n",
    "print(inverse_reg_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  task,  1  1  0.12041199826559248\n",
      "2  task,  3  1  0.12041199826559248\n",
      "1  investig  1  1  0.16901960800285137\n",
      "1  feedback  1  1  0.12041199826559248\n",
      "2  feedback  4  1  0.0752574989159953\n",
      "1  find  1  1  0.12041199826559248\n",
      "2  find  3  1  0.12041199826559248\n",
      "1  pseudo-relev  1  1  0.16901960800285137\n",
      "1  upto  1  1  0.16901960800285137\n",
      "1  documents.  1  1  0.16901960800285137\n",
      "1  ultim  1  1  0.16901960800285137\n",
      "1  success  1  1  0.12041199826559248\n",
      "2  success  4  1  0.0752574989159953\n",
      "1  text  1  1  0.12041199826559248\n",
      "2  text  3  1  0.12041199826559248\n",
      "1  instruct  1  1  0.12041199826559248\n",
      "2  instruct  5  1  0.1505149978319906\n",
      "1  state-of-art.  1  1  0.16901960800285137\n",
      "1  9%  1  1  0.16901960800285137\n",
      "1  msmarco  1  1  0.16901960800285137\n",
      "1  zero-shot  1  3  0.5070588240085541\n",
      "1  multipl  1  1  0.09542425094393249\n",
      "2  multipl  4  1  0.059640156839957804\n",
      "3  multipl  6  1  0.06816017924566606\n",
      "1  technique,  1  1  0.16901960800285137\n",
      "1  ensembl  1  2  0.33803921600570275\n",
      "1  rank  1  1  0.12041199826559248\n",
      "2  rank  2  6  0.6020599913279624\n",
      "1  queri  1  3  0.23876400520322255\n",
      "2  queri  2  1  0.06632333477867293\n",
      "3  queri  4  8  0.3979400086720376\n",
      "4  queri  5  1  0.0994850021680094\n",
      "1  transform  1  1  0.16901960800285137\n",
      "1  set  1  2  0.19084850188786498\n",
      "2  set  3  1  0.09542425094393249\n",
      "3  set  5  2  0.23856062735983122\n",
      "1  abil  1  1  0.12041199826559248\n",
      "2  abil  5  1  0.1505149978319906\n",
      "1  shown  1  1  0.16901960800285137\n",
      "1  intent  1  1  0.12041199826559248\n",
      "2  intent  4  2  0.1505149978319906\n",
      "1  search  1  2  0.19084850188786498\n",
      "2  search  4  1  0.059640156839957804\n",
      "3  search  5  2  0.23856062735983122\n",
      "1  5%  1  1  0.16901960800285137\n",
      "1  map  1  1  0.16901960800285137\n",
      "1  improv  1  5  0.3979400086720376\n",
      "2  improv  2  1  0.06632333477867293\n",
      "3  improv  3  3  0.23876400520322255\n",
      "4  improv  4  1  0.0497425010840047\n",
      "1  better  1  2  0.33803921600570275\n",
      "1  feedback,  1  1  0.16901960800285137\n",
      "1  pseudo  1  1  0.16901960800285137\n",
      "1  recently,  1  1  0.16901960800285137\n",
      "1  performance.  1  1  0.16901960800285137\n",
      "1  techniqu  1  1  0.09542425094393249\n",
      "2  techniqu  2  1  0.07952020911994373\n",
      "3  techniqu  4  1  0.059640156839957804\n",
      "1  relev  1  2  0.33803921600570275\n",
      "1  experience.  1  1  0.16901960800285137\n",
      "1  qr  1  1  0.16901960800285137\n",
      "1  reformul  1  1  0.12041199826559248\n",
      "2  reformul  4  3  0.22577249674798588\n",
      "1  evalu  1  1  0.09542425094393249\n",
      "2  evalu  4  1  0.059640156839957804\n",
      "3  evalu  6  1  0.06816017924566606\n",
      "1  tasks,  1  1  0.09542425094393249\n",
      "2  tasks,  2  1  0.07952020911994373\n",
      "3  tasks,  3  1  0.09542425094393249\n",
      "1  incorpor  1  1  0.16901960800285137\n",
      "1  18%  1  1  0.16901960800285137\n",
      "1  mani  1  1  0.16901960800285137\n",
      "1  leverag  1  1  0.09542425094393249\n",
      "2  leverag  4  2  0.11928031367991561\n",
      "3  leverag  5  1  0.11928031367991561\n",
      "1  gain  1  1  0.16901960800285137\n",
      "1  help  1  1  0.16901960800285137\n",
      "1  base  1  1  0.09542425094393249\n",
      "2  base  2  2  0.15904041823988746\n",
      "3  base  4  1  0.059640156839957804\n",
      "1  reformulation(qr)  1  1  0.16901960800285137\n",
      "1  approach  1  1  0.07958800173440753\n",
      "2  approach  2  1  0.06632333477867293\n",
      "3  approach  3  1  0.07958800173440753\n",
      "4  approach  5  2  0.1989700043360188\n",
      "1  take  1  1  0.09542425094393249\n",
      "2  take  3  1  0.09542425094393249\n",
      "3  take  5  1  0.11928031367991561\n",
      "1  genqrensemblerf  1  2  0.33803921600570275\n",
      "1  benefit  1  1  0.16901960800285137\n",
      "1  rel  1  2  0.33803921600570275\n",
      "1  models.  1  1  0.12041199826559248\n",
      "2  models.  3  2  0.24082399653118497\n",
      "1  previou  1  1  0.09542425094393249\n",
      "2  previou  2  1  0.07952020911994373\n",
      "3  previou  4  1  0.059640156839957804\n",
      "1  genqrensembl  1  2  0.33803921600570275\n",
      "1  inspir  1  1  0.12041199826559248\n",
      "2  inspir  3  1  0.12041199826559248\n",
      "1  user’  1  2  0.33803921600570275\n",
      "1  gener  1  2  0.15917600346881505\n",
      "2  gener  4  3  0.14922750325201412\n",
      "3  gener  5  2  0.1989700043360188\n",
      "4  gener  6  4  0.22739429066973577\n",
      "1  retriev  1  1  0.12041199826559248\n",
      "2  retriev  4  4  0.3010299956639812\n",
      "1  knowledg  1  1  0.16901960800285137\n",
      "1  passag  1  1  0.16901960800285137\n",
      "1  due  1  1  0.16901960800285137\n",
      "1  show  1  1  0.12041199826559248\n",
      "2  show  2  1  0.10034333188799373\n",
      "1  context,  1  1  0.16901960800285137\n",
      "1  ndcg@10  1  2  0.33803921600570275\n",
      "1  languag  1  1  0.06020599913279624\n",
      "2  languag  2  1  0.050171665943996864\n",
      "3  languag  3  1  0.06020599913279624\n",
      "4  languag  4  1  0.03762874945799765\n",
      "5  languag  5  2  0.1505149978319906\n",
      "6  languag  6  2  0.08600857018970891\n",
      "1  use  1  3  0.20545360849332375\n",
      "2  use  2  5  0.28535223401850524\n",
      "3  use  4  1  0.042802835102775785\n",
      "4  use  5  2  0.17121134041110314\n",
      "5  use  6  3  0.14675257749523127\n",
      "1  promis  1  1  0.16901960800285137\n",
      "1  mrr  1  1  0.16901960800285137\n",
      "1  benchmarks,  1  1  0.16901960800285137\n",
      "1  inher  1  1  0.16901960800285137\n",
      "1  keyword  1  1  0.16901960800285137\n",
      "1  origin  1  1  0.16901960800285137\n",
      "1  exploit  1  1  0.16901960800285137\n",
      "1  24%  1  1  0.16901960800285137\n",
      "1  larg  1  1  0.06020599913279624\n",
      "2  larg  2  1  0.050171665943996864\n",
      "3  larg  3  1  0.06020599913279624\n",
      "4  larg  4  1  0.03762874945799765\n",
      "5  larg  5  1  0.0752574989159953\n",
      "6  larg  6  1  0.043004285094854454\n",
      "1  paraphras  1  1  0.16901960800285137\n",
      "1  ir  1  1  0.16901960800285137\n",
      "1  reformulation.  1  1  0.16901960800285137\n",
      "1  align  1  1  0.16901960800285137\n",
      "1  introduc  1  1  0.12041199826559248\n",
      "2  introduc  5  2  0.3010299956639812\n",
      "1  variant,  1  1  0.16901960800285137\n",
      "1  strategi  1  1  0.07958800173440753\n",
      "2  strategi  3  1  0.07958800173440753\n",
      "3  strategi  4  1  0.0497425010840047\n",
      "4  strategi  5  2  0.1989700043360188\n",
      "1  prompt  1  2  0.15917600346881505\n",
      "2  prompt  2  4  0.2652933391146917\n",
      "3  prompt  3  3  0.23876400520322255\n",
      "4  prompt  6  2  0.11369714533486788\n",
      "1  propos  1  1  0.06848453616444126\n",
      "2  propos  2  2  0.1141408936074021\n",
      "3  propos  3  1  0.06848453616444126\n",
      "4  propos  4  1  0.042802835102775785\n",
      "5  propos  5  1  0.08560567020555157\n",
      "1  feedback.  1  1  0.16901960800285137\n",
      "1  post-retriev  1  1  0.16901960800285137\n",
      "1  four  1  1  0.16901960800285137\n",
      "1  effici  2  1  0.10034333188799373\n",
      "2  effici  3  5  0.6020599913279624\n",
      "1  averag  2  1  0.14084967333570947\n",
      "1  baselin  2  2  0.28169934667141894\n",
      "1  solutions,  2  1  0.14084967333570947\n",
      "1  flan-ul2  2  1  0.14084967333570947\n",
      "1  beir  2  1  0.10034333188799373\n",
      "2  beir  4  1  0.0752574989159953\n",
      "1  solut  2  2  0.28169934667141894\n",
      "1  linear  2  1  0.14084967333570947\n",
      "1  parameters,  2  1  0.14084967333570947\n",
      "1  challeng  2  1  0.14084967333570947\n",
      "1  first  2  1  0.07952020911994373\n",
      "2  first  4  1  0.059640156839957804\n",
      "3  first  5  1  0.11928031367991561\n",
      "1  pointwis  2  2  0.28169934667141894\n",
      "1  achiev  2  2  0.15904041823988746\n",
      "2  achiev  4  1  0.059640156839957804\n",
      "3  achiev  5  1  0.11928031367991561\n",
      "1  exist  2  1  0.14084967333570947\n",
      "1  model  2  3  0.17121134041110314\n",
      "2  model  3  5  0.3424226808222063\n",
      "3  model  4  2  0.08560567020555157\n",
      "4  model  5  2  0.17121134041110314\n",
      "5  model  6  1  0.048917525831743754\n",
      "1  variant  2  1  0.14084967333570947\n",
      "1  ranker  2  1  0.10034333188799373\n",
      "2  ranker  5  1  0.1505149978319906\n",
      "1  ndcg@10.  2  1  0.10034333188799373\n",
      "2  ndcg@10.  4  1  0.0752574989159953\n",
      "1  literatur  2  1  0.14084967333570947\n",
      "1  result  2  2  0.13264666955734586\n",
      "2  result  3  1  0.07958800173440753\n",
      "3  result  5  1  0.0994850021680094\n",
      "4  result  6  2  0.11369714533486788\n",
      "1  research  2  1  0.10034333188799373\n",
      "2  research  3  1  0.12041199826559248\n",
      "1  seven  2  1  0.14084967333570947\n",
      "1  commerci  2  2  0.28169934667141894\n",
      "1  directli  2  1  0.14084967333570947\n",
      "1  standard  2  1  0.14084967333570947\n",
      "1  chatgpt  2  1  0.14084967333570947\n",
      "1  (llms)  2  1  0.10034333188799373\n",
      "2  (llms)  4  1  0.0752574989159953\n",
      "1  2019  2  1  0.14084967333570947\n",
      "1  formulations.  2  1  0.14084967333570947\n",
      "1  (prp).  2  1  0.14084967333570947\n",
      "1  10%  2  1  0.14084967333570947\n",
      "1  open-sourc  2  1  0.10034333188799373\n",
      "2  open-sourc  6  1  0.08600857018970891\n",
      "1  paramet  2  1  0.14084967333570947\n",
      "1  interest  2  1  0.14084967333570947\n",
      "1  175b  2  1  0.14084967333570947\n",
      "1  listwis  2  1  0.14084967333570947\n",
      "1  llm  2  2  0.1141408936074021\n",
      "2  llm  3  1  0.06848453616444126\n",
      "3  llm  4  1  0.042802835102775785\n",
      "4  llm  5  2  0.17121134041110314\n",
      "5  llm  6  2  0.09783505166348751\n",
      "1  perform  2  2  0.20068666377598746\n",
      "2  perform  4  2  0.1505149978319906\n",
      "1  problem.  2  1  0.14084967333570947\n",
      "1  complex  2  1  0.10034333188799373\n",
      "2  complex  5  1  0.1505149978319906\n",
      "1  prp  2  3  0.4225490200071284\n",
      "1  (estimated)  2  1  0.14084967333570947\n",
      "1  however,  2  1  0.14084967333570947\n",
      "1  llm-base  2  2  0.15904041823988746\n",
      "2  llm-base  3  2  0.19084850188786498\n",
      "3  llm-base  6  1  0.06816017924566606\n",
      "1  reduc  2  1  0.10034333188799373\n",
      "2  reduc  3  1  0.12041199826559248\n",
      "1  even  2  1  0.14084967333570947\n",
      "1  understand  2  1  0.10034333188799373\n",
      "2  understand  3  1  0.12041199826559248\n",
      "1  moderate-s  2  1  0.14084967333570947\n",
      "1  paper,  2  1  0.06632333477867293\n",
      "2  paper,  4  1  0.0497425010840047\n",
      "3  paper,  5  1  0.0994850021680094\n",
      "4  paper,  6  1  0.05684857266743394\n",
      "1  llms.  2  1  0.10034333188799373\n",
      "2  llms.  5  1  0.1505149978319906\n",
      "1  datasets.  2  1  0.14084967333570947\n",
      "1  analyz  2  1  0.14084967333570947\n",
      "1  significantli  2  1  0.07952020911994373\n",
      "2  significantli  3  1  0.09542425094393249\n",
      "3  significantli  4  1  0.059640156839957804\n",
      "1  off-the-shelf  2  1  0.14084967333570947\n",
      "1  50x  2  1  0.14084967333570947\n",
      "1  gpt-4  2  1  0.14084967333570947\n",
      "1  pairwis  2  1  0.14084967333570947\n",
      "1  metrics.  2  1  0.10034333188799373\n",
      "2  metrics.  6  1  0.08600857018970891\n",
      "1  argu  2  1  0.14084967333570947\n",
      "1  possibl  2  1  0.14084967333570947\n",
      "1  furthermore,  2  1  0.10034333188799373\n",
      "2  furthermore,  4  1  0.0752574989159953\n",
      "1  fine-tun  2  1  0.10034333188799373\n",
      "2  fine-tun  3  1  0.12041199826559248\n",
      "1  trec-dl  2  1  0.14084967333570947\n",
      "1  competit  2  1  0.14084967333570947\n",
      "1  favor  2  1  0.14084967333570947\n",
      "1  4.2%  2  1  0.14084967333570947\n",
      "1  blackbox  2  2  0.28169934667141894\n",
      "1  burden  2  1  0.14084967333570947\n",
      "1  difficult  2  1  0.14084967333570947\n",
      "1  2020,  2  1  0.14084967333570947\n",
      "1  method  2  1  0.10034333188799373\n",
      "2  method  4  1  0.0752574989159953\n",
      "1  practic  2  1  0.14084967333570947\n",
      "1  outperform  2  4  0.5633986933428379\n",
      "1  benchmark  2  2  0.15904041823988746\n",
      "2  benchmark  4  1  0.059640156839957804\n",
      "3  benchmark  5  1  0.11928031367991561\n",
      "1  templat  2  1  0.10034333188799373\n",
      "2  templat  3  2  0.24082399653118497\n",
      "1  call  2  1  0.14084967333570947\n",
      "1  instructgpt  2  1  0.14084967333570947\n",
      "1  sever  2  1  0.14084967333570947\n",
      "1  literature,  2  1  0.14084967333570947\n",
      "1  found  2  1  0.14084967333570947\n",
      "1  feed  2  1  0.14084967333570947\n",
      "1  supervis  2  1  0.14084967333570947\n",
      "1  12-10%  2  1  0.14084967333570947\n",
      "1  document  2  2  0.28169934667141894\n",
      "1  new  2  1  0.14084967333570947\n",
      "1  fulli  2  1  0.14084967333570947\n",
      "1  state-of-the-art  2  1  0.10034333188799373\n",
      "2  state-of-the-art  4  1  0.0752574989159953\n",
      "1  best  2  1  0.14084967333570947\n",
      "1  20b  2  1  0.14084967333570947\n",
      "1  candid  2  1  0.14084967333570947\n",
      "1  size,  2  1  0.14084967333570947\n",
      "1  text,  3  1  0.16901960800285137\n",
      "1  item  3  1  0.12041199826559248\n",
      "2  item  6  1  0.08600857018970891\n",
      "1  design  3  1  0.16901960800285137\n",
      "1  long  3  3  0.5070588240085541\n",
      "1  manifest  3  1  0.16901960800285137\n",
      "1  could  3  2  0.33803921600570275\n",
      "1  reasoning,  3  1  0.16901960800285137\n",
      "1  dataset  3  1  0.12041199826559248\n",
      "2  dataset  6  4  0.34403428075883563\n",
      "1  enough  3  1  0.16901960800285137\n",
      "1  system  3  1  0.16901960800285137\n",
      "1  bridg  3  2  0.24082399653118497\n",
      "2  bridg  5  1  0.1505149978319906\n",
      "1  response.  3  1  0.16901960800285137\n",
      "1  power  3  1  0.09542425094393249\n",
      "2  power  5  1  0.11928031367991561\n",
      "3  power  6  1  0.06816017924566606\n",
      "1  time  3  1  0.16901960800285137\n",
      "1  information.  3  1  0.16901960800285137\n",
      "1  may  3  2  0.33803921600570275\n",
      "1  fill  3  1  0.16901960800285137\n",
      "1  limit  3  1  0.12041199826559248\n",
      "2  limit  4  1  0.0752574989159953\n",
      "1  user/item  3  1  0.16901960800285137\n",
      "1  tasks.  3  1  0.12041199826559248\n",
      "2  tasks.  6  1  0.08600857018970891\n",
      "1  unleash  3  1  0.16901960800285137\n",
      "1  specif  3  1  0.16901960800285137\n",
      "1  allow  3  1  0.12041199826559248\n",
      "2  allow  5  1  0.1505149978319906\n",
      "1  process,  3  1  0.12041199826559248\n",
      "2  process,  5  1  0.1505149978319906\n",
      "1  e.g.,  3  1  0.16901960800285137\n",
      "1  requir  3  1  0.16901960800285137\n",
      "1  time.  3  1  0.12041199826559248\n",
      "2  time.  4  1  0.0752574989159953\n",
      "1  top-n  3  1  0.16901960800285137\n",
      "1  recommend  3  5  0.6020599913279624\n",
      "2  recommend  6  1  0.08600857018970891\n",
      "1  unparallel  3  1  0.16901960800285137\n",
      "1  attempt  3  1  0.16901960800285137\n",
      "1  noisi  3  1  0.16901960800285137\n",
      "1  input  3  1  0.09542425094393249\n",
      "2  input  4  1  0.059640156839957804\n",
      "3  input  5  1  0.11928031367991561\n",
      "1  capabl  3  1  0.16901960800285137\n",
      "1  although  3  1  0.16901960800285137\n",
      "1  mostli  3  1  0.16901960800285137\n",
      "1  variou  3  1  0.12041199826559248\n",
      "2  variou  4  1  0.0752574989159953\n",
      "1  thu  3  1  0.16901960800285137\n",
      "1  discret  3  2  0.33803921600570275\n",
      "1  distil  3  2  0.33803921600570275\n",
      "1  address  3  1  0.16901960800285137\n",
      "1  models,  3  1  0.16901960800285137\n",
      "1  sequenti  3  1  0.12041199826559248\n",
      "2  sequenti  5  1  0.1505149978319906\n",
      "1  commun  3  1  0.16901960800285137\n",
      "1  problems,  3  1  0.16901960800285137\n",
      "1  (pod)  3  1  0.16901960800285137\n",
      "1  extens  3  1  0.16901960800285137\n",
      "1  immedi  3  1  0.16901960800285137\n",
      "1  usual  3  2  0.33803921600570275\n",
      "1  vector  3  1  0.16901960800285137\n",
      "1  experiment  3  1  0.16901960800285137\n",
      "1  word  3  2  0.33803921600570275\n",
      "1  infer  3  3  0.5070588240085541\n",
      "1  recommendation.  3  1  0.16901960800285137\n",
      "1  real-world  3  1  0.16901960800285137\n",
      "1  task  3  1  0.12041199826559248\n",
      "2  task  5  2  0.3010299956639812\n",
      "1  contain  3  1  0.16901960800285137\n",
      "1  continu  3  1  0.16901960800285137\n",
      "1  also  3  1  0.12041199826559248\n",
      "2  also  5  1  0.1505149978319906\n",
      "1  need  3  1  0.16901960800285137\n",
      "1  user  3  1  0.16901960800285137\n",
      "1  improved,  3  1  0.16901960800285137\n",
      "1  id  3  3  0.5070588240085541\n",
      "1  train  3  3  0.5070588240085541\n",
      "1  three  3  1  0.16901960800285137\n",
      "1  plain  3  1  0.16901960800285137\n",
      "1  limited.  3  1  0.16901960800285137\n",
      "1  (i.e.,  3  1  0.16901960800285137\n",
      "1  given  3  1  0.12041199826559248\n",
      "2  given  5  1  0.1505149978319906\n",
      "1  multi-step  3  1  0.16901960800285137\n",
      "1  prompt)  3  1  0.16901960800285137\n",
      "1  effect  3  1  0.09542425094393249\n",
      "2  effect  4  1  0.059640156839957804\n",
      "3  effect  5  1  0.11928031367991561\n",
      "1  demonstr  3  1  0.09542425094393249\n",
      "2  demonstr  4  1  0.059640156839957804\n",
      "3  demonstr  6  1  0.06816017924566606\n",
      "1  (llm)  3  1  0.16901960800285137\n",
      "1  complet  4  1  0.1056372550017821\n",
      "1  optim  4  1  0.1056372550017821\n",
      "1  performance,  4  1  0.1056372550017821\n",
      "1  experi  4  1  0.0752574989159953\n",
      "2  experi  5  1  0.1505149978319906\n",
      "1  integr  4  1  0.0752574989159953\n",
      "2  integr  5  1  0.1505149978319906\n",
      "1  gencrf:  4  1  0.1056372550017821\n",
      "1  custom  4  1  0.1056372550017821\n",
      "1  recent  4  1  0.059640156839957804\n",
      "2  recent  5  1  0.11928031367991561\n",
      "3  recent  6  1  0.06816017924566606\n",
      "1  differentiated,  4  1  0.1056372550017821\n",
      "1  crucial  4  1  0.1056372550017821\n",
      "1  redund  4  1  0.1056372550017821\n",
      "1  (ir)  4  1  0.1056372550017821\n",
      "1  divers  4  4  0.4225490200071284\n",
      "1  llms,  4  1  0.1056372550017821\n",
      "1  gencrf  4  2  0.2112745100035642\n",
      "1  enhanc  4  1  0.0752574989159953\n",
      "2  enhanc  5  1  0.1505149978319906\n",
      "1  process  4  1  0.0752574989159953\n",
      "2  process  6  1  0.08600857018970891\n",
      "1  prompts,  4  1  0.1056372550017821\n",
      "1  rate  4  1  0.1056372550017821\n",
      "1  well-known  4  1  0.1056372550017821\n",
      "1  problem  4  1  0.1056372550017821\n",
      "1  explor  4  1  0.0752574989159953\n",
      "2  explor  6  1  0.08600857018970891\n",
      "1  adapt  4  2  0.2112745100035642\n",
      "1  group  4  1  0.1056372550017821\n",
      "1  constrain  4  1  0.1056372550017821\n",
      "1  captur  4  2  0.1505149978319906\n",
      "2  captur  5  3  0.45154499349597177\n",
      "1  advanc  4  1  0.1056372550017821\n",
      "1  sota  4  1  0.1056372550017821\n",
      "1  modifi  4  1  0.1056372550017821\n",
      "1  loops.  4  1  0.1056372550017821\n",
      "1  novel  4  1  0.0752574989159953\n",
      "2  novel  5  1  0.1505149978319906\n",
      "1  innov  4  1  0.1056372550017821\n",
      "1  query.  4  1  0.1056372550017821\n",
      "1  potenti  4  1  0.0752574989159953\n",
      "2  potenti  6  1  0.08600857018970891\n",
      "1  well-gener  4  1  0.1056372550017821\n",
      "1  intents.  4  2  0.2112745100035642\n",
      "1  (qerm)  4  1  0.1056372550017821\n",
      "1  boost  4  1  0.1056372550017821\n",
      "1  combin  4  1  0.0752574989159953\n",
      "2  combin  6  1  0.08600857018970891\n",
      "1  reward  4  1  0.1056372550017821\n",
      "1  inform  4  2  0.11928031367991561\n",
      "2  inform  5  2  0.23856062735983122\n",
      "3  inform  6  1  0.06816017924566606\n",
      "1  empir  4  1  0.1056372550017821\n",
      "1  user'  4  1  0.0752574989159953\n",
      "2  user'  5  1  0.1505149978319906\n",
      "1  singl  4  1  0.1056372550017821\n",
      "1  field  4  1  0.1056372550017821\n",
      "1  surpass  4  1  0.1056372550017821\n",
      "1  variabl  4  1  0.1056372550017821\n",
      "1  repres  4  1  0.1056372550017821\n",
      "1  framework  4  2  0.2112745100035642\n",
      "1  expansions,  4  1  0.1056372550017821\n",
      "1  aggreg  4  1  0.1056372550017821\n",
      "1  retrieval.  4  1  0.1056372550017821\n",
      "1  often  4  1  0.1056372550017821\n",
      "1  distinctli  4  1  0.1056372550017821\n",
      "1  refin  4  1  0.1056372550017821\n",
      "1  automat  4  1  0.1056372550017821\n",
      "1  12%  4  1  0.1056372550017821\n",
      "1  phase  4  1  0.1056372550017821\n",
      "1  aim  4  1  0.0752574989159953\n",
      "2  aim  5  1  0.1505149978319906\n",
      "1  initi  4  1  0.1056372550017821\n",
      "1  reformulation,  4  1  0.1056372550017821\n",
      "1  cluster  4  2  0.2112745100035642\n",
      "1  weight  4  1  0.1056372550017821\n",
      "1  semant  5  2  0.4225490200071284\n",
      "1  interact  5  2  0.4225490200071284\n",
      "1  methodolog  5  1  0.2112745100035642\n",
      "1  represent  5  1  0.2112745100035642\n",
      "1  documents,  5  1  0.2112745100035642\n",
      "1  advantag  5  1  0.2112745100035642\n",
      "1  information,  5  1  0.2112745100035642\n",
      "1  understanding,  5  1  0.2112745100035642\n",
      "1  modern  5  1  0.2112745100035642\n",
      "1  object  5  1  0.2112745100035642\n",
      "1  text.  5  1  0.2112745100035642\n",
      "1  modeling.  5  1  0.2112745100035642\n",
      "1  analysi  5  1  0.2112745100035642\n",
      "1  superior  5  1  0.2112745100035642\n",
      "1  content  5  1  0.2112745100035642\n",
      "1  llm.  5  1  0.2112745100035642\n",
      "1  current  5  1  0.2112745100035642\n",
      "1  aol  5  1  0.2112745100035642\n",
      "1  prediction,  5  1  0.2112745100035642\n",
      "1  tradit  5  1  0.2112745100035642\n",
      "1  confirm  5  1  0.2112745100035642\n",
      "1  concretely,  5  1  0.2112745100035642\n",
      "1  learn  5  1  0.2112745100035642\n",
      "1  approach.  5  1  0.2112745100035642\n",
      "1  history,  5  1  0.2112745100035642\n",
      "1  interactions.  5  1  0.2112745100035642\n",
      "1  focu  5  1  0.2112745100035642\n",
      "1  learning,  5  1  0.2112745100035642\n",
      "1  offer  5  1  0.2112745100035642\n",
      "1  typic  5  1  0.2112745100035642\n",
      "1  discrep  5  1  0.2112745100035642\n",
      "1  paradigm  5  1  0.2112745100035642\n",
      "1  pre-train  5  1  0.2112745100035642\n",
      "1  produc  5  1  0.2112745100035642\n",
      "1  format.  5  1  0.2112745100035642\n",
      "1  generation,  5  1  0.2112745100035642\n",
      "1  word-level  5  1  0.2112745100035642\n",
      "1  grammar  5  1  0.2112745100035642\n",
      "1  action  5  1  0.2112745100035642\n",
      "1  text-bas  5  1  0.2112745100035642\n",
      "1  self-supervis  5  1  0.2112745100035642\n",
      "1  comprehens  5  1  0.2112745100035642\n",
      "1  deep  5  1  0.2112745100035642\n",
      "1  fulfil  5  1  0.2112745100035642\n",
      "1  datasets,  5  1  0.2112745100035642\n",
      "1  topolog  5  1  0.2112745100035642\n",
      "1  graph-to-text  5  1  0.2112745100035642\n",
      "1  this,  5  1  0.2112745100035642\n",
      "1  overlook  5  1  0.2112745100035642\n",
      "1  enabl  5  1  0.2112745100035642\n",
      "1  priorit  5  1  0.2112745100035642\n",
      "1  rule  5  1  0.2112745100035642\n",
      "1  grammar,  5  1  0.2112745100035642\n",
      "1  session  5  3  0.6338235300106926\n",
      "1  includ  5  1  0.2112745100035642\n",
      "1  contrast  5  1  0.2112745100035642\n",
      "1  seamlessli  5  1  0.2112745100035642\n",
      "1  two  5  1  0.2112745100035642\n",
      "1  graph  5  4  0.8450980400142568\n",
      "1  graph-bas  5  1  0.2112745100035642\n",
      "1  moreover,  5  1  0.2112745100035642\n",
      "1  coarse-grain  5  1  0.2112745100035642\n",
      "1  corpora,  5  1  0.2112745100035642\n",
      "1  (sgr),  5  1  0.2112745100035642\n",
      "1  convert  5  1  0.2112745100035642\n",
      "1  fine-grained.  5  1  0.2112745100035642\n",
      "1  neglect  5  1  0.2112745100035642\n",
      "1  textual  5  2  0.4225490200071284\n",
      "1  link  5  1  0.2112745100035642\n",
      "1  symbol  5  4  0.8450980400142568\n",
      "1  tiangong-st,  5  1  0.2112745100035642\n",
      "1  seri  5  1  0.2112745100035642\n",
      "1  structur  5  3  0.6338235300106926\n",
      "1  natur  5  1  0.1505149978319906\n",
      "2  natur  6  1  0.08600857018970891\n",
      "1  within  5  1  0.2112745100035642\n",
      "1  need.  5  1  0.2112745100035642\n",
      "1  gap  5  1  0.2112745100035642\n",
      "1  node  5  1  0.2112745100035642\n",
      "1  (llms).  5  1  0.2112745100035642\n",
      "1  involv  5  1  0.2112745100035642\n",
      "1  llms'  5  1  0.2112745100035642\n",
      "1  data  6  1  0.1207282914306081\n",
      "1  1m  6  1  0.1207282914306081\n",
      "1  consid  6  1  0.1207282914306081\n",
      "1  few-shot  6  1  0.1207282914306081\n",
      "1  scrape  6  2  0.2414565828612162\n",
      "1  book  6  1  0.1207282914306081\n",
      "1  titl  6  1  0.1207282914306081\n",
      "1  movi  6  3  0.36218487429182433\n",
      "1  manual  6  1  0.1207282914306081\n",
      "1  ndcg  6  1  0.1207282914306081\n",
      "1  gpt-3.5,  6  1  0.1207282914306081\n",
      "1  emerg  6  1  0.1207282914306081\n",
      "1  concis  6  1  0.1207282914306081\n",
      "1  alpaca  6  1  0.1207282914306081\n",
      "1  llm,  6  1  0.1207282914306081\n",
      "1  viewer  6  1  0.1207282914306081\n",
      "1  promise,  6  1  0.1207282914306081\n",
      "1  suscept  6  1  0.1207282914306081\n",
      "1  compris  6  1  0.1207282914306081\n",
      "1  obtain  6  2  0.2414565828612162\n",
      "1  cast  6  1  0.1207282914306081\n",
      "1  role  6  1  0.1207282914306081\n",
      "1  time-consum  6  1  0.1207282914306081\n",
      "1  study,  6  1  0.1207282914306081\n",
      "1  signific  6  1  0.1207282914306081\n",
      "1  publish  6  1  0.1207282914306081\n",
      "1  systems.  6  1  0.1207282914306081\n",
      "1  descriptions.  6  1  0.1207282914306081\n",
      "1  captiv  6  1  0.1207282914306081\n",
      "1  essenti  6  1  0.1207282914306081\n",
      "1  (llms),  6  1  0.1207282914306081\n",
      "1  director  6  1  0.1207282914306081\n",
      "1  provid  6  1  0.1207282914306081\n",
      "1  featur  6  1  0.1207282914306081\n",
      "1  techniques,  6  1  0.1207282914306081\n",
      "1  consist  6  1  0.1207282914306081\n",
      "1  inconsistencies.  6  1  0.1207282914306081\n",
      "1  detail  6  2  0.2414565828612162\n",
      "1  author  6  1  0.1207282914306081\n",
      "1  web  6  1  0.1207282914306081\n",
      "1  pivot  6  1  0.1207282914306081\n",
      "1  sourc  6  1  0.1207282914306081\n",
      "1  movielen  6  1  0.1207282914306081\n",
      "1  hits,  6  1  0.1207282914306081\n",
      "1  exhibit  6  1  0.1207282914306081\n",
      "1  traditionally,  6  1  0.1207282914306081\n",
      "1  subsequently,  6  1  0.1207282914306081\n",
      "1  top  6  1  0.1207282914306081\n",
      "1  like  6  2  0.2414565828612162\n",
      "1  dataset.  6  1  0.1207282914306081\n",
      "1  conduct  6  1  0.1207282914306081\n",
      "1  mrr,  6  1  0.1207282914306081\n",
      "1  goodread  6  2  0.2414565828612162\n",
      "1  items.  6  1  0.1207282914306081\n",
      "1  tool  6  1  0.1207282914306081\n",
      "1  compar  6  2  0.2414565828612162\n",
      "1  alpaca,  6  1  0.1207282914306081\n",
      "1  name  6  3  0.36218487429182433\n",
      "1  one  6  1  0.1207282914306081\n",
      "1  web-scrap  6  1  0.1207282914306081\n",
      "1  ml  6  1  0.1207282914306081\n",
      "1  descript  6  7  0.8450980400142568\n",
      "1  years,  6  1  0.1207282914306081\n",
      "1  open  6  1  0.1207282914306081\n",
      "1  play  6  1  0.1207282914306081\n",
      "1  summari  6  1  0.1207282914306081\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inverse_split_porter = {}\n",
    "\n",
    "for i in range(len(termes_split_porter)):\n",
    "    seen_terms = set()  # Track terms processed in the current document\n",
    "\n",
    "    for j in range(len(termes_split_porter[i])):\n",
    "        term = termes_split_porter[i][j]\n",
    "\n",
    "        if (term, i) not in seen_terms:\n",
    "            seen_terms.add((term, i))\n",
    "\n",
    "            if term not in inverse_split_porter:\n",
    "                inverse_split_porter[term] = []\n",
    "            \n",
    "            frequency_term = frequency_dict_split_porter_documents[i][termes_split_porter[i][j]]\n",
    "            poids_term = poids(frequency_term, max_frequency_dict_split_porter_documents[i], document_frequency_dict_split_porter[termes_split_porter[i][j]], n_split)\n",
    "            \n",
    "            inverse_split_porter[term].append((i + 1, frequency_term, poids_term))\n",
    "\n",
    "inverse_split_porter_output = \"\"\n",
    "for term, docs in inverse_split_porter.items():\n",
    "    for idx, doc_info in enumerate(docs, 1):\n",
    "        doc_num, frequency_term, poids_term = doc_info\n",
    "        inverse_split_porter_output += f\"{idx}  {term}  {doc_num}  {frequency_term}  {poids_term}\\n\"\n",
    "\n",
    "print(inverse_split_porter_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  investig  1  1  0.16901960800285137\n",
      "1  feedback  1  3  0.3612359947967774\n",
      "2  feedback  4  1  0.06689555459199582\n",
      "1  experi  1  1  0.09542425094393249\n",
      "2  experi  4  1  0.05301347274662915\n",
      "3  experi  5  1  0.07952020911994373\n",
      "1  find  1  1  0.12041199826559248\n",
      "2  find  3  1  0.0752574989159953\n",
      "1  pseudo-relev  1  1  0.16901960800285137\n",
      "1  upto  1  1  0.16901960800285137\n",
      "1  ultim  1  1  0.16901960800285137\n",
      "1  success  1  1  0.12041199826559248\n",
      "2  success  4  1  0.06689555459199582\n",
      "1  text  1  1  0.09542425094393249\n",
      "2  text  3  2  0.11928031367991561\n",
      "3  text  5  1  0.07952020911994373\n",
      "1  instruct  1  1  0.12041199826559248\n",
      "2  instruct  5  1  0.10034333188799373\n",
      "1  recent  1  1  0.07958800173440753\n",
      "2  recent  4  1  0.04421555651911529\n",
      "3  recent  5  1  0.06632333477867293\n",
      "4  recent  6  1  0.0497425010840047\n",
      "1  9%  1  1  0.16901960800285137\n",
      "1  msmarco  1  1  0.16901960800285137\n",
      "1  zero-shot  1  3  0.5070588240085541\n",
      "1  multipl  1  1  0.09542425094393249\n",
      "2  multipl  4  1  0.05301347274662915\n",
      "3  multipl  6  1  0.059640156839957804\n",
      "1  ensembl  1  2  0.33803921600570275\n",
      "1  rank  1  1  0.12041199826559248\n",
      "2  rank  2  6  0.6020599913279624\n",
      "1  queri  1  3  0.23876400520322255\n",
      "2  queri  2  1  0.06632333477867293\n",
      "3  queri  4  9  0.3979400086720376\n",
      "4  queri  5  1  0.06632333477867293\n",
      "1  transform  1  1  0.16901960800285137\n",
      "1  set  1  2  0.19084850188786498\n",
      "2  set  3  1  0.059640156839957804\n",
      "3  set  5  2  0.15904041823988746\n",
      "1  abil  1  1  0.12041199826559248\n",
      "2  abil  5  1  0.10034333188799373\n",
      "1  model  1  1  0.06020599913279624\n",
      "2  model  2  3  0.1505149978319906\n",
      "3  model  3  8  0.3010299956639812\n",
      "4  model  4  2  0.06689555459199582\n",
      "5  model  5  3  0.1505149978319906\n",
      "6  model  6  1  0.03762874945799765\n",
      "1  variant  1  1  0.12041199826559248\n",
      "2  variant  2  1  0.10034333188799373\n",
      "1  shown  1  1  0.16901960800285137\n",
      "1  intent  1  1  0.12041199826559248\n",
      "2  intent  4  4  0.2675822183679833\n",
      "1  state-of-art  1  1  0.16901960800285137\n",
      "1  search  1  2  0.19084850188786498\n",
      "2  search  4  1  0.05301347274662915\n",
      "3  search  5  2  0.15904041823988746\n",
      "1  5%  1  1  0.16901960800285137\n",
      "1  map  1  1  0.16901960800285137\n",
      "1  better  1  2  0.33803921600570275\n",
      "1  improv  1  5  0.3979400086720376\n",
      "2  improv  2  1  0.06632333477867293\n",
      "3  improv  3  4  0.1989700043360188\n",
      "4  improv  4  1  0.04421555651911529\n",
      "1  pseudo  1  1  0.16901960800285137\n",
      "1  techniqu  1  2  0.15917600346881505\n",
      "2  techniqu  2  1  0.06632333477867293\n",
      "3  techniqu  4  1  0.04421555651911529\n",
      "4  techniqu  6  1  0.0497425010840047\n",
      "1  perform  1  1  0.09542425094393249\n",
      "2  perform  2  2  0.15904041823988746\n",
      "3  perform  4  3  0.15904041823988746\n",
      "1  relev  1  2  0.33803921600570275\n",
      "1  qr  1  2  0.33803921600570275\n",
      "1  context  1  1  0.16901960800285137\n",
      "1  reformul  1  3  0.3612359947967774\n",
      "2  reformul  4  4  0.2675822183679833\n",
      "1  evalu  1  1  0.09542425094393249\n",
      "2  evalu  4  1  0.05301347274662915\n",
      "3  evalu  6  1  0.059640156839957804\n",
      "1  incorpor  1  1  0.16901960800285137\n",
      "1  18%  1  1  0.16901960800285137\n",
      "1  mani  1  1  0.16901960800285137\n",
      "1  leverag  1  1  0.09542425094393249\n",
      "2  leverag  4  2  0.1060269454932583\n",
      "3  leverag  5  1  0.07952020911994373\n",
      "1  gain  1  1  0.16901960800285137\n",
      "1  help  1  1  0.16901960800285137\n",
      "1  base  1  1  0.09542425094393249\n",
      "2  base  2  2  0.15904041823988746\n",
      "3  base  4  1  0.05301347274662915\n",
      "1  approach  1  1  0.07958800173440753\n",
      "2  approach  2  1  0.06632333477867293\n",
      "3  approach  3  1  0.0497425010840047\n",
      "4  approach  5  3  0.1989700043360188\n",
      "1  take  1  1  0.09542425094393249\n",
      "2  take  3  1  0.059640156839957804\n",
      "3  take  5  1  0.07952020911994373\n",
      "1  genqrensemblerf  1  2  0.33803921600570275\n",
      "1  benefit  1  1  0.16901960800285137\n",
      "1  rel  1  2  0.33803921600570275\n",
      "1  previou  1  1  0.09542425094393249\n",
      "2  previou  2  1  0.07952020911994373\n",
      "3  previou  4  1  0.05301347274662915\n",
      "1  genqrensembl  1  2  0.33803921600570275\n",
      "1  inspir  1  1  0.12041199826559248\n",
      "2  inspir  3  1  0.0752574989159953\n",
      "1  gener  1  2  0.15917600346881505\n",
      "2  gener  4  3  0.13264666955734586\n",
      "3  gener  5  3  0.1989700043360188\n",
      "4  gener  6  4  0.1989700043360188\n",
      "1  retriev  1  1  0.12041199826559248\n",
      "2  retriev  4  5  0.3344777729599791\n",
      "1  task  1  2  0.13696907232888253\n",
      "2  task  2  1  0.05707044680370105\n",
      "3  task  3  4  0.17121134041110314\n",
      "4  task  5  2  0.1141408936074021\n",
      "5  task  6  1  0.042802835102775785\n",
      "1  knowledg  1  1  0.16901960800285137\n",
      "1  passag  1  1  0.16901960800285137\n",
      "1  due  1  1  0.16901960800285137\n",
      "1  show  1  1  0.12041199826559248\n",
      "2  show  2  1  0.10034333188799373\n",
      "1  ndcg@10  1  2  0.19084850188786498\n",
      "2  ndcg@10  2  1  0.07952020911994373\n",
      "3  ndcg@10  4  1  0.05301347274662915\n",
      "1  languag  1  1  0.06020599913279624\n",
      "2  languag  2  1  0.050171665943996864\n",
      "3  languag  3  1  0.03762874945799765\n",
      "4  languag  4  1  0.03344777729599791\n",
      "5  languag  5  2  0.10034333188799373\n",
      "6  languag  6  2  0.0752574989159953\n",
      "1  use  1  3  0.20545360849332375\n",
      "2  use  2  5  0.28535223401850524\n",
      "3  use  4  1  0.0380469645358007\n",
      "4  use  5  2  0.1141408936074021\n",
      "5  use  6  3  0.12840850530832737\n",
      "1  promis  1  1  0.12041199826559248\n",
      "2  promis  6  1  0.0752574989159953\n",
      "1  mrr  1  1  0.12041199826559248\n",
      "2  mrr  6  1  0.0752574989159953\n",
      "1  user  1  2  0.15917600346881505\n",
      "2  user  3  1  0.0497425010840047\n",
      "3  user  4  1  0.04421555651911529\n",
      "4  user  5  1  0.06632333477867293\n",
      "1  inher  1  1  0.16901960800285137\n",
      "1  keyword  1  1  0.16901960800285137\n",
      "1  origin  1  1  0.16901960800285137\n",
      "1  exploit  1  1  0.16901960800285137\n",
      "1  24%  1  1  0.16901960800285137\n",
      "1  benchmark  1  1  0.07958800173440753\n",
      "2  benchmark  2  2  0.13264666955734586\n",
      "3  benchmark  4  1  0.04421555651911529\n",
      "4  benchmark  5  1  0.06632333477867293\n",
      "1  larg  1  1  0.06020599913279624\n",
      "2  larg  2  1  0.050171665943996864\n",
      "3  larg  3  1  0.03762874945799765\n",
      "4  larg  4  1  0.03344777729599791\n",
      "5  larg  5  1  0.050171665943996864\n",
      "6  larg  6  1  0.03762874945799765\n",
      "1  paraphras  1  1  0.16901960800285137\n",
      "1  ir  1  1  0.12041199826559248\n",
      "2  ir  4  1  0.06689555459199582\n",
      "1  align  1  1  0.16901960800285137\n",
      "1  introduc  1  1  0.12041199826559248\n",
      "2  introduc  5  2  0.20068666377598746\n",
      "1  strategi  1  1  0.07958800173440753\n",
      "2  strategi  3  1  0.0497425010840047\n",
      "3  strategi  4  1  0.04421555651911529\n",
      "4  strategi  5  2  0.13264666955734586\n",
      "1  document  1  1  0.09542425094393249\n",
      "2  document  2  2  0.15904041823988746\n",
      "3  document  5  1  0.07952020911994373\n",
      "1  prompt  1  2  0.13696907232888253\n",
      "2  prompt  2  4  0.2282817872148042\n",
      "3  prompt  3  4  0.17121134041110314\n",
      "4  prompt  4  1  0.0380469645358007\n",
      "5  prompt  6  2  0.08560567020555157\n",
      "1  propos  1  1  0.06848453616444126\n",
      "2  propos  2  2  0.1141408936074021\n",
      "3  propos  3  1  0.042802835102775785\n",
      "4  propos  4  1  0.0380469645358007\n",
      "5  propos  5  1  0.05707044680370105\n",
      "1  post-retriev  1  1  0.16901960800285137\n",
      "1  four  1  1  0.16901960800285137\n",
      "1  effici  2  1  0.10034333188799373\n",
      "2  effici  3  5  0.3762874945799765\n",
      "1  averag  2  1  0.14084967333570947\n",
      "1  baselin  2  2  0.28169934667141894\n",
      "1  flan-ul2  2  1  0.14084967333570947\n",
      "1  beir  2  1  0.10034333188799373\n",
      "2  beir  4  1  0.06689555459199582\n",
      "1  solut  2  3  0.4225490200071284\n",
      "1  dataset  2  1  0.06632333477867293\n",
      "2  dataset  3  1  0.0497425010840047\n",
      "3  dataset  5  1  0.06632333477867293\n",
      "4  dataset  6  5  0.2487125054200235\n",
      "1  linear  2  1  0.14084967333570947\n",
      "1  challeng  2  1  0.14084967333570947\n",
      "1  first  2  1  0.07952020911994373\n",
      "2  first  4  1  0.05301347274662915\n",
      "3  first  5  1  0.07952020911994373\n",
      "1  pointwis  2  2  0.28169934667141894\n",
      "1  achiev  2  2  0.15904041823988746\n",
      "2  achiev  4  1  0.05301347274662915\n",
      "3  achiev  5  1  0.07952020911994373\n",
      "1  exist  2  1  0.14084967333570947\n",
      "1  paper  2  1  0.06632333477867293\n",
      "2  paper  4  1  0.04421555651911529\n",
      "3  paper  5  1  0.06632333477867293\n",
      "4  paper  6  1  0.0497425010840047\n",
      "1  ranker  2  1  0.10034333188799373\n",
      "2  ranker  5  1  0.10034333188799373\n",
      "1  metric  2  1  0.10034333188799373\n",
      "2  metric  6  1  0.0752574989159953\n",
      "1  literatur  2  2  0.28169934667141894\n",
      "1  result  2  2  0.13264666955734586\n",
      "2  result  3  1  0.0497425010840047\n",
      "3  result  5  1  0.06632333477867293\n",
      "4  result  6  2  0.0994850021680094\n",
      "1  research  2  1  0.10034333188799373\n",
      "2  research  3  1  0.0752574989159953\n",
      "1  seven  2  1  0.14084967333570947\n",
      "1  commerci  2  2  0.28169934667141894\n",
      "1  directli  2  1  0.14084967333570947\n",
      "1  standard  2  1  0.14084967333570947\n",
      "1  chatgpt  2  1  0.14084967333570947\n",
      "1  furthermor  2  1  0.10034333188799373\n",
      "2  furthermor  4  1  0.06689555459199582\n",
      "1  estim  2  1  0.14084967333570947\n",
      "1  2019  2  1  0.14084967333570947\n",
      "1  10%  2  1  0.14084967333570947\n",
      "1  open-sourc  2  1  0.10034333188799373\n",
      "2  open-sourc  6  1  0.0752574989159953\n",
      "1  problem  2  1  0.07952020911994373\n",
      "2  problem  3  1  0.059640156839957804\n",
      "3  problem  4  1  0.05301347274662915\n",
      "1  paramet  2  2  0.28169934667141894\n",
      "1  interest  2  1  0.14084967333570947\n",
      "1  2020  2  1  0.14084967333570947\n",
      "1  listwis  2  1  0.14084967333570947\n",
      "1  175b  2  1  0.14084967333570947\n",
      "1  llm  2  4  0.2282817872148042\n",
      "2  llm  3  2  0.08560567020555157\n",
      "3  llm  4  3  0.1141408936074021\n",
      "4  llm  5  6  0.3424226808222063\n",
      "5  llm  6  4  0.17121134041110314\n",
      "1  complex  2  1  0.10034333188799373\n",
      "2  complex  5  1  0.10034333188799373\n",
      "1  size  2  1  0.14084967333570947\n",
      "1  howev  2  1  0.14084967333570947\n",
      "1  formul  2  1  0.14084967333570947\n",
      "1  prp  2  4  0.5633986933428379\n",
      "1  llm-base  2  2  0.15904041823988746\n",
      "2  llm-base  3  2  0.11928031367991561\n",
      "3  llm-base  6  1  0.059640156839957804\n",
      "1  reduc  2  1  0.10034333188799373\n",
      "2  reduc  3  1  0.0752574989159953\n",
      "1  even  2  1  0.14084967333570947\n",
      "1  understand  2  1  0.07952020911994373\n",
      "2  understand  3  1  0.059640156839957804\n",
      "3  understand  5  1  0.07952020911994373\n",
      "1  moderate-s  2  1  0.14084967333570947\n",
      "1  analyz  2  1  0.14084967333570947\n",
      "1  significantli  2  1  0.07952020911994373\n",
      "2  significantli  3  1  0.059640156839957804\n",
      "3  significantli  4  1  0.05301347274662915\n",
      "1  off-the-shelf  2  1  0.14084967333570947\n",
      "1  50x  2  1  0.14084967333570947\n",
      "1  gpt-4  2  1  0.14084967333570947\n",
      "1  pairwis  2  1  0.14084967333570947\n",
      "1  argu  2  1  0.14084967333570947\n",
      "1  possibl  2  1  0.14084967333570947\n",
      "1  fine-tun  2  1  0.10034333188799373\n",
      "2  fine-tun  3  1  0.0752574989159953\n",
      "1  trec-dl  2  1  0.14084967333570947\n",
      "1  competit  2  1  0.14084967333570947\n",
      "1  favor  2  1  0.14084967333570947\n",
      "1  4.2%  2  1  0.14084967333570947\n",
      "1  blackbox  2  2  0.28169934667141894\n",
      "1  burden  2  1  0.14084967333570947\n",
      "1  difficult  2  1  0.14084967333570947\n",
      "1  method  2  1  0.10034333188799373\n",
      "2  method  4  1  0.06689555459199582\n",
      "1  practic  2  1  0.14084967333570947\n",
      "1  outperform  2  4  0.5633986933428379\n",
      "1  templat  2  1  0.10034333188799373\n",
      "2  templat  3  2  0.1505149978319906\n",
      "1  call  2  1  0.14084967333570947\n",
      "1  instructgpt  2  1  0.14084967333570947\n",
      "1  sever  2  1  0.14084967333570947\n",
      "1  found  2  1  0.14084967333570947\n",
      "1  feed  2  1  0.14084967333570947\n",
      "1  supervis  2  1  0.14084967333570947\n",
      "1  12-10%  2  1  0.14084967333570947\n",
      "1  new  2  1  0.14084967333570947\n",
      "1  fulli  2  1  0.14084967333570947\n",
      "1  state-of-the-art  2  1  0.10034333188799373\n",
      "2  state-of-the-art  4  1  0.06689555459199582\n",
      "1  best  2  1  0.14084967333570947\n",
      "1  20b  2  1  0.14084967333570947\n",
      "1  candid  2  1  0.14084967333570947\n",
      "1  item  3  1  0.0752574989159953\n",
      "2  item  6  2  0.1505149978319906\n",
      "1  design  3  1  0.1056372550017821\n",
      "1  pod  3  1  0.1056372550017821\n",
      "1  long  3  3  0.3169117650053463\n",
      "1  manifest  3  1  0.1056372550017821\n",
      "1  could  3  2  0.2112745100035642\n",
      "1  enough  3  1  0.1056372550017821\n",
      "1  system  3  1  0.0752574989159953\n",
      "2  system  6  1  0.0752574989159953\n",
      "1  bridg  3  2  0.1505149978319906\n",
      "2  bridg  5  1  0.10034333188799373\n",
      "1  power  3  1  0.059640156839957804\n",
      "2  power  5  1  0.07952020911994373\n",
      "3  power  6  1  0.059640156839957804\n",
      "1  time  3  2  0.1505149978319906\n",
      "2  time  4  1  0.06689555459199582\n",
      "1  may  3  2  0.2112745100035642\n",
      "1  fill  3  1  0.1056372550017821\n",
      "1  limit  3  2  0.1505149978319906\n",
      "2  limit  4  1  0.06689555459199582\n",
      "1  user/item  3  1  0.1056372550017821\n",
      "1  unleash  3  1  0.1056372550017821\n",
      "1  specif  3  1  0.1056372550017821\n",
      "1  allow  3  1  0.0752574989159953\n",
      "2  allow  5  1  0.10034333188799373\n",
      "1  i.e.  3  1  0.1056372550017821\n",
      "1  reason  3  1  0.1056372550017821\n",
      "1  process  3  1  0.0497425010840047\n",
      "2  process  4  1  0.04421555651911529\n",
      "3  process  5  1  0.06632333477867293\n",
      "4  process  6  1  0.0497425010840047\n",
      "1  requir  3  1  0.1056372550017821\n",
      "1  top-n  3  1  0.1056372550017821\n",
      "1  recommend  3  6  0.45154499349597177\n",
      "2  recommend  6  1  0.0752574989159953\n",
      "1  unparallel  3  1  0.1056372550017821\n",
      "1  attempt  3  1  0.1056372550017821\n",
      "1  noisi  3  1  0.1056372550017821\n",
      "1  input  3  1  0.059640156839957804\n",
      "2  input  4  1  0.05301347274662915\n",
      "3  input  5  1  0.07952020911994373\n",
      "1  capabl  3  1  0.1056372550017821\n",
      "1  although  3  1  0.1056372550017821\n",
      "1  mostli  3  1  0.1056372550017821\n",
      "1  variou  3  1  0.0752574989159953\n",
      "2  variou  4  1  0.06689555459199582\n",
      "1  thu  3  1  0.1056372550017821\n",
      "1  e.g.  3  1  0.1056372550017821\n",
      "1  discret  3  2  0.2112745100035642\n",
      "1  distil  3  2  0.2112745100035642\n",
      "1  address  3  1  0.1056372550017821\n",
      "1  sequenti  3  1  0.0752574989159953\n",
      "2  sequenti  5  1  0.10034333188799373\n",
      "1  commun  3  1  0.1056372550017821\n",
      "1  extens  3  1  0.1056372550017821\n",
      "1  immedi  3  1  0.1056372550017821\n",
      "1  usual  3  2  0.2112745100035642\n",
      "1  respons  3  1  0.1056372550017821\n",
      "1  vector  3  1  0.1056372550017821\n",
      "1  experiment  3  1  0.1056372550017821\n",
      "1  word  3  2  0.2112745100035642\n",
      "1  infer  3  3  0.3169117650053463\n",
      "1  real-world  3  1  0.1056372550017821\n",
      "1  contain  3  1  0.1056372550017821\n",
      "1  inform  3  1  0.0497425010840047\n",
      "2  inform  4  2  0.08843111303823058\n",
      "3  inform  5  3  0.1989700043360188\n",
      "4  inform  6  1  0.0497425010840047\n",
      "1  continu  3  1  0.1056372550017821\n",
      "1  also  3  1  0.0752574989159953\n",
      "2  also  5  1  0.10034333188799373\n",
      "1  need  3  1  0.0752574989159953\n",
      "2  need  5  1  0.10034333188799373\n",
      "1  id  3  3  0.3169117650053463\n",
      "1  train  3  3  0.3169117650053463\n",
      "1  three  3  1  0.1056372550017821\n",
      "1  plain  3  1  0.1056372550017821\n",
      "1  given  3  1  0.0752574989159953\n",
      "2  given  5  1  0.10034333188799373\n",
      "1  multi-step  3  1  0.1056372550017821\n",
      "1  effect  3  1  0.059640156839957804\n",
      "2  effect  4  1  0.05301347274662915\n",
      "3  effect  5  1  0.07952020911994373\n",
      "1  demonstr  3  1  0.059640156839957804\n",
      "2  demonstr  4  1  0.05301347274662915\n",
      "3  demonstr  6  1  0.059640156839957804\n",
      "1  complet  4  1  0.09389978222380631\n",
      "1  optim  4  1  0.09389978222380631\n",
      "1  integr  4  1  0.06689555459199582\n",
      "2  integr  5  1  0.10034333188799373\n",
      "1  custom  4  1  0.09389978222380631\n",
      "1  qerm  4  1  0.09389978222380631\n",
      "1  loop  4  1  0.09389978222380631\n",
      "1  crucial  4  1  0.09389978222380631\n",
      "1  redund  4  1  0.09389978222380631\n",
      "1  divers  4  4  0.37559912889522523\n",
      "1  gencrf  4  3  0.28169934667141894\n",
      "1  enhanc  4  1  0.06689555459199582\n",
      "2  enhanc  5  1  0.10034333188799373\n",
      "1  differenti  4  1  0.09389978222380631\n",
      "1  rate  4  1  0.09389978222380631\n",
      "1  well-known  4  1  0.09389978222380631\n",
      "1  explor  4  1  0.06689555459199582\n",
      "2  explor  6  1  0.0752574989159953\n",
      "1  adapt  4  2  0.18779956444761262\n",
      "1  expans  4  1  0.09389978222380631\n",
      "1  group  4  1  0.09389978222380631\n",
      "1  constrain  4  1  0.09389978222380631\n",
      "1  captur  4  2  0.13379110918399165\n",
      "2  captur  5  3  0.3010299956639812\n",
      "1  advanc  4  1  0.09389978222380631\n",
      "1  sota  4  1  0.09389978222380631\n",
      "1  modifi  4  1  0.09389978222380631\n",
      "1  novel  4  1  0.06689555459199582\n",
      "2  novel  5  1  0.10034333188799373\n",
      "1  innov  4  1  0.09389978222380631\n",
      "1  potenti  4  1  0.06689555459199582\n",
      "2  potenti  6  1  0.0752574989159953\n",
      "1  well-gener  4  1  0.09389978222380631\n",
      "1  boost  4  1  0.09389978222380631\n",
      "1  combin  4  1  0.06689555459199582\n",
      "2  combin  6  1  0.0752574989159953\n",
      "1  reward  4  1  0.09389978222380631\n",
      "1  empir  4  1  0.09389978222380631\n",
      "1  field  4  1  0.09389978222380631\n",
      "1  singl  4  1  0.09389978222380631\n",
      "1  surpass  4  1  0.09389978222380631\n",
      "1  variabl  4  1  0.09389978222380631\n",
      "1  repres  4  1  0.09389978222380631\n",
      "1  framework  4  2  0.18779956444761262\n",
      "1  aggreg  4  1  0.09389978222380631\n",
      "1  often  4  1  0.09389978222380631\n",
      "1  distinctli  4  1  0.09389978222380631\n",
      "1  refin  4  1  0.09389978222380631\n",
      "1  automat  4  1  0.09389978222380631\n",
      "1  12%  4  1  0.09389978222380631\n",
      "1  phase  4  1  0.09389978222380631\n",
      "1  aim  4  1  0.06689555459199582\n",
      "2  aim  5  1  0.10034333188799373\n",
      "1  initi  4  1  0.09389978222380631\n",
      "1  cluster  4  2  0.18779956444761262\n",
      "1  weight  4  1  0.09389978222380631\n",
      "1  semant  5  2  0.28169934667141894\n",
      "1  interact  5  3  0.4225490200071284\n",
      "1  methodolog  5  1  0.14084967333570947\n",
      "1  represent  5  1  0.14084967333570947\n",
      "1  advantag  5  1  0.14084967333570947\n",
      "1  modern  5  1  0.14084967333570947\n",
      "1  object  5  1  0.14084967333570947\n",
      "1  analysi  5  1  0.14084967333570947\n",
      "1  superior  5  1  0.14084967333570947\n",
      "1  content  5  1  0.14084967333570947\n",
      "1  fine-grain  5  1  0.14084967333570947\n",
      "1  current  5  1  0.14084967333570947\n",
      "1  concret  5  1  0.14084967333570947\n",
      "1  aol  5  1  0.14084967333570947\n",
      "1  tradit  5  1  0.10034333188799373\n",
      "2  tradit  6  1  0.0752574989159953\n",
      "1  format  5  1  0.14084967333570947\n",
      "1  confirm  5  1  0.14084967333570947\n",
      "1  learn  5  2  0.28169934667141894\n",
      "1  focu  5  1  0.14084967333570947\n",
      "1  corpora  5  1  0.14084967333570947\n",
      "1  offer  5  1  0.14084967333570947\n",
      "1  typic  5  1  0.14084967333570947\n",
      "1  discrep  5  1  0.14084967333570947\n",
      "1  paradigm  5  1  0.14084967333570947\n",
      "1  pre-train  5  1  0.14084967333570947\n",
      "1  produc  5  1  0.14084967333570947\n",
      "1  word-level  5  1  0.14084967333570947\n",
      "1  predict  5  1  0.14084967333570947\n",
      "1  tiangong-st  5  1  0.14084967333570947\n",
      "1  grammar  5  2  0.28169934667141894\n",
      "1  action  5  1  0.14084967333570947\n",
      "1  text-bas  5  1  0.14084967333570947\n",
      "1  self-supervis  5  1  0.14084967333570947\n",
      "1  comprehens  5  1  0.14084967333570947\n",
      "1  deep  5  1  0.14084967333570947\n",
      "1  fulfil  5  1  0.14084967333570947\n",
      "1  topolog  5  1  0.14084967333570947\n",
      "1  graph-to-text  5  1  0.14084967333570947\n",
      "1  overlook  5  1  0.14084967333570947\n",
      "1  enabl  5  1  0.14084967333570947\n",
      "1  priorit  5  1  0.14084967333570947\n",
      "1  rule  5  1  0.14084967333570947\n",
      "1  includ  5  1  0.14084967333570947\n",
      "1  session  5  3  0.4225490200071284\n",
      "1  contrast  5  1  0.14084967333570947\n",
      "1  histori  5  1  0.14084967333570947\n",
      "1  seamlessli  5  1  0.14084967333570947\n",
      "1  two  5  1  0.14084967333570947\n",
      "1  graph  5  4  0.5633986933428379\n",
      "1  sgr  5  1  0.14084967333570947\n",
      "1  graph-bas  5  1  0.14084967333570947\n",
      "1  coarse-grain  5  1  0.14084967333570947\n",
      "1  convert  5  1  0.14084967333570947\n",
      "1  moreov  5  1  0.14084967333570947\n",
      "1  neglect  5  1  0.14084967333570947\n",
      "1  textual  5  2  0.28169934667141894\n",
      "1  link  5  1  0.14084967333570947\n",
      "1  symbol  5  4  0.5633986933428379\n",
      "1  seri  5  1  0.14084967333570947\n",
      "1  structur  5  3  0.4225490200071284\n",
      "1  natur  5  1  0.10034333188799373\n",
      "2  natur  6  1  0.0752574989159953\n",
      "1  within  5  1  0.14084967333570947\n",
      "1  gap  5  1  0.14084967333570947\n",
      "1  node  5  1  0.14084967333570947\n",
      "1  involv  5  1  0.14084967333570947\n",
      "1  data  6  1  0.1056372550017821\n",
      "1  1m  6  1  0.1056372550017821\n",
      "1  gpt-3.5  6  1  0.1056372550017821\n",
      "1  consid  6  1  0.1056372550017821\n",
      "1  few-shot  6  1  0.1056372550017821\n",
      "1  inconsist  6  1  0.1056372550017821\n",
      "1  scrape  6  2  0.2112745100035642\n",
      "1  book  6  1  0.1056372550017821\n",
      "1  titl  6  1  0.1056372550017821\n",
      "1  movi  6  3  0.3169117650053463\n",
      "1  manual  6  1  0.1056372550017821\n",
      "1  ndcg  6  1  0.1056372550017821\n",
      "1  emerg  6  1  0.1056372550017821\n",
      "1  concis  6  1  0.1056372550017821\n",
      "1  alpaca  6  2  0.2112745100035642\n",
      "1  viewer  6  1  0.1056372550017821\n",
      "1  subsequ  6  1  0.1056372550017821\n",
      "1  suscept  6  1  0.1056372550017821\n",
      "1  compris  6  1  0.1056372550017821\n",
      "1  obtain  6  2  0.2112745100035642\n",
      "1  cast  6  1  0.1056372550017821\n",
      "1  role  6  1  0.1056372550017821\n",
      "1  time-consum  6  1  0.1056372550017821\n",
      "1  signific  6  1  0.1056372550017821\n",
      "1  publish  6  1  0.1056372550017821\n",
      "1  captiv  6  1  0.1056372550017821\n",
      "1  essenti  6  1  0.1056372550017821\n",
      "1  director  6  1  0.1056372550017821\n",
      "1  provid  6  1  0.1056372550017821\n",
      "1  featur  6  1  0.1056372550017821\n",
      "1  consist  6  1  0.1056372550017821\n",
      "1  detail  6  2  0.2112745100035642\n",
      "1  author  6  1  0.1056372550017821\n",
      "1  web  6  1  0.1056372550017821\n",
      "1  pivot  6  1  0.1056372550017821\n",
      "1  sourc  6  1  0.1056372550017821\n",
      "1  movielen  6  1  0.1056372550017821\n",
      "1  year  6  1  0.1056372550017821\n",
      "1  exhibit  6  1  0.1056372550017821\n",
      "1  top  6  1  0.1056372550017821\n",
      "1  like  6  2  0.2112745100035642\n",
      "1  conduct  6  1  0.1056372550017821\n",
      "1  goodread  6  2  0.2112745100035642\n",
      "1  tool  6  1  0.1056372550017821\n",
      "1  compar  6  2  0.2112745100035642\n",
      "1  studi  6  1  0.1056372550017821\n",
      "1  name  6  3  0.3169117650053463\n",
      "1  one  6  1  0.1056372550017821\n",
      "1  web-scrap  6  1  0.1056372550017821\n",
      "1  ml  6  1  0.1056372550017821\n",
      "1  descript  6  8  0.8450980400142568\n",
      "1  hit  6  1  0.1056372550017821\n",
      "1  open  6  1  0.1056372550017821\n",
      "1  play  6  1  0.1056372550017821\n",
      "1  summari  6  1  0.1056372550017821\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inverse_reg_porter = {}\n",
    "\n",
    "for i in range(len(termes_reg_porter)):\n",
    "    seen_terms = set()  # Track terms processed in the current document\n",
    "\n",
    "    for j in range(len(termes_reg_porter[i])):\n",
    "        term = termes_reg_porter[i][j]\n",
    "\n",
    "        if (term, i) not in seen_terms:\n",
    "            seen_terms.add((term, i))\n",
    "\n",
    "            if term not in inverse_reg_porter:\n",
    "                inverse_reg_porter[term] = []\n",
    "            \n",
    "            frequency_term = frequency_dict_reg_porter_documents[i][termes_reg_porter[i][j]]\n",
    "            poids_term = poids(frequency_term, max_frequency_dict_reg_porter_documents[i], document_frequency_dict_reg_porter[termes_reg_porter[i][j]], n_reg)\n",
    "            \n",
    "            inverse_reg_porter[term].append((i + 1, frequency_term, poids_term))\n",
    "\n",
    "inverse_reg_porter_output = \"\"\n",
    "for term, docs in inverse_reg_porter.items():\n",
    "    for idx, doc_info in enumerate(docs, 1):\n",
    "        doc_num, frequency_term, poids_term = doc_info\n",
    "        inverse_reg_porter_output += f\"{idx}  {term}  {doc_num}  {frequency_term}  {poids_term}\\n\"\n",
    "\n",
    "print(inverse_reg_porter_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  pass  1  1  0.16901960800285137\n",
      "1  investig  1  1  0.16901960800285137\n",
      "1  feedback  1  3  0.3612359947967774\n",
      "2  feedback  4  1  0.06689555459199582\n",
      "1  find  1  1  0.12041199826559248\n",
      "2  find  3  1  0.0752574989159953\n",
      "1  docu  1  1  0.09542425094393249\n",
      "2  docu  2  2  0.13632035849133212\n",
      "3  docu  5  1  0.09542425094393249\n",
      "1  techn  1  2  0.15917600346881505\n",
      "2  techn  2  1  0.05684857266743394\n",
      "3  techn  4  1  0.04421555651911529\n",
      "4  techn  6  1  0.0497425010840047\n",
      "1  upto  1  1  0.16901960800285137\n",
      "1  ultim  1  1  0.16901960800285137\n",
      "1  success  1  1  0.12041199826559248\n",
      "2  success  4  1  0.06689555459199582\n",
      "1  text  1  1  0.09542425094393249\n",
      "2  text  3  2  0.11928031367991561\n",
      "3  text  5  3  0.28627275283179743\n",
      "1  instruct  1  1  0.12041199826559248\n",
      "2  instruct  5  1  0.12041199826559248\n",
      "1  9%  1  1  0.16901960800285137\n",
      "1  msmarco  1  1  0.16901960800285137\n",
      "1  zero-shot  1  3  0.5070588240085541\n",
      "1  multipl  1  1  0.09542425094393249\n",
      "2  multipl  4  1  0.05301347274662915\n",
      "3  multipl  6  1  0.059640156839957804\n",
      "1  ensembl  1  2  0.33803921600570275\n",
      "1  rank  1  1  0.09542425094393249\n",
      "2  rank  2  7  0.47712125471966244\n",
      "3  rank  5  1  0.09542425094393249\n",
      "1  prom  1  1  0.12041199826559248\n",
      "2  prom  6  1  0.0752574989159953\n",
      "1  transform  1  1  0.16901960800285137\n",
      "1  set  1  2  0.19084850188786498\n",
      "2  set  3  1  0.059640156839957804\n",
      "3  set  5  2  0.19084850188786498\n",
      "1  model  1  1  0.06020599913279624\n",
      "2  model  2  3  0.12901285528456335\n",
      "3  model  3  8  0.3010299956639812\n",
      "4  model  4  2  0.06689555459199582\n",
      "5  model  5  3  0.1806179973983887\n",
      "6  model  6  1  0.03762874945799765\n",
      "1  shown  1  1  0.16901960800285137\n",
      "1  inh  1  1  0.16901960800285137\n",
      "1  us  1  5  0.3010299956639812\n",
      "2  us  2  5  0.21502142547427228\n",
      "3  us  3  3  0.11288624837399294\n",
      "4  us  4  2  0.06689555459199582\n",
      "5  us  5  3  0.1806179973983887\n",
      "6  us  6  3  0.11288624837399294\n",
      "1  state-of-art  1  1  0.16901960800285137\n",
      "1  search  1  2  0.19084850188786498\n",
      "2  search  4  1  0.05301347274662915\n",
      "3  search  5  2  0.19084850188786498\n",
      "1  5%  1  1  0.16901960800285137\n",
      "1  map  1  1  0.16901960800285137\n",
      "1  improv  1  5  0.3979400086720376\n",
      "2  improv  2  1  0.05684857266743394\n",
      "3  improv  3  4  0.1989700043360188\n",
      "4  improv  4  1  0.04421555651911529\n",
      "1  rec  1  1  0.07958800173440753\n",
      "2  rec  4  1  0.04421555651911529\n",
      "3  rec  5  1  0.07958800173440753\n",
      "4  rec  6  1  0.0497425010840047\n",
      "1  pseudo  1  1  0.16901960800285137\n",
      "1  many  1  1  0.16901960800285137\n",
      "1  expery  1  1  0.07958800173440753\n",
      "2  expery  3  1  0.0497425010840047\n",
      "3  expery  4  1  0.04421555651911529\n",
      "4  expery  5  1  0.07958800173440753\n",
      "1  bas  1  1  0.09542425094393249\n",
      "2  bas  2  2  0.13632035849133212\n",
      "3  bas  4  1  0.05301347274662915\n",
      "1  tak  1  1  0.09542425094393249\n",
      "2  tak  3  1  0.059640156839957804\n",
      "3  tak  5  1  0.09542425094393249\n",
      "1  perform  1  1  0.09542425094393249\n",
      "2  perform  2  2  0.13632035849133212\n",
      "3  perform  4  3  0.15904041823988746\n",
      "1  relev  1  2  0.33803921600570275\n",
      "1  qr  1  2  0.33803921600570275\n",
      "1  langu  1  1  0.06020599913279624\n",
      "2  langu  2  1  0.043004285094854454\n",
      "3  langu  3  1  0.03762874945799765\n",
      "4  langu  4  1  0.03344777729599791\n",
      "5  langu  5  2  0.12041199826559248\n",
      "6  langu  6  2  0.0752574989159953\n",
      "1  context  1  1  0.16901960800285137\n",
      "1  lev  1  1  0.09542425094393249\n",
      "2  lev  4  2  0.1060269454932583\n",
      "3  lev  5  1  0.09542425094393249\n",
      "1  evalu  1  1  0.09542425094393249\n",
      "2  evalu  4  1  0.05301347274662915\n",
      "3  evalu  6  1  0.059640156839957804\n",
      "1  post-retrieval  1  1  0.16901960800285137\n",
      "1  18%  1  1  0.16901960800285137\n",
      "1  gain  1  1  0.16901960800285137\n",
      "1  help  1  1  0.16901960800285137\n",
      "1  strategies  1  1  0.09542425094393249\n",
      "2  strategies  4  1  0.05301347274662915\n",
      "3  strategies  5  2  0.19084850188786498\n",
      "1  approach  1  1  0.07958800173440753\n",
      "2  approach  2  1  0.05684857266743394\n",
      "3  approach  3  1  0.0497425010840047\n",
      "4  approach  5  3  0.23876400520322255\n",
      "1  genqrensemblerf  1  2  0.33803921600570275\n",
      "1  benefit  1  1  0.16901960800285137\n",
      "1  rel  1  2  0.33803921600570275\n",
      "1  abl  1  1  0.12041199826559248\n",
      "2  abl  5  1  0.12041199826559248\n",
      "1  genqrensembl  1  2  0.33803921600570275\n",
      "1  vary  1  1  0.07958800173440753\n",
      "2  vary  2  1  0.05684857266743394\n",
      "3  vary  3  1  0.0497425010840047\n",
      "4  vary  4  2  0.08843111303823058\n",
      "1  prevy  1  1  0.09542425094393249\n",
      "2  prevy  2  1  0.06816017924566606\n",
      "3  prevy  4  1  0.05301347274662915\n",
      "1  inspir  1  1  0.12041199826559248\n",
      "2  inspir  3  1  0.0752574989159953\n",
      "1  retriev  1  1  0.12041199826559248\n",
      "2  retriev  4  5  0.3344777729599791\n",
      "1  int  1  1  0.12041199826559248\n",
      "2  int  4  4  0.2675822183679833\n",
      "1  task  1  2  0.13696907232888253\n",
      "2  task  2  1  0.048917525831743754\n",
      "3  task  3  4  0.17121134041110314\n",
      "4  task  5  2  0.13696907232888253\n",
      "5  task  6  1  0.042802835102775785\n",
      "1  knowledg  1  1  0.16901960800285137\n",
      "1  due  1  1  0.16901960800285137\n",
      "1  show  1  1  0.12041199826559248\n",
      "2  show  2  1  0.08600857018970891\n",
      "1  ndcg@10  1  2  0.19084850188786498\n",
      "2  ndcg@10  2  1  0.06816017924566606\n",
      "3  ndcg@10  4  1  0.05301347274662915\n",
      "1  mrr  1  1  0.12041199826559248\n",
      "2  mrr  6  1  0.0752574989159953\n",
      "1  keyword  1  1  0.16901960800285137\n",
      "1  origin  1  1  0.16901960800285137\n",
      "1  exploit  1  1  0.16901960800285137\n",
      "1  24%  1  1  0.16901960800285137\n",
      "1  query  1  3  0.23876400520322255\n",
      "2  query  2  1  0.05684857266743394\n",
      "3  query  4  9  0.3979400086720376\n",
      "4  query  5  1  0.07958800173440753\n",
      "1  larg  1  1  0.06020599913279624\n",
      "2  larg  2  1  0.043004285094854454\n",
      "3  larg  3  1  0.03762874945799765\n",
      "4  larg  4  1  0.03344777729599791\n",
      "5  larg  5  1  0.06020599913279624\n",
      "6  larg  6  1  0.03762874945799765\n",
      "1  benchmark  1  1  0.07958800173440753\n",
      "2  benchmark  2  2  0.11369714533486788\n",
      "3  benchmark  4  1  0.04421555651911529\n",
      "4  benchmark  5  1  0.07958800173440753\n",
      "1  reform  1  3  0.3612359947967774\n",
      "2  reform  4  4  0.2675822183679833\n",
      "1  bet  1  2  0.33803921600570275\n",
      "1  paraphras  1  1  0.16901960800285137\n",
      "1  ir  1  1  0.12041199826559248\n",
      "2  ir  4  1  0.06689555459199582\n",
      "1  align  1  1  0.16901960800285137\n",
      "1  introduc  1  1  0.12041199826559248\n",
      "2  introduc  5  2  0.24082399653118497\n",
      "1  prompt  1  2  0.13696907232888253\n",
      "2  prompt  2  4  0.19567010332697501\n",
      "3  prompt  3  4  0.17121134041110314\n",
      "4  prompt  4  1  0.0380469645358007\n",
      "5  prompt  6  2  0.08560567020555157\n",
      "1  incorp  1  1  0.16901960800285137\n",
      "1  propos  1  1  0.06848453616444126\n",
      "2  propos  2  2  0.09783505166348751\n",
      "3  propos  3  1  0.042802835102775785\n",
      "4  propos  4  1  0.0380469645358007\n",
      "5  propos  5  1  0.06848453616444126\n",
      "1  gen  1  2  0.15917600346881505\n",
      "2  gen  4  3  0.13264666955734586\n",
      "3  gen  5  3  0.23876400520322255\n",
      "4  gen  6  4  0.1989700043360188\n",
      "1  pseudo-relevance  1  1  0.16901960800285137\n",
      "1  four  1  1  0.16901960800285137\n",
      "1  pairw  2  1  0.1207282914306081\n",
      "1  efficy  2  1  0.08600857018970891\n",
      "2  efficy  3  5  0.3762874945799765\n",
      "1  baselin  2  2  0.2414565828612162\n",
      "1  flan-ul2  2  1  0.1207282914306081\n",
      "1  beir  2  1  0.08600857018970891\n",
      "2  beir  4  1  0.06689555459199582\n",
      "1  dataset  2  1  0.05684857266743394\n",
      "2  dataset  3  1  0.0497425010840047\n",
      "3  dataset  5  1  0.07958800173440753\n",
      "4  dataset  6  5  0.2487125054200235\n",
      "1  linear  2  1  0.1207282914306081\n",
      "1  moderate-sized  2  1  0.1207282914306081\n",
      "1  direct  2  1  0.08600857018970891\n",
      "2  direct  6  1  0.0752574989159953\n",
      "1  solv  2  3  0.36218487429182433\n",
      "1  listw  2  1  0.1207282914306081\n",
      "1  challeng  2  1  0.1207282914306081\n",
      "1  fine-tuned  2  1  0.1207282914306081\n",
      "1  first  2  1  0.06816017924566606\n",
      "2  first  4  1  0.05301347274662915\n",
      "3  first  5  1  0.09542425094393249\n",
      "1  cal  2  1  0.1207282914306081\n",
      "1  achiev  2  2  0.13632035849133212\n",
      "2  achiev  4  1  0.05301347274662915\n",
      "3  achiev  5  1  0.09542425094393249\n",
      "1  llm-based  2  2  0.13632035849133212\n",
      "2  llm-based  3  2  0.11928031367991561\n",
      "3  llm-based  6  1  0.059640156839957804\n",
      "1  open-sourced  2  1  0.08600857018970891\n",
      "2  open-sourced  6  1  0.0752574989159953\n",
      "1  result  2  2  0.11369714533486788\n",
      "2  result  3  1  0.0497425010840047\n",
      "3  result  5  1  0.07958800173440753\n",
      "4  result  6  2  0.0994850021680094\n",
      "1  ev  2  1  0.1207282914306081\n",
      "1  research  2  1  0.08600857018970891\n",
      "2  research  3  1  0.0752574989159953\n",
      "1  standard  2  1  0.1207282914306081\n",
      "1  chatgpt  2  1  0.1207282914306081\n",
      "1  estim  2  1  0.1207282914306081\n",
      "1  2019  2  1  0.1207282914306081\n",
      "1  10%  2  1  0.1207282914306081\n",
      "1  problem  2  1  0.06816017924566606\n",
      "2  problem  3  1  0.059640156839957804\n",
      "3  problem  4  1  0.05301347274662915\n",
      "1  paramet  2  2  0.2414565828612162\n",
      "1  pointw  2  2  0.2414565828612162\n",
      "1  interest  2  1  0.1207282914306081\n",
      "1  2020  2  1  0.1207282914306081\n",
      "1  175b  2  1  0.1207282914306081\n",
      "1  complex  2  1  0.08600857018970891\n",
      "2  complex  5  1  0.12041199826559248\n",
      "1  fee  2  1  0.1207282914306081\n",
      "1  lit  2  2  0.2414565828612162\n",
      "1  howev  2  1  0.1207282914306081\n",
      "1  prp  2  4  0.4829131657224324\n",
      "1  analys  2  1  0.08600857018970891\n",
      "2  analys  5  1  0.12041199826559248\n",
      "1  reduc  2  1  0.08600857018970891\n",
      "2  reduc  3  1  0.0752574989159953\n",
      "1  understand  2  1  0.06816017924566606\n",
      "2  understand  3  1  0.059640156839957804\n",
      "3  understand  5  1  0.09542425094393249\n",
      "1  superv  2  1  0.1207282914306081\n",
      "1  commerc  2  2  0.2414565828612162\n",
      "1  furtherm  2  1  0.08600857018970891\n",
      "2  furtherm  4  1  0.06689555459199582\n",
      "1  templ  2  1  0.08600857018970891\n",
      "2  templ  3  2  0.1505149978319906\n",
      "1  off-the-shelf  2  1  0.1207282914306081\n",
      "1  50x  2  1  0.1207282914306081\n",
      "1  gpt-4  2  1  0.1207282914306081\n",
      "1  argu  2  1  0.1207282914306081\n",
      "1  met  2  1  0.08600857018970891\n",
      "2  met  6  1  0.0752574989159953\n",
      "1  trec-dl  2  1  0.1207282914306081\n",
      "1  pap  2  1  0.05684857266743394\n",
      "2  pap  4  1  0.04421555651911529\n",
      "3  pap  5  1  0.07958800173440753\n",
      "4  pap  6  1  0.0497425010840047\n",
      "1  pract  2  1  0.1207282914306081\n",
      "1  competit  2  1  0.1207282914306081\n",
      "1  sev  2  2  0.2414565828612162\n",
      "1  4.2%  2  1  0.1207282914306081\n",
      "1  blackbox  2  2  0.2414565828612162\n",
      "1  llms  2  4  0.22739429066973577\n",
      "2  llms  4  3  0.13264666955734586\n",
      "3  llms  5  5  0.3979400086720376\n",
      "4  llms  6  3  0.14922750325201412\n",
      "1  difficult  2  1  0.1207282914306081\n",
      "1  method  2  1  0.08600857018970891\n",
      "2  method  4  1  0.06689555459199582\n",
      "1  outperform  2  4  0.4829131657224324\n",
      "1  instructgpt  2  1  0.1207282914306081\n",
      "1  av  2  1  0.1207282914306081\n",
      "1  ful  2  1  0.1207282914306081\n",
      "1  found  2  1  0.1207282914306081\n",
      "1  burd  2  1  0.1207282914306081\n",
      "1  siz  2  1  0.1207282914306081\n",
      "1  form  2  1  0.08600857018970891\n",
      "2  form  5  1  0.12041199826559248\n",
      "1  fav  2  1  0.1207282914306081\n",
      "1  poss  2  1  0.1207282914306081\n",
      "1  12-10%  2  1  0.1207282914306081\n",
      "1  new  2  1  0.1207282914306081\n",
      "1  state-of-the-art  2  1  0.08600857018970891\n",
      "2  state-of-the-art  4  1  0.06689555459199582\n",
      "1  best  2  1  0.1207282914306081\n",
      "1  20b  2  1  0.1207282914306081\n",
      "1  sign  2  1  0.05684857266743394\n",
      "2  sign  3  1  0.0497425010840047\n",
      "3  sign  4  1  0.04421555651911529\n",
      "4  sign  6  1  0.0497425010840047\n",
      "1  candid  2  1  0.1207282914306081\n",
      "1  ex  2  1  0.1207282914306081\n",
      "1  item  3  1  0.0752574989159953\n",
      "2  item  6  2  0.1505149978319906\n",
      "1  design  3  1  0.1056372550017821\n",
      "1  pod  3  1  0.1056372550017821\n",
      "1  long  3  3  0.3169117650053463\n",
      "1  manifest  3  1  0.1056372550017821\n",
      "1  could  3  2  0.2112745100035642\n",
      "1  strategy  3  1  0.1056372550017821\n",
      "1  enough  3  1  0.1056372550017821\n",
      "1  extend  3  1  0.1056372550017821\n",
      "1  system  3  1  0.0752574989159953\n",
      "2  system  6  1  0.0752574989159953\n",
      "1  bridg  3  2  0.1505149978319906\n",
      "2  bridg  5  1  0.12041199826559248\n",
      "1  may  3  2  0.2112745100035642\n",
      "1  limit  3  2  0.1505149978319906\n",
      "2  limit  4  1  0.06689555459199582\n",
      "1  user/item  3  1  0.1056372550017821\n",
      "1  unleash  3  1  0.1056372550017821\n",
      "1  fil  3  1  0.1056372550017821\n",
      "1  allow  3  1  0.0752574989159953\n",
      "2  allow  5  1  0.12041199826559248\n",
      "1  i.e.  3  1  0.1056372550017821\n",
      "1  reason  3  1  0.1056372550017821\n",
      "1  process  3  1  0.0497425010840047\n",
      "2  process  4  1  0.04421555651911529\n",
      "3  process  5  1  0.07958800173440753\n",
      "4  process  6  1  0.0497425010840047\n",
      "1  requir  3  1  0.1056372550017821\n",
      "1  top-n  3  1  0.1056372550017821\n",
      "1  recommend  3  6  0.45154499349597177\n",
      "2  recommend  6  1  0.0752574989159953\n",
      "1  unparallel  3  1  0.1056372550017821\n",
      "1  attempt  3  1  0.1056372550017821\n",
      "1  input  3  1  0.059640156839957804\n",
      "2  input  4  1  0.05301347274662915\n",
      "3  input  5  1  0.09542425094393249\n",
      "1  although  3  1  0.1056372550017821\n",
      "1  thu  3  1  0.1056372550017821\n",
      "1  e.g.  3  1  0.1056372550017821\n",
      "1  discret  3  2  0.2112745100035642\n",
      "1  distil  3  2  0.2112745100035642\n",
      "1  llm  3  2  0.11928031367991561\n",
      "2  llm  5  1  0.09542425094393249\n",
      "3  llm  6  1  0.059640156839957804\n",
      "1  address  3  1  0.1056372550017821\n",
      "1  commun  3  1  0.1056372550017821\n",
      "1  inf  3  3  0.3169117650053463\n",
      "1  fine-tuning  3  1  0.1056372550017821\n",
      "1  nee  3  1  0.0752574989159953\n",
      "2  nee  5  1  0.12041199826559248\n",
      "1  respons  3  1  0.1056372550017821\n",
      "1  word  3  2  0.2112745100035642\n",
      "1  real-world  3  1  0.1056372550017821\n",
      "1  sequ  3  1  0.0752574989159953\n",
      "2  sequ  5  1  0.12041199826559248\n",
      "1  contain  3  1  0.1056372550017821\n",
      "1  inform  3  1  0.0497425010840047\n",
      "2  inform  4  2  0.08843111303823058\n",
      "3  inform  5  3  0.23876400520322255\n",
      "4  inform  6  1  0.0497425010840047\n",
      "1  pow  3  1  0.059640156839957804\n",
      "2  pow  5  1  0.09542425094393249\n",
      "3  pow  6  1  0.059640156839957804\n",
      "1  continu  3  1  0.1056372550017821\n",
      "1  also  3  1  0.0752574989159953\n",
      "2  also  5  1  0.12041199826559248\n",
      "1  vect  3  1  0.1056372550017821\n",
      "1  cap  3  1  0.1056372550017821\n",
      "1  most  3  1  0.1056372550017821\n",
      "1  immedy  3  1  0.1056372550017821\n",
      "1  id  3  3  0.3169117650053463\n",
      "1  train  3  3  0.3169117650053463\n",
      "1  three  3  1  0.1056372550017821\n",
      "1  plain  3  1  0.1056372550017821\n",
      "1  tim  3  2  0.1505149978319906\n",
      "2  tim  4  1  0.06689555459199582\n",
      "1  noisy  3  1  0.1056372550017821\n",
      "1  giv  3  1  0.0752574989159953\n",
      "2  giv  5  1  0.12041199826559248\n",
      "1  multi-step  3  1  0.1056372550017821\n",
      "1  spec  3  1  0.1056372550017821\n",
      "1  effect  3  1  0.059640156839957804\n",
      "2  effect  4  1  0.05301347274662915\n",
      "3  effect  5  1  0.09542425094393249\n",
      "1  demonst  3  1  0.059640156839957804\n",
      "2  demonst  4  1  0.05301347274662915\n",
      "3  demonst  6  1  0.059640156839957804\n",
      "1  complet  4  1  0.09389978222380631\n",
      "1  optim  4  1  0.09389978222380631\n",
      "1  integr  4  1  0.06689555459199582\n",
      "2  integr  5  1  0.12041199826559248\n",
      "1  phas  4  1  0.09389978222380631\n",
      "1  custom  4  1  0.09389978222380631\n",
      "1  qerm  4  1  0.09389978222380631\n",
      "1  loop  4  1  0.09389978222380631\n",
      "1  rat  4  1  0.09389978222380631\n",
      "1  redund  4  1  0.09389978222380631\n",
      "1  oft  4  1  0.09389978222380631\n",
      "1  differenty  4  1  0.09389978222380631\n",
      "1  divers  4  4  0.37559912889522523\n",
      "1  well-generated  4  1  0.09389978222380631\n",
      "1  gencrf  4  3  0.28169934667141894\n",
      "1  mod  4  1  0.09389978222380631\n",
      "1  well-known  4  1  0.09389978222380631\n",
      "1  adapt  4  2  0.18779956444761262\n",
      "1  group  4  1  0.09389978222380631\n",
      "1  adv  4  1  0.06689555459199582\n",
      "2  adv  5  1  0.12041199826559248\n",
      "1  constrain  4  1  0.09389978222380631\n",
      "1  cruc  4  1  0.09389978222380631\n",
      "1  sota  4  1  0.09389978222380631\n",
      "1  expand  4  1  0.09389978222380631\n",
      "1  novel  4  1  0.06689555459199582\n",
      "2  novel  5  1  0.12041199826559248\n",
      "1  innov  4  1  0.09389978222380631\n",
      "1  pot  4  1  0.06689555459199582\n",
      "2  pot  6  1  0.0752574989159953\n",
      "1  boost  4  1  0.09389978222380631\n",
      "1  combin  4  1  0.06689555459199582\n",
      "2  combin  6  1  0.0752574989159953\n",
      "1  capt  4  2  0.1060269454932583\n",
      "2  capt  5  3  0.28627275283179743\n",
      "3  capt  6  1  0.059640156839957804\n",
      "1  autom  4  1  0.09389978222380631\n",
      "1  clust  4  2  0.18779956444761262\n",
      "1  reward  4  1  0.09389978222380631\n",
      "1  empir  4  1  0.09389978222380631\n",
      "1  field  4  1  0.09389978222380631\n",
      "1  singl  4  1  0.09389978222380631\n",
      "1  surpass  4  1  0.09389978222380631\n",
      "1  repres  4  1  0.06689555459199582\n",
      "2  repres  5  1  0.12041199826559248\n",
      "1  enh  4  1  0.06689555459199582\n",
      "2  enh  5  1  0.12041199826559248\n",
      "1  framework  4  2  0.18779956444761262\n",
      "1  init  4  1  0.09389978222380631\n",
      "1  aggreg  4  1  0.09389978222380631\n",
      "1  distinct  4  1  0.09389978222380631\n",
      "1  expl  4  1  0.06689555459199582\n",
      "2  expl  6  1  0.0752574989159953\n",
      "1  refin  4  1  0.09389978222380631\n",
      "1  12%  4  1  0.09389978222380631\n",
      "1  aim  4  1  0.06689555459199582\n",
      "2  aim  5  1  0.12041199826559248\n",
      "1  weight  4  1  0.09389978222380631\n",
      "1  seamless  5  1  0.16901960800285137\n",
      "1  interact  5  3  0.5070588240085541\n",
      "1  graph-based  5  1  0.16901960800285137\n",
      "1  methodolog  5  1  0.16901960800285137\n",
      "1  foc  5  1  0.16901960800285137\n",
      "1  fine-grained  5  1  0.16901960800285137\n",
      "1  gramm  5  2  0.33803921600570275\n",
      "1  structures  5  1  0.16901960800285137\n",
      "1  modern  5  1  0.16901960800285137\n",
      "1  object  5  1  0.16901960800285137\n",
      "1  nod  5  1  0.16901960800285137\n",
      "1  act  5  1  0.16901960800285137\n",
      "1  pre-trained  5  1  0.16901960800285137\n",
      "1  text-based  5  1  0.16901960800285137\n",
      "1  rul  5  1  0.16901960800285137\n",
      "1  concret  5  1  0.16901960800285137\n",
      "1  aol  5  1  0.16901960800285137\n",
      "1  tradit  5  1  0.12041199826559248\n",
      "2  tradit  6  1  0.0752574989159953\n",
      "1  hist  5  1  0.16901960800285137\n",
      "1  confirm  5  1  0.16901960800285137\n",
      "1  en  5  1  0.16901960800285137\n",
      "1  learn  5  2  0.33803921600570275\n",
      "1  corpor  5  1  0.16901960800285137\n",
      "1  discrep  5  1  0.16901960800285137\n",
      "1  paradigm  5  1  0.16901960800285137\n",
      "1  produc  5  1  0.16901960800285137\n",
      "1  structure  5  1  0.16901960800285137\n",
      "1  word-level  5  1  0.16901960800285137\n",
      "1  predict  5  1  0.16901960800285137\n",
      "1  tiangong-st  5  1  0.16901960800285137\n",
      "1  sess  5  3  0.5070588240085541\n",
      "1  sem  5  2  0.33803921600570275\n",
      "1  comprehend  5  1  0.16901960800285137\n",
      "1  structural  5  1  0.16901960800285137\n",
      "1  deep  5  1  0.16901960800285137\n",
      "1  fulfil  5  1  0.16901960800285137\n",
      "1  graph-to-text  5  1  0.16901960800285137\n",
      "1  topolog  5  1  0.16901960800285137\n",
      "1  cont  5  1  0.12041199826559248\n",
      "2  cont  6  1  0.0752574989159953\n",
      "1  off  5  1  0.16901960800285137\n",
      "1  overlook  5  1  0.16901960800285137\n",
      "1  coarse-grained  5  1  0.16901960800285137\n",
      "1  priorit  5  1  0.16901960800285137\n",
      "1  includ  5  1  0.16901960800285137\n",
      "1  contrast  5  1  0.16901960800285137\n",
      "1  two  5  1  0.16901960800285137\n",
      "1  sery  5  1  0.16901960800285137\n",
      "1  graph  5  4  0.6760784320114055\n",
      "1  sgr  5  1  0.16901960800285137\n",
      "1  nat  5  1  0.12041199826559248\n",
      "2  nat  6  1  0.0752574989159953\n",
      "1  self-supervised  5  1  0.16901960800285137\n",
      "1  convert  5  1  0.16901960800285137\n",
      "1  moreov  5  1  0.16901960800285137\n",
      "1  neglect  5  1  0.16901960800285137\n",
      "1  typ  5  1  0.16901960800285137\n",
      "1  link  5  1  0.16901960800285137\n",
      "1  symbol  5  4  0.6760784320114055\n",
      "1  cur  5  1  0.16901960800285137\n",
      "1  within  5  1  0.16901960800285137\n",
      "1  gap  5  1  0.16901960800285137\n",
      "1  involv  5  1  0.16901960800285137\n",
      "1  supery  5  1  0.16901960800285137\n",
      "1  1m  6  1  0.1056372550017821\n",
      "1  gpt-3.5  6  1  0.1056372550017821\n",
      "1  consid  6  1  0.1056372550017821\n",
      "1  few-shot  6  1  0.1056372550017821\n",
      "1  inconsist  6  1  0.1056372550017821\n",
      "1  book  6  1  0.1056372550017821\n",
      "1  titl  6  1  0.1056372550017821\n",
      "1  ndcg  6  1  0.1056372550017821\n",
      "1  emerg  6  1  0.1056372550017821\n",
      "1  alpac  6  2  0.2112745100035642\n",
      "1  lik  6  2  0.2112745100035642\n",
      "1  movy  6  3  0.3169117650053463\n",
      "1  subsequ  6  1  0.1056372550017821\n",
      "1  suscept  6  1  0.1056372550017821\n",
      "1  conduc  6  1  0.1056372550017821\n",
      "1  scraping  6  1  0.1056372550017821\n",
      "1  obtain  6  2  0.2112745100035642\n",
      "1  cast  6  1  0.1056372550017821\n",
      "1  publ  6  1  0.1056372550017821\n",
      "1  ess  6  1  0.1056372550017821\n",
      "1  man  6  1  0.1056372550017821\n",
      "1  provid  6  1  0.1056372550017821\n",
      "1  web-scraped  6  1  0.1056372550017821\n",
      "1  scraped  6  1  0.1056372550017821\n",
      "1  consist  6  1  0.1056372550017821\n",
      "1  describ  6  8  0.8450980400142568\n",
      "1  detail  6  2  0.2112745100035642\n",
      "1  feat  6  1  0.1056372550017821\n",
      "1  web  6  1  0.1056372550017821\n",
      "1  pivot  6  1  0.1056372550017821\n",
      "1  sourc  6  1  0.1056372550017821\n",
      "1  year  6  1  0.1056372550017821\n",
      "1  rol  6  1  0.1056372550017821\n",
      "1  time-consuming  6  1  0.1056372550017821\n",
      "1  exhibit  6  1  0.1056372550017821\n",
      "1  op  6  1  0.1056372550017821\n",
      "1  top  6  1  0.1056372550017821\n",
      "1  on  6  1  0.1056372550017821\n",
      "1  nam  6  3  0.3169117650053463\n",
      "1  dat  6  1  0.1056372550017821\n",
      "1  sum  6  1  0.1056372550017821\n",
      "1  goodread  6  2  0.2112745100035642\n",
      "1  compr  6  1  0.1056372550017821\n",
      "1  moviel  6  1  0.1056372550017821\n",
      "1  tool  6  1  0.1056372550017821\n",
      "1  auth  6  1  0.1056372550017821\n",
      "1  comp  6  2  0.2112745100035642\n",
      "1  view  6  1  0.1056372550017821\n",
      "1  ml  6  1  0.1056372550017821\n",
      "1  study  6  1  0.1056372550017821\n",
      "1  hit  6  1  0.1056372550017821\n",
      "1  play  6  1  0.1056372550017821\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inverse_reg_lancaster = {}\n",
    "\n",
    "for i in range(len(termes_reg_lancaster)):\n",
    "    seen_terms = set()  # Track terms processed in the current document\n",
    "\n",
    "    for j in range(len(termes_reg_lancaster[i])):\n",
    "        term = termes_reg_lancaster[i][j]\n",
    "\n",
    "        if (term, i) not in seen_terms:\n",
    "            seen_terms.add((term, i))\n",
    "\n",
    "            if term not in inverse_reg_lancaster:\n",
    "                inverse_reg_lancaster[term] = []\n",
    "            \n",
    "            frequency_term = frequency_dict_reg_lancaster_documents[i][termes_reg_lancaster[i][j]]\n",
    "            poids_term = poids(frequency_term, max_frequency_dict_reg_lancaster_documents[i], document_frequency_dict_reg_lancaster[termes_reg_lancaster[i][j]], n_reg)\n",
    "            \n",
    "            inverse_reg_lancaster[term].append((i + 1, frequency_term, poids_term))\n",
    "\n",
    "inverse_reg_lancaster_output = \"\"\n",
    "for term, docs in inverse_reg_lancaster.items():\n",
    "    for idx, doc_info in enumerate(docs, 1):\n",
    "        doc_num, frequency_term, poids_term = doc_info\n",
    "        inverse_reg_lancaster_output += f\"{idx}  {term}  {doc_num}  {frequency_term}  {poids_term}\\n\"\n",
    "\n",
    "print(inverse_reg_lancaster_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  task,  1  1  0.12041199826559248\n",
      "2  task,  3  1  0.12041199826559248\n",
      "1  pass  1  1  0.16901960800285137\n",
      "1  investig  1  1  0.16901960800285137\n",
      "1  feedback  1  1  0.12041199826559248\n",
      "2  feedback  4  1  0.0752574989159953\n",
      "1  find  1  1  0.12041199826559248\n",
      "2  find  3  1  0.12041199826559248\n",
      "1  techn  1  1  0.09542425094393249\n",
      "2  techn  2  1  0.06816017924566606\n",
      "3  techn  4  1  0.059640156839957804\n",
      "1  upto  1  1  0.16901960800285137\n",
      "1  documents.  1  1  0.16901960800285137\n",
      "1  ultim  1  1  0.16901960800285137\n",
      "1  success  1  1  0.12041199826559248\n",
      "2  success  4  1  0.0752574989159953\n",
      "1  text  1  1  0.09542425094393249\n",
      "2  text  3  1  0.09542425094393249\n",
      "3  text  5  2  0.23856062735983122\n",
      "1  instruct  1  1  0.12041199826559248\n",
      "2  instruct  5  1  0.1505149978319906\n",
      "1  state-of-art.  1  1  0.16901960800285137\n",
      "1  9%  1  1  0.16901960800285137\n",
      "1  msmarco  1  1  0.16901960800285137\n",
      "1  zero-shot  1  3  0.5070588240085541\n",
      "1  multipl  1  1  0.09542425094393249\n",
      "2  multipl  4  1  0.059640156839957804\n",
      "3  multipl  6  1  0.06816017924566606\n",
      "1  technique,  1  1  0.16901960800285137\n",
      "1  ensembl  1  2  0.33803921600570275\n",
      "1  rank  1  1  0.09542425094393249\n",
      "2  rank  2  7  0.47712125471966244\n",
      "3  rank  5  1  0.11928031367991561\n",
      "1  transform  1  1  0.16901960800285137\n",
      "1  prom  1  1  0.16901960800285137\n",
      "1  set  1  2  0.19084850188786498\n",
      "2  set  3  1  0.09542425094393249\n",
      "3  set  5  2  0.23856062735983122\n",
      "1  shown  1  1  0.16901960800285137\n",
      "1  inh  1  1  0.16901960800285137\n",
      "1  us  1  3  0.1806179973983887\n",
      "2  us  2  5  0.21502142547427228\n",
      "3  us  3  3  0.1806179973983887\n",
      "4  us  4  1  0.03762874945799765\n",
      "5  us  5  2  0.1505149978319906\n",
      "6  us  6  3  0.12901285528456335\n",
      "1  search  1  2  0.19084850188786498\n",
      "2  search  4  1  0.059640156839957804\n",
      "3  search  5  2  0.23856062735983122\n",
      "1  5%  1  1  0.16901960800285137\n",
      "1  map  1  1  0.16901960800285137\n",
      "1  improv  1  5  0.3979400086720376\n",
      "2  improv  2  1  0.05684857266743394\n",
      "3  improv  3  3  0.23876400520322255\n",
      "4  improv  4  1  0.0497425010840047\n",
      "1  feedback,  1  1  0.16901960800285137\n",
      "1  pseudo  1  1  0.16901960800285137\n",
      "1  recently,  1  1  0.16901960800285137\n",
      "1  many  1  1  0.16901960800285137\n",
      "1  bas  1  1  0.09542425094393249\n",
      "2  bas  2  2  0.13632035849133212\n",
      "3  bas  4  1  0.059640156839957804\n",
      "1  performance.  1  1  0.16901960800285137\n",
      "1  tak  1  1  0.09542425094393249\n",
      "2  tak  3  1  0.09542425094393249\n",
      "3  tak  5  1  0.11928031367991561\n",
      "1  relev  1  2  0.33803921600570275\n",
      "1  experience.  1  1  0.16901960800285137\n",
      "1  qr  1  1  0.16901960800285137\n",
      "1  langu  1  1  0.06020599913279624\n",
      "2  langu  2  1  0.043004285094854454\n",
      "3  langu  3  1  0.06020599913279624\n",
      "4  langu  4  1  0.03762874945799765\n",
      "5  langu  5  2  0.1505149978319906\n",
      "6  langu  6  2  0.08600857018970891\n",
      "1  lev  1  1  0.09542425094393249\n",
      "2  lev  4  2  0.11928031367991561\n",
      "3  lev  5  1  0.11928031367991561\n",
      "1  evalu  1  1  0.09542425094393249\n",
      "2  evalu  4  1  0.059640156839957804\n",
      "3  evalu  6  1  0.06816017924566606\n",
      "1  post-retrieval  1  1  0.16901960800285137\n",
      "1  tasks,  1  1  0.09542425094393249\n",
      "2  tasks,  2  1  0.06816017924566606\n",
      "3  tasks,  3  1  0.09542425094393249\n",
      "1  18%  1  1  0.16901960800285137\n",
      "1  gain  1  1  0.16901960800285137\n",
      "1  help  1  1  0.16901960800285137\n",
      "1  reformulation(qr)  1  1  0.16901960800285137\n",
      "1  strategies  1  1  0.09542425094393249\n",
      "2  strategies  4  1  0.059640156839957804\n",
      "3  strategies  5  2  0.23856062735983122\n",
      "1  approach  1  1  0.07958800173440753\n",
      "2  approach  2  1  0.05684857266743394\n",
      "3  approach  3  1  0.07958800173440753\n",
      "4  approach  5  2  0.1989700043360188\n",
      "1  genqrensemblerf  1  2  0.33803921600570275\n",
      "1  benefit  1  1  0.16901960800285137\n",
      "1  rel  1  2  0.33803921600570275\n",
      "1  models.  1  1  0.12041199826559248\n",
      "2  models.  3  2  0.24082399653118497\n",
      "1  abl  1  1  0.12041199826559248\n",
      "2  abl  5  1  0.1505149978319906\n",
      "1  genqrensembl  1  2  0.33803921600570275\n",
      "1  prevy  1  1  0.09542425094393249\n",
      "2  prevy  2  1  0.06816017924566606\n",
      "3  prevy  4  1  0.059640156839957804\n",
      "1  inspir  1  1  0.12041199826559248\n",
      "2  inspir  3  1  0.12041199826559248\n",
      "1  retriev  1  1  0.12041199826559248\n",
      "2  retriev  4  4  0.3010299956639812\n",
      "1  int  1  1  0.12041199826559248\n",
      "2  int  4  2  0.1505149978319906\n",
      "1  knowledg  1  1  0.16901960800285137\n",
      "1  due  1  1  0.16901960800285137\n",
      "1  show  1  1  0.12041199826559248\n",
      "2  show  2  1  0.08600857018970891\n",
      "1  context,  1  1  0.16901960800285137\n",
      "1  ndcg@10  1  2  0.33803921600570275\n",
      "1  mrr  1  1  0.16901960800285137\n",
      "1  benchmarks,  1  1  0.16901960800285137\n",
      "1  keyword  1  1  0.16901960800285137\n",
      "1  origin  1  1  0.16901960800285137\n",
      "1  exploit  1  1  0.16901960800285137\n",
      "1  24%  1  1  0.16901960800285137\n",
      "1  query  1  3  0.23876400520322255\n",
      "2  query  2  1  0.05684857266743394\n",
      "3  query  4  8  0.3979400086720376\n",
      "4  query  5  1  0.0994850021680094\n",
      "1  larg  1  1  0.06020599913279624\n",
      "2  larg  2  1  0.043004285094854454\n",
      "3  larg  3  1  0.06020599913279624\n",
      "4  larg  4  1  0.03762874945799765\n",
      "5  larg  5  1  0.0752574989159953\n",
      "6  larg  6  1  0.043004285094854454\n",
      "1  reform  1  1  0.12041199826559248\n",
      "2  reform  4  3  0.22577249674798588\n",
      "1  bet  1  2  0.33803921600570275\n",
      "1  paraphras  1  1  0.16901960800285137\n",
      "1  ir  1  1  0.16901960800285137\n",
      "1  reformulation.  1  1  0.16901960800285137\n",
      "1  align  1  1  0.16901960800285137\n",
      "1  introduc  1  1  0.12041199826559248\n",
      "2  introduc  5  2  0.3010299956639812\n",
      "1  variant,  1  1  0.16901960800285137\n",
      "1  prompt  1  2  0.15917600346881505\n",
      "2  prompt  2  4  0.22739429066973577\n",
      "3  prompt  3  3  0.23876400520322255\n",
      "4  prompt  6  2  0.11369714533486788\n",
      "1  incorp  1  1  0.16901960800285137\n",
      "1  propos  1  1  0.06848453616444126\n",
      "2  propos  2  2  0.09783505166348751\n",
      "3  propos  3  1  0.06848453616444126\n",
      "4  propos  4  1  0.042802835102775785\n",
      "5  propos  5  1  0.08560567020555157\n",
      "1  gen  1  2  0.15917600346881505\n",
      "2  gen  4  3  0.14922750325201412\n",
      "3  gen  5  2  0.1989700043360188\n",
      "4  gen  6  4  0.22739429066973577\n",
      "1  pseudo-relevance  1  1  0.16901960800285137\n",
      "1  feedback.  1  1  0.16901960800285137\n",
      "1  user’s  1  2  0.33803921600570275\n",
      "1  four  1  1  0.16901960800285137\n",
      "1  pairw  2  1  0.1207282914306081\n",
      "1  efficy  2  1  0.08600857018970891\n",
      "2  efficy  3  5  0.6020599913279624\n",
      "1  baselin  2  2  0.2414565828612162\n",
      "1  docu  2  2  0.2414565828612162\n",
      "1  solutions,  2  1  0.1207282914306081\n",
      "1  flan-ul2  2  1  0.1207282914306081\n",
      "1  beir  2  1  0.08600857018970891\n",
      "2  beir  4  1  0.0752574989159953\n",
      "1  linear  2  1  0.1207282914306081\n",
      "1  moderate-sized  2  1  0.1207282914306081\n",
      "1  parameters,  2  1  0.1207282914306081\n",
      "1  direct  2  1  0.08600857018970891\n",
      "2  direct  6  1  0.08600857018970891\n",
      "1  solv  2  2  0.2414565828612162\n",
      "1  listw  2  1  0.1207282914306081\n",
      "1  challeng  2  1  0.1207282914306081\n",
      "1  fine-tuned  2  1  0.1207282914306081\n",
      "1  first  2  1  0.06816017924566606\n",
      "2  first  4  1  0.059640156839957804\n",
      "3  first  5  1  0.11928031367991561\n",
      "1  cal  2  1  0.1207282914306081\n",
      "1  achiev  2  2  0.13632035849133212\n",
      "2  achiev  4  1  0.059640156839957804\n",
      "3  achiev  5  1  0.11928031367991561\n",
      "1  llm-based  2  2  0.13632035849133212\n",
      "2  llm-based  3  2  0.19084850188786498\n",
      "3  llm-based  6  1  0.06816017924566606\n",
      "1  model  2  3  0.14675257749523127\n",
      "2  model  3  5  0.3424226808222063\n",
      "3  model  4  2  0.08560567020555157\n",
      "4  model  5  2  0.17121134041110314\n",
      "5  model  6  1  0.048917525831743754\n",
      "1  open-sourced  2  1  0.08600857018970891\n",
      "2  open-sourced  6  1  0.08600857018970891\n",
      "1  ndcg@10.  2  1  0.08600857018970891\n",
      "2  ndcg@10.  4  1  0.0752574989159953\n",
      "1  result  2  2  0.11369714533486788\n",
      "2  result  3  1  0.07958800173440753\n",
      "3  result  5  1  0.0994850021680094\n",
      "4  result  6  2  0.11369714533486788\n",
      "1  ev  2  1  0.1207282914306081\n",
      "1  research  2  1  0.08600857018970891\n",
      "2  research  3  1  0.12041199826559248\n",
      "1  standard  2  1  0.1207282914306081\n",
      "1  chatgpt  2  1  0.1207282914306081\n",
      "1  (llms)  2  1  0.08600857018970891\n",
      "2  (llms)  4  1  0.0752574989159953\n",
      "1  2019  2  1  0.1207282914306081\n",
      "1  formulations.  2  1  0.1207282914306081\n",
      "1  (prp).  2  1  0.1207282914306081\n",
      "1  10%  2  1  0.1207282914306081\n",
      "1  paramet  2  1  0.1207282914306081\n",
      "1  pointw  2  2  0.2414565828612162\n",
      "1  interest  2  1  0.1207282914306081\n",
      "1  175b  2  1  0.1207282914306081\n",
      "1  perform  2  2  0.17201714037941782\n",
      "2  perform  4  2  0.1505149978319906\n",
      "1  problem.  2  1  0.1207282914306081\n",
      "1  complex  2  1  0.08600857018970891\n",
      "2  complex  5  1  0.1505149978319906\n",
      "1  fee  2  1  0.1207282914306081\n",
      "1  lit  2  1  0.1207282914306081\n",
      "1  prp  2  3  0.36218487429182433\n",
      "1  (estimated)  2  1  0.1207282914306081\n",
      "1  analys  2  1  0.08600857018970891\n",
      "2  analys  5  1  0.1505149978319906\n",
      "1  however,  2  1  0.1207282914306081\n",
      "1  reduc  2  1  0.08600857018970891\n",
      "2  reduc  3  1  0.12041199826559248\n",
      "1  understand  2  1  0.08600857018970891\n",
      "2  understand  3  1  0.12041199826559248\n",
      "1  superv  2  1  0.1207282914306081\n",
      "1  paper,  2  1  0.05684857266743394\n",
      "2  paper,  4  1  0.0497425010840047\n",
      "3  paper,  5  1  0.0994850021680094\n",
      "4  paper,  6  1  0.05684857266743394\n",
      "1  commerc  2  2  0.2414565828612162\n",
      "1  llms.  2  1  0.08600857018970891\n",
      "2  llms.  5  1  0.1505149978319906\n",
      "1  datasets.  2  1  0.1207282914306081\n",
      "1  templ  2  1  0.08600857018970891\n",
      "2  templ  3  2  0.24082399653118497\n",
      "1  off-the-shelf  2  1  0.1207282914306081\n",
      "1  50x  2  1  0.1207282914306081\n",
      "1  gpt-4  2  1  0.1207282914306081\n",
      "1  metrics.  2  1  0.08600857018970891\n",
      "2  metrics.  6  1  0.08600857018970891\n",
      "1  argu  2  1  0.1207282914306081\n",
      "1  vary  2  1  0.06816017924566606\n",
      "2  vary  3  1  0.09542425094393249\n",
      "3  vary  4  2  0.11928031367991561\n",
      "1  furthermore,  2  1  0.08600857018970891\n",
      "2  furthermore,  4  1  0.0752574989159953\n",
      "1  trec-dl  2  1  0.1207282914306081\n",
      "1  pract  2  1  0.1207282914306081\n",
      "1  competit  2  1  0.1207282914306081\n",
      "1  sev  2  2  0.2414565828612162\n",
      "1  4.2%  2  1  0.1207282914306081\n",
      "1  blackbox  2  2  0.2414565828612162\n",
      "1  llms  2  2  0.11369714533486788\n",
      "2  llms  4  1  0.0497425010840047\n",
      "3  llms  5  2  0.1989700043360188\n",
      "4  llms  6  2  0.11369714533486788\n",
      "1  difficult  2  1  0.1207282914306081\n",
      "1  2020,  2  1  0.1207282914306081\n",
      "1  method  2  1  0.08600857018970891\n",
      "2  method  4  1  0.0752574989159953\n",
      "1  outperform  2  4  0.4829131657224324\n",
      "1  benchmark  2  2  0.13632035849133212\n",
      "2  benchmark  4  1  0.059640156839957804\n",
      "3  benchmark  5  1  0.11928031367991561\n",
      "1  instructgpt  2  1  0.1207282914306081\n",
      "1  av  2  1  0.1207282914306081\n",
      "1  ful  2  1  0.1207282914306081\n",
      "1  literature,  2  1  0.1207282914306081\n",
      "1  found  2  1  0.1207282914306081\n",
      "1  burd  2  1  0.1207282914306081\n",
      "1  fav  2  1  0.1207282914306081\n",
      "1  poss  2  1  0.1207282914306081\n",
      "1  12-10%  2  1  0.1207282914306081\n",
      "1  new  2  1  0.1207282914306081\n",
      "1  state-of-the-art  2  1  0.08600857018970891\n",
      "2  state-of-the-art  4  1  0.0752574989159953\n",
      "1  best  2  1  0.1207282914306081\n",
      "1  20b  2  1  0.1207282914306081\n",
      "1  sign  2  1  0.05684857266743394\n",
      "2  sign  3  1  0.07958800173440753\n",
      "3  sign  4  1  0.0497425010840047\n",
      "4  sign  6  1  0.05684857266743394\n",
      "1  candid  2  1  0.1207282914306081\n",
      "1  size,  2  1  0.1207282914306081\n",
      "1  ex  2  1  0.1207282914306081\n",
      "1  text,  3  1  0.16901960800285137\n",
      "1  item  3  1  0.12041199826559248\n",
      "2  item  6  1  0.08600857018970891\n",
      "1  design  3  1  0.16901960800285137\n",
      "1  long  3  3  0.5070588240085541\n",
      "1  manifest  3  1  0.16901960800285137\n",
      "1  could  3  2  0.33803921600570275\n",
      "1  reasoning,  3  1  0.16901960800285137\n",
      "1  strategy  3  1  0.16901960800285137\n",
      "1  dataset  3  1  0.12041199826559248\n",
      "2  dataset  6  4  0.34403428075883563\n",
      "1  enough  3  1  0.16901960800285137\n",
      "1  extend  3  1  0.16901960800285137\n",
      "1  system  3  1  0.16901960800285137\n",
      "1  bridg  3  2  0.24082399653118497\n",
      "2  bridg  5  1  0.1505149978319906\n",
      "1  response.  3  1  0.16901960800285137\n",
      "1  information.  3  1  0.16901960800285137\n",
      "1  may  3  2  0.33803921600570275\n",
      "1  limit  3  1  0.12041199826559248\n",
      "2  limit  4  1  0.0752574989159953\n",
      "1  user/item  3  1  0.16901960800285137\n",
      "1  tasks.  3  1  0.12041199826559248\n",
      "2  tasks.  6  1  0.08600857018970891\n",
      "1  unleash  3  1  0.16901960800285137\n",
      "1  fil  3  1  0.16901960800285137\n",
      "1  allow  3  1  0.12041199826559248\n",
      "2  allow  5  1  0.1505149978319906\n",
      "1  process,  3  1  0.12041199826559248\n",
      "2  process,  5  1  0.1505149978319906\n",
      "1  e.g.,  3  1  0.16901960800285137\n",
      "1  requir  3  1  0.16901960800285137\n",
      "1  time.  3  1  0.12041199826559248\n",
      "2  time.  4  1  0.0752574989159953\n",
      "1  top-n  3  1  0.16901960800285137\n",
      "1  recommend  3  5  0.6020599913279624\n",
      "2  recommend  6  1  0.08600857018970891\n",
      "1  unparallel  3  1  0.16901960800285137\n",
      "1  attempt  3  1  0.16901960800285137\n",
      "1  input  3  1  0.09542425094393249\n",
      "2  input  4  1  0.059640156839957804\n",
      "3  input  5  1  0.11928031367991561\n",
      "1  although  3  1  0.16901960800285137\n",
      "1  thu  3  1  0.16901960800285137\n",
      "1  expery  3  1  0.09542425094393249\n",
      "2  expery  4  1  0.059640156839957804\n",
      "3  expery  5  1  0.11928031367991561\n",
      "1  discret  3  2  0.33803921600570275\n",
      "1  distil  3  2  0.33803921600570275\n",
      "1  llm  3  1  0.16901960800285137\n",
      "1  address  3  1  0.16901960800285137\n",
      "1  models,  3  1  0.16901960800285137\n",
      "1  commun  3  1  0.16901960800285137\n",
      "1  problems,  3  1  0.16901960800285137\n",
      "1  (pod)  3  1  0.16901960800285137\n",
      "1  inf  3  3  0.5070588240085541\n",
      "1  fine-tuning  3  1  0.16901960800285137\n",
      "1  nee  3  1  0.16901960800285137\n",
      "1  word  3  2  0.33803921600570275\n",
      "1  recommendation.  3  1  0.16901960800285137\n",
      "1  real-world  3  1  0.16901960800285137\n",
      "1  sequ  3  1  0.12041199826559248\n",
      "2  sequ  5  1  0.1505149978319906\n",
      "1  task  3  1  0.12041199826559248\n",
      "2  task  5  2  0.3010299956639812\n",
      "1  contain  3  1  0.16901960800285137\n",
      "1  pow  3  1  0.09542425094393249\n",
      "2  pow  5  1  0.11928031367991561\n",
      "3  pow  6  1  0.06816017924566606\n",
      "1  continu  3  1  0.16901960800285137\n",
      "1  also  3  1  0.12041199826559248\n",
      "2  also  5  1  0.1505149978319906\n",
      "1  vect  3  1  0.16901960800285137\n",
      "1  cap  3  1  0.16901960800285137\n",
      "1  most  3  1  0.16901960800285137\n",
      "1  immedy  3  1  0.16901960800285137\n",
      "1  improved,  3  1  0.16901960800285137\n",
      "1  id  3  3  0.5070588240085541\n",
      "1  train  3  3  0.5070588240085541\n",
      "1  three  3  1  0.16901960800285137\n",
      "1  plain  3  1  0.16901960800285137\n",
      "1  limited.  3  1  0.16901960800285137\n",
      "1  tim  3  1  0.16901960800285137\n",
      "1  noisy  3  1  0.16901960800285137\n",
      "1  (i.e.,  3  1  0.16901960800285137\n",
      "1  giv  3  1  0.12041199826559248\n",
      "2  giv  5  1  0.1505149978319906\n",
      "1  multi-step  3  1  0.16901960800285137\n",
      "1  prompt)  3  1  0.16901960800285137\n",
      "1  spec  3  1  0.16901960800285137\n",
      "1  effect  3  1  0.09542425094393249\n",
      "2  effect  4  1  0.059640156839957804\n",
      "3  effect  5  1  0.11928031367991561\n",
      "1  demonst  3  1  0.09542425094393249\n",
      "2  demonst  4  1  0.059640156839957804\n",
      "3  demonst  6  1  0.06816017924566606\n",
      "1  (llm)  3  1  0.16901960800285137\n",
      "1  complet  4  1  0.1056372550017821\n",
      "1  optim  4  1  0.1056372550017821\n",
      "1  performance,  4  1  0.1056372550017821\n",
      "1  integr  4  1  0.0752574989159953\n",
      "2  integr  5  1  0.1505149978319906\n",
      "1  phas  4  1  0.1056372550017821\n",
      "1  gencrf:  4  1  0.1056372550017821\n",
      "1  custom  4  1  0.1056372550017821\n",
      "1  differentiated,  4  1  0.1056372550017821\n",
      "1  rat  4  1  0.1056372550017821\n",
      "1  redund  4  1  0.1056372550017821\n",
      "1  oft  4  1  0.1056372550017821\n",
      "1  (ir)  4  1  0.1056372550017821\n",
      "1  divers  4  4  0.4225490200071284\n",
      "1  well-generated  4  1  0.1056372550017821\n",
      "1  llms,  4  1  0.1056372550017821\n",
      "1  gencrf  4  2  0.2112745100035642\n",
      "1  process  4  1  0.0752574989159953\n",
      "2  process  6  1  0.08600857018970891\n",
      "1  prompts,  4  1  0.1056372550017821\n",
      "1  mod  4  1  0.1056372550017821\n",
      "1  rec  4  1  0.059640156839957804\n",
      "2  rec  5  1  0.11928031367991561\n",
      "3  rec  6  1  0.06816017924566606\n",
      "1  well-known  4  1  0.1056372550017821\n",
      "1  problem  4  1  0.1056372550017821\n",
      "1  adapt  4  2  0.2112745100035642\n",
      "1  group  4  1  0.1056372550017821\n",
      "1  adv  4  1  0.0752574989159953\n",
      "2  adv  5  1  0.1505149978319906\n",
      "1  constrain  4  1  0.1056372550017821\n",
      "1  cruc  4  1  0.1056372550017821\n",
      "1  sota  4  1  0.1056372550017821\n",
      "1  loops.  4  1  0.1056372550017821\n",
      "1  novel  4  1  0.0752574989159953\n",
      "2  novel  5  1  0.1505149978319906\n",
      "1  innov  4  1  0.1056372550017821\n",
      "1  query.  4  1  0.1056372550017821\n",
      "1  pot  4  1  0.0752574989159953\n",
      "2  pot  6  1  0.08600857018970891\n",
      "1  boost  4  1  0.1056372550017821\n",
      "1  intents.  4  2  0.2112745100035642\n",
      "1  (qerm)  4  1  0.1056372550017821\n",
      "1  combin  4  1  0.0752574989159953\n",
      "2  combin  6  1  0.08600857018970891\n",
      "1  capt  4  2  0.11928031367991561\n",
      "2  capt  5  3  0.35784094103974684\n",
      "3  capt  6  1  0.06816017924566606\n",
      "1  autom  4  1  0.1056372550017821\n",
      "1  clust  4  2  0.2112745100035642\n",
      "1  reward  4  1  0.1056372550017821\n",
      "1  inform  4  2  0.11928031367991561\n",
      "2  inform  5  2  0.23856062735983122\n",
      "3  inform  6  1  0.06816017924566606\n",
      "1  empir  4  1  0.1056372550017821\n",
      "1  user's  4  1  0.0752574989159953\n",
      "2  user's  5  1  0.1505149978319906\n",
      "1  field  4  1  0.1056372550017821\n",
      "1  singl  4  1  0.1056372550017821\n",
      "1  surpass  4  1  0.1056372550017821\n",
      "1  repres  4  1  0.0752574989159953\n",
      "2  repres  5  1  0.1505149978319906\n",
      "1  enh  4  1  0.0752574989159953\n",
      "2  enh  5  1  0.1505149978319906\n",
      "1  framework  4  2  0.2112745100035642\n",
      "1  expansions,  4  1  0.1056372550017821\n",
      "1  init  4  1  0.1056372550017821\n",
      "1  aggreg  4  1  0.1056372550017821\n",
      "1  retrieval.  4  1  0.1056372550017821\n",
      "1  distinct  4  1  0.1056372550017821\n",
      "1  expl  4  1  0.0752574989159953\n",
      "2  expl  6  1  0.08600857018970891\n",
      "1  refin  4  1  0.1056372550017821\n",
      "1  12%  4  1  0.1056372550017821\n",
      "1  aim  4  1  0.0752574989159953\n",
      "2  aim  5  1  0.1505149978319906\n",
      "1  reformulation,  4  1  0.1056372550017821\n",
      "1  weight  4  1  0.1056372550017821\n",
      "1  seamless  5  1  0.2112745100035642\n",
      "1  interact  5  2  0.4225490200071284\n",
      "1  graph-based  5  1  0.2112745100035642\n",
      "1  methodolog  5  1  0.2112745100035642\n",
      "1  foc  5  1  0.2112745100035642\n",
      "1  documents,  5  1  0.2112745100035642\n",
      "1  information,  5  1  0.2112745100035642\n",
      "1  understanding,  5  1  0.2112745100035642\n",
      "1  gramm  5  1  0.2112745100035642\n",
      "1  structures  5  1  0.2112745100035642\n",
      "1  modern  5  1  0.2112745100035642\n",
      "1  object  5  1  0.2112745100035642\n",
      "1  nod  5  1  0.2112745100035642\n",
      "1  act  5  1  0.2112745100035642\n",
      "1  pre-trained  5  1  0.2112745100035642\n",
      "1  text.  5  1  0.2112745100035642\n",
      "1  modeling.  5  1  0.2112745100035642\n",
      "1  text-based  5  1  0.2112745100035642\n",
      "1  rul  5  1  0.2112745100035642\n",
      "1  llm.  5  1  0.2112745100035642\n",
      "1  aol  5  1  0.2112745100035642\n",
      "1  prediction,  5  1  0.2112745100035642\n",
      "1  tradit  5  1  0.2112745100035642\n",
      "1  confirm  5  1  0.2112745100035642\n",
      "1  concretely,  5  1  0.2112745100035642\n",
      "1  en  5  1  0.2112745100035642\n",
      "1  learn  5  1  0.2112745100035642\n",
      "1  approach.  5  1  0.2112745100035642\n",
      "1  history,  5  1  0.2112745100035642\n",
      "1  interactions.  5  1  0.2112745100035642\n",
      "1  learning,  5  1  0.2112745100035642\n",
      "1  discrep  5  1  0.2112745100035642\n",
      "1  supery  5  1  0.2112745100035642\n",
      "1  paradigm  5  1  0.2112745100035642\n",
      "1  produc  5  1  0.2112745100035642\n",
      "1  format.  5  1  0.2112745100035642\n",
      "1  generation,  5  1  0.2112745100035642\n",
      "1  structure  5  1  0.2112745100035642\n",
      "1  word-level  5  1  0.2112745100035642\n",
      "1  sess  5  3  0.6338235300106926\n",
      "1  sem  5  2  0.4225490200071284\n",
      "1  comprehend  5  1  0.2112745100035642\n",
      "1  structural  5  1  0.2112745100035642\n",
      "1  deep  5  1  0.2112745100035642\n",
      "1  fulfil  5  1  0.2112745100035642\n",
      "1  datasets,  5  1  0.2112745100035642\n",
      "1  graph-to-text  5  1  0.2112745100035642\n",
      "1  topolog  5  1  0.2112745100035642\n",
      "1  cont  5  1  0.1505149978319906\n",
      "2  cont  6  1  0.08600857018970891\n",
      "1  off  5  1  0.2112745100035642\n",
      "1  this,  5  1  0.2112745100035642\n",
      "1  overlook  5  1  0.2112745100035642\n",
      "1  coarse-grained  5  1  0.2112745100035642\n",
      "1  priorit  5  1  0.2112745100035642\n",
      "1  grammar,  5  1  0.2112745100035642\n",
      "1  includ  5  1  0.2112745100035642\n",
      "1  contrast  5  1  0.2112745100035642\n",
      "1  two  5  1  0.2112745100035642\n",
      "1  sery  5  1  0.2112745100035642\n",
      "1  graph  5  4  0.8450980400142568\n",
      "1  moreover,  5  1  0.2112745100035642\n",
      "1  corpora,  5  1  0.2112745100035642\n",
      "1  nat  5  1  0.1505149978319906\n",
      "2  nat  6  1  0.08600857018970891\n",
      "1  self-supervised  5  1  0.2112745100035642\n",
      "1  (sgr),  5  1  0.2112745100035642\n",
      "1  convert  5  1  0.2112745100035642\n",
      "1  fine-grained.  5  1  0.2112745100035642\n",
      "1  neglect  5  1  0.2112745100035642\n",
      "1  typ  5  1  0.2112745100035642\n",
      "1  link  5  1  0.2112745100035642\n",
      "1  symbol  5  4  0.8450980400142568\n",
      "1  tiangong-st,  5  1  0.2112745100035642\n",
      "1  cur  5  1  0.2112745100035642\n",
      "1  within  5  1  0.2112745100035642\n",
      "1  need.  5  1  0.2112745100035642\n",
      "1  gap  5  1  0.2112745100035642\n",
      "1  (llms).  5  1  0.2112745100035642\n",
      "1  involv  5  1  0.2112745100035642\n",
      "1  llms'  5  1  0.2112745100035642\n",
      "1  1m  6  1  0.1207282914306081\n",
      "1  consid  6  1  0.1207282914306081\n",
      "1  few-shot  6  1  0.1207282914306081\n",
      "1  book  6  1  0.1207282914306081\n",
      "1  titl  6  1  0.1207282914306081\n",
      "1  ndcg  6  1  0.1207282914306081\n",
      "1  gpt-3.5,  6  1  0.1207282914306081\n",
      "1  emerg  6  1  0.1207282914306081\n",
      "1  alpac  6  1  0.1207282914306081\n",
      "1  lik  6  2  0.2414565828612162\n",
      "1  llm,  6  1  0.1207282914306081\n",
      "1  movy  6  3  0.36218487429182433\n",
      "1  promise,  6  1  0.1207282914306081\n",
      "1  suscept  6  1  0.1207282914306081\n",
      "1  conduc  6  1  0.1207282914306081\n",
      "1  scraping  6  1  0.1207282914306081\n",
      "1  obtain  6  2  0.2414565828612162\n",
      "1  cast  6  1  0.1207282914306081\n",
      "1  study,  6  1  0.1207282914306081\n",
      "1  systems.  6  1  0.1207282914306081\n",
      "1  descriptions.  6  1  0.1207282914306081\n",
      "1  publ  6  1  0.1207282914306081\n",
      "1  (llms),  6  1  0.1207282914306081\n",
      "1  ess  6  1  0.1207282914306081\n",
      "1  man  6  1  0.1207282914306081\n",
      "1  provid  6  1  0.1207282914306081\n",
      "1  web-scraped  6  1  0.1207282914306081\n",
      "1  scraped  6  1  0.1207282914306081\n",
      "1  techniques,  6  1  0.1207282914306081\n",
      "1  consist  6  1  0.1207282914306081\n",
      "1  describ  6  7  0.8450980400142568\n",
      "1  inconsistencies.  6  1  0.1207282914306081\n",
      "1  detail  6  2  0.2414565828612162\n",
      "1  feat  6  1  0.1207282914306081\n",
      "1  web  6  1  0.1207282914306081\n",
      "1  pivot  6  1  0.1207282914306081\n",
      "1  sourc  6  1  0.1207282914306081\n",
      "1  rol  6  1  0.1207282914306081\n",
      "1  hits,  6  1  0.1207282914306081\n",
      "1  time-consuming  6  1  0.1207282914306081\n",
      "1  exhibit  6  1  0.1207282914306081\n",
      "1  traditionally,  6  1  0.1207282914306081\n",
      "1  op  6  1  0.1207282914306081\n",
      "1  subsequently,  6  1  0.1207282914306081\n",
      "1  top  6  1  0.1207282914306081\n",
      "1  dataset.  6  1  0.1207282914306081\n",
      "1  on  6  1  0.1207282914306081\n",
      "1  nam  6  3  0.36218487429182433\n",
      "1  dat  6  1  0.1207282914306081\n",
      "1  sum  6  1  0.1207282914306081\n",
      "1  mrr,  6  1  0.1207282914306081\n",
      "1  goodread  6  2  0.2414565828612162\n",
      "1  compr  6  1  0.1207282914306081\n",
      "1  moviel  6  1  0.1207282914306081\n",
      "1  items.  6  1  0.1207282914306081\n",
      "1  tool  6  1  0.1207282914306081\n",
      "1  alpaca,  6  1  0.1207282914306081\n",
      "1  auth  6  1  0.1207282914306081\n",
      "1  comp  6  2  0.2414565828612162\n",
      "1  view  6  1  0.1207282914306081\n",
      "1  ml  6  1  0.1207282914306081\n",
      "1  years,  6  1  0.1207282914306081\n",
      "1  play  6  1  0.1207282914306081\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inverse_split_lancaster = {}\n",
    "\n",
    "for i in range(len(termes_split_lancaster)):\n",
    "    seen_terms = set()  # Track terms processed in the current document\n",
    "\n",
    "    for j in range(len(termes_split_lancaster[i])):\n",
    "        term = termes_split_lancaster[i][j]\n",
    "\n",
    "        if (term, i) not in seen_terms:\n",
    "            seen_terms.add((term, i))\n",
    "\n",
    "            if term not in inverse_split_lancaster:\n",
    "                inverse_split_lancaster[term] = []\n",
    "            \n",
    "            frequency_term = frequency_dict_split_lancaster_documents[i][termes_split_lancaster[i][j]]\n",
    "            poids_term = poids(frequency_term, max_frequency_dict_split_lancaster_documents[i], document_frequency_dict_split_lancaster[termes_split_lancaster[i][j]], n_split)\n",
    "            \n",
    "            inverse_split_lancaster[term].append((i + 1, frequency_term, poids_term))\n",
    "\n",
    "inverse_split_lancaster_output = \"\"\n",
    "for term, docs in inverse_split_lancaster.items():\n",
    "    for idx, doc_info in enumerate(docs, 1):\n",
    "        doc_num, frequency_term, poids_term = doc_info\n",
    "        inverse_split_lancaster_output += f\"{idx}  {term}  {doc_num}  {frequency_term}  {poids_term}\\n\"\n",
    "\n",
    "print(inverse_split_lancaster_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving Files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved to descripteur_split.txt\n"
     ]
    }
   ],
   "source": [
    "output_file_path = 'descripteur_split.txt'\n",
    "\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(descripteur_split)\n",
    "\n",
    "print(f'file saved to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved to descripteur_reg.txt\n"
     ]
    }
   ],
   "source": [
    "output_file_path = 'descripteur_reg.txt'\n",
    "\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(descripteur_reg)\n",
    "\n",
    "print(f'file saved to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved to descripteur_split_porter.txt\n"
     ]
    }
   ],
   "source": [
    "output_file_path = 'descripteur_split_porter.txt'\n",
    "\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(descripteur_split_porter)\n",
    "\n",
    "print(f'file saved to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved to descripteur_reg_porter.txt\n"
     ]
    }
   ],
   "source": [
    "output_file_path = 'descripteur_reg_porter.txt'\n",
    "\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(descripteur_reg_porter)\n",
    "\n",
    "print(f'file saved to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved to descripteur_split_lancaster.txt\n"
     ]
    }
   ],
   "source": [
    "output_file_path = 'descripteur_split_lancaster.txt'\n",
    "\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(descripteur_split_lancaster)\n",
    "\n",
    "print(f'file saved to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved to descripteur_reg_lancaster.txt\n"
     ]
    }
   ],
   "source": [
    "output_file_path = 'descripteur_reg_lancaster.txt'\n",
    "\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(descripteur_reg_lancaster)\n",
    "\n",
    "print(f'file saved to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved to inverse_split.txt\n"
     ]
    }
   ],
   "source": [
    "output_file_path = 'inverse_split.txt'\n",
    "\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(inverse_split_output)\n",
    "\n",
    "print(f'file saved to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved to inverse_reg.txt\n"
     ]
    }
   ],
   "source": [
    "output_file_path = 'inverse_reg.txt'\n",
    "\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(inverse_reg_output)\n",
    "\n",
    "print(f'file saved to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved to inverse_split_porter.txt\n"
     ]
    }
   ],
   "source": [
    "output_file_path = 'inverse_split_porter.txt'\n",
    "\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(inverse_split_porter_output)\n",
    "\n",
    "print(f'file saved to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved to inverse_reg_porter.txt\n"
     ]
    }
   ],
   "source": [
    "output_file_path = 'inverse_reg_porter.txt'\n",
    "\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(inverse_reg_porter_output)\n",
    "\n",
    "print(f'file saved to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved to inverse_split_lancaster.txt\n"
     ]
    }
   ],
   "source": [
    "output_file_path = 'inverse_split_lancaster.txt'\n",
    "\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(inverse_split_lancaster_output)\n",
    "\n",
    "print(f'file saved to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved to inverse_reg_lancaster.txt\n"
     ]
    }
   ],
   "source": [
    "output_file_path = 'inverse_reg_lancaster.txt'\n",
    "\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(inverse_reg_lancaster_output)\n",
    "\n",
    "print(f'file saved to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8809bf823046569963b464e53ed88a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Text(value='', description='Query:', layout=Layout(width='60%'), placeholder='Enter your query …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d5ad75f970f4bec902602ba50707ce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HBox(children=(Dropdown(description='Preprocessing:', layout=Layout(width='45%'), options=('Spl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69dd90d74bbc484c95f65f7d1d6f13cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', description='Results:', layout=Layout(height='300px', width='100%'), placeholder='Results w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import nltk \n",
    "Porter = nltk.PorterStemmer()\n",
    "Lancaster = nltk.LancasterStemmer() \n",
    "\n",
    "# Colors\n",
    "border_color = 'lightgray'\n",
    "background_color = 'lightblue'  # Light blue\n",
    "container_background_color = 'lightgray'  # Slightly darker blue\n",
    "\n",
    "# Create the text input for the query\n",
    "query_input = widgets.Text(\n",
    "    description='Query:',\n",
    "    placeholder='Enter your query here',\n",
    "    layout=widgets.Layout(width='60%')\n",
    ")\n",
    "\n",
    "# Create a button to submit the query\n",
    "submit_button = widgets.Button(\n",
    "    description='Search',\n",
    "    layout=widgets.Layout(width='20%')\n",
    ")\n",
    "\n",
    "# Combine query input and submit button in a single line with styling\n",
    "query_container = widgets.HBox(\n",
    "    [query_input, submit_button],\n",
    "    layout=widgets.Layout(\n",
    "        border=f'2px solid {border_color}',\n",
    "        border_radius='10px',\n",
    "        padding='10px',\n",
    "        background_color=border_color\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create dropdowns for preprocessing parameters\n",
    "preprocessing_options = ['Split', 'Reg']\n",
    "stemming_options = ['Porter', 'Lancaster', 'No Stemming']\n",
    "\n",
    "preprocessing_dropdown = widgets.Dropdown(\n",
    "    options=preprocessing_options,\n",
    "    description='Preprocessing:',\n",
    "    layout=widgets.Layout(width='45%')\n",
    ")\n",
    "\n",
    "stemming_dropdown = widgets.Dropdown(\n",
    "    options=stemming_options,\n",
    "    description='Stemming:',\n",
    "    layout=widgets.Layout(width='45%')\n",
    ")\n",
    "\n",
    "# Group preprocessing and stemming dropdowns in a container\n",
    "preprocessing_container = widgets.HBox(\n",
    "    [preprocessing_dropdown, stemming_dropdown],\n",
    "    layout=widgets.Layout(\n",
    "        border=f'2px solid {border_color}',\n",
    "        border_radius='10px',\n",
    "        padding='10px',\n",
    "        background_color=container_background_color,\n",
    "        justify_content='space-between',\n",
    "        width='50%'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create checkboxes for file selection\n",
    "file_options = ['DOCS per Term', 'Terms per Doc']\n",
    "file_selection = widgets.RadioButtons(\n",
    "    options=file_options,\n",
    "    description='File Type:',\n",
    "    layout=widgets.Layout(width='40%')\n",
    ")\n",
    "\n",
    "# Group preprocessing_container and file_selection in a single line container\n",
    "dropdowns_container = widgets.HBox(\n",
    "    [preprocessing_container, file_selection],\n",
    "    layout=widgets.Layout(\n",
    "        border=f'2px solid {border_color}',\n",
    "        border_radius='10px',\n",
    "        padding='10px',\n",
    "        background_color=background_color,\n",
    "        justify_content='space-between'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create a text area to display results\n",
    "result_area = widgets.Textarea(\n",
    "    description='Results:',\n",
    "    placeholder='Results will be displayed here',\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(\n",
    "        width='100%',\n",
    "        height='300px',\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Function to handle button click\n",
    "def on_submit(b):\n",
    "    query = query_input.value\n",
    "    preprocessing = preprocessing_dropdown.value\n",
    "    stemming = stemming_dropdown.value\n",
    "    selected_file = file_selection.value\n",
    "\n",
    "    # Determine file path based on selection\n",
    "    file_path = \"\"\n",
    "    if selected_file == \"Terms per Doc\":  # descriptive file\n",
    "        if preprocessing == \"Split\":\n",
    "            match stemming:\n",
    "                case 'No Stemming':\n",
    "                    file_path = 'descripteur_split.txt'\n",
    "                case 'Porter':\n",
    "                    file_path = 'descripteur_split_porter.txt'\n",
    "                case 'Lancaster':\n",
    "                    file_path = 'descripteur_split_lancaster.txt'\n",
    "        else:\n",
    "            match stemming:\n",
    "                case 'No Stemming':\n",
    "                    file_path = 'descripteur_reg.txt'\n",
    "                case 'Porter':\n",
    "                    file_path = 'descripteur_reg_porter.txt'\n",
    "                case 'Lancaster':\n",
    "                    file_path = 'descripteur_reg_lancaster.txt'\n",
    "    else:  # inverse file\n",
    "        if preprocessing == \"Split\":\n",
    "            match stemming:\n",
    "                case 'No Stemming':\n",
    "                    file_path = 'inverse_split.txt'\n",
    "                case 'Porter':\n",
    "                    file_path = 'inverse_split_porter.txt'\n",
    "                    query = Porter.stem(query)\n",
    "                case 'Lancaster':\n",
    "                    file_path = 'inverse_split_lancaster.txt'\n",
    "                    query = Lancaster.stem(query)\n",
    "        else:\n",
    "            match stemming:\n",
    "                case 'No Stemming':\n",
    "                    file_path = 'inverse_reg.txt'\n",
    "                case 'Porter':\n",
    "                    file_path = 'inverse_reg_porter.txt'\n",
    "                    query = Porter.stem(query)\n",
    "                case 'Lancaster':\n",
    "                    file_path = 'inverse_reg_lancaster.txt'\n",
    "                    query = Lancaster.stem(query)\n",
    "\n",
    "    # Initialize result content with the correct header and numbered lines\n",
    "    line_counter = 1\n",
    "    if selected_file == \"Terms per Doc\":\n",
    "        result_content = \"N  Ndoc   Term           Freq   Weight  Positions\\n\"\n",
    "        \n",
    "        # Track terms and frequencies for the selected document\n",
    "        term_count = 0\n",
    "        \n",
    "        \n",
    "        # Filter the file content based on query and file type\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                parts = line.split()\n",
    "                \n",
    "                # Check if the document number matches the query\n",
    "                if parts[0] == query:\n",
    "                    # Format and add the numbered line to result_content\n",
    "                    formatted_line = f\"{line_counter:<3} {parts[0]:<5} {parts[1]:<15} {parts[2]:<5} {parts[3]:<10} {parts[4]:<10}\\n\"\n",
    "                    result_content += formatted_line\n",
    "                    line_counter += 1\n",
    "                    term_count += int(parts[2])  # Increment by term frequency\n",
    "                \n",
    "        # Append document vocabulary and size\n",
    "        result_content += f\"-------------------------------------------------------------------\"\n",
    "        result_content += f\"\\n# Doc vocabulary: {line_counter-1}               \"\n",
    "        result_content += f\"# Doc size: {term_count}\\n\"\n",
    "    \n",
    "    else:\n",
    "        result_content = \"N   Term            Ndoc   Freq   Weight\\n\"\n",
    "        \n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                parts = line.split()\n",
    "                \n",
    "                \n",
    "                if parts[1] == query:\n",
    "                   \n",
    "                    formatted_line = f\"{parts[0]:<3} {parts[1]:<15} {parts[2]:<5} {parts[3]:<5} {parts[4]:<10}\\n\"\n",
    "                    result_content += formatted_line\n",
    "                    line_counter += 1\n",
    "\n",
    "  \n",
    "    if line_counter == 1:  # Only header is present\n",
    "        result_content += \"No matching results found.\"\n",
    "    \n",
    "    \n",
    "    result_area.value = result_content\n",
    "\n",
    "submit_button.on_click(on_submit)\n",
    "\n",
    "# Display all widgets\n",
    "display(query_container, dropdowns_container, result_area)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

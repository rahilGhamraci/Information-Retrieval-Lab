{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "\n",
    "for i in range(6):\n",
    "    with open('..\\\\Collection\\\\D'+str(i+1)+'.txt', 'r', encoding='utf-8') as file:\n",
    "        documents.append(file.read())\n",
    "       \n",
    "\n",
    "print(len(documents))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Reformulation(QR) is a set of techniques used to transform a user’s original search query to a text that better aligns with the user’s intent and improves their search experience. Recently, zero-shot QR has been shown to be a promising approach due to its ability to exploit knowledge inherent in large language models. By taking inspiration from the success of ensemble prompting strategies which have benefited many tasks, we investigate if they can help improve query reformulation. In this context, we propose an ensemble based prompting technique, GenQREnsemble which leverages paraphrases of a zero-shot instruction to generate multiple sets of keywords ultimately improving retrieval performance. We further introduce its post-retrieval variant, GenQREnsembleRF to incorporate pseudo relevant feedback. On evaluations over four IR benchmarks, we find that GenQREnsemble generates better reformulations with relative nDCG@10 improvements up to 18% and MAP improvements upto 24% over the previous zero-shot state-of-art. On the MSMarco Passage Ranking task, GenQREnsembleRF shows relative gains of 5% MRR using pseudo-relevance feedback, and 9% nDCG@10 using relevant feedback documents.\n"
     ]
    }
   ],
   "source": [
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency(terms):\n",
    "\n",
    "    values = terms\n",
    "    \n",
    "    # Dictionary to store the frequency of each value\n",
    "    frequency_dict = {}\n",
    "    \n",
    "    # Iterate over the values and count frequencies\n",
    "    \n",
    "    for i in range(len(values)):\n",
    "        if values[i] in frequency_dict:\n",
    "            frequency_dict[values[i]] += 1\n",
    "        else:\n",
    "            frequency_dict[values[i]] = 1\n",
    "    \n",
    "    \n",
    "    return frequency_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "def poids(frequency,max_frequency,collection_frequency,n):\n",
    "\n",
    "    poids = (frequency / max_frequency) * (math.log10(1+ (n / collection_frequency)))\n",
    "    \n",
    "    return poids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spliting words using split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "StopWords = nltk.corpus.stopwords.words('english') \n",
    "\n",
    "# Initialize variables\n",
    "\n",
    "#list that containes the unique terms of each document using split\n",
    "termes_split = []\n",
    "\n",
    "#list that containes the unique terms along with their frecuencies of each document using split\n",
    "frequency_dict_split_documents = []\n",
    "\n",
    "#list that containes max frequency of each document using split\n",
    "max_frequency_dict_split_documents = []\n",
    "\n",
    "#list that containes the unique terms along with their frecuencies of all the collection using split\n",
    "document_frequency_dict_split = {}\n",
    "\n",
    "\n",
    "# Filtering out stopwords and calculating frequencies in one loop\n",
    "for i in range(6):\n",
    "    \n",
    "\n",
    "    unique_stems = list(set([term for term in documents[i].split() if term.lower() not in StopWords]))\n",
    "    filtered_terms = [term for term in documents[i].split() if term.lower() not in StopWords] # we need it to calculate frequencies\n",
    "    \n",
    "    termes_split.append(unique_stems)\n",
    "    \n",
    "    frequency_dict = frequency(filtered_terms)\n",
    "    frequency_dict_split_documents.append(frequency_dict)\n",
    "    max_frequency_dict_split_documents.append(max(frequency_dict.values()))\n",
    "    \n",
    "    # Calculate document frequency for each unique term in the whole collection\n",
    "    for term in unique_stems:\n",
    "        if term in document_frequency_dict_split:\n",
    "            document_frequency_dict_split[term] += 1\n",
    "        else:\n",
    "            document_frequency_dict_split[term] = 1\n",
    "\n",
    "n_split = len(termes_split)\n",
    "print(len(termes_split))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Large': 1, 'language': 1, 'models': 4, '(LLM)': 1, 'manifested': 1, 'unparalleled': 1, 'modeling': 1, 'capability': 1, 'various': 1, 'tasks,': 1, 'e.g.,': 1, 'multi-step': 1, 'reasoning,': 1, 'input': 1, 'mostly': 1, 'limited': 1, 'plain': 1, 'text,': 1, 'could': 2, 'long': 2, 'contain': 1, 'noisy': 1, 'information.': 1, 'Long': 1, 'text': 1, 'take': 1, 'time': 1, 'process,': 1, 'thus': 1, 'may': 2, 'efficient': 1, 'enough': 1, 'recommender': 1, 'systems': 1, 'require': 1, 'immediate': 1, 'response.': 1, 'LLM-based': 2, 'recommendation': 4, 'models,': 1, 'user': 1, 'item': 1, 'IDs': 3, 'usually': 2, 'filled': 1, 'template': 2, '(i.e.,': 1, 'discrete': 2, 'prompt)': 1, 'allow': 1, 'understand': 1, 'given': 1, 'task,': 1, 'need': 1, 'extensive': 1, 'fine-tuning': 1, 'bridge': 2, 'user/item': 1, 'words': 2, 'unleash': 1, 'power': 1, 'LLM': 1, 'recommendation.': 1, 'address': 1, 'problems,': 1, 'propose': 1, 'distill': 1, 'prompt': 2, 'specific': 1, 'task': 1, 'set': 1, 'continuous': 1, 'vectors': 1, 'reduce': 1, 'inference': 3, 'time.': 1, 'also': 1, 'design': 1, 'training': 3, 'strategy': 1, 'attempt': 1, 'improve': 2, 'efficiency': 4, 'models.': 2, 'Experimental': 1, 'results': 1, 'three': 1, 'real-world': 1, 'datasets': 1, 'demonstrate': 1, 'effectiveness': 1, 'PrOmpt': 1, 'Distillation': 1, '(POD)': 1, 'approach': 1, 'sequential': 1, 'top-N': 1, 'tasks.': 1, 'Although': 1, 'significantly': 1, 'improved,': 1, 'improvement': 1, 'limited.': 1, 'finding': 1, 'inspire': 1, 'researchers': 1, 'community': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(frequency_dict_split_documents[2])\n",
    "len(frequency_dict_split_documents[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ExpReg = nltk.RegexpTokenizer('(?:[A-Za-z]\\.)+|[A-Za-z]+[\\-@]\\d+(?:\\.\\d+)?|\\d+[A-Za-z]+|\\d+(?:[\\.\\,\\-]\\d+)?%?|\\w+(?:[\\-/]\\w+)*') # \\d : équivalent à [0-9] \n",
    "StopWords = nltk.corpus.stopwords.words('english') \n",
    "\n",
    "\n",
    "StopWords = nltk.corpus.stopwords.words('english') \n",
    "\n",
    "# Initialize variables\n",
    "\n",
    "#list that containes the unique terms of each document using regx\n",
    "termes_reg = []\n",
    "\n",
    "#list that containes the unique terms along with their frecuencies of each document using regx\n",
    "frequency_dict_reg_documents = []\n",
    "\n",
    "#list that containes max frequency of each document using split\n",
    "max_frequency_dict_reg_documents = []\n",
    "\n",
    "#list that containes the unique terms along with their frecuencies of all the collection using regx\n",
    "document_frequency_dict_reg = {}\n",
    "\n",
    "\n",
    "\n",
    "# Filtering out stopwords and calculating frequencies in one loop\n",
    "for i in range(6):\n",
    " \n",
    "\n",
    "    unique_stems = list(set([term for term in ExpReg.tokenize(documents[i]) if term.lower() not in StopWords]))\n",
    "    filtered_terms = [term for term in ExpReg.tokenize(documents[i])  if term.lower() not in StopWords]\n",
    "    termes_reg.append(unique_stems)\n",
    "    \n",
    "    # Calculating frequencies of unique_stems\n",
    "  \n",
    "    frequency_dict = frequency(filtered_terms)\n",
    "    frequency_dict_reg_documents.append(frequency_dict)\n",
    "    max_frequency_dict_reg_documents.append(max(frequency_dict.values()))\n",
    "    \n",
    "    # Calculating document frequencies for each unique term in the whole collection\n",
    "    for term in unique_stems:\n",
    "        if term in document_frequency_dict_reg:\n",
    "            document_frequency_dict_reg[term] += 1\n",
    "        else:\n",
    "            document_frequency_dict_reg[term] = 1\n",
    "\n",
    "n_reg = len(termes_reg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Query': 2, 'reformulation': 3, 'well-known': 1, 'problem': 1, 'Information': 2, 'Retrieval': 2, 'IR': 1, 'aimed': 1, 'enhancing': 1, 'single': 1, 'search': 1, 'successful': 1, 'completion': 1, 'rate': 1, 'automatically': 1, 'modifying': 1, 'user': 1, 'input': 1, 'query': 5, 'Recent': 1, 'methods': 1, 'leverage': 1, 'Large': 1, 'Language': 1, 'Models': 1, 'LLMs': 3, 'improve': 1, 'often': 1, 'generate': 2, 'limited': 1, 'redundant': 1, 'expansions': 1, 'potentially': 1, 'constraining': 1, 'effectiveness': 1, 'capturing': 1, 'diverse': 4, 'intents': 3, 'paper': 1, 'propose': 1, 'GenCRF': 3, 'Generative': 1, 'Clustering': 1, 'Reformulation': 1, 'Framework': 1, 'capture': 1, 'intentions': 1, 'adaptively': 1, 'based': 1, 'multiple': 1, 'differentiated': 1, 'well-generated': 1, 'queries': 2, 'retrieval': 2, 'phase': 1, 'first': 1, 'time': 1, 'leverages': 1, 'variable': 1, 'initial': 1, 'using': 1, 'customized': 1, 'prompts': 1, 'clusters': 1, 'groups': 1, 'distinctly': 1, 'represent': 1, 'Furthermore': 1, 'framework': 1, 'explores': 1, 'combine': 1, 'innovative': 1, 'weighted': 1, 'aggregation': 1, 'strategies': 1, 'optimize': 1, 'performance': 3, 'crucially': 1, 'integrates': 1, 'novel': 1, 'Evaluation': 1, 'Rewarding': 1, 'Model': 1, 'QERM': 1, 'refine': 1, 'process': 1, 'feedback': 1, 'loops': 1, 'Empirical': 1, 'experiments': 1, 'BEIR': 1, 'benchmark': 1, 'demonstrate': 1, 'achieves': 1, 'state-of-the-art': 1, 'surpassing': 1, 'previous': 1, 'SOTAs': 1, '12%': 1, 'nDCG@10': 1, 'techniques': 1, 'adapted': 1, 'various': 1, 'significantly': 1, 'boosting': 1, 'retriever': 1, 'advancing': 1, 'field': 1}\n"
     ]
    }
   ],
   "source": [
    "print(frequency_dict_reg_documents[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n"
     ]
    }
   ],
   "source": [
    "termes_split_porter = []\n",
    "termes_reg_porter = []\n",
    "Porter = nltk.PorterStemmer()\n",
    "\n",
    "#list that containes the unique terms along with their frecuencies of each document using split and porter\n",
    "frequency_dict_split_porter_documents = []\n",
    "\n",
    "#list that containes max frequency of each document using split and porter\n",
    "max_frequency_dict_split_porter_documents = []\n",
    "\n",
    "#list that containes the unique terms along with their frecuencies of all the collection using split and porter\n",
    "document_frequency_dict_split_porter = {}\n",
    "\n",
    "#list that containes the unique terms along with their frecuencies of each document using regx and porter\n",
    "frequency_dict_reg_porter_documents = []\n",
    "\n",
    "#list that containes max frequency of each document using regx and porter\n",
    "max_frequency_dict_reg_porter_documents = []\n",
    "\n",
    "#list that containes the unique terms along with their frecuencies of all the collection using regx and porter\n",
    "document_frequency_dict_reg_porter = {}\n",
    "\n",
    "for i in range(6):\n",
    "    # Stemming and keeping only unique terms for `termes_split_porter`\n",
    "    unique_stems = list(set([Porter.stem(terme) for terme in termes_split[i]]))\n",
    "    termes_split_porter.append(unique_stems)\n",
    "    \n",
    "    # Calculating frequencies of unique_stems\n",
    "    filtered_terms = [Porter.stem(terme) for terme in termes_split[i]]\n",
    "    frequency_dict = frequency(filtered_terms)\n",
    "    frequency_dict_split_porter_documents.append(frequency_dict)\n",
    "    max_frequency_dict_split_porter_documents.append(max(frequency_dict.values()))\n",
    "    \n",
    "    # Calculate document frequency for each unique term in the whole collection\n",
    "    for term in unique_stems:\n",
    "        if term in document_frequency_dict_split_porter:\n",
    "            document_frequency_dict_split_porter[term] += 1\n",
    "        else:\n",
    "            document_frequency_dict_split_porter[term] = 1\n",
    "   \n",
    "\n",
    "    # Stemming and keeping only unique terms for `termes_reg_porter`\n",
    "    unique_stems = list(set([Porter.stem(terme) for terme in termes_reg[i]]))\n",
    "    termes_reg_porter.append(unique_stems)\n",
    "    \n",
    "    # Calculating frequencies of unique_stems\n",
    "    filtered_terms = [Porter.stem(terme) for terme in termes_reg[i]]\n",
    "    frequency_dict = frequency(filtered_terms)\n",
    "    frequency_dict_reg_porter_documents.append(frequency_dict)\n",
    "    max_frequency_dict_reg_porter_documents.append(max(frequency_dict.values()))\n",
    "    \n",
    "    # Calculate document frequency for each unique term\n",
    "    for term in unique_stems:\n",
    "        if term in document_frequency_dict_reg_porter:\n",
    "            document_frequency_dict_reg_porter[term] += 1\n",
    "        else:\n",
    "            document_frequency_dict_reg_porter[term] = 1\n",
    "   \n",
    "        \n",
    "print(len(frequency_dict_reg_porter_documents[3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': 1,\n",
       " 'usual': 1,\n",
       " 'pod': 1,\n",
       " 'model': 2,\n",
       " 'design': 1,\n",
       " 'thu': 1,\n",
       " 'strategi': 1,\n",
       " 'attempt': 1,\n",
       " 'prompt': 2,\n",
       " 'commun': 1,\n",
       " 'demonstr': 1,\n",
       " 'extens': 1,\n",
       " 'templat': 1,\n",
       " 'item': 1,\n",
       " 'may': 1,\n",
       " 'e.g.': 1,\n",
       " 'requir': 1,\n",
       " 'experiment': 1,\n",
       " 'specif': 1,\n",
       " 'limit': 1,\n",
       " 'recommend': 2,\n",
       " 'plain': 1,\n",
       " 'distil': 2,\n",
       " 'take': 1,\n",
       " 'enough': 1,\n",
       " 'user/item': 1,\n",
       " 'long': 2,\n",
       " 'manifest': 1,\n",
       " 'approach': 1,\n",
       " 'effect': 1,\n",
       " 'find': 1,\n",
       " 'reduc': 1,\n",
       " 'system': 1,\n",
       " 'research': 1,\n",
       " 'contain': 1,\n",
       " 'understand': 1,\n",
       " 'multi-step': 1,\n",
       " 'although': 1,\n",
       " 'result': 1,\n",
       " 'variou': 1,\n",
       " 'problem': 1,\n",
       " 'noisi': 1,\n",
       " 'i.e.': 1,\n",
       " 'input': 1,\n",
       " 'power': 1,\n",
       " 'improv': 3,\n",
       " 'larg': 1,\n",
       " 'effici': 2,\n",
       " 'sequenti': 1,\n",
       " 'fine-tun': 1,\n",
       " 'llm-base': 1,\n",
       " 'discret': 1,\n",
       " 'significantli': 1,\n",
       " 'inspir': 1,\n",
       " 'need': 1,\n",
       " 'three': 1,\n",
       " 'train': 1,\n",
       " 'llm': 1,\n",
       " 'also': 1,\n",
       " 'set': 1,\n",
       " 'time': 1,\n",
       " 'unparallel': 1,\n",
       " 'fill': 1,\n",
       " 'given': 1,\n",
       " 'propos': 1,\n",
       " 'task': 2,\n",
       " 'respons': 1,\n",
       " 'user': 1,\n",
       " 'allow': 1,\n",
       " 'id': 1,\n",
       " 'top-n': 1,\n",
       " 'inform': 1,\n",
       " 'word': 1,\n",
       " 'vector': 1,\n",
       " 'process': 1,\n",
       " 'could': 1,\n",
       " 'text': 1,\n",
       " 'address': 1,\n",
       " 'real-world': 1,\n",
       " 'continu': 1,\n",
       " 'bridg': 1,\n",
       " 'unleash': 1,\n",
       " 'mostli': 1,\n",
       " 'reason': 1,\n",
       " 'capabl': 1,\n",
       " 'infer': 1,\n",
       " 'immedi': 1,\n",
       " 'languag': 1}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency_dict_reg_porter_documents[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n"
     ]
    }
   ],
   "source": [
    "termes_split_lancaster = []\n",
    "termes_reg_lancaster = []\n",
    "Lancaster = nltk.LancasterStemmer() \n",
    "\n",
    "\n",
    "#list that containes the unique terms along with their frecuencies of each document using split and lancaster\n",
    "frequency_dict_split_lancaster_documents = []\n",
    "\n",
    "#list that containes max frequency of each document using split and lancaster\n",
    "max_frequency_dict_split_lancaster_documents = []\n",
    "\n",
    "#list that containes the unique terms along with their frecuencies of all the collection using split and lancaster\n",
    "document_frequency_dict_split_lancaster = {}\n",
    "\n",
    "#list that containes the unique terms along with their frecuencies of each document using regx and lancaster\n",
    "frequency_dict_reg_lancaster_documents = []\n",
    "\n",
    "#list that containes max frequency of each document using regx and lancaster\n",
    "max_frequency_dict_reg_lancaster_documents = []\n",
    "\n",
    "#list that containes the unique terms along with their frecuencies of all the collection using regx and lancaster\n",
    "document_frequency_dict_reg_lancaster = {}\n",
    "\n",
    "\n",
    "for i in range(6):\n",
    "    # Stemming and keeping only unique terms for `termes_split_lancaster`\n",
    "    unique_stems = list(set([Lancaster.stem(terme) for terme in termes_split[i]]))\n",
    "    termes_split_lancaster.append(unique_stems)\n",
    "    \n",
    "    # Calculating frequencies of unique_stems\n",
    "    filtered_terms = [Lancaster.stem(terme) for terme in termes_split[i]]\n",
    "    frequency_dict = frequency(filtered_terms)\n",
    "    frequency_dict_split_lancaster_documents.append(frequency_dict)\n",
    "    max_frequency_dict_split_lancaster_documents.append(max(frequency_dict.values()))\n",
    "    \n",
    "    # Calculate document frequency for each unique term\n",
    "    for term in unique_stems:\n",
    "        if term in document_frequency_dict_split_lancaster:\n",
    "            document_frequency_dict_split_lancaster[term] += 1\n",
    "        else:\n",
    "            document_frequency_dict_split_lancaster[term] = 1\n",
    "   \n",
    "\n",
    "    # Stemming and keeping only unique terms for `termes_reg_lancaster`\n",
    "    unique_stems = list(set([Lancaster.stem(terme) for terme in termes_reg[i]]))\n",
    "    termes_reg_lancaster.append(unique_stems)\n",
    "    \n",
    "    # Calculating frequencies of unique_stems\n",
    "    filtered_terms = [Lancaster.stem(terme)for terme in termes_reg[i]]\n",
    "    frequency_dict = frequency(filtered_terms)\n",
    "    frequency_dict_reg_lancaster_documents.append(frequency_dict)\n",
    "    max_frequency_dict_reg_lancaster_documents.append(max(frequency_dict.values()))\n",
    "    \n",
    "    # Calculate document frequency for each unique term in the whole collection\n",
    "    for term in unique_stems:\n",
    "        if term in document_frequency_dict_reg_lancaster:\n",
    "            document_frequency_dict_reg_lancaster[term] += 1\n",
    "        else:\n",
    "            document_frequency_dict_reg_lancaster[term] = 1\n",
    "   \n",
    "        \n",
    "print(len(frequency_dict_reg_lancaster_documents[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'capt': 2,\n",
       " 'differenty': 1,\n",
       " 'limit': 1,\n",
       " 'vary': 2,\n",
       " 'process': 1,\n",
       " 'lev': 2,\n",
       " 'redund': 1,\n",
       " 'beir': 1,\n",
       " 'larg': 1,\n",
       " 'adapt': 2,\n",
       " 'model': 2,\n",
       " 'well-generated': 1,\n",
       " 'bas': 1,\n",
       " 'expery': 1,\n",
       " 'distinct': 1,\n",
       " 'method': 1,\n",
       " 'improv': 1,\n",
       " 'feedback': 1,\n",
       " 'weight': 1,\n",
       " 'framework': 2,\n",
       " 'refin': 1,\n",
       " 'reform': 2,\n",
       " 'phas': 1,\n",
       " 'retriev': 3,\n",
       " 'int': 2,\n",
       " 'mod': 1,\n",
       " 'pap': 1,\n",
       " 'reward': 1,\n",
       " 'pot': 1,\n",
       " 'inform': 1,\n",
       " 'langu': 1,\n",
       " 'propos': 1,\n",
       " 'effect': 1,\n",
       " 'demonst': 1,\n",
       " 'integr': 1,\n",
       " 'multipl': 1,\n",
       " 'empir': 1,\n",
       " 'rec': 1,\n",
       " 'clust': 2,\n",
       " 'gencrf': 1,\n",
       " 'llms': 1,\n",
       " 'singl': 1,\n",
       " 'prevy': 1,\n",
       " 'complet': 1,\n",
       " 'boost': 1,\n",
       " 'query': 3,\n",
       " 'us': 2,\n",
       " 'success': 1,\n",
       " 'expl': 1,\n",
       " 'aggreg': 1,\n",
       " 'group': 1,\n",
       " 'rat': 1,\n",
       " 'furtherm': 1,\n",
       " 'adv': 1,\n",
       " 'ir': 1,\n",
       " 'qerm': 1,\n",
       " 'oft': 1,\n",
       " 'custom': 1,\n",
       " 'surpass': 1,\n",
       " 'repres': 1,\n",
       " 'loop': 1,\n",
       " 'evalu': 1,\n",
       " 'ndcg@10': 1,\n",
       " '12%': 1,\n",
       " 'well-known': 1,\n",
       " 'first': 1,\n",
       " 'perform': 1,\n",
       " 'sota': 1,\n",
       " 'field': 1,\n",
       " 'enh': 1,\n",
       " 'gen': 2,\n",
       " 'aim': 1,\n",
       " 'achiev': 1,\n",
       " 'sign': 1,\n",
       " 'input': 1,\n",
       " 'constrain': 1,\n",
       " 'autom': 1,\n",
       " 'tim': 1,\n",
       " 'novel': 1,\n",
       " 'optim': 1,\n",
       " 'state-of-the-art': 1,\n",
       " 'expand': 1,\n",
       " 'search': 1,\n",
       " 'prompt': 1,\n",
       " 'divers': 1,\n",
       " 'combin': 1,\n",
       " 'init': 1,\n",
       " 'cruc': 1,\n",
       " 'benchmark': 1,\n",
       " 'problem': 1,\n",
       " 'innov': 1,\n",
       " 'techn': 1,\n",
       " 'strategies': 1}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency_dict_reg_lancaster_documents[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description file creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  inspiration  1 0.28169934667141894\n",
      "1  Passage  1 0.28169934667141894\n",
      "1  18%  1 0.28169934667141894\n",
      "1  taking  1 0.28169934667141894\n",
      "1  sets  1 0.28169934667141894\n",
      "1  intent  1 0.28169934667141894\n",
      "1  improvements  2 0.5633986933428379\n",
      "1  retrieval  1 0.20068666377598746\n",
      "1  QR  1 0.28169934667141894\n",
      "1  Ranking  1 0.20068666377598746\n",
      "1  used  1 0.15904041823988746\n",
      "1  leverages  1 0.20068666377598746\n",
      "1  incorporate  1 0.28169934667141894\n",
      "1  technique,  1 0.28169934667141894\n",
      "1  5%  1 0.28169934667141894\n",
      "1  MRR  1 0.28169934667141894\n",
      "1  paraphrases  1 0.28169934667141894\n",
      "1  prompting  2 0.4013733275519749\n",
      "1  nDCG@10  2 0.5633986933428379\n",
      "1  query  2 0.3180808364797749\n",
      "1  pseudo  1 0.28169934667141894\n",
      "1  shown  1 0.28169934667141894\n",
      "1  introduce  1 0.20068666377598746\n",
      "1  shows  1 0.28169934667141894\n",
      "1  strategies  1 0.15904041823988746\n",
      "1  GenQREnsembleRF  2 0.5633986933428379\n",
      "1  evaluations  1 0.28169934667141894\n",
      "1  approach  1 0.15904041823988746\n",
      "1  generate  1 0.15904041823988746\n",
      "1  based  1 0.15904041823988746\n",
      "1  inherent  1 0.28169934667141894\n",
      "1  GenQREnsemble  2 0.5633986933428379\n",
      "1  user’s  2 0.5633986933428379\n",
      "1  post-retrieval  1 0.28169934667141894\n",
      "1  performance.  1 0.28169934667141894\n",
      "1  state-of-art.  1 0.28169934667141894\n",
      "1  large  1 0.28169934667141894\n",
      "1  four  1 0.28169934667141894\n",
      "1  tasks,  1 0.15904041823988746\n",
      "1  success  1 0.28169934667141894\n",
      "1  aligns  1 0.28169934667141894\n",
      "1  improving  1 0.28169934667141894\n",
      "1  24%  1 0.28169934667141894\n",
      "1  transform  1 0.28169934667141894\n",
      "1  documents.  1 0.28169934667141894\n",
      "1  relative  2 0.5633986933428379\n",
      "1  benchmarks,  1 0.28169934667141894\n",
      "1  previous  1 0.15904041823988746\n",
      "1  experience.  1 0.28169934667141894\n",
      "1  find  1 0.28169934667141894\n",
      "1  feedback,  1 0.28169934667141894\n",
      "1  multiple  1 0.15904041823988746\n",
      "1  Query  1 0.20068666377598746\n",
      "1  set  1 0.15904041823988746\n",
      "1  reformulation.  1 0.28169934667141894\n",
      "1  propose  1 0.1141408936074021\n",
      "1  ensemble  2 0.5633986933428379\n",
      "1  9%  1 0.28169934667141894\n",
      "1  MSMarco  1 0.28169934667141894\n",
      "1  feedback  1 0.20068666377598746\n",
      "1  using  2 0.2282817872148042\n",
      "1  pseudo-relevance  1 0.28169934667141894\n",
      "1  due  1 0.28169934667141894\n",
      "1  context,  1 0.28169934667141894\n",
      "1  gains  1 0.28169934667141894\n",
      "1  ability  1 0.20068666377598746\n",
      "1  original  1 0.28169934667141894\n",
      "1  reformulations  1 0.28169934667141894\n",
      "1  exploit  1 0.28169934667141894\n",
      "1  relevant  2 0.5633986933428379\n",
      "1  benefited  1 0.28169934667141894\n",
      "1  improve  1 0.13264666955734586\n",
      "1  text  1 0.20068666377598746\n",
      "1  Recently,  1 0.28169934667141894\n",
      "1  knowledge  1 0.28169934667141894\n",
      "1  MAP  1 0.28169934667141894\n",
      "1  investigate  1 0.28169934667141894\n",
      "1  feedback.  1 0.28169934667141894\n",
      "1  generates  1 0.28169934667141894\n",
      "1  upto  1 0.28169934667141894\n",
      "1  promising  1 0.28169934667141894\n",
      "1  Reformulation(QR)  1 0.28169934667141894\n",
      "1  task,  1 0.20068666377598746\n",
      "1  ultimately  1 0.28169934667141894\n",
      "1  many  1 0.28169934667141894\n",
      "1  search  2 0.3180808364797749\n",
      "1  variant,  1 0.28169934667141894\n",
      "1  improves  1 0.28169934667141894\n",
      "1  zero-shot  3 0.8450980400142568\n",
      "1  models.  1 0.20068666377598746\n",
      "1  better  2 0.5633986933428379\n",
      "1  techniques  1 0.20068666377598746\n",
      "1  instruction  1 0.20068666377598746\n",
      "1  language  1 0.13264666955734586\n",
      "1  IR  1 0.28169934667141894\n",
      "1  help  1 0.28169934667141894\n",
      "1  keywords  1 0.28169934667141894\n",
      "2  possible  1 0.2112745100035642\n",
      "2  open-sourced  1 0.1505149978319906\n",
      "2  GPT-4  1 0.2112745100035642\n",
      "2  complexity  1 0.2112745100035642\n",
      "2  Ranking  2 0.3010299956639812\n",
      "2  analyze  1 0.2112745100035642\n",
      "2  template  1 0.1505149978319906\n",
      "2  used  1 0.11928031367991561\n",
      "2  rankers  1 0.2112745100035642\n",
      "2  called  1 0.2112745100035642\n",
      "2  standard  1 0.2112745100035642\n",
      "2  Models  1 0.0994850021680094\n",
      "2  moderate-sized  1 0.2112745100035642\n",
      "2  performs  1 0.2112745100035642\n",
      "2  formulations.  1 0.2112745100035642\n",
      "2  outperform  1 0.2112745100035642\n",
      "2  literature  1 0.2112745100035642\n",
      "2  even  1 0.2112745100035642\n",
      "2  documents  2 0.4225490200071284\n",
      "2  query  1 0.11928031367991561\n",
      "2  technique  1 0.2112745100035642\n",
      "2  baselines  1 0.2112745100035642\n",
      "2  10%  1 0.2112745100035642\n",
      "2  Flan-UL2  1 0.2112745100035642\n",
      "2  state-of-the-art  1 0.1505149978319906\n",
      "2  solution  1 0.2112745100035642\n",
      "2  found  1 0.2112745100035642\n",
      "2  prompt  2 0.3010299956639812\n",
      "2  outperforming  1 0.2112745100035642\n",
      "2  problem.  1 0.2112745100035642\n",
      "2  existing  1 0.2112745100035642\n",
      "2  favorably  1 0.2112745100035642\n",
      "2  directly  1 0.2112745100035642\n",
      "2  several  1 0.2112745100035642\n",
      "2  argue  1 0.2112745100035642\n",
      "2  approach  1 0.11928031367991561\n",
      "2  supervised  1 0.2112745100035642\n",
      "2  based  2 0.23856062735983122\n",
      "2  average  1 0.2112745100035642\n",
      "2  commercial  2 0.4225490200071284\n",
      "2  ChatGPT  1 0.2112745100035642\n",
      "2  reduce  1 0.1505149978319906\n",
      "2  researchers  1 0.1505149978319906\n",
      "2  understand  1 0.1505149978319906\n",
      "2  4.2%  1 0.2112745100035642\n",
      "2  variants  1 0.2112745100035642\n",
      "2  results  2 0.1989700043360188\n",
      "2  performance  1 0.1505149978319906\n",
      "2  burden  1 0.2112745100035642\n",
      "2  TREC-DL  1 0.2112745100035642\n",
      "2  achieve  2 0.3010299956639812\n",
      "2  Furthermore,  1 0.1505149978319906\n",
      "2  tasks,  1 0.11928031367991561\n",
      "2  20B  1 0.2112745100035642\n",
      "2  Large  1 0.08560567020555157\n",
      "2  efficiency  1 0.1505149978319906\n",
      "2  off-the-shelf  1 0.2112745100035642\n",
      "2  benchmarks  1 0.2112745100035642\n",
      "2  LLM-based  2 0.23856062735983122\n",
      "2  (LLMs)  1 0.1505149978319906\n",
      "2  significantly  1 0.11928031367991561\n",
      "2  feeding  1 0.2112745100035642\n",
      "2  previous  1 0.11928031367991561\n",
      "2  LLMs.  1 0.1505149978319906\n",
      "2  benchmark  1 0.11928031367991561\n",
      "2  parameters  1 0.2112745100035642\n",
      "2  paper,  1 0.0994850021680094\n",
      "2  model  2 0.4225490200071284\n",
      "2  Pairwise  1 0.2112745100035642\n",
      "2  baseline  1 0.2112745100035642\n",
      "2  methods  1 0.1505149978319906\n",
      "2  propose  2 0.17121134041110314\n",
      "2  show  1 0.2112745100035642\n",
      "2  literature,  1 0.2112745100035642\n",
      "2  fully  1 0.2112745100035642\n",
      "2  12-10%  1 0.2112745100035642\n",
      "2  (PRP).  1 0.2112745100035642\n",
      "2  2019  1 0.2112745100035642\n",
      "2  2020,  1 0.2112745100035642\n",
      "2  metrics.  1 0.1505149978319906\n",
      "2  using  4 0.3424226808222063\n",
      "2  175B  1 0.2112745100035642\n",
      "2  parameters,  1 0.2112745100035642\n",
      "2  Prompting  1 0.2112745100035642\n",
      "2  (estimated)  1 0.2112745100035642\n",
      "2  size,  1 0.2112745100035642\n",
      "2  datasets.  1 0.2112745100035642\n",
      "2  listwise  1 0.2112745100035642\n",
      "2  interesting  1 0.2112745100035642\n",
      "2  blackbox  2 0.4225490200071284\n",
      "2  InstructGPT  1 0.2112745100035642\n",
      "2  solutions  1 0.2112745100035642\n",
      "2  difficult  1 0.2112745100035642\n",
      "2  improve  1 0.0994850021680094\n",
      "2  prompts  1 0.2112745100035642\n",
      "2  outperforms  2 0.4225490200071284\n",
      "2  best  1 0.2112745100035642\n",
      "2  ranking  4 0.8450980400142568\n",
      "2  pointwise  2 0.4225490200071284\n",
      "2  challenging  1 0.2112745100035642\n",
      "2  competitive  1 0.2112745100035642\n",
      "2  candidate  1 0.2112745100035642\n",
      "2  BEIR  1 0.1505149978319906\n",
      "2  NDCG@10.  1 0.2112745100035642\n",
      "2  solutions,  1 0.2112745100035642\n",
      "2  However,  1 0.2112745100035642\n",
      "2  50x  1 0.2112745100035642\n",
      "2  PRP  3 0.6338235300106926\n",
      "2  linear  1 0.2112745100035642\n",
      "2  first  1 0.11928031367991561\n",
      "2  practical  1 0.2112745100035642\n",
      "2  seven  1 0.2112745100035642\n",
      "2  new  1 0.2112745100035642\n",
      "2  LLMs  2 0.1989700043360188\n",
      "2  fine-tuned  1 0.2112745100035642\n",
      "2  Language  1 0.0994850021680094\n",
      "3  datasets  1 0.2112745100035642\n",
      "3  process,  1 0.1505149978319906\n",
      "3  usually  2 0.4225490200071284\n",
      "3  models  4 0.8450980400142568\n",
      "3  design  1 0.2112745100035642\n",
      "3  thus  1 0.2112745100035642\n",
      "3  strategy  1 0.2112745100035642\n",
      "3  attempt  1 0.2112745100035642\n",
      "3  PrOmpt  1 0.2112745100035642\n",
      "3  community  1 0.2112745100035642\n",
      "3  demonstrate  1 0.1505149978319906\n",
      "3  extensive  1 0.2112745100035642\n",
      "3  template  2 0.3010299956639812\n",
      "3  item  1 0.1505149978319906\n",
      "3  may  2 0.4225490200071284\n",
      "3  require  1 0.2112745100035642\n",
      "3  Experimental  1 0.2112745100035642\n",
      "3  specific  1 0.2112745100035642\n",
      "3  limited  1 0.1505149978319906\n",
      "3  tasks.  1 0.1505149978319906\n",
      "3  (i.e.,  1 0.2112745100035642\n",
      "3  recommender  1 0.2112745100035642\n",
      "3  plain  1 0.2112745100035642\n",
      "3  distill  1 0.2112745100035642\n",
      "3  take  1 0.1505149978319906\n",
      "3  prompt  2 0.3010299956639812\n",
      "3  enough  1 0.2112745100035642\n",
      "3  limited.  1 0.2112745100035642\n",
      "3  user/item  1 0.2112745100035642\n",
      "3  long  2 0.4225490200071284\n",
      "3  manifested  1 0.2112745100035642\n",
      "3  approach  1 0.11928031367991561\n",
      "3  effectiveness  1 0.1505149978319906\n",
      "3  finding  1 0.2112745100035642\n",
      "3  reduce  1 0.1505149978319906\n",
      "3  systems  1 0.2112745100035642\n",
      "3  researchers  1 0.1505149978319906\n",
      "3  contain  1 0.2112745100035642\n",
      "3  (POD)  1 0.2112745100035642\n",
      "3  understand  1 0.1505149978319906\n",
      "3  multi-step  1 0.2112745100035642\n",
      "3  time.  1 0.1505149978319906\n",
      "3  Although  1 0.2112745100035642\n",
      "3  results  1 0.0994850021680094\n",
      "3  various  1 0.1505149978319906\n",
      "3  Long  1 0.2112745100035642\n",
      "3  noisy  1 0.2112745100035642\n",
      "3  tasks,  1 0.11928031367991561\n",
      "3  Distillation  1 0.2112745100035642\n",
      "3  input  1 0.1505149978319906\n",
      "3  power  1 0.1505149978319906\n",
      "3  improvement  1 0.2112745100035642\n",
      "3  Large  1 0.08560567020555157\n",
      "3  efficiency  4 0.6020599913279624\n",
      "3  sequential  1 0.1505149978319906\n",
      "3  fine-tuning  1 0.2112745100035642\n",
      "3  LLM-based  2 0.23856062735983122\n",
      "3  discrete  2 0.4225490200071284\n",
      "3  significantly  1 0.11928031367991561\n",
      "3  inspire  1 0.2112745100035642\n",
      "3  models,  1 0.2112745100035642\n",
      "3  need  1 0.2112745100035642\n",
      "3  three  1 0.2112745100035642\n",
      "3  training  3 0.6338235300106926\n",
      "3  LLM  1 0.2112745100035642\n",
      "3  also  1 0.1505149978319906\n",
      "3  set  1 0.11928031367991561\n",
      "3  time  1 0.2112745100035642\n",
      "3  unparalleled  1 0.2112745100035642\n",
      "3  information.  1 0.2112745100035642\n",
      "3  filled  1 0.2112745100035642\n",
      "3  given  1 0.1505149978319906\n",
      "3  propose  1 0.08560567020555157\n",
      "3  response.  1 0.2112745100035642\n",
      "3  task  1 0.1505149978319906\n",
      "3  user  1 0.2112745100035642\n",
      "3  allow  1 0.2112745100035642\n",
      "3  IDs  3 0.6338235300106926\n",
      "3  prompt)  1 0.2112745100035642\n",
      "3  recommendation.  1 0.2112745100035642\n",
      "3  problems,  1 0.2112745100035642\n",
      "3  top-N  1 0.2112745100035642\n",
      "3  words  2 0.4225490200071284\n",
      "3  vectors  1 0.2112745100035642\n",
      "3  improve  2 0.1989700043360188\n",
      "3  could  2 0.4225490200071284\n",
      "3  text  1 0.1505149978319906\n",
      "3  address  1 0.2112745100035642\n",
      "3  real-world  1 0.2112745100035642\n",
      "3  continuous  1 0.2112745100035642\n",
      "3  recommendation  4 0.6020599913279624\n",
      "3  bridge  2 0.4225490200071284\n",
      "3  unleash  1 0.2112745100035642\n",
      "3  e.g.,  1 0.2112745100035642\n",
      "3  mostly  1 0.2112745100035642\n",
      "3  task,  1 0.1505149978319906\n",
      "3  reasoning,  1 0.2112745100035642\n",
      "3  efficient  1 0.2112745100035642\n",
      "3  modeling  1 0.1505149978319906\n",
      "3  improved,  1 0.2112745100035642\n",
      "3  models.  2 0.3010299956639812\n",
      "3  capability  1 0.2112745100035642\n",
      "3  text,  1 0.2112745100035642\n",
      "3  (LLM)  1 0.2112745100035642\n",
      "3  inference  3 0.6338235300106926\n",
      "3  immediate  1 0.2112745100035642\n",
      "3  language  1 0.0994850021680094\n",
      "4  explores  1 0.2112745100035642\n",
      "4  retriever  1 0.2112745100035642\n",
      "4  initial  1 0.2112745100035642\n",
      "4  completion  1 0.2112745100035642\n",
      "4  SOTAs  1 0.2112745100035642\n",
      "4  demonstrate  1 0.1505149978319906\n",
      "4  retrieval  2 0.3010299956639812\n",
      "4  leverages  1 0.1505149978319906\n",
      "4  nDCG@10.  1 0.2112745100035642\n",
      "4  Clustering  1 0.2112745100035642\n",
      "4  Model  1 0.2112745100035642\n",
      "4  represent  1 0.2112745100035642\n",
      "4  Models  1 0.0994850021680094\n",
      "4  limited  1 0.1505149978319906\n",
      "4  rate  1 0.2112745100035642\n",
      "4  Generative  1 0.2112745100035642\n",
      "4  problem  1 0.2112745100035642\n",
      "4  query  4 0.47712125471966244\n",
      "4  experiments  1 0.2112745100035642\n",
      "4  state-of-the-art  1 0.1505149978319906\n",
      "4  automatically  1 0.2112745100035642\n",
      "4  strategies  1 0.11928031367991561\n",
      "4  customized  1 0.2112745100035642\n",
      "4  combine  1 0.2112745100035642\n",
      "4  Reformulation  1 0.2112745100035642\n",
      "4  distinctly  1 0.2112745100035642\n",
      "4  boosting  1 0.2112745100035642\n",
      "4  leverage  1 0.2112745100035642\n",
      "4  capturing  1 0.1505149978319906\n",
      "4  generate  2 0.23856062735983122\n",
      "4  based  1 0.11928031367991561\n",
      "4  effectiveness  1 0.1505149978319906\n",
      "4  capture  1 0.1505149978319906\n",
      "4  surpassing  1 0.2112745100035642\n",
      "4  time.  1 0.1505149978319906\n",
      "4  various  1 0.1505149978319906\n",
      "4  performance  2 0.3010299956639812\n",
      "4  expansions,  1 0.2112745100035642\n",
      "4  novel  1 0.1505149978319906\n",
      "4  reformulation  2 0.4225490200071284\n",
      "4  Furthermore,  1 0.1505149978319906\n",
      "4  advancing  1 0.2112745100035642\n",
      "4  (QERM)  1 0.2112745100035642\n",
      "4  query.  1 0.2112745100035642\n",
      "4  Empirical  1 0.2112745100035642\n",
      "4  input  1 0.1505149978319906\n",
      "4  Large  1 0.08560567020555157\n",
      "4  successful  1 0.2112745100035642\n",
      "4  crucially  1 0.2112745100035642\n",
      "4  performance,  1 0.2112745100035642\n",
      "4  refine  1 0.2112745100035642\n",
      "4  well-generated  1 0.2112745100035642\n",
      "4  (LLMs)  1 0.1505149978319906\n",
      "4  adaptively  1 0.2112745100035642\n",
      "4  Framework  1 0.2112745100035642\n",
      "4  significantly  1 0.11928031367991561\n",
      "4  field  1 0.2112745100035642\n",
      "4  LLMs,  1 0.2112745100035642\n",
      "4  Retrieval.  1 0.2112745100035642\n",
      "4  intents.  2 0.4225490200071284\n",
      "4  previous  1 0.11928031367991561\n",
      "4  single  1 0.2112745100035642\n",
      "4  variable  1 0.2112745100035642\n",
      "4  Evaluation  1 0.2112745100035642\n",
      "4  benchmark  1 0.11928031367991561\n",
      "4  12%  1 0.2112745100035642\n",
      "4  Information  2 0.4225490200071284\n",
      "4  adapted  1 0.2112745100035642\n",
      "4  multiple  1 0.11928031367991561\n",
      "4  Query  2 0.3010299956639812\n",
      "4  queries  2 0.3010299956639812\n",
      "4  weighted  1 0.2112745100035642\n",
      "4  paper,  1 0.0994850021680094\n",
      "4  groups  1 0.2112745100035642\n",
      "4  differentiated,  1 0.2112745100035642\n",
      "4  phase  1 0.2112745100035642\n",
      "4  framework  1 0.2112745100035642\n",
      "4  methods  1 0.1505149978319906\n",
      "4  propose  1 0.08560567020555157\n",
      "4  constraining  1 0.2112745100035642\n",
      "4  feedback  1 0.1505149978319906\n",
      "4  using  1 0.08560567020555157\n",
      "4  enhancing  1 0.2112745100035642\n",
      "4  Rewarding  1 0.2112745100035642\n",
      "4  aggregation  1 0.2112745100035642\n",
      "4  intentions  1 0.2112745100035642\n",
      "4  user's  1 0.1505149978319906\n",
      "4  achieves  1 0.2112745100035642\n",
      "4  GenCRF  2 0.4225490200071284\n",
      "4  reformulation,  1 0.2112745100035642\n",
      "4  improve  1 0.0994850021680094\n",
      "4  process  1 0.2112745100035642\n",
      "4  aimed  1 0.2112745100035642\n",
      "4  integrates  1 0.2112745100035642\n",
      "4  intents  1 0.2112745100035642\n",
      "4  (IR)  1 0.2112745100035642\n",
      "4  loops.  1 0.2112745100035642\n",
      "4  well-known  1 0.2112745100035642\n",
      "4  potentially  1 0.2112745100035642\n",
      "4  BEIR  1 0.1505149978319906\n",
      "4  often  1 0.2112745100035642\n",
      "4  Recent  1 0.2112745100035642\n",
      "4  GenCRF:  1 0.2112745100035642\n",
      "4  first  1 0.11928031367991561\n",
      "4  Retrieval  1 0.2112745100035642\n",
      "4  search  1 0.11928031367991561\n",
      "4  diverse  4 0.8450980400142568\n",
      "4  prompts,  1 0.2112745100035642\n",
      "4  redundant  1 0.2112745100035642\n",
      "4  modifying  1 0.2112745100035642\n",
      "4  LLMs  1 0.0994850021680094\n",
      "4  techniques  1 0.1505149978319906\n",
      "4  clusters  1 0.2112745100035642\n",
      "4  optimize  1 0.2112745100035642\n",
      "4  innovative  1 0.2112745100035642\n",
      "4  Language  1 0.0994850021680094\n",
      "5  Ranker  1 0.28169934667141894\n",
      "5  history,  1 0.28169934667141894\n",
      "5  corpora,  1 0.28169934667141894\n",
      "5  graph-based  1 0.28169934667141894\n",
      "5  process,  1 0.20068666377598746\n",
      "5  complex  1 0.28169934667141894\n",
      "5  structures  1 0.28169934667141894\n",
      "5  bridges  1 0.28169934667141894\n",
      "5  interactive  1 0.28169934667141894\n",
      "5  (SGR),  1 0.28169934667141894\n",
      "5  interaction  1 0.28169934667141894\n",
      "5  format.  1 0.28169934667141894\n",
      "5  contrastive  1 0.28169934667141894\n",
      "5  inputs  1 0.28169934667141894\n",
      "5  Models  1 0.13264666955734586\n",
      "5  actions  1 0.28169934667141894\n",
      "5  LLMs'  1 0.28169934667141894\n",
      "5  modern  1 0.28169934667141894\n",
      "5  documents,  1 0.28169934667141894\n",
      "5  Moreover,  1 0.28169934667141894\n",
      "5  objective  1 0.28169934667141894\n",
      "5  prioritize  1 0.28169934667141894\n",
      "5  generative  1 0.28169934667141894\n",
      "5  introduce  2 0.4013733275519749\n",
      "5  Current  1 0.28169934667141894\n",
      "5  take  1 0.20068666377598746\n",
      "5  strategies  2 0.3180808364797749\n",
      "5  natural  1 0.20068666377598746\n",
      "5  information,  1 0.28169934667141894\n",
      "5  effective  1 0.28169934667141894\n",
      "5  this,  1 0.28169934667141894\n",
      "5  approaches  2 0.5633986933428379\n",
      "5  structural  1 0.28169934667141894\n",
      "5  generalized  1 0.28169934667141894\n",
      "5  capturing  1 0.20068666377598746\n",
      "5  graph-to-text  1 0.28169934667141894\n",
      "5  focus  1 0.28169934667141894\n",
      "5  aims  1 0.28169934667141894\n",
      "5  grammar,  1 0.28169934667141894\n",
      "5  datasets,  1 0.28169934667141894\n",
      "5  capture  2 0.4013733275519749\n",
      "5  AOL  1 0.28169934667141894\n",
      "5  need.  1 0.28169934667141894\n",
      "5  produce  1 0.28169934667141894\n",
      "5  pre-trained  1 0.28169934667141894\n",
      "5  results  1 0.13264666955734586\n",
      "5  allows  1 0.28169934667141894\n",
      "5  recent  1 0.20068666377598746\n",
      "5  novel  1 0.20068666377598746\n",
      "5  two  1 0.28169934667141894\n",
      "5  (LLMs).  1 0.28169934667141894\n",
      "5  achieve  1 0.20068666377598746\n",
      "5  link  1 0.28169934667141894\n",
      "5  confirm  1 0.28169934667141894\n",
      "5  use  1 0.20068666377598746\n",
      "5  modeling.  1 0.28169934667141894\n",
      "5  power  1 0.20068666377598746\n",
      "5  discrepancy  1 0.28169934667141894\n",
      "5  learning,  1 0.28169934667141894\n",
      "5  Large  1 0.1141408936074021\n",
      "5  sequential  1 0.20068666377598746\n",
      "5  leveraging  1 0.28169934667141894\n",
      "5  paradigm  1 0.28169934667141894\n",
      "5  self-supervised  1 0.28169934667141894\n",
      "5  prediction,  1 0.28169934667141894\n",
      "5  representation  1 0.28169934667141894\n",
      "5  benchmark  1 0.15904041823988746\n",
      "5  LLMs.  1 0.20068666377598746\n",
      "5  advantage  1 0.28169934667141894\n",
      "5  graph  3 0.8450980400142568\n",
      "5  grammar  1 0.28169934667141894\n",
      "5  queries  1 0.20068666377598746\n",
      "5  neglecting  1 0.28169934667141894\n",
      "5  also  1 0.20068666377598746\n",
      "5  set  2 0.3180808364797749\n",
      "5  including  1 0.28169934667141894\n",
      "5  Tiangong-ST,  1 0.28169934667141894\n",
      "5  paper,  1 0.13264666955734586\n",
      "5  typically  1 0.28169934667141894\n",
      "5  convert  1 0.28169934667141894\n",
      "5  comprehensive  1 0.28169934667141894\n",
      "5  given  1 0.20068666377598746\n",
      "5  propose  1 0.1141408936074021\n",
      "5  task  1 0.20068666377598746\n",
      "5  interactions.  1 0.28169934667141894\n",
      "5  using  1 0.1141408936074021\n",
      "5  structure  1 0.28169934667141894\n",
      "5  fulfill  1 0.28169934667141894\n",
      "5  offers  1 0.28169934667141894\n",
      "5  information  2 0.5633986933428379\n",
      "5  ability  1 0.20068666377598746\n",
      "5  rules  1 0.28169934667141894\n",
      "5  analysis  1 0.28169934667141894\n",
      "5  user's  1 0.20068666377598746\n",
      "5  integrating  1 0.28169934667141894\n",
      "5  coarse-grained  1 0.28169934667141894\n",
      "5  traditional  1 0.28169934667141894\n",
      "5  understanding,  1 0.28169934667141894\n",
      "5  word-level  1 0.28169934667141894\n",
      "5  learning  1 0.28169934667141894\n",
      "5  generation,  1 0.28169934667141894\n",
      "5  symbolic  3 0.8450980400142568\n",
      "5  textual  2 0.5633986933428379\n",
      "5  content  1 0.28169934667141894\n",
      "5  enable  1 0.28169934667141894\n",
      "5  fine-grained.  1 0.28169934667141894\n",
      "5  node  1 0.28169934667141894\n",
      "5  enhance  1 0.28169934667141894\n",
      "5  deep  1 0.28169934667141894\n",
      "5  semantic  2 0.5633986933428379\n",
      "5  Symbolic  1 0.28169934667141894\n",
      "5  first  1 0.15904041823988746\n",
      "5  Concretely,  1 0.28169934667141894\n",
      "5  Session  1 0.28169934667141894\n",
      "5  methodology  1 0.28169934667141894\n",
      "5  topological  1 0.28169934667141894\n",
      "5  search  2 0.3180808364797749\n",
      "5  modeling  1 0.20068666377598746\n",
      "5  text.  1 0.28169934667141894\n",
      "5  Graph  1 0.28169934667141894\n",
      "5  seamlessly  1 0.28169934667141894\n",
      "5  involves  1 0.28169934667141894\n",
      "5  within  1 0.28169934667141894\n",
      "5  LLMs  2 0.2652933391146917\n",
      "5  approach.  1 0.28169934667141894\n",
      "5  session  2 0.5633986933428379\n",
      "5  text-based  1 0.28169934667141894\n",
      "5  series  1 0.28169934667141894\n",
      "5  instruction  1 0.20068666377598746\n",
      "5  language  1 0.13264666955734586\n",
      "5  gap  1 0.28169934667141894\n",
      "5  tasks  1 0.28169934667141894\n",
      "5  Language  1 0.13264666955734586\n",
      "5  Experiment  1 0.28169934667141894\n",
      "5  overlooking  1 0.28169934667141894\n",
      "5  superiority  1 0.28169934667141894\n",
      "5  LLM.  1 0.28169934667141894\n",
      "6  providing  1 0.2112745100035642\n",
      "6  GPT-3.5,  1 0.2112745100035642\n",
      "6  directors  1 0.2112745100035642\n",
      "6  Hits,  1 0.2112745100035642\n",
      "6  systems.  1 0.2112745100035642\n",
      "6  consisting  1 0.2112745100035642\n",
      "6  open-sourced  1 0.1505149978319906\n",
      "6  source  1 0.2112745100035642\n",
      "6  used  1 0.11928031367991561\n",
      "6  descriptions  4 0.8450980400142568\n",
      "6  item  1 0.1505149978319906\n",
      "6  emerged  1 0.2112745100035642\n",
      "6  features  1 0.2112745100035642\n",
      "6  Models  1 0.0994850021680094\n",
      "6  tasks.  1 0.1505149978319906\n",
      "6  summaries  1 0.2112745100035642\n",
      "6  considering  1 0.2112745100035642\n",
      "6  web  1 0.2112745100035642\n",
      "6  captivate  1 0.2112745100035642\n",
      "6  processing  1 0.2112745100035642\n",
      "6  prompting  1 0.1505149978319906\n",
      "6  comprising  1 0.2112745100035642\n",
      "6  essential  1 0.2112745100035642\n",
      "6  exhibits  1 0.2112745100035642\n",
      "6  natural  1 0.1505149978319906\n",
      "6  Alpaca,  1 0.2112745100035642\n",
      "6  (LLMs),  1 0.2112745100035642\n",
      "6  promise,  1 0.2112745100035642\n",
      "6  publisher  1 0.2112745100035642\n",
      "6  ones  1 0.2112745100035642\n",
      "6  Goodreads  2 0.4225490200071284\n",
      "6  generate  2 0.23856062735983122\n",
      "6  1M  1 0.2112745100035642\n",
      "6  viewers  1 0.2112745100035642\n",
      "6  data  1 0.2112745100035642\n",
      "6  inconsistencies.  1 0.2112745100035642\n",
      "6  informative  1 0.2112745100035642\n",
      "6  evaluation  1 0.2112745100035642\n",
      "6  generation  1 0.2112745100035642\n",
      "6  results  2 0.1989700043360188\n",
      "6  recent  1 0.1505149978319906\n",
      "6  powerful  1 0.2112745100035642\n",
      "6  descriptions.  1 0.2112745100035642\n",
      "6  subsequently,  1 0.2112745100035642\n",
      "6  dataset  3 0.6338235300106926\n",
      "6  scraping  1 0.2112745100035642\n",
      "6  use  1 0.1505149978319906\n",
      "6  cast  1 0.2112745100035642\n",
      "6  MRR,  1 0.2112745100035642\n",
      "6  Large  1 0.08560567020555157\n",
      "6  author  1 0.2112745100035642\n",
      "6  compared  1 0.2112745100035642\n",
      "6  prompted  1 0.2112745100035642\n",
      "6  web-scraped  1 0.2112745100035642\n",
      "6  LLM-based  1 0.11928031367991561\n",
      "6  obtained  2 0.4225490200071284\n",
      "6  Traditionally,  1 0.2112745100035642\n",
      "6  manual  1 0.2112745100035642\n",
      "6  demonstrated  1 0.2112745100035642\n",
      "6  description  3 0.6338235300106926\n",
      "6  potential  1 0.2112745100035642\n",
      "6  open  1 0.2112745100035642\n",
      "6  multiple  1 0.11928031367991561\n",
      "6  paper,  1 0.0994850021680094\n",
      "6  significant  1 0.2112745100035642\n",
      "6  Top  1 0.2112745100035642\n",
      "6  study,  1 0.2112745100035642\n",
      "6  books  1 0.2112745100035642\n",
      "6  comparable  1 0.2112745100035642\n",
      "6  metrics.  1 0.1505149978319906\n",
      "6  using  1 0.08560567020555157\n",
      "6  LLM,  1 0.2112745100035642\n",
      "6  explored  1 0.2112745100035642\n",
      "6  NDCG  1 0.2112745100035642\n",
      "6  items.  1 0.2112745100035642\n",
      "6  few-shot  1 0.2112745100035642\n",
      "6  generated  1 0.2112745100035642\n",
      "6  techniques,  1 0.2112745100035642\n",
      "6  recommendation  1 0.1505149978319906\n",
      "6  Dataset  1 0.2112745100035642\n",
      "6  like  2 0.4225490200071284\n",
      "6  combination  1 0.2112745100035642\n",
      "6  MovieLens  1 0.2112745100035642\n",
      "6  ML  1 0.2112745100035642\n",
      "6  plays  1 0.2112745100035642\n",
      "6  pivotal  1 0.2112745100035642\n",
      "6  susceptible  1 0.2112745100035642\n",
      "6  names  3 0.6338235300106926\n",
      "6  dataset.  1 0.2112745100035642\n",
      "6  concise  1 0.2112745100035642\n",
      "6  years,  1 0.2112745100035642\n",
      "6  Alpaca  1 0.2112745100035642\n",
      "6  tools  1 0.2112745100035642\n",
      "6  titles  1 0.2112745100035642\n",
      "6  conduct  1 0.2112745100035642\n",
      "6  time-consuming  1 0.2112745100035642\n",
      "6  LLMs  2 0.1989700043360188\n",
      "6  scraped  1 0.2112745100035642\n",
      "6  detailed  2 0.4225490200071284\n",
      "6  language  1 0.0994850021680094\n",
      "6  Language  1 0.0994850021680094\n",
      "6  movie  3 0.6338235300106926\n",
      "6  role  1 0.2112745100035642\n",
      "\n"
     ]
    }
   ],
   "source": [
    "descripteur_split =\"\"\n",
    "\n",
    "for i in range(len(termes_split)):\n",
    "    for j in range(len(termes_split[i])):\n",
    "        frequency_term = frequency_dict_split_documents[i][termes_split[i][j]]\n",
    "        poids_term = poids(frequency_term,max_frequency_dict_split_documents[i],document_frequency_dict_split[termes_split[i][j]],n_split)\n",
    "        descripteur_split = descripteur_split + (str(i+1)+ \"  \" +termes_split[i][j]+ \"  \" +str(frequency_term)+\" \"+ str(poids_term)+\"\\n\")\n",
    "\n",
    "\n",
    "print(descripteur_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  inspiration  1 0.28169934667141894\n",
      "1  models  1 0.20068666377598746\n",
      "1  Passage  1 0.28169934667141894\n",
      "1  18%  1 0.28169934667141894\n",
      "1  taking  1 0.28169934667141894\n",
      "1  sets  1 0.28169934667141894\n",
      "1  intent  1 0.28169934667141894\n",
      "1  improvements  2 0.5633986933428379\n",
      "1  retrieval  1 0.20068666377598746\n",
      "1  QR  2 0.5633986933428379\n",
      "1  Ranking  1 0.20068666377598746\n",
      "1  used  1 0.15904041823988746\n",
      "1  leverages  1 0.20068666377598746\n",
      "1  state-of-art  1 0.28169934667141894\n",
      "1  incorporate  1 0.28169934667141894\n",
      "1  Recently  1 0.28169934667141894\n",
      "1  5%  1 0.28169934667141894\n",
      "1  MRR  1 0.20068666377598746\n",
      "1  paraphrases  1 0.28169934667141894\n",
      "1  prompting  2 0.4013733275519749\n",
      "1  nDCG@10  2 0.4013733275519749\n",
      "1  documents  1 0.15904041823988746\n",
      "1  query  2 0.3180808364797749\n",
      "1  pseudo  1 0.28169934667141894\n",
      "1  technique  1 0.20068666377598746\n",
      "1  shown  1 0.28169934667141894\n",
      "1  introduce  1 0.20068666377598746\n",
      "1  shows  1 0.28169934667141894\n",
      "1  strategies  1 0.15904041823988746\n",
      "1  Reformulation  1 0.20068666377598746\n",
      "1  GenQREnsembleRF  2 0.5633986933428379\n",
      "1  evaluations  1 0.28169934667141894\n",
      "1  context  1 0.28169934667141894\n",
      "1  approach  1 0.13264666955734586\n",
      "1  generate  1 0.15904041823988746\n",
      "1  based  1 0.15904041823988746\n",
      "1  inherent  1 0.28169934667141894\n",
      "1  GenQREnsemble  2 0.5633986933428379\n",
      "1  variant  1 0.28169934667141894\n",
      "1  performance  1 0.15904041823988746\n",
      "1  reformulation  1 0.20068666377598746\n",
      "1  post-retrieval  1 0.28169934667141894\n",
      "1  large  1 0.28169934667141894\n",
      "1  four  1 0.28169934667141894\n",
      "1  success  1 0.28169934667141894\n",
      "1  aligns  1 0.28169934667141894\n",
      "1  improving  1 0.28169934667141894\n",
      "1  benchmarks  1 0.20068666377598746\n",
      "1  24%  1 0.28169934667141894\n",
      "1  transform  1 0.28169934667141894\n",
      "1  relative  2 0.5633986933428379\n",
      "1  previous  1 0.15904041823988746\n",
      "1  find  1 0.28169934667141894\n",
      "1  multiple  1 0.15904041823988746\n",
      "1  Query  1 0.20068666377598746\n",
      "1  set  1 0.15904041823988746\n",
      "1  experience  1 0.28169934667141894\n",
      "1  propose  1 0.1141408936074021\n",
      "1  task  1 0.15904041823988746\n",
      "1  ensemble  2 0.5633986933428379\n",
      "1  9%  1 0.28169934667141894\n",
      "1  user  2 0.2652933391146917\n",
      "1  MSMarco  1 0.28169934667141894\n",
      "1  feedback  3 0.6020599913279624\n",
      "1  using  2 0.2282817872148042\n",
      "1  pseudo-relevance  1 0.28169934667141894\n",
      "1  due  1 0.28169934667141894\n",
      "1  gains  1 0.28169934667141894\n",
      "1  ability  1 0.20068666377598746\n",
      "1  original  1 0.28169934667141894\n",
      "1  reformulations  1 0.28169934667141894\n",
      "1  exploit  1 0.28169934667141894\n",
      "1  relevant  2 0.5633986933428379\n",
      "1  benefited  1 0.28169934667141894\n",
      "1  improve  1 0.13264666955734586\n",
      "1  text  1 0.15904041823988746\n",
      "1  knowledge  1 0.28169934667141894\n",
      "1  MAP  1 0.28169934667141894\n",
      "1  investigate  1 0.28169934667141894\n",
      "1  generates  1 0.28169934667141894\n",
      "1  upto  1 0.28169934667141894\n",
      "1  promising  1 0.28169934667141894\n",
      "1  ultimately  1 0.28169934667141894\n",
      "1  many  1 0.28169934667141894\n",
      "1  search  2 0.3180808364797749\n",
      "1  improves  1 0.28169934667141894\n",
      "1  zero-shot  3 0.8450980400142568\n",
      "1  better  2 0.5633986933428379\n",
      "1  techniques  1 0.15904041823988746\n",
      "1  instruction  1 0.20068666377598746\n",
      "1  language  1 0.13264666955734586\n",
      "1  IR  1 0.20068666377598746\n",
      "1  tasks  1 0.1141408936074021\n",
      "1  help  1 0.28169934667141894\n",
      "1  keywords  1 0.28169934667141894\n",
      "2  datasets  1 0.11928031367991561\n",
      "2  possible  1 0.2112745100035642\n",
      "2  estimated  1 0.2112745100035642\n",
      "2  open-sourced  1 0.1505149978319906\n",
      "2  GPT-4  1 0.2112745100035642\n",
      "2  complexity  1 0.2112745100035642\n",
      "2  Ranking  2 0.3010299956639812\n",
      "2  analyze  1 0.2112745100035642\n",
      "2  template  1 0.1505149978319906\n",
      "2  used  1 0.11928031367991561\n",
      "2  Furthermore  1 0.1505149978319906\n",
      "2  rankers  1 0.2112745100035642\n",
      "2  called  1 0.2112745100035642\n",
      "2  metrics  1 0.1505149978319906\n",
      "2  standard  1 0.2112745100035642\n",
      "2  paper  1 0.0994850021680094\n",
      "2  Models  1 0.0994850021680094\n",
      "2  moderate-sized  1 0.2112745100035642\n",
      "2  performs  1 0.2112745100035642\n",
      "2  outperform  1 0.2112745100035642\n",
      "2  literature  2 0.4225490200071284\n",
      "2  even  1 0.2112745100035642\n",
      "2  problem  1 0.1505149978319906\n",
      "2  documents  2 0.23856062735983122\n",
      "2  query  1 0.11928031367991561\n",
      "2  technique  1 0.1505149978319906\n",
      "2  baselines  1 0.2112745100035642\n",
      "2  2020  1 0.2112745100035642\n",
      "2  Flan-UL2  1 0.2112745100035642\n",
      "2  state-of-the-art  1 0.1505149978319906\n",
      "2  10%  1 0.2112745100035642\n",
      "2  solution  1 0.2112745100035642\n",
      "2  found  1 0.2112745100035642\n",
      "2  prompt  2 0.3010299956639812\n",
      "2  outperforming  1 0.2112745100035642\n",
      "2  existing  1 0.2112745100035642\n",
      "2  favorably  1 0.2112745100035642\n",
      "2  directly  1 0.2112745100035642\n",
      "2  several  1 0.2112745100035642\n",
      "2  argue  1 0.2112745100035642\n",
      "2  approach  1 0.0994850021680094\n",
      "2  supervised  1 0.2112745100035642\n",
      "2  based  2 0.23856062735983122\n",
      "2  average  1 0.2112745100035642\n",
      "2  commercial  2 0.4225490200071284\n",
      "2  ChatGPT  1 0.2112745100035642\n",
      "2  reduce  1 0.1505149978319906\n",
      "2  researchers  1 0.1505149978319906\n",
      "2  understand  1 0.1505149978319906\n",
      "2  4.2%  1 0.2112745100035642\n",
      "2  variants  1 0.2112745100035642\n",
      "2  results  2 0.1989700043360188\n",
      "2  performance  1 0.11928031367991561\n",
      "2  burden  1 0.2112745100035642\n",
      "2  TREC-DL  1 0.2112745100035642\n",
      "2  achieve  2 0.3010299956639812\n",
      "2  formulations  1 0.2112745100035642\n",
      "2  20B  1 0.2112745100035642\n",
      "2  Large  1 0.08560567020555157\n",
      "2  efficiency  1 0.1505149978319906\n",
      "2  off-the-shelf  1 0.2112745100035642\n",
      "2  benchmarks  1 0.1505149978319906\n",
      "2  LLM-based  2 0.23856062735983122\n",
      "2  significantly  1 0.11928031367991561\n",
      "2  However  1 0.2112745100035642\n",
      "2  feeding  1 0.2112745100035642\n",
      "2  previous  1 0.11928031367991561\n",
      "2  benchmark  1 0.11928031367991561\n",
      "2  parameters  2 0.4225490200071284\n",
      "2  model  2 0.4225490200071284\n",
      "2  Pairwise  1 0.2112745100035642\n",
      "2  baseline  1 0.2112745100035642\n",
      "2  methods  1 0.1505149978319906\n",
      "2  propose  2 0.17121134041110314\n",
      "2  show  1 0.2112745100035642\n",
      "2  fully  1 0.2112745100035642\n",
      "2  12-10%  1 0.2112745100035642\n",
      "2  2019  1 0.2112745100035642\n",
      "2  using  4 0.3424226808222063\n",
      "2  175B  1 0.2112745100035642\n",
      "2  Prompting  1 0.2112745100035642\n",
      "2  listwise  1 0.2112745100035642\n",
      "2  interesting  1 0.2112745100035642\n",
      "2  blackbox  2 0.4225490200071284\n",
      "2  InstructGPT  1 0.2112745100035642\n",
      "2  solutions  2 0.4225490200071284\n",
      "2  NDCG@10  1 0.2112745100035642\n",
      "2  difficult  1 0.2112745100035642\n",
      "2  improve  1 0.0994850021680094\n",
      "2  prompts  1 0.1505149978319906\n",
      "2  outperforms  2 0.4225490200071284\n",
      "2  best  1 0.2112745100035642\n",
      "2  ranking  4 0.8450980400142568\n",
      "2  pointwise  2 0.4225490200071284\n",
      "2  challenging  1 0.2112745100035642\n",
      "2  competitive  1 0.2112745100035642\n",
      "2  candidate  1 0.2112745100035642\n",
      "2  BEIR  1 0.1505149978319906\n",
      "2  50x  1 0.2112745100035642\n",
      "2  PRP  4 0.8450980400142568\n",
      "2  linear  1 0.2112745100035642\n",
      "2  first  1 0.11928031367991561\n",
      "2  size  1 0.2112745100035642\n",
      "2  practical  1 0.2112745100035642\n",
      "2  seven  1 0.2112745100035642\n",
      "2  new  1 0.2112745100035642\n",
      "2  LLMs  4 0.3979400086720376\n",
      "2  fine-tuned  1 0.2112745100035642\n",
      "2  tasks  1 0.08560567020555157\n",
      "2  Language  1 0.0994850021680094\n",
      "3  datasets  1 0.06816017924566606\n",
      "3  usually  2 0.2414565828612162\n",
      "3  POD  1 0.1207282914306081\n",
      "3  models  7 0.6020599913279624\n",
      "3  design  1 0.1207282914306081\n",
      "3  thus  1 0.1207282914306081\n",
      "3  strategy  1 0.1207282914306081\n",
      "3  attempt  1 0.1207282914306081\n",
      "3  PrOmpt  1 0.1207282914306081\n",
      "3  community  1 0.1207282914306081\n",
      "3  demonstrate  1 0.08600857018970891\n",
      "3  extensive  1 0.1207282914306081\n",
      "3  template  2 0.17201714037941782\n",
      "3  item  1 0.08600857018970891\n",
      "3  may  2 0.2414565828612162\n",
      "3  e.g.  1 0.1207282914306081\n",
      "3  require  1 0.1207282914306081\n",
      "3  Experimental  1 0.1207282914306081\n",
      "3  specific  1 0.1207282914306081\n",
      "3  limited  2 0.17201714037941782\n",
      "3  recommender  1 0.1207282914306081\n",
      "3  plain  1 0.1207282914306081\n",
      "3  distill  1 0.1207282914306081\n",
      "3  take  1 0.08600857018970891\n",
      "3  prompt  3 0.2580257105691267\n",
      "3  enough  1 0.1207282914306081\n",
      "3  user/item  1 0.1207282914306081\n",
      "3  long  2 0.2414565828612162\n",
      "3  manifested  1 0.1207282914306081\n",
      "3  approach  1 0.05684857266743394\n",
      "3  effectiveness  1 0.08600857018970891\n",
      "3  finding  1 0.1207282914306081\n",
      "3  reduce  1 0.08600857018970891\n",
      "3  systems  1 0.08600857018970891\n",
      "3  researchers  1 0.08600857018970891\n",
      "3  contain  1 0.1207282914306081\n",
      "3  understand  1 0.08600857018970891\n",
      "3  multi-step  1 0.1207282914306081\n",
      "3  Although  1 0.1207282914306081\n",
      "3  results  1 0.05684857266743394\n",
      "3  various  1 0.08600857018970891\n",
      "3  problems  1 0.1207282914306081\n",
      "3  Long  1 0.1207282914306081\n",
      "3  noisy  1 0.1207282914306081\n",
      "3  i.e.  1 0.1207282914306081\n",
      "3  Distillation  1 0.1207282914306081\n",
      "3  input  1 0.08600857018970891\n",
      "3  power  1 0.08600857018970891\n",
      "3  improvement  1 0.1207282914306081\n",
      "3  Large  1 0.048917525831743754\n",
      "3  efficiency  4 0.34403428075883563\n",
      "3  sequential  1 0.08600857018970891\n",
      "3  fine-tuning  1 0.1207282914306081\n",
      "3  LLM-based  2 0.13632035849133212\n",
      "3  discrete  2 0.2414565828612162\n",
      "3  significantly  1 0.06816017924566606\n",
      "3  inspire  1 0.1207282914306081\n",
      "3  need  1 0.08600857018970891\n",
      "3  three  1 0.1207282914306081\n",
      "3  training  3 0.36218487429182433\n",
      "3  LLM  2 0.13632035849133212\n",
      "3  also  1 0.08600857018970891\n",
      "3  set  1 0.06816017924566606\n",
      "3  time  2 0.17201714037941782\n",
      "3  unparalleled  1 0.1207282914306081\n",
      "3  filled  1 0.1207282914306081\n",
      "3  given  1 0.08600857018970891\n",
      "3  propose  1 0.048917525831743754\n",
      "3  task  2 0.13632035849133212\n",
      "3  response  1 0.1207282914306081\n",
      "3  improved  1 0.1207282914306081\n",
      "3  user  1 0.05684857266743394\n",
      "3  allow  1 0.1207282914306081\n",
      "3  IDs  3 0.36218487429182433\n",
      "3  top-N  1 0.1207282914306081\n",
      "3  information  1 0.08600857018970891\n",
      "3  words  2 0.2414565828612162\n",
      "3  vectors  1 0.1207282914306081\n",
      "3  improve  2 0.11369714533486788\n",
      "3  process  1 0.06816017924566606\n",
      "3  could  2 0.2414565828612162\n",
      "3  text  2 0.13632035849133212\n",
      "3  address  1 0.1207282914306081\n",
      "3  real-world  1 0.1207282914306081\n",
      "3  continuous  1 0.1207282914306081\n",
      "3  recommendation  5 0.43004285094854455\n",
      "3  bridge  2 0.2414565828612162\n",
      "3  unleash  1 0.1207282914306081\n",
      "3  mostly  1 0.1207282914306081\n",
      "3  reasoning  1 0.1207282914306081\n",
      "3  efficient  1 0.1207282914306081\n",
      "3  modeling  1 0.08600857018970891\n",
      "3  capability  1 0.1207282914306081\n",
      "3  inference  3 0.36218487429182433\n",
      "3  immediate  1 0.1207282914306081\n",
      "3  language  1 0.05684857266743394\n",
      "3  tasks  2 0.09783505166348751\n",
      "4  explores  1 0.16901960800285137\n",
      "4  retriever  1 0.16901960800285137\n",
      "4  initial  1 0.16901960800285137\n",
      "4  expansions  1 0.16901960800285137\n",
      "4  completion  1 0.16901960800285137\n",
      "4  SOTAs  1 0.16901960800285137\n",
      "4  demonstrate  1 0.12041199826559248\n",
      "4  retrieval  2 0.24082399653118497\n",
      "4  Furthermore  1 0.12041199826559248\n",
      "4  leverages  1 0.12041199826559248\n",
      "4  Clustering  1 0.16901960800285137\n",
      "4  Model  1 0.16901960800285137\n",
      "4  represent  1 0.16901960800285137\n",
      "4  paper  1 0.07958800173440753\n",
      "4  Models  1 0.07958800173440753\n",
      "4  limited  1 0.12041199826559248\n",
      "4  rate  1 0.16901960800285137\n",
      "4  Generative  1 0.16901960800285137\n",
      "4  QERM  1 0.16901960800285137\n",
      "4  problem  1 0.12041199826559248\n",
      "4  nDCG@10  1 0.12041199826559248\n",
      "4  query  5 0.47712125471966244\n",
      "4  experiments  1 0.16901960800285137\n",
      "4  state-of-the-art  1 0.12041199826559248\n",
      "4  automatically  1 0.16901960800285137\n",
      "4  strategies  1 0.09542425094393249\n",
      "4  customized  1 0.16901960800285137\n",
      "4  combine  1 0.16901960800285137\n",
      "4  Reformulation  1 0.12041199826559248\n",
      "4  distinctly  1 0.16901960800285137\n",
      "4  boosting  1 0.16901960800285137\n",
      "4  leverage  1 0.16901960800285137\n",
      "4  capturing  1 0.12041199826559248\n",
      "4  generate  2 0.19084850188786498\n",
      "4  based  1 0.09542425094393249\n",
      "4  effectiveness  1 0.12041199826559248\n",
      "4  capture  1 0.12041199826559248\n",
      "4  surpassing  1 0.16901960800285137\n",
      "4  various  1 0.12041199826559248\n",
      "4  performance  3 0.28627275283179743\n",
      "4  novel  1 0.12041199826559248\n",
      "4  reformulation  3 0.3612359947967774\n",
      "4  loops  1 0.16901960800285137\n",
      "4  advancing  1 0.16901960800285137\n",
      "4  Empirical  1 0.16901960800285137\n",
      "4  input  1 0.12041199826559248\n",
      "4  Large  1 0.06848453616444126\n",
      "4  successful  1 0.16901960800285137\n",
      "4  crucially  1 0.16901960800285137\n",
      "4  refine  1 0.16901960800285137\n",
      "4  well-generated  1 0.16901960800285137\n",
      "4  adaptively  1 0.16901960800285137\n",
      "4  Framework  1 0.16901960800285137\n",
      "4  significantly  1 0.09542425094393249\n",
      "4  field  1 0.16901960800285137\n",
      "4  previous  1 0.09542425094393249\n",
      "4  single  1 0.16901960800285137\n",
      "4  variable  1 0.16901960800285137\n",
      "4  Evaluation  1 0.16901960800285137\n",
      "4  benchmark  1 0.09542425094393249\n",
      "4  12%  1 0.16901960800285137\n",
      "4  Information  2 0.33803921600570275\n",
      "4  adapted  1 0.16901960800285137\n",
      "4  multiple  1 0.09542425094393249\n",
      "4  Query  2 0.24082399653118497\n",
      "4  queries  2 0.24082399653118497\n",
      "4  weighted  1 0.16901960800285137\n",
      "4  time  1 0.12041199826559248\n",
      "4  groups  1 0.16901960800285137\n",
      "4  phase  1 0.16901960800285137\n",
      "4  framework  1 0.16901960800285137\n",
      "4  methods  1 0.12041199826559248\n",
      "4  propose  1 0.06848453616444126\n",
      "4  user  1 0.07958800173440753\n",
      "4  constraining  1 0.16901960800285137\n",
      "4  feedback  1 0.12041199826559248\n",
      "4  using  1 0.06848453616444126\n",
      "4  enhancing  1 0.16901960800285137\n",
      "4  Rewarding  1 0.16901960800285137\n",
      "4  aggregation  1 0.16901960800285137\n",
      "4  intentions  1 0.16901960800285137\n",
      "4  achieves  1 0.16901960800285137\n",
      "4  GenCRF  3 0.5070588240085541\n",
      "4  improve  1 0.07958800173440753\n",
      "4  process  1 0.09542425094393249\n",
      "4  aimed  1 0.16901960800285137\n",
      "4  integrates  1 0.16901960800285137\n",
      "4  prompts  1 0.12041199826559248\n",
      "4  intents  3 0.5070588240085541\n",
      "4  well-known  1 0.16901960800285137\n",
      "4  potentially  1 0.16901960800285137\n",
      "4  BEIR  1 0.12041199826559248\n",
      "4  often  1 0.16901960800285137\n",
      "4  Recent  1 0.16901960800285137\n",
      "4  first  1 0.09542425094393249\n",
      "4  Retrieval  2 0.33803921600570275\n",
      "4  search  1 0.09542425094393249\n",
      "4  diverse  4 0.6760784320114055\n",
      "4  redundant  1 0.16901960800285137\n",
      "4  modifying  1 0.16901960800285137\n",
      "4  LLMs  3 0.23876400520322255\n",
      "4  differentiated  1 0.16901960800285137\n",
      "4  techniques  1 0.09542425094393249\n",
      "4  clusters  1 0.16901960800285137\n",
      "4  optimize  1 0.16901960800285137\n",
      "4  innovative  1 0.16901960800285137\n",
      "4  IR  1 0.12041199826559248\n",
      "4  Language  1 0.07958800173440753\n",
      "5  Ranker  1 0.16901960800285137\n",
      "5  datasets  1 0.09542425094393249\n",
      "5  graph-based  1 0.16901960800285137\n",
      "5  complex  1 0.16901960800285137\n",
      "5  structures  1 0.16901960800285137\n",
      "5  bridges  1 0.16901960800285137\n",
      "5  interactive  1 0.16901960800285137\n",
      "5  interaction  1 0.16901960800285137\n",
      "5  Tiangong-ST  1 0.16901960800285137\n",
      "5  contrastive  1 0.16901960800285137\n",
      "5  inputs  1 0.16901960800285137\n",
      "5  paper  1 0.07958800173440753\n",
      "5  Models  1 0.07958800173440753\n",
      "5  actions  1 0.16901960800285137\n",
      "5  Concretely  1 0.16901960800285137\n",
      "5  modern  1 0.16901960800285137\n",
      "5  documents  1 0.09542425094393249\n",
      "5  objective  1 0.16901960800285137\n",
      "5  prioritize  1 0.16901960800285137\n",
      "5  generative  1 0.16901960800285137\n",
      "5  introduce  2 0.24082399653118497\n",
      "5  Current  1 0.16901960800285137\n",
      "5  understanding  1 0.16901960800285137\n",
      "5  take  1 0.12041199826559248\n",
      "5  strategies  2 0.19084850188786498\n",
      "5  natural  1 0.12041199826559248\n",
      "5  effective  1 0.16901960800285137\n",
      "5  approaches  2 0.33803921600570275\n",
      "5  structural  1 0.16901960800285137\n",
      "5  generalized  1 0.16901960800285137\n",
      "5  capturing  1 0.12041199826559248\n",
      "5  graph-to-text  1 0.16901960800285137\n",
      "5  focus  1 0.16901960800285137\n",
      "5  aims  1 0.16901960800285137\n",
      "5  approach  1 0.07958800173440753\n",
      "5  capture  2 0.24082399653118497\n",
      "5  AOL  1 0.16901960800285137\n",
      "5  produce  1 0.16901960800285137\n",
      "5  generation  1 0.12041199826559248\n",
      "5  pre-trained  1 0.16901960800285137\n",
      "5  results  1 0.07958800173440753\n",
      "5  allows  1 0.16901960800285137\n",
      "5  recent  1 0.12041199826559248\n",
      "5  novel  1 0.12041199826559248\n",
      "5  two  1 0.16901960800285137\n",
      "5  achieve  1 0.12041199826559248\n",
      "5  link  1 0.16901960800285137\n",
      "5  confirm  1 0.16901960800285137\n",
      "5  use  1 0.12041199826559248\n",
      "5  power  1 0.12041199826559248\n",
      "5  discrepancy  1 0.16901960800285137\n",
      "5  Large  1 0.06848453616444126\n",
      "5  sequential  1 0.12041199826559248\n",
      "5  leveraging  1 0.16901960800285137\n",
      "5  paradigm  1 0.16901960800285137\n",
      "5  self-supervised  1 0.16901960800285137\n",
      "5  corpora  1 0.16901960800285137\n",
      "5  representation  1 0.16901960800285137\n",
      "5  benchmark  1 0.09542425094393249\n",
      "5  need  1 0.12041199826559248\n",
      "5  advantage  1 0.16901960800285137\n",
      "5  graph  3 0.5070588240085541\n",
      "5  grammar  2 0.33803921600570275\n",
      "5  queries  1 0.12041199826559248\n",
      "5  neglecting  1 0.16901960800285137\n",
      "5  LLM  1 0.09542425094393249\n",
      "5  also  1 0.12041199826559248\n",
      "5  set  2 0.19084850188786498\n",
      "5  including  1 0.16901960800285137\n",
      "5  typically  1 0.16901960800285137\n",
      "5  convert  1 0.16901960800285137\n",
      "5  comprehensive  1 0.16901960800285137\n",
      "5  given  1 0.12041199826559248\n",
      "5  propose  1 0.06848453616444126\n",
      "5  task  1 0.09542425094393249\n",
      "5  user  1 0.07958800173440753\n",
      "5  Moreover  1 0.16901960800285137\n",
      "5  using  1 0.06848453616444126\n",
      "5  prediction  1 0.16901960800285137\n",
      "5  structure  1 0.16901960800285137\n",
      "5  fulfill  1 0.16901960800285137\n",
      "5  offers  1 0.16901960800285137\n",
      "5  information  3 0.3612359947967774\n",
      "5  ability  1 0.12041199826559248\n",
      "5  rules  1 0.16901960800285137\n",
      "5  analysis  1 0.16901960800285137\n",
      "5  SGR  1 0.16901960800285137\n",
      "5  integrating  1 0.16901960800285137\n",
      "5  coarse-grained  1 0.16901960800285137\n",
      "5  process  1 0.09542425094393249\n",
      "5  text  1 0.09542425094393249\n",
      "5  traditional  1 0.16901960800285137\n",
      "5  word-level  1 0.16901960800285137\n",
      "5  fine-grained  1 0.16901960800285137\n",
      "5  learning  2 0.33803921600570275\n",
      "5  interactions  1 0.16901960800285137\n",
      "5  symbolic  3 0.5070588240085541\n",
      "5  textual  2 0.33803921600570275\n",
      "5  content  1 0.16901960800285137\n",
      "5  enable  1 0.16901960800285137\n",
      "5  history  1 0.16901960800285137\n",
      "5  format  1 0.16901960800285137\n",
      "5  node  1 0.16901960800285137\n",
      "5  enhance  1 0.16901960800285137\n",
      "5  deep  1 0.16901960800285137\n",
      "5  semantic  2 0.33803921600570275\n",
      "5  Symbolic  1 0.16901960800285137\n",
      "5  first  1 0.09542425094393249\n",
      "5  Session  1 0.16901960800285137\n",
      "5  methodology  1 0.16901960800285137\n",
      "5  topological  1 0.16901960800285137\n",
      "5  search  2 0.19084850188786498\n",
      "5  modeling  2 0.24082399653118497\n",
      "5  Graph  1 0.16901960800285137\n",
      "5  seamlessly  1 0.16901960800285137\n",
      "5  involves  1 0.16901960800285137\n",
      "5  within  1 0.16901960800285137\n",
      "5  LLMs  5 0.3979400086720376\n",
      "5  session  2 0.33803921600570275\n",
      "5  text-based  1 0.16901960800285137\n",
      "5  series  1 0.16901960800285137\n",
      "5  instruction  1 0.12041199826559248\n",
      "5  language  1 0.07958800173440753\n",
      "5  gap  1 0.16901960800285137\n",
      "5  tasks  1 0.06848453616444126\n",
      "5  Language  1 0.07958800173440753\n",
      "5  Experiment  1 0.16901960800285137\n",
      "5  overlooking  1 0.16901960800285137\n",
      "5  superiority  1 0.16901960800285137\n",
      "6  providing  1 0.16901960800285137\n",
      "6  directors  1 0.16901960800285137\n",
      "6  consisting  1 0.16901960800285137\n",
      "6  open-sourced  1 0.12041199826559248\n",
      "6  source  1 0.16901960800285137\n",
      "6  promise  1 0.16901960800285137\n",
      "6  used  1 0.09542425094393249\n",
      "6  metrics  1 0.12041199826559248\n",
      "6  descriptions  5 0.8450980400142568\n",
      "6  item  1 0.12041199826559248\n",
      "6  emerged  1 0.16901960800285137\n",
      "6  paper  1 0.07958800173440753\n",
      "6  features  1 0.16901960800285137\n",
      "6  Models  1 0.07958800173440753\n",
      "6  summaries  1 0.16901960800285137\n",
      "6  MRR  1 0.12041199826559248\n",
      "6  considering  1 0.16901960800285137\n",
      "6  years  1 0.16901960800285137\n",
      "6  web  1 0.16901960800285137\n",
      "6  captivate  1 0.16901960800285137\n",
      "6  processing  1 0.16901960800285137\n",
      "6  prompting  1 0.12041199826559248\n",
      "6  comprising  1 0.16901960800285137\n",
      "6  GPT-3.5  1 0.16901960800285137\n",
      "6  essential  1 0.16901960800285137\n",
      "6  exhibits  1 0.16901960800285137\n",
      "6  items  1 0.16901960800285137\n",
      "6  natural  1 0.12041199826559248\n",
      "6  publisher  1 0.16901960800285137\n",
      "6  ones  1 0.16901960800285137\n",
      "6  Goodreads  2 0.33803921600570275\n",
      "6  generate  2 0.19084850188786498\n",
      "6  1M  1 0.16901960800285137\n",
      "6  viewers  1 0.16901960800285137\n",
      "6  data  1 0.16901960800285137\n",
      "6  informative  1 0.16901960800285137\n",
      "6  systems  1 0.12041199826559248\n",
      "6  evaluation  1 0.16901960800285137\n",
      "6  generation  1 0.12041199826559248\n",
      "6  results  2 0.15917600346881505\n",
      "6  recent  1 0.12041199826559248\n",
      "6  powerful  1 0.16901960800285137\n",
      "6  dataset  4 0.6760784320114055\n",
      "6  scraping  1 0.16901960800285137\n",
      "6  use  1 0.12041199826559248\n",
      "6  cast  1 0.16901960800285137\n",
      "6  Large  1 0.06848453616444126\n",
      "6  author  1 0.16901960800285137\n",
      "6  compared  1 0.16901960800285137\n",
      "6  prompted  1 0.16901960800285137\n",
      "6  web-scraped  1 0.16901960800285137\n",
      "6  LLM-based  1 0.09542425094393249\n",
      "6  obtained  2 0.33803921600570275\n",
      "6  manual  1 0.16901960800285137\n",
      "6  demonstrated  1 0.16901960800285137\n",
      "6  description  3 0.5070588240085541\n",
      "6  potential  1 0.16901960800285137\n",
      "6  open  1 0.16901960800285137\n",
      "6  LLM  1 0.09542425094393249\n",
      "6  multiple  1 0.09542425094393249\n",
      "6  Traditionally  1 0.16901960800285137\n",
      "6  significant  1 0.16901960800285137\n",
      "6  Top  1 0.16901960800285137\n",
      "6  books  1 0.16901960800285137\n",
      "6  comparable  1 0.16901960800285137\n",
      "6  inconsistencies  1 0.16901960800285137\n",
      "6  using  1 0.06848453616444126\n",
      "6  explored  1 0.16901960800285137\n",
      "6  NDCG  1 0.16901960800285137\n",
      "6  few-shot  1 0.16901960800285137\n",
      "6  generated  1 0.16901960800285137\n",
      "6  recommendation  1 0.12041199826559248\n",
      "6  Dataset  1 0.16901960800285137\n",
      "6  like  2 0.33803921600570275\n",
      "6  combination  1 0.16901960800285137\n",
      "6  MovieLens  1 0.16901960800285137\n",
      "6  ML  1 0.16901960800285137\n",
      "6  plays  1 0.16901960800285137\n",
      "6  pivotal  1 0.16901960800285137\n",
      "6  susceptible  1 0.16901960800285137\n",
      "6  names  3 0.5070588240085541\n",
      "6  study  1 0.16901960800285137\n",
      "6  concise  1 0.16901960800285137\n",
      "6  Alpaca  2 0.33803921600570275\n",
      "6  tools  1 0.16901960800285137\n",
      "6  titles  1 0.16901960800285137\n",
      "6  conduct  1 0.16901960800285137\n",
      "6  subsequently  1 0.16901960800285137\n",
      "6  time-consuming  1 0.16901960800285137\n",
      "6  LLMs  3 0.23876400520322255\n",
      "6  scraped  1 0.16901960800285137\n",
      "6  detailed  2 0.33803921600570275\n",
      "6  techniques  1 0.09542425094393249\n",
      "6  language  1 0.07958800173440753\n",
      "6  Hits  1 0.16901960800285137\n",
      "6  tasks  1 0.06848453616444126\n",
      "6  Language  1 0.07958800173440753\n",
      "6  movie  3 0.5070588240085541\n",
      "6  role  1 0.16901960800285137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "descripteur_reg =\"\"\n",
    "\n",
    "for i in range(len(termes_reg)):\n",
    "    for j in range(len(termes_reg[i])):\n",
    "        frequency_term = frequency_dict_reg_documents[i][termes_reg[i][j]]\n",
    "        poids_term = poids(frequency_term,max_frequency_dict_reg_documents[i],document_frequency_dict_reg[termes_reg[i][j]],n_reg)\n",
    "        descripteur_reg = descripteur_reg + (str(i+1)+ \"  \" +termes_reg[i][j]+ \"  \" +str(frequency_term)+\" \"+ str(poids_term)+\"\\n\")\n",
    "\n",
    "\n",
    "print(descripteur_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  rank  1 0.1505149978319906\n",
      "1  relev  1 0.2112745100035642\n",
      "1  improv  4 0.3979400086720376\n",
      "1  18%  1 0.2112745100035642\n",
      "1  evalu  1 0.11928031367991561\n",
      "1  intent  1 0.1505149978319906\n",
      "1  msmarco  1 0.2112745100035642\n",
      "1  knowledg  1 0.2112745100035642\n",
      "1  instruct  1 0.1505149978319906\n",
      "1  technique,  1 0.2112745100035642\n",
      "1  investig  1 0.2112745100035642\n",
      "1  rel  1 0.2112745100035642\n",
      "1  recently,  1 0.2112745100035642\n",
      "1  promis  1 0.2112745100035642\n",
      "1  5%  1 0.2112745100035642\n",
      "1  retriev  1 0.1505149978319906\n",
      "1  shown  1 0.2112745100035642\n",
      "1  pseudo  1 0.2112745100035642\n",
      "1  mani  1 0.2112745100035642\n",
      "1  propos  1 0.08560567020555157\n",
      "1  take  1 0.11928031367991561\n",
      "1  leverag  1 0.11928031367991561\n",
      "1  prompt  1 0.0994850021680094\n",
      "1  approach  1 0.0994850021680094\n",
      "1  performance.  1 0.2112745100035642\n",
      "1  state-of-art.  1 0.2112745100035642\n",
      "1  four  1 0.2112745100035642\n",
      "1  use  2 0.17121134041110314\n",
      "1  tasks,  1 0.11928031367991561\n",
      "1  success  1 0.1505149978319906\n",
      "1  larg  1 0.0752574989159953\n",
      "1  24%  1 0.2112745100035642\n",
      "1  transform  1 0.2112745100035642\n",
      "1  reformulation(qr)  1 0.2112745100035642\n",
      "1  ultim  1 0.2112745100035642\n",
      "1  ndcg@10  1 0.2112745100035642\n",
      "1  pseudo-relev  1 0.2112745100035642\n",
      "1  documents.  1 0.2112745100035642\n",
      "1  benchmarks,  1 0.2112745100035642\n",
      "1  experience.  1 0.2112745100035642\n",
      "1  find  1 0.1505149978319906\n",
      "1  base  1 0.11928031367991561\n",
      "1  feedback,  1 0.2112745100035642\n",
      "1  set  2 0.23856062735983122\n",
      "1  qr  1 0.2112745100035642\n",
      "1  reformulation.  1 0.2112745100035642\n",
      "1  ir  1 0.2112745100035642\n",
      "1  show  1 0.1505149978319906\n",
      "1  9%  1 0.2112745100035642\n",
      "1  genqrensemblerf  1 0.2112745100035642\n",
      "1  benefit  1 0.2112745100035642\n",
      "1  ensembl  1 0.2112745100035642\n",
      "1  feedback  1 0.1505149978319906\n",
      "1  introduc  1 0.1505149978319906\n",
      "1  user’  1 0.2112745100035642\n",
      "1  due  1 0.2112745100035642\n",
      "1  context,  1 0.2112745100035642\n",
      "1  paraphras  1 0.2112745100035642\n",
      "1  exploit  1 0.2112745100035642\n",
      "1  inher  1 0.2112745100035642\n",
      "1  mrr  1 0.2112745100035642\n",
      "1  origin  1 0.2112745100035642\n",
      "1  text  1 0.1505149978319906\n",
      "1  post-retriev  1 0.2112745100035642\n",
      "1  languag  1 0.0752574989159953\n",
      "1  strategi  1 0.0994850021680094\n",
      "1  previou  1 0.11928031367991561\n",
      "1  feedback.  1 0.2112745100035642\n",
      "1  upto  1 0.2112745100035642\n",
      "1  align  1 0.2112745100035642\n",
      "1  keyword  1 0.2112745100035642\n",
      "1  task,  1 0.1505149978319906\n",
      "1  abil  1 0.1505149978319906\n",
      "1  genqrensembl  1 0.2112745100035642\n",
      "1  search  1 0.11928031367991561\n",
      "1  variant,  1 0.2112745100035642\n",
      "1  multipl  1 0.11928031367991561\n",
      "1  techniqu  1 0.11928031367991561\n",
      "1  incorpor  1 0.2112745100035642\n",
      "1  queri  2 0.1989700043360188\n",
      "1  gener  2 0.1989700043360188\n",
      "1  zero-shot  1 0.2112745100035642\n",
      "1  models.  1 0.1505149978319906\n",
      "1  reformul  1 0.1505149978319906\n",
      "1  better  1 0.2112745100035642\n",
      "1  gain  1 0.2112745100035642\n",
      "1  passag  1 0.2112745100035642\n",
      "1  map  1 0.2112745100035642\n",
      "1  inspir  1 0.1505149978319906\n",
      "1  help  1 0.2112745100035642\n",
      "2  rank  2 0.4013733275519749\n",
      "2  complex  1 0.20068666377598746\n",
      "2  (prp).  1 0.28169934667141894\n",
      "2  analyz  1 0.28169934667141894\n",
      "2  improv  1 0.13264666955734586\n",
      "2  moderate-s  1 0.28169934667141894\n",
      "2  gpt-4  1 0.28169934667141894\n",
      "2  averag  1 0.28169934667141894\n",
      "2  baselin  2 0.5633986933428379\n",
      "2  standard  1 0.28169934667141894\n",
      "2  open-sourc  1 0.20068666377598746\n",
      "2  flan-ul2  1 0.28169934667141894\n",
      "2  challeng  1 0.28169934667141894\n",
      "2  pairwis  1 0.28169934667141894\n",
      "2  furthermore,  1 0.20068666377598746\n",
      "2  formulations.  1 0.28169934667141894\n",
      "2  outperform  3 0.8450980400142568\n",
      "2  listwis  1 0.28169934667141894\n",
      "2  even  1 0.28169934667141894\n",
      "2  fine-tun  1 0.20068666377598746\n",
      "2  pointwis  1 0.28169934667141894\n",
      "2  10%  1 0.28169934667141894\n",
      "2  state-of-the-art  1 0.20068666377598746\n",
      "2  propos  1 0.1141408936074021\n",
      "2  directli  1 0.28169934667141894\n",
      "2  20b  1 0.28169934667141894\n",
      "2  found  1 0.28169934667141894\n",
      "2  interest  1 0.28169934667141894\n",
      "2  prompt  3 0.3979400086720376\n",
      "2  chatgpt  1 0.28169934667141894\n",
      "2  feed  1 0.28169934667141894\n",
      "2  problem.  1 0.28169934667141894\n",
      "2  method  1 0.20068666377598746\n",
      "2  ndcg@10.  1 0.20068666377598746\n",
      "2  trec-dl  1 0.28169934667141894\n",
      "2  175b  1 0.28169934667141894\n",
      "2  approach  1 0.13264666955734586\n",
      "2  (llms)  1 0.20068666377598746\n",
      "2  llm-base  1 0.15904041823988746\n",
      "2  reduc  1 0.20068666377598746\n",
      "2  variant  1 0.28169934667141894\n",
      "2  understand  1 0.20068666377598746\n",
      "2  4.2%  1 0.28169934667141894\n",
      "2  literatur  1 0.28169934667141894\n",
      "2  burden  1 0.28169934667141894\n",
      "2  exist  1 0.28169934667141894\n",
      "2  perform  2 0.4013733275519749\n",
      "2  use  2 0.2282817872148042\n",
      "2  tasks,  1 0.15904041823988746\n",
      "2  research  1 0.20068666377598746\n",
      "2  llm  1 0.1141408936074021\n",
      "2  sever  1 0.28169934667141894\n",
      "2  significantli  1 0.15904041823988746\n",
      "2  larg  1 0.10034333188799373\n",
      "2  off-the-shelf  1 0.28169934667141894\n",
      "2  practic  1 0.28169934667141894\n",
      "2  favor  1 0.28169934667141894\n",
      "2  document  1 0.28169934667141894\n",
      "2  fulli  1 0.28169934667141894\n",
      "2  ranker  1 0.20068666377598746\n",
      "2  benchmark  2 0.3180808364797749\n",
      "2  base  1 0.15904041823988746\n",
      "2  paper,  1 0.13264666955734586\n",
      "2  model  2 0.2282817872148042\n",
      "2  show  1 0.20068666377598746\n",
      "2  paramet  1 0.28169934667141894\n",
      "2  literature,  1 0.28169934667141894\n",
      "2  12-10%  1 0.28169934667141894\n",
      "2  2019  1 0.28169934667141894\n",
      "2  2020,  1 0.28169934667141894\n",
      "2  metrics.  1 0.20068666377598746\n",
      "2  beir  1 0.20068666377598746\n",
      "2  parameters,  1 0.28169934667141894\n",
      "2  (estimated)  1 0.28169934667141894\n",
      "2  templat  1 0.20068666377598746\n",
      "2  achiev  1 0.15904041823988746\n",
      "2  size,  1 0.28169934667141894\n",
      "2  datasets.  1 0.28169934667141894\n",
      "2  blackbox  1 0.28169934667141894\n",
      "2  difficult  1 0.28169934667141894\n",
      "2  prp  1 0.28169934667141894\n",
      "2  argu  1 0.28169934667141894\n",
      "2  best  1 0.28169934667141894\n",
      "2  llms.  1 0.20068666377598746\n",
      "2  languag  1 0.10034333188799373\n",
      "2  competit  1 0.28169934667141894\n",
      "2  previou  1 0.15904041823988746\n",
      "2  solutions,  1 0.28169934667141894\n",
      "2  however,  1 0.28169934667141894\n",
      "2  instructgpt  1 0.28169934667141894\n",
      "2  supervis  1 0.28169934667141894\n",
      "2  50x  1 0.28169934667141894\n",
      "2  linear  1 0.28169934667141894\n",
      "2  first  1 0.15904041823988746\n",
      "2  candid  1 0.28169934667141894\n",
      "2  techniqu  1 0.15904041823988746\n",
      "2  effici  1 0.20068666377598746\n",
      "2  queri  1 0.13264666955734586\n",
      "2  seven  1 0.28169934667141894\n",
      "2  new  1 0.28169934667141894\n",
      "2  result  1 0.13264666955734586\n",
      "2  commerci  1 0.28169934667141894\n",
      "2  call  1 0.28169934667141894\n",
      "2  possibl  1 0.28169934667141894\n",
      "2  solut  2 0.5633986933428379\n",
      "3  train  1 0.4225490200071284\n",
      "3  distil  2 0.8450980400142568\n",
      "3  process,  1 0.3010299956639812\n",
      "3  improv  2 0.3979400086720376\n",
      "3  design  1 0.4225490200071284\n",
      "3  attempt  1 0.4225490200071284\n",
      "3  experiment  1 0.4225490200071284\n",
      "3  item  1 0.3010299956639812\n",
      "3  may  1 0.4225490200071284\n",
      "3  although  1 0.4225490200071284\n",
      "3  extens  1 0.4225490200071284\n",
      "3  mostli  1 0.4225490200071284\n",
      "3  tasks.  1 0.3010299956639812\n",
      "3  demonstr  1 0.23856062735983122\n",
      "3  (i.e.,  1 0.4225490200071284\n",
      "3  limit  1 0.3010299956639812\n",
      "3  word  1 0.4225490200071284\n",
      "3  fine-tun  1 0.3010299956639812\n",
      "3  plain  1 0.4225490200071284\n",
      "3  bridg  1 0.3010299956639812\n",
      "3  propos  1 0.17121134041110314\n",
      "3  take  1 0.23856062735983122\n",
      "3  id  1 0.4225490200071284\n",
      "3  capabl  1 0.4225490200071284\n",
      "3  prompt  2 0.3979400086720376\n",
      "3  manifest  1 0.4225490200071284\n",
      "3  enough  1 0.4225490200071284\n",
      "3  variou  1 0.3010299956639812\n",
      "3  limited.  1 0.4225490200071284\n",
      "3  user/item  1 0.4225490200071284\n",
      "3  long  2 0.8450980400142568\n",
      "3  approach  1 0.1989700043360188\n",
      "3  llm-base  1 0.23856062735983122\n",
      "3  reduc  1 0.3010299956639812\n",
      "3  contain  1 0.4225490200071284\n",
      "3  understand  1 0.3010299956639812\n",
      "3  multi-step  1 0.4225490200071284\n",
      "3  time.  1 0.3010299956639812\n",
      "3  requir  1 0.4225490200071284\n",
      "3  usual  1 0.4225490200071284\n",
      "3  dataset  1 0.3010299956639812\n",
      "3  (pod)  1 0.4225490200071284\n",
      "3  discret  1 0.4225490200071284\n",
      "3  unparallel  1 0.4225490200071284\n",
      "3  tasks,  1 0.23856062735983122\n",
      "3  research  1 0.3010299956639812\n",
      "3  llm  1 0.17121134041110314\n",
      "3  input  1 0.23856062735983122\n",
      "3  power  1 0.23856062735983122\n",
      "3  significantli  1 0.23856062735983122\n",
      "3  vector  1 0.4225490200071284\n",
      "3  larg  1 0.1505149978319906\n",
      "3  specif  1 0.4225490200071284\n",
      "3  fill  1 0.4225490200071284\n",
      "3  infer  1 0.4225490200071284\n",
      "3  thu  1 0.4225490200071284\n",
      "3  models,  1 0.4225490200071284\n",
      "3  (llm)  1 0.4225490200071284\n",
      "3  find  1 0.3010299956639812\n",
      "3  need  1 0.4225490200071284\n",
      "3  three  1 0.4225490200071284\n",
      "3  also  1 0.3010299956639812\n",
      "3  set  1 0.23856062735983122\n",
      "3  time  1 0.4225490200071284\n",
      "3  continu  1 0.4225490200071284\n",
      "3  model  2 0.3424226808222063\n",
      "3  information.  1 0.4225490200071284\n",
      "3  given  1 0.3010299956639812\n",
      "3  response.  1 0.4225490200071284\n",
      "3  task  1 0.3010299956639812\n",
      "3  user  1 0.4225490200071284\n",
      "3  effect  1 0.23856062735983122\n",
      "3  allow  1 0.3010299956639812\n",
      "3  prompt)  1 0.4225490200071284\n",
      "3  recommendation.  1 0.4225490200071284\n",
      "3  problems,  1 0.4225490200071284\n",
      "3  templat  1 0.3010299956639812\n",
      "3  could  1 0.4225490200071284\n",
      "3  text  1 0.3010299956639812\n",
      "3  address  1 0.4225490200071284\n",
      "3  real-world  1 0.4225490200071284\n",
      "3  commun  1 0.4225490200071284\n",
      "3  unleash  1 0.4225490200071284\n",
      "3  languag  1 0.1505149978319906\n",
      "3  strategi  1 0.1989700043360188\n",
      "3  e.g.,  1 0.4225490200071284\n",
      "3  task,  1 0.3010299956639812\n",
      "3  top-n  1 0.4225490200071284\n",
      "3  reasoning,  1 0.4225490200071284\n",
      "3  sequenti  1 0.3010299956639812\n",
      "3  recommend  2 0.6020599913279624\n",
      "3  noisi  1 0.4225490200071284\n",
      "3  effici  2 0.6020599913279624\n",
      "3  improved,  1 0.4225490200071284\n",
      "3  immedi  1 0.4225490200071284\n",
      "3  models.  1 0.3010299956639812\n",
      "3  result  1 0.1989700043360188\n",
      "3  system  1 0.4225490200071284\n",
      "3  text,  1 0.4225490200071284\n",
      "3  inspir  1 0.3010299956639812\n",
      "4  innov  1 0.28169934667141894\n",
      "4  improv  1 0.13264666955734586\n",
      "4  gencrf:  1 0.28169934667141894\n",
      "4  evalu  1 0.15904041823988746\n",
      "4  intent  2 0.4013733275519749\n",
      "4  adapt  2 0.5633986933428379\n",
      "4  modifi  1 0.28169934667141894\n",
      "4  aggreg  1 0.28169934667141894\n",
      "4  empir  1 0.28169934667141894\n",
      "4  inform  1 0.15904041823988746\n",
      "4  boost  1 0.28169934667141894\n",
      "4  experi  1 0.20068666377598746\n",
      "4  demonstr  1 0.15904041823988746\n",
      "4  combin  1 0.20068666377598746\n",
      "4  aim  1 0.20068666377598746\n",
      "4  rate  1 0.28169934667141894\n",
      "4  retriev  3 0.6020599913279624\n",
      "4  furthermore,  1 0.20068666377598746\n",
      "4  (qerm)  1 0.28169934667141894\n",
      "4  limit  1 0.20068666377598746\n",
      "4  problem  1 0.28169934667141894\n",
      "4  enhanc  1 0.20068666377598746\n",
      "4  state-of-the-art  1 0.20068666377598746\n",
      "4  propos  1 0.1141408936074021\n",
      "4  leverag  2 0.3180808364797749\n",
      "4  group  1 0.28169934667141894\n",
      "4  variou  1 0.20068666377598746\n",
      "4  cluster  2 0.5633986933428379\n",
      "4  ndcg@10.  1 0.20068666377598746\n",
      "4  method  1 0.20068666377598746\n",
      "4  advanc  1 0.28169934667141894\n",
      "4  reward  1 0.28169934667141894\n",
      "4  variabl  1 0.28169934667141894\n",
      "4  (llms)  1 0.20068666377598746\n",
      "4  time.  1 0.20068666377598746\n",
      "4  expansions,  1 0.28169934667141894\n",
      "4  recent  1 0.15904041823988746\n",
      "4  novel  1 0.20068666377598746\n",
      "4  perform  1 0.20068666377598746\n",
      "4  crucial  1 0.28169934667141894\n",
      "4  use  1 0.1141408936074021\n",
      "4  query.  1 0.28169934667141894\n",
      "4  llm  1 0.1141408936074021\n",
      "4  retrieval.  1 0.28169934667141894\n",
      "4  input  1 0.15904041823988746\n",
      "4  success  1 0.20068666377598746\n",
      "4  redund  1 0.28169934667141894\n",
      "4  significantli  1 0.15904041823988746\n",
      "4  complet  1 0.28169934667141894\n",
      "4  larg  1 0.10034333188799373\n",
      "4  performance,  1 0.28169934667141894\n",
      "4  field  1 0.28169934667141894\n",
      "4  intents.  1 0.28169934667141894\n",
      "4  custom  1 0.28169934667141894\n",
      "4  12%  1 0.28169934667141894\n",
      "4  benchmark  1 0.15904041823988746\n",
      "4  optim  1 0.28169934667141894\n",
      "4  base  1 0.15904041823988746\n",
      "4  repres  1 0.28169934667141894\n",
      "4  paper,  1 0.13264666955734586\n",
      "4  differentiated,  1 0.28169934667141894\n",
      "4  phase  1 0.28169934667141894\n",
      "4  model  2 0.2282817872148042\n",
      "4  framework  2 0.5633986933428379\n",
      "4  distinctli  1 0.28169934667141894\n",
      "4  refin  1 0.28169934667141894\n",
      "4  effect  1 0.15904041823988746\n",
      "4  feedback  1 0.20068666377598746\n",
      "4  beir  1 0.20068666377598746\n",
      "4  initi  1 0.28169934667141894\n",
      "4  achiev  1 0.15904041823988746\n",
      "4  singl  1 0.28169934667141894\n",
      "4  reformulation,  1 0.28169934667141894\n",
      "4  explor  1 0.20068666377598746\n",
      "4  process  1 0.20068666377598746\n",
      "4  user'  1 0.20068666377598746\n",
      "4  weight  1 0.28169934667141894\n",
      "4  constrain  1 0.28169934667141894\n",
      "4  loops.  1 0.28169934667141894\n",
      "4  well-known  1 0.28169934667141894\n",
      "4  languag  1 0.10034333188799373\n",
      "4  strategi  1 0.13264666955734586\n",
      "4  previou  1 0.15904041823988746\n",
      "4  potenti  1 0.20068666377598746\n",
      "4  often  1 0.28169934667141894\n",
      "4  well-gener  1 0.28169934667141894\n",
      "4  sota  1 0.28169934667141894\n",
      "4  gencrf  1 0.28169934667141894\n",
      "4  captur  2 0.4013733275519749\n",
      "4  (ir)  1 0.28169934667141894\n",
      "4  first  1 0.15904041823988746\n",
      "4  search  1 0.15904041823988746\n",
      "4  llms,  1 0.28169934667141894\n",
      "4  multipl  1 0.15904041823988746\n",
      "4  techniqu  1 0.15904041823988746\n",
      "4  queri  3 0.3979400086720376\n",
      "4  surpass  1 0.28169934667141894\n",
      "4  prompts,  1 0.28169934667141894\n",
      "4  divers  1 0.28169934667141894\n",
      "4  gener  2 0.2652933391146917\n",
      "4  reformul  2 0.4013733275519749\n",
      "4  automat  1 0.28169934667141894\n",
      "4  integr  1 0.20068666377598746\n",
      "5  symbol  2 0.5633986933428379\n",
      "5  corpora,  1 0.28169934667141894\n",
      "5  history,  1 0.28169934667141894\n",
      "5  pre-train  1 0.28169934667141894\n",
      "5  process,  1 0.20068666377598746\n",
      "5  complex  1 0.20068666377598746\n",
      "5  neglect  1 0.28169934667141894\n",
      "5  contrast  1 0.28169934667141894\n",
      "5  learn  1 0.28169934667141894\n",
      "5  format.  1 0.28169934667141894\n",
      "5  action  1 0.28169934667141894\n",
      "5  represent  1 0.28169934667141894\n",
      "5  includ  1 0.28169934667141894\n",
      "5  text-bas  1 0.28169934667141894\n",
      "5  instruct  1 0.20068666377598746\n",
      "5  (sgr),  1 0.28169934667141894\n",
      "5  inform  1 0.15904041823988746\n",
      "5  experi  1 0.20068666377598746\n",
      "5  modern  1 0.28169934667141894\n",
      "5  aim  1 0.20068666377598746\n",
      "5  documents,  1 0.28169934667141894\n",
      "5  interact  2 0.5633986933428379\n",
      "5  enhanc  1 0.20068666377598746\n",
      "5  bridg  1 0.20068666377598746\n",
      "5  analysi  1 0.28169934667141894\n",
      "5  propos  1 0.1141408936074021\n",
      "5  typic  1 0.28169934667141894\n",
      "5  take  1 0.15904041823988746\n",
      "5  leverag  1 0.15904041823988746\n",
      "5  (llms).  1 0.28169934667141894\n",
      "5  information,  1 0.28169934667141894\n",
      "5  this,  1 0.28169934667141894\n",
      "5  overlook  1 0.28169934667141894\n",
      "5  graph-bas  1 0.28169934667141894\n",
      "5  graph-to-text  1 0.28169934667141894\n",
      "5  grammar,  1 0.28169934667141894\n",
      "5  datasets,  1 0.28169934667141894\n",
      "5  approach  1 0.13264666955734586\n",
      "5  superior  1 0.28169934667141894\n",
      "5  need.  1 0.28169934667141894\n",
      "5  natur  1 0.20068666377598746\n",
      "5  discrep  1 0.28169934667141894\n",
      "5  concretely,  1 0.28169934667141894\n",
      "5  recent  1 0.15904041823988746\n",
      "5  novel  1 0.20068666377598746\n",
      "5  two  1 0.28169934667141894\n",
      "5  link  1 0.28169934667141894\n",
      "5  confirm  1 0.28169934667141894\n",
      "5  use  2 0.2282817872148042\n",
      "5  llm  1 0.1141408936074021\n",
      "5  modeling.  1 0.28169934667141894\n",
      "5  input  1 0.15904041823988746\n",
      "5  power  1 0.15904041823988746\n",
      "5  learning,  1 0.28169934667141894\n",
      "5  fulfil  1 0.28169934667141894\n",
      "5  larg  1 0.10034333188799373\n",
      "5  tiangong-st,  1 0.28169934667141894\n",
      "5  paradigm  1 0.28169934667141894\n",
      "5  topolog  1 0.28169934667141894\n",
      "5  tradit  1 0.28169934667141894\n",
      "5  advantag  1 0.28169934667141894\n",
      "5  ranker  1 0.20068666377598746\n",
      "5  prediction,  1 0.28169934667141894\n",
      "5  semant  1 0.28169934667141894\n",
      "5  benchmark  1 0.15904041823988746\n",
      "5  methodolog  1 0.28169934667141894\n",
      "5  offer  1 0.28169934667141894\n",
      "5  produc  1 0.28169934667141894\n",
      "5  llms'  1 0.28169934667141894\n",
      "5  graph  2 0.5633986933428379\n",
      "5  grammar  1 0.28169934667141894\n",
      "5  also  1 0.20068666377598746\n",
      "5  set  1 0.15904041823988746\n",
      "5  self-supervis  1 0.28169934667141894\n",
      "5  paper,  1 0.13264666955734586\n",
      "5  model  2 0.2282817872148042\n",
      "5  convert  1 0.28169934667141894\n",
      "5  given  1 0.20068666377598746\n",
      "5  task  2 0.4013733275519749\n",
      "5  seamlessli  1 0.28169934667141894\n",
      "5  interactions.  1 0.28169934667141894\n",
      "5  effect  1 0.15904041823988746\n",
      "5  allow  1 0.20068666377598746\n",
      "5  introduc  1 0.20068666377598746\n",
      "5  achiev  1 0.15904041823988746\n",
      "5  object  1 0.28169934667141894\n",
      "5  user'  1 0.20068666377598746\n",
      "5  understanding,  1 0.28169934667141894\n",
      "5  moreover,  1 0.28169934667141894\n",
      "5  word-level  1 0.28169934667141894\n",
      "5  structur  3 0.8450980400142568\n",
      "5  generation,  1 0.28169934667141894\n",
      "5  involv  1 0.28169934667141894\n",
      "5  llms.  1 0.20068666377598746\n",
      "5  textual  1 0.28169934667141894\n",
      "5  languag  2 0.20068666377598746\n",
      "5  strategi  1 0.13264666955734586\n",
      "5  content  1 0.28169934667141894\n",
      "5  llm.  1 0.28169934667141894\n",
      "5  fine-grained.  1 0.28169934667141894\n",
      "5  priorit  1 0.28169934667141894\n",
      "5  node  1 0.28169934667141894\n",
      "5  captur  2 0.4013733275519749\n",
      "5  rule  1 0.28169934667141894\n",
      "5  deep  1 0.28169934667141894\n",
      "5  first  1 0.15904041823988746\n",
      "5  abil  1 0.20068666377598746\n",
      "5  enabl  1 0.28169934667141894\n",
      "5  focu  1 0.28169934667141894\n",
      "5  sequenti  1 0.20068666377598746\n",
      "5  search  1 0.15904041823988746\n",
      "5  text.  1 0.28169934667141894\n",
      "5  coarse-grain  1 0.28169934667141894\n",
      "5  seri  1 0.28169934667141894\n",
      "5  queri  1 0.13264666955734586\n",
      "5  gener  2 0.2652933391146917\n",
      "5  within  1 0.28169934667141894\n",
      "5  result  1 0.13264666955734586\n",
      "5  aol  1 0.28169934667141894\n",
      "5  approach.  1 0.28169934667141894\n",
      "5  session  2 0.5633986933428379\n",
      "5  integr  1 0.20068666377598746\n",
      "5  comprehens  1 0.28169934667141894\n",
      "5  current  1 0.28169934667141894\n",
      "5  gap  1 0.28169934667141894\n",
      "6  play  1 0.28169934667141894\n",
      "6  systems.  1 0.28169934667141894\n",
      "6  viewer  1 0.28169934667141894\n",
      "6  evalu  1 0.15904041823988746\n",
      "6  compar  2 0.5633986933428379\n",
      "6  alpaca  1 0.28169934667141894\n",
      "6  item  1 0.20068666377598746\n",
      "6  consid  1 0.28169934667141894\n",
      "6  open-sourc  1 0.20068666377598746\n",
      "6  inform  1 0.15904041823988746\n",
      "6  obtain  1 0.28169934667141894\n",
      "6  publish  1 0.28169934667141894\n",
      "6  tasks.  1 0.20068666377598746\n",
      "6  demonstr  1 0.15904041823988746\n",
      "6  combin  1 0.20068666377598746\n",
      "6  web  1 0.28169934667141894\n",
      "6  alpaca,  1 0.28169934667141894\n",
      "6  director  1 0.28169934667141894\n",
      "6  prompt  2 0.2652933391146917\n",
      "6  hits,  1 0.28169934667141894\n",
      "6  one  1 0.28169934667141894\n",
      "6  ndcg  1 0.28169934667141894\n",
      "6  featur  1 0.28169934667141894\n",
      "6  promise,  1 0.28169934667141894\n",
      "6  gpt-3.5,  1 0.28169934667141894\n",
      "6  top  1 0.28169934667141894\n",
      "6  consist  1 0.28169934667141894\n",
      "6  movielen  1 0.28169934667141894\n",
      "6  data  1 0.28169934667141894\n",
      "6  inconsistencies.  1 0.28169934667141894\n",
      "6  llm-base  1 0.15904041823988746\n",
      "6  emerg  1 0.28169934667141894\n",
      "6  signific  1 0.28169934667141894\n",
      "6  natur  1 0.20068666377598746\n",
      "6  1m  1 0.28169934667141894\n",
      "6  titl  1 0.28169934667141894\n",
      "6  recent  1 0.15904041823988746\n",
      "6  descriptions.  1 0.28169934667141894\n",
      "6  subsequently,  1 0.28169934667141894\n",
      "6  dataset  2 0.4013733275519749\n",
      "6  book  1 0.28169934667141894\n",
      "6  compris  1 0.28169934667141894\n",
      "6  use  3 0.3424226808222063\n",
      "6  cast  1 0.28169934667141894\n",
      "6  llm  1 0.1141408936074021\n",
      "6  power  1 0.15904041823988746\n",
      "6  summari  1 0.28169934667141894\n",
      "6  author  1 0.28169934667141894\n",
      "6  larg  1 0.10034333188799373\n",
      "6  web-scrap  1 0.28169934667141894\n",
      "6  traditionally,  1 0.28169934667141894\n",
      "6  manual  1 0.28169934667141894\n",
      "6  descript  2 0.5633986933428379\n",
      "6  open  1 0.28169934667141894\n",
      "6  pivot  1 0.28169934667141894\n",
      "6  paper,  1 0.13264666955734586\n",
      "6  ml  1 0.28169934667141894\n",
      "6  model  1 0.1141408936074021\n",
      "6  name  1 0.28169934667141894\n",
      "6  study,  1 0.28169934667141894\n",
      "6  metrics.  1 0.20068666377598746\n",
      "6  llm,  1 0.28169934667141894\n",
      "6  provid  1 0.28169934667141894\n",
      "6  time-consum  1 0.28169934667141894\n",
      "6  goodread  1 0.28169934667141894\n",
      "6  explor  1 0.20068666377598746\n",
      "6  process  1 0.20068666377598746\n",
      "6  items.  1 0.28169934667141894\n",
      "6  suscept  1 0.28169934667141894\n",
      "6  movi  1 0.28169934667141894\n",
      "6  few-shot  1 0.28169934667141894\n",
      "6  concis  1 0.28169934667141894\n",
      "6  techniques,  1 0.28169934667141894\n",
      "6  languag  2 0.20068666377598746\n",
      "6  exhibit  1 0.28169934667141894\n",
      "6  potenti  1 0.20068666377598746\n",
      "6  like  1 0.28169934667141894\n",
      "6  tool  1 0.28169934667141894\n",
      "6  essenti  1 0.28169934667141894\n",
      "6  sourc  1 0.28169934667141894\n",
      "6  captiv  1 0.28169934667141894\n",
      "6  (llms),  1 0.28169934667141894\n",
      "6  detail  1 0.28169934667141894\n",
      "6  mrr,  1 0.28169934667141894\n",
      "6  recommend  1 0.20068666377598746\n",
      "6  multipl  1 0.15904041823988746\n",
      "6  dataset.  1 0.28169934667141894\n",
      "6  years,  1 0.28169934667141894\n",
      "6  conduct  1 0.28169934667141894\n",
      "6  gener  3 0.3979400086720376\n",
      "6  result  1 0.13264666955734586\n",
      "6  scrape  2 0.5633986933428379\n",
      "6  role  1 0.28169934667141894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "descripteur_split_porter =\"\"\n",
    "\n",
    "for i in range(len(termes_split_porter)):\n",
    "    \n",
    "    for j in range(len(termes_split_porter[i])):\n",
    "\n",
    "        term = termes_split_porter[i][j]\n",
    "        #print(str(i) + \" \" +str(j)+ \" \" +term +\"\\n\")\n",
    "\n",
    "        frequency_term = frequency_dict_split_porter_documents[i][term]\n",
    "        max_frequancy = max_frequency_dict_split_porter_documents[i]\n",
    "        frequency_in_collection = document_frequency_dict_split_porter[term]\n",
    "\n",
    "        poids_term = poids(frequency_term,max_frequancy,frequency_in_collection,n_split)\n",
    "\n",
    "        descripteur_split_porter = descripteur_split_porter + (str(i+1)+ \"  \" +termes_split_porter[i][j]+ \"  \" +str(frequency_term)+\" \"+ str(poids_term)+\"\\n\")\n",
    "\n",
    "\n",
    "print(descripteur_split_porter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  rank  1 0.1505149978319906\n",
      "1  relev  1 0.2112745100035642\n",
      "1  improv  4 0.3979400086720376\n",
      "1  18%  1 0.2112745100035642\n",
      "1  evalu  1 0.11928031367991561\n",
      "1  intent  1 0.1505149978319906\n",
      "1  msmarco  1 0.2112745100035642\n",
      "1  knowledg  1 0.2112745100035642\n",
      "1  instruct  1 0.1505149978319906\n",
      "1  technique,  1 0.2112745100035642\n",
      "1  investig  1 0.2112745100035642\n",
      "1  rel  1 0.2112745100035642\n",
      "1  recently,  1 0.2112745100035642\n",
      "1  promis  1 0.2112745100035642\n",
      "1  5%  1 0.2112745100035642\n",
      "1  retriev  1 0.1505149978319906\n",
      "1  shown  1 0.2112745100035642\n",
      "1  pseudo  1 0.2112745100035642\n",
      "1  mani  1 0.2112745100035642\n",
      "1  propos  1 0.08560567020555157\n",
      "1  take  1 0.11928031367991561\n",
      "1  leverag  1 0.11928031367991561\n",
      "1  prompt  1 0.0994850021680094\n",
      "1  approach  1 0.0994850021680094\n",
      "1  performance.  1 0.2112745100035642\n",
      "1  state-of-art.  1 0.2112745100035642\n",
      "1  four  1 0.2112745100035642\n",
      "1  use  2 0.17121134041110314\n",
      "1  tasks,  1 0.11928031367991561\n",
      "1  success  1 0.1505149978319906\n",
      "1  larg  1 0.0752574989159953\n",
      "1  24%  1 0.2112745100035642\n",
      "1  transform  1 0.2112745100035642\n",
      "1  reformulation(qr)  1 0.2112745100035642\n",
      "1  ultim  1 0.2112745100035642\n",
      "1  ndcg@10  1 0.2112745100035642\n",
      "1  pseudo-relev  1 0.2112745100035642\n",
      "1  documents.  1 0.2112745100035642\n",
      "1  benchmarks,  1 0.2112745100035642\n",
      "1  experience.  1 0.2112745100035642\n",
      "1  find  1 0.1505149978319906\n",
      "1  base  1 0.11928031367991561\n",
      "1  feedback,  1 0.2112745100035642\n",
      "1  set  2 0.23856062735983122\n",
      "1  qr  1 0.2112745100035642\n",
      "1  reformulation.  1 0.2112745100035642\n",
      "1  ir  1 0.2112745100035642\n",
      "1  show  1 0.1505149978319906\n",
      "1  9%  1 0.2112745100035642\n",
      "1  genqrensemblerf  1 0.2112745100035642\n",
      "1  benefit  1 0.2112745100035642\n",
      "1  ensembl  1 0.2112745100035642\n",
      "1  feedback  1 0.1505149978319906\n",
      "1  introduc  1 0.1505149978319906\n",
      "1  user’  1 0.2112745100035642\n",
      "1  due  1 0.2112745100035642\n",
      "1  context,  1 0.2112745100035642\n",
      "1  paraphras  1 0.2112745100035642\n",
      "1  exploit  1 0.2112745100035642\n",
      "1  inher  1 0.2112745100035642\n",
      "1  mrr  1 0.2112745100035642\n",
      "1  origin  1 0.2112745100035642\n",
      "1  text  1 0.1505149978319906\n",
      "1  post-retriev  1 0.2112745100035642\n",
      "1  languag  1 0.0752574989159953\n",
      "1  strategi  1 0.0994850021680094\n",
      "1  previou  1 0.11928031367991561\n",
      "1  feedback.  1 0.2112745100035642\n",
      "1  upto  1 0.2112745100035642\n",
      "1  align  1 0.2112745100035642\n",
      "1  keyword  1 0.2112745100035642\n",
      "1  task,  1 0.1505149978319906\n",
      "1  abil  1 0.1505149978319906\n",
      "1  genqrensembl  1 0.2112745100035642\n",
      "1  search  1 0.11928031367991561\n",
      "1  variant,  1 0.2112745100035642\n",
      "1  multipl  1 0.11928031367991561\n",
      "1  techniqu  1 0.11928031367991561\n",
      "1  incorpor  1 0.2112745100035642\n",
      "1  queri  2 0.1989700043360188\n",
      "1  gener  2 0.1989700043360188\n",
      "1  zero-shot  1 0.2112745100035642\n",
      "1  models.  1 0.1505149978319906\n",
      "1  reformul  1 0.1505149978319906\n",
      "1  better  1 0.2112745100035642\n",
      "1  gain  1 0.2112745100035642\n",
      "1  passag  1 0.2112745100035642\n",
      "1  map  1 0.2112745100035642\n",
      "1  inspir  1 0.1505149978319906\n",
      "1  help  1 0.2112745100035642\n",
      "2  rank  2 0.4013733275519749\n",
      "2  complex  1 0.20068666377598746\n",
      "2  (prp).  1 0.28169934667141894\n",
      "2  analyz  1 0.28169934667141894\n",
      "2  improv  1 0.13264666955734586\n",
      "2  moderate-s  1 0.28169934667141894\n",
      "2  gpt-4  1 0.28169934667141894\n",
      "2  averag  1 0.28169934667141894\n",
      "2  baselin  2 0.5633986933428379\n",
      "2  standard  1 0.28169934667141894\n",
      "2  open-sourc  1 0.20068666377598746\n",
      "2  flan-ul2  1 0.28169934667141894\n",
      "2  challeng  1 0.28169934667141894\n",
      "2  pairwis  1 0.28169934667141894\n",
      "2  furthermore,  1 0.20068666377598746\n",
      "2  formulations.  1 0.28169934667141894\n",
      "2  outperform  3 0.8450980400142568\n",
      "2  listwis  1 0.28169934667141894\n",
      "2  even  1 0.28169934667141894\n",
      "2  fine-tun  1 0.20068666377598746\n",
      "2  pointwis  1 0.28169934667141894\n",
      "2  10%  1 0.28169934667141894\n",
      "2  state-of-the-art  1 0.20068666377598746\n",
      "2  propos  1 0.1141408936074021\n",
      "2  directli  1 0.28169934667141894\n",
      "2  20b  1 0.28169934667141894\n",
      "2  found  1 0.28169934667141894\n",
      "2  interest  1 0.28169934667141894\n",
      "2  prompt  3 0.3979400086720376\n",
      "2  chatgpt  1 0.28169934667141894\n",
      "2  feed  1 0.28169934667141894\n",
      "2  problem.  1 0.28169934667141894\n",
      "2  method  1 0.20068666377598746\n",
      "2  ndcg@10.  1 0.20068666377598746\n",
      "2  trec-dl  1 0.28169934667141894\n",
      "2  175b  1 0.28169934667141894\n",
      "2  approach  1 0.13264666955734586\n",
      "2  (llms)  1 0.20068666377598746\n",
      "2  llm-base  1 0.15904041823988746\n",
      "2  reduc  1 0.20068666377598746\n",
      "2  variant  1 0.28169934667141894\n",
      "2  understand  1 0.20068666377598746\n",
      "2  4.2%  1 0.28169934667141894\n",
      "2  literatur  1 0.28169934667141894\n",
      "2  burden  1 0.28169934667141894\n",
      "2  exist  1 0.28169934667141894\n",
      "2  perform  2 0.4013733275519749\n",
      "2  use  2 0.2282817872148042\n",
      "2  tasks,  1 0.15904041823988746\n",
      "2  research  1 0.20068666377598746\n",
      "2  llm  1 0.1141408936074021\n",
      "2  sever  1 0.28169934667141894\n",
      "2  significantli  1 0.15904041823988746\n",
      "2  larg  1 0.10034333188799373\n",
      "2  off-the-shelf  1 0.28169934667141894\n",
      "2  practic  1 0.28169934667141894\n",
      "2  favor  1 0.28169934667141894\n",
      "2  document  1 0.28169934667141894\n",
      "2  fulli  1 0.28169934667141894\n",
      "2  ranker  1 0.20068666377598746\n",
      "2  benchmark  2 0.3180808364797749\n",
      "2  base  1 0.15904041823988746\n",
      "2  paper,  1 0.13264666955734586\n",
      "2  model  2 0.2282817872148042\n",
      "2  show  1 0.20068666377598746\n",
      "2  paramet  1 0.28169934667141894\n",
      "2  literature,  1 0.28169934667141894\n",
      "2  12-10%  1 0.28169934667141894\n",
      "2  2019  1 0.28169934667141894\n",
      "2  2020,  1 0.28169934667141894\n",
      "2  metrics.  1 0.20068666377598746\n",
      "2  beir  1 0.20068666377598746\n",
      "2  parameters,  1 0.28169934667141894\n",
      "2  (estimated)  1 0.28169934667141894\n",
      "2  templat  1 0.20068666377598746\n",
      "2  achiev  1 0.15904041823988746\n",
      "2  size,  1 0.28169934667141894\n",
      "2  datasets.  1 0.28169934667141894\n",
      "2  blackbox  1 0.28169934667141894\n",
      "2  difficult  1 0.28169934667141894\n",
      "2  prp  1 0.28169934667141894\n",
      "2  argu  1 0.28169934667141894\n",
      "2  best  1 0.28169934667141894\n",
      "2  llms.  1 0.20068666377598746\n",
      "2  languag  1 0.10034333188799373\n",
      "2  competit  1 0.28169934667141894\n",
      "2  previou  1 0.15904041823988746\n",
      "2  solutions,  1 0.28169934667141894\n",
      "2  however,  1 0.28169934667141894\n",
      "2  instructgpt  1 0.28169934667141894\n",
      "2  supervis  1 0.28169934667141894\n",
      "2  50x  1 0.28169934667141894\n",
      "2  linear  1 0.28169934667141894\n",
      "2  first  1 0.15904041823988746\n",
      "2  candid  1 0.28169934667141894\n",
      "2  techniqu  1 0.15904041823988746\n",
      "2  effici  1 0.20068666377598746\n",
      "2  queri  1 0.13264666955734586\n",
      "2  seven  1 0.28169934667141894\n",
      "2  new  1 0.28169934667141894\n",
      "2  result  1 0.13264666955734586\n",
      "2  commerci  1 0.28169934667141894\n",
      "2  call  1 0.28169934667141894\n",
      "2  possibl  1 0.28169934667141894\n",
      "2  solut  2 0.5633986933428379\n",
      "3  train  1 0.4225490200071284\n",
      "3  distil  2 0.8450980400142568\n",
      "3  process,  1 0.3010299956639812\n",
      "3  improv  2 0.3979400086720376\n",
      "3  design  1 0.4225490200071284\n",
      "3  attempt  1 0.4225490200071284\n",
      "3  experiment  1 0.4225490200071284\n",
      "3  item  1 0.3010299956639812\n",
      "3  may  1 0.4225490200071284\n",
      "3  although  1 0.4225490200071284\n",
      "3  extens  1 0.4225490200071284\n",
      "3  mostli  1 0.4225490200071284\n",
      "3  tasks.  1 0.3010299956639812\n",
      "3  demonstr  1 0.23856062735983122\n",
      "3  (i.e.,  1 0.4225490200071284\n",
      "3  limit  1 0.3010299956639812\n",
      "3  word  1 0.4225490200071284\n",
      "3  fine-tun  1 0.3010299956639812\n",
      "3  plain  1 0.4225490200071284\n",
      "3  bridg  1 0.3010299956639812\n",
      "3  propos  1 0.17121134041110314\n",
      "3  take  1 0.23856062735983122\n",
      "3  id  1 0.4225490200071284\n",
      "3  capabl  1 0.4225490200071284\n",
      "3  prompt  2 0.3979400086720376\n",
      "3  manifest  1 0.4225490200071284\n",
      "3  enough  1 0.4225490200071284\n",
      "3  variou  1 0.3010299956639812\n",
      "3  limited.  1 0.4225490200071284\n",
      "3  user/item  1 0.4225490200071284\n",
      "3  long  2 0.8450980400142568\n",
      "3  approach  1 0.1989700043360188\n",
      "3  llm-base  1 0.23856062735983122\n",
      "3  reduc  1 0.3010299956639812\n",
      "3  contain  1 0.4225490200071284\n",
      "3  understand  1 0.3010299956639812\n",
      "3  multi-step  1 0.4225490200071284\n",
      "3  time.  1 0.3010299956639812\n",
      "3  requir  1 0.4225490200071284\n",
      "3  usual  1 0.4225490200071284\n",
      "3  dataset  1 0.3010299956639812\n",
      "3  (pod)  1 0.4225490200071284\n",
      "3  discret  1 0.4225490200071284\n",
      "3  unparallel  1 0.4225490200071284\n",
      "3  tasks,  1 0.23856062735983122\n",
      "3  research  1 0.3010299956639812\n",
      "3  llm  1 0.17121134041110314\n",
      "3  input  1 0.23856062735983122\n",
      "3  power  1 0.23856062735983122\n",
      "3  significantli  1 0.23856062735983122\n",
      "3  vector  1 0.4225490200071284\n",
      "3  larg  1 0.1505149978319906\n",
      "3  specif  1 0.4225490200071284\n",
      "3  fill  1 0.4225490200071284\n",
      "3  infer  1 0.4225490200071284\n",
      "3  thu  1 0.4225490200071284\n",
      "3  models,  1 0.4225490200071284\n",
      "3  (llm)  1 0.4225490200071284\n",
      "3  find  1 0.3010299956639812\n",
      "3  need  1 0.4225490200071284\n",
      "3  three  1 0.4225490200071284\n",
      "3  also  1 0.3010299956639812\n",
      "3  set  1 0.23856062735983122\n",
      "3  time  1 0.4225490200071284\n",
      "3  continu  1 0.4225490200071284\n",
      "3  model  2 0.3424226808222063\n",
      "3  information.  1 0.4225490200071284\n",
      "3  given  1 0.3010299956639812\n",
      "3  response.  1 0.4225490200071284\n",
      "3  task  1 0.3010299956639812\n",
      "3  user  1 0.4225490200071284\n",
      "3  effect  1 0.23856062735983122\n",
      "3  allow  1 0.3010299956639812\n",
      "3  prompt)  1 0.4225490200071284\n",
      "3  recommendation.  1 0.4225490200071284\n",
      "3  problems,  1 0.4225490200071284\n",
      "3  templat  1 0.3010299956639812\n",
      "3  could  1 0.4225490200071284\n",
      "3  text  1 0.3010299956639812\n",
      "3  address  1 0.4225490200071284\n",
      "3  real-world  1 0.4225490200071284\n",
      "3  commun  1 0.4225490200071284\n",
      "3  unleash  1 0.4225490200071284\n",
      "3  languag  1 0.1505149978319906\n",
      "3  strategi  1 0.1989700043360188\n",
      "3  e.g.,  1 0.4225490200071284\n",
      "3  task,  1 0.3010299956639812\n",
      "3  top-n  1 0.4225490200071284\n",
      "3  reasoning,  1 0.4225490200071284\n",
      "3  sequenti  1 0.3010299956639812\n",
      "3  recommend  2 0.6020599913279624\n",
      "3  noisi  1 0.4225490200071284\n",
      "3  effici  2 0.6020599913279624\n",
      "3  improved,  1 0.4225490200071284\n",
      "3  immedi  1 0.4225490200071284\n",
      "3  models.  1 0.3010299956639812\n",
      "3  result  1 0.1989700043360188\n",
      "3  system  1 0.4225490200071284\n",
      "3  text,  1 0.4225490200071284\n",
      "3  inspir  1 0.3010299956639812\n",
      "4  innov  1 0.28169934667141894\n",
      "4  improv  1 0.13264666955734586\n",
      "4  gencrf:  1 0.28169934667141894\n",
      "4  evalu  1 0.15904041823988746\n",
      "4  intent  2 0.4013733275519749\n",
      "4  adapt  2 0.5633986933428379\n",
      "4  modifi  1 0.28169934667141894\n",
      "4  aggreg  1 0.28169934667141894\n",
      "4  empir  1 0.28169934667141894\n",
      "4  inform  1 0.15904041823988746\n",
      "4  boost  1 0.28169934667141894\n",
      "4  experi  1 0.20068666377598746\n",
      "4  demonstr  1 0.15904041823988746\n",
      "4  combin  1 0.20068666377598746\n",
      "4  aim  1 0.20068666377598746\n",
      "4  rate  1 0.28169934667141894\n",
      "4  retriev  3 0.6020599913279624\n",
      "4  furthermore,  1 0.20068666377598746\n",
      "4  (qerm)  1 0.28169934667141894\n",
      "4  limit  1 0.20068666377598746\n",
      "4  problem  1 0.28169934667141894\n",
      "4  enhanc  1 0.20068666377598746\n",
      "4  state-of-the-art  1 0.20068666377598746\n",
      "4  propos  1 0.1141408936074021\n",
      "4  leverag  2 0.3180808364797749\n",
      "4  group  1 0.28169934667141894\n",
      "4  variou  1 0.20068666377598746\n",
      "4  cluster  2 0.5633986933428379\n",
      "4  ndcg@10.  1 0.20068666377598746\n",
      "4  method  1 0.20068666377598746\n",
      "4  advanc  1 0.28169934667141894\n",
      "4  reward  1 0.28169934667141894\n",
      "4  variabl  1 0.28169934667141894\n",
      "4  (llms)  1 0.20068666377598746\n",
      "4  time.  1 0.20068666377598746\n",
      "4  expansions,  1 0.28169934667141894\n",
      "4  recent  1 0.15904041823988746\n",
      "4  novel  1 0.20068666377598746\n",
      "4  perform  1 0.20068666377598746\n",
      "4  crucial  1 0.28169934667141894\n",
      "4  use  1 0.1141408936074021\n",
      "4  query.  1 0.28169934667141894\n",
      "4  llm  1 0.1141408936074021\n",
      "4  retrieval.  1 0.28169934667141894\n",
      "4  input  1 0.15904041823988746\n",
      "4  success  1 0.20068666377598746\n",
      "4  redund  1 0.28169934667141894\n",
      "4  significantli  1 0.15904041823988746\n",
      "4  complet  1 0.28169934667141894\n",
      "4  larg  1 0.10034333188799373\n",
      "4  performance,  1 0.28169934667141894\n",
      "4  field  1 0.28169934667141894\n",
      "4  intents.  1 0.28169934667141894\n",
      "4  custom  1 0.28169934667141894\n",
      "4  12%  1 0.28169934667141894\n",
      "4  benchmark  1 0.15904041823988746\n",
      "4  optim  1 0.28169934667141894\n",
      "4  base  1 0.15904041823988746\n",
      "4  repres  1 0.28169934667141894\n",
      "4  paper,  1 0.13264666955734586\n",
      "4  differentiated,  1 0.28169934667141894\n",
      "4  phase  1 0.28169934667141894\n",
      "4  model  2 0.2282817872148042\n",
      "4  framework  2 0.5633986933428379\n",
      "4  distinctli  1 0.28169934667141894\n",
      "4  refin  1 0.28169934667141894\n",
      "4  effect  1 0.15904041823988746\n",
      "4  feedback  1 0.20068666377598746\n",
      "4  beir  1 0.20068666377598746\n",
      "4  initi  1 0.28169934667141894\n",
      "4  achiev  1 0.15904041823988746\n",
      "4  singl  1 0.28169934667141894\n",
      "4  reformulation,  1 0.28169934667141894\n",
      "4  explor  1 0.20068666377598746\n",
      "4  process  1 0.20068666377598746\n",
      "4  user'  1 0.20068666377598746\n",
      "4  weight  1 0.28169934667141894\n",
      "4  constrain  1 0.28169934667141894\n",
      "4  loops.  1 0.28169934667141894\n",
      "4  well-known  1 0.28169934667141894\n",
      "4  languag  1 0.10034333188799373\n",
      "4  strategi  1 0.13264666955734586\n",
      "4  previou  1 0.15904041823988746\n",
      "4  potenti  1 0.20068666377598746\n",
      "4  often  1 0.28169934667141894\n",
      "4  well-gener  1 0.28169934667141894\n",
      "4  sota  1 0.28169934667141894\n",
      "4  gencrf  1 0.28169934667141894\n",
      "4  captur  2 0.4013733275519749\n",
      "4  (ir)  1 0.28169934667141894\n",
      "4  first  1 0.15904041823988746\n",
      "4  search  1 0.15904041823988746\n",
      "4  llms,  1 0.28169934667141894\n",
      "4  multipl  1 0.15904041823988746\n",
      "4  techniqu  1 0.15904041823988746\n",
      "4  queri  3 0.3979400086720376\n",
      "4  surpass  1 0.28169934667141894\n",
      "4  prompts,  1 0.28169934667141894\n",
      "4  divers  1 0.28169934667141894\n",
      "4  gener  2 0.2652933391146917\n",
      "4  reformul  2 0.4013733275519749\n",
      "4  automat  1 0.28169934667141894\n",
      "4  integr  1 0.20068666377598746\n",
      "5  symbol  2 0.5633986933428379\n",
      "5  corpora,  1 0.28169934667141894\n",
      "5  history,  1 0.28169934667141894\n",
      "5  pre-train  1 0.28169934667141894\n",
      "5  process,  1 0.20068666377598746\n",
      "5  complex  1 0.20068666377598746\n",
      "5  neglect  1 0.28169934667141894\n",
      "5  contrast  1 0.28169934667141894\n",
      "5  learn  1 0.28169934667141894\n",
      "5  format.  1 0.28169934667141894\n",
      "5  action  1 0.28169934667141894\n",
      "5  represent  1 0.28169934667141894\n",
      "5  includ  1 0.28169934667141894\n",
      "5  text-bas  1 0.28169934667141894\n",
      "5  instruct  1 0.20068666377598746\n",
      "5  (sgr),  1 0.28169934667141894\n",
      "5  inform  1 0.15904041823988746\n",
      "5  experi  1 0.20068666377598746\n",
      "5  modern  1 0.28169934667141894\n",
      "5  aim  1 0.20068666377598746\n",
      "5  documents,  1 0.28169934667141894\n",
      "5  interact  2 0.5633986933428379\n",
      "5  enhanc  1 0.20068666377598746\n",
      "5  bridg  1 0.20068666377598746\n",
      "5  analysi  1 0.28169934667141894\n",
      "5  propos  1 0.1141408936074021\n",
      "5  typic  1 0.28169934667141894\n",
      "5  take  1 0.15904041823988746\n",
      "5  leverag  1 0.15904041823988746\n",
      "5  (llms).  1 0.28169934667141894\n",
      "5  information,  1 0.28169934667141894\n",
      "5  this,  1 0.28169934667141894\n",
      "5  overlook  1 0.28169934667141894\n",
      "5  graph-bas  1 0.28169934667141894\n",
      "5  graph-to-text  1 0.28169934667141894\n",
      "5  grammar,  1 0.28169934667141894\n",
      "5  datasets,  1 0.28169934667141894\n",
      "5  approach  1 0.13264666955734586\n",
      "5  superior  1 0.28169934667141894\n",
      "5  need.  1 0.28169934667141894\n",
      "5  natur  1 0.20068666377598746\n",
      "5  discrep  1 0.28169934667141894\n",
      "5  concretely,  1 0.28169934667141894\n",
      "5  recent  1 0.15904041823988746\n",
      "5  novel  1 0.20068666377598746\n",
      "5  two  1 0.28169934667141894\n",
      "5  link  1 0.28169934667141894\n",
      "5  confirm  1 0.28169934667141894\n",
      "5  use  2 0.2282817872148042\n",
      "5  llm  1 0.1141408936074021\n",
      "5  modeling.  1 0.28169934667141894\n",
      "5  input  1 0.15904041823988746\n",
      "5  power  1 0.15904041823988746\n",
      "5  learning,  1 0.28169934667141894\n",
      "5  fulfil  1 0.28169934667141894\n",
      "5  larg  1 0.10034333188799373\n",
      "5  tiangong-st,  1 0.28169934667141894\n",
      "5  paradigm  1 0.28169934667141894\n",
      "5  topolog  1 0.28169934667141894\n",
      "5  tradit  1 0.28169934667141894\n",
      "5  advantag  1 0.28169934667141894\n",
      "5  ranker  1 0.20068666377598746\n",
      "5  prediction,  1 0.28169934667141894\n",
      "5  semant  1 0.28169934667141894\n",
      "5  benchmark  1 0.15904041823988746\n",
      "5  methodolog  1 0.28169934667141894\n",
      "5  offer  1 0.28169934667141894\n",
      "5  produc  1 0.28169934667141894\n",
      "5  llms'  1 0.28169934667141894\n",
      "5  graph  2 0.5633986933428379\n",
      "5  grammar  1 0.28169934667141894\n",
      "5  also  1 0.20068666377598746\n",
      "5  set  1 0.15904041823988746\n",
      "5  self-supervis  1 0.28169934667141894\n",
      "5  paper,  1 0.13264666955734586\n",
      "5  model  2 0.2282817872148042\n",
      "5  convert  1 0.28169934667141894\n",
      "5  given  1 0.20068666377598746\n",
      "5  task  2 0.4013733275519749\n",
      "5  seamlessli  1 0.28169934667141894\n",
      "5  interactions.  1 0.28169934667141894\n",
      "5  effect  1 0.15904041823988746\n",
      "5  allow  1 0.20068666377598746\n",
      "5  introduc  1 0.20068666377598746\n",
      "5  achiev  1 0.15904041823988746\n",
      "5  object  1 0.28169934667141894\n",
      "5  user'  1 0.20068666377598746\n",
      "5  understanding,  1 0.28169934667141894\n",
      "5  moreover,  1 0.28169934667141894\n",
      "5  word-level  1 0.28169934667141894\n",
      "5  structur  3 0.8450980400142568\n",
      "5  generation,  1 0.28169934667141894\n",
      "5  involv  1 0.28169934667141894\n",
      "5  llms.  1 0.20068666377598746\n",
      "5  textual  1 0.28169934667141894\n",
      "5  languag  2 0.20068666377598746\n",
      "5  strategi  1 0.13264666955734586\n",
      "5  content  1 0.28169934667141894\n",
      "5  llm.  1 0.28169934667141894\n",
      "5  fine-grained.  1 0.28169934667141894\n",
      "5  priorit  1 0.28169934667141894\n",
      "5  node  1 0.28169934667141894\n",
      "5  captur  2 0.4013733275519749\n",
      "5  rule  1 0.28169934667141894\n",
      "5  deep  1 0.28169934667141894\n",
      "5  first  1 0.15904041823988746\n",
      "5  abil  1 0.20068666377598746\n",
      "5  enabl  1 0.28169934667141894\n",
      "5  focu  1 0.28169934667141894\n",
      "5  sequenti  1 0.20068666377598746\n",
      "5  search  1 0.15904041823988746\n",
      "5  text.  1 0.28169934667141894\n",
      "5  coarse-grain  1 0.28169934667141894\n",
      "5  seri  1 0.28169934667141894\n",
      "5  queri  1 0.13264666955734586\n",
      "5  gener  2 0.2652933391146917\n",
      "5  within  1 0.28169934667141894\n",
      "5  result  1 0.13264666955734586\n",
      "5  aol  1 0.28169934667141894\n",
      "5  approach.  1 0.28169934667141894\n",
      "5  session  2 0.5633986933428379\n",
      "5  integr  1 0.20068666377598746\n",
      "5  comprehens  1 0.28169934667141894\n",
      "5  current  1 0.28169934667141894\n",
      "5  gap  1 0.28169934667141894\n",
      "6  play  1 0.28169934667141894\n",
      "6  systems.  1 0.28169934667141894\n",
      "6  viewer  1 0.28169934667141894\n",
      "6  evalu  1 0.15904041823988746\n",
      "6  compar  2 0.5633986933428379\n",
      "6  alpaca  1 0.28169934667141894\n",
      "6  item  1 0.20068666377598746\n",
      "6  consid  1 0.28169934667141894\n",
      "6  open-sourc  1 0.20068666377598746\n",
      "6  inform  1 0.15904041823988746\n",
      "6  obtain  1 0.28169934667141894\n",
      "6  publish  1 0.28169934667141894\n",
      "6  tasks.  1 0.20068666377598746\n",
      "6  demonstr  1 0.15904041823988746\n",
      "6  combin  1 0.20068666377598746\n",
      "6  web  1 0.28169934667141894\n",
      "6  alpaca,  1 0.28169934667141894\n",
      "6  director  1 0.28169934667141894\n",
      "6  prompt  2 0.2652933391146917\n",
      "6  hits,  1 0.28169934667141894\n",
      "6  one  1 0.28169934667141894\n",
      "6  ndcg  1 0.28169934667141894\n",
      "6  featur  1 0.28169934667141894\n",
      "6  promise,  1 0.28169934667141894\n",
      "6  gpt-3.5,  1 0.28169934667141894\n",
      "6  top  1 0.28169934667141894\n",
      "6  consist  1 0.28169934667141894\n",
      "6  movielen  1 0.28169934667141894\n",
      "6  data  1 0.28169934667141894\n",
      "6  inconsistencies.  1 0.28169934667141894\n",
      "6  llm-base  1 0.15904041823988746\n",
      "6  emerg  1 0.28169934667141894\n",
      "6  signific  1 0.28169934667141894\n",
      "6  natur  1 0.20068666377598746\n",
      "6  1m  1 0.28169934667141894\n",
      "6  titl  1 0.28169934667141894\n",
      "6  recent  1 0.15904041823988746\n",
      "6  descriptions.  1 0.28169934667141894\n",
      "6  subsequently,  1 0.28169934667141894\n",
      "6  dataset  2 0.4013733275519749\n",
      "6  book  1 0.28169934667141894\n",
      "6  compris  1 0.28169934667141894\n",
      "6  use  3 0.3424226808222063\n",
      "6  cast  1 0.28169934667141894\n",
      "6  llm  1 0.1141408936074021\n",
      "6  power  1 0.15904041823988746\n",
      "6  summari  1 0.28169934667141894\n",
      "6  author  1 0.28169934667141894\n",
      "6  larg  1 0.10034333188799373\n",
      "6  web-scrap  1 0.28169934667141894\n",
      "6  traditionally,  1 0.28169934667141894\n",
      "6  manual  1 0.28169934667141894\n",
      "6  descript  2 0.5633986933428379\n",
      "6  open  1 0.28169934667141894\n",
      "6  pivot  1 0.28169934667141894\n",
      "6  paper,  1 0.13264666955734586\n",
      "6  ml  1 0.28169934667141894\n",
      "6  model  1 0.1141408936074021\n",
      "6  name  1 0.28169934667141894\n",
      "6  study,  1 0.28169934667141894\n",
      "6  metrics.  1 0.20068666377598746\n",
      "6  llm,  1 0.28169934667141894\n",
      "6  provid  1 0.28169934667141894\n",
      "6  time-consum  1 0.28169934667141894\n",
      "6  goodread  1 0.28169934667141894\n",
      "6  explor  1 0.20068666377598746\n",
      "6  process  1 0.20068666377598746\n",
      "6  items.  1 0.28169934667141894\n",
      "6  suscept  1 0.28169934667141894\n",
      "6  movi  1 0.28169934667141894\n",
      "6  few-shot  1 0.28169934667141894\n",
      "6  concis  1 0.28169934667141894\n",
      "6  techniques,  1 0.28169934667141894\n",
      "6  languag  2 0.20068666377598746\n",
      "6  exhibit  1 0.28169934667141894\n",
      "6  potenti  1 0.20068666377598746\n",
      "6  like  1 0.28169934667141894\n",
      "6  tool  1 0.28169934667141894\n",
      "6  essenti  1 0.28169934667141894\n",
      "6  sourc  1 0.28169934667141894\n",
      "6  captiv  1 0.28169934667141894\n",
      "6  (llms),  1 0.28169934667141894\n",
      "6  detail  1 0.28169934667141894\n",
      "6  mrr,  1 0.28169934667141894\n",
      "6  recommend  1 0.20068666377598746\n",
      "6  multipl  1 0.15904041823988746\n",
      "6  dataset.  1 0.28169934667141894\n",
      "6  years,  1 0.28169934667141894\n",
      "6  conduct  1 0.28169934667141894\n",
      "6  gener  3 0.3979400086720376\n",
      "6  result  1 0.13264666955734586\n",
      "6  scrape  2 0.5633986933428379\n",
      "6  role  1 0.28169934667141894\n",
      "6  role  1 0.28169934667141894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "descripteur_reg_porter =\"\"\n",
    "\n",
    "for i in range(len(termes_reg_porter)):\n",
    "    \n",
    "    for j in range(len(termes_reg_porter[i])):\n",
    "\n",
    "        term = termes_reg_porter[i][j]\n",
    "        #print(str(i) + \" \" +str(j)+ \" \" +term +\"\\n\")\n",
    "\n",
    "        frequency_term = frequency_dict_reg_porter_documents[i][term]\n",
    "        max_frequancy = max_frequency_dict_reg_porter_documents[i]\n",
    "        frequency_in_collection = document_frequency_dict_reg_porter[term]\n",
    "\n",
    "        poids_term = poids(frequency_term,max_frequancy,frequency_in_collection,n_reg)\n",
    "\n",
    "        descripteur_reg_porter = descripteur_split_porter + (str(i+1)+ \"  \" +termes_reg_porter[i][j]+ \"  \" +str(frequency_term)+\" \"+ str(poids_term)+\"\\n\")\n",
    "\n",
    "\n",
    "print(descripteur_reg_porter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  lev  1 0.11928031367991561\n",
      "1  rank  1 0.11928031367991561\n",
      "1  relev  1 0.2112745100035642\n",
      "1  improv  4 0.3979400086720376\n",
      "1  18%  1 0.2112745100035642\n",
      "1  evalu  1 0.11928031367991561\n",
      "1  tak  1 0.11928031367991561\n",
      "1  msmarco  1 0.2112745100035642\n",
      "1  knowledg  1 0.2112745100035642\n",
      "1  instruct  1 0.1505149978319906\n",
      "1  technique,  1 0.2112745100035642\n",
      "1  investig  1 0.2112745100035642\n",
      "1  rel  1 0.2112745100035642\n",
      "1  recently,  1 0.2112745100035642\n",
      "1  5%  1 0.2112745100035642\n",
      "1  retriev  1 0.1505149978319906\n",
      "1  query  2 0.1989700043360188\n",
      "1  shown  1 0.2112745100035642\n",
      "1  pseudo  1 0.2112745100035642\n",
      "1  propos  1 0.08560567020555157\n",
      "1  us  2 0.1505149978319906\n",
      "1  strategies  1 0.11928031367991561\n",
      "1  prompt  1 0.0994850021680094\n",
      "1  abl  1 0.1505149978319906\n",
      "1  incorp  1 0.2112745100035642\n",
      "1  approach  1 0.0994850021680094\n",
      "1  user’s  1 0.2112745100035642\n",
      "1  post-retrieval  1 0.2112745100035642\n",
      "1  performance.  1 0.2112745100035642\n",
      "1  state-of-art.  1 0.2112745100035642\n",
      "1  four  1 0.2112745100035642\n",
      "1  int  1 0.1505149978319906\n",
      "1  tasks,  1 0.11928031367991561\n",
      "1  success  1 0.1505149978319906\n",
      "1  larg  1 0.0752574989159953\n",
      "1  24%  1 0.2112745100035642\n",
      "1  transform  1 0.2112745100035642\n",
      "1  reformulation(qr)  1 0.2112745100035642\n",
      "1  ultim  1 0.2112745100035642\n",
      "1  ndcg@10  1 0.2112745100035642\n",
      "1  documents.  1 0.2112745100035642\n",
      "1  benchmarks,  1 0.2112745100035642\n",
      "1  experience.  1 0.2112745100035642\n",
      "1  find  1 0.1505149978319906\n",
      "1  feedback,  1 0.2112745100035642\n",
      "1  inh  1 0.2112745100035642\n",
      "1  set  2 0.23856062735983122\n",
      "1  prom  1 0.2112745100035642\n",
      "1  qr  1 0.2112745100035642\n",
      "1  bas  1 0.11928031367991561\n",
      "1  reformulation.  1 0.2112745100035642\n",
      "1  ir  1 0.2112745100035642\n",
      "1  show  1 0.1505149978319906\n",
      "1  prevy  1 0.11928031367991561\n",
      "1  9%  1 0.2112745100035642\n",
      "1  genqrensemblerf  1 0.2112745100035642\n",
      "1  benefit  1 0.2112745100035642\n",
      "1  ensembl  1 0.2112745100035642\n",
      "1  feedback  1 0.1505149978319906\n",
      "1  introduc  1 0.1505149978319906\n",
      "1  pseudo-relevance  1 0.2112745100035642\n",
      "1  due  1 0.2112745100035642\n",
      "1  context,  1 0.2112745100035642\n",
      "1  paraphras  1 0.2112745100035642\n",
      "1  exploit  1 0.2112745100035642\n",
      "1  reform  1 0.1505149978319906\n",
      "1  mrr  1 0.2112745100035642\n",
      "1  origin  1 0.2112745100035642\n",
      "1  text  1 0.11928031367991561\n",
      "1  techn  1 0.11928031367991561\n",
      "1  feedback.  1 0.2112745100035642\n",
      "1  upto  1 0.2112745100035642\n",
      "1  align  1 0.2112745100035642\n",
      "1  keyword  1 0.2112745100035642\n",
      "1  task,  1 0.1505149978319906\n",
      "1  many  1 0.2112745100035642\n",
      "1  pass  1 0.2112745100035642\n",
      "1  genqrensembl  1 0.2112745100035642\n",
      "1  search  1 0.11928031367991561\n",
      "1  variant,  1 0.2112745100035642\n",
      "1  multipl  1 0.11928031367991561\n",
      "1  langu  1 0.0752574989159953\n",
      "1  zero-shot  1 0.2112745100035642\n",
      "1  models.  1 0.1505149978319906\n",
      "1  bet  1 0.2112745100035642\n",
      "1  gain  1 0.2112745100035642\n",
      "1  gen  2 0.1989700043360188\n",
      "1  map  1 0.2112745100035642\n",
      "1  inspir  1 0.1505149978319906\n",
      "1  help  1 0.2112745100035642\n",
      "2  rank  3 0.47712125471966244\n",
      "2  complex  1 0.20068666377598746\n",
      "2  (prp).  1 0.28169934667141894\n",
      "2  improv  1 0.13264666955734586\n",
      "2  ev  1 0.28169934667141894\n",
      "2  efficy  1 0.20068666377598746\n",
      "2  open-sourced  1 0.20068666377598746\n",
      "2  gpt-4  1 0.28169934667141894\n",
      "2  baselin  2 0.5633986933428379\n",
      "2  standard  1 0.28169934667141894\n",
      "2  flan-ul2  1 0.28169934667141894\n",
      "2  moderate-sized  1 0.28169934667141894\n",
      "2  challeng  1 0.28169934667141894\n",
      "2  furthermore,  1 0.20068666377598746\n",
      "2  formulations.  1 0.28169934667141894\n",
      "2  outperform  3 0.8450980400142568\n",
      "2  query  1 0.13264666955734586\n",
      "2  llms  1 0.13264666955734586\n",
      "2  10%  1 0.28169934667141894\n",
      "2  state-of-the-art  1 0.20068666377598746\n",
      "2  propos  1 0.1141408936074021\n",
      "2  20b  1 0.28169934667141894\n",
      "2  us  2 0.20068666377598746\n",
      "2  found  1 0.28169934667141894\n",
      "2  interest  1 0.28169934667141894\n",
      "2  pract  1 0.28169934667141894\n",
      "2  prompt  3 0.3979400086720376\n",
      "2  chatgpt  1 0.28169934667141894\n",
      "2  problem.  1 0.28169934667141894\n",
      "2  method  1 0.20068666377598746\n",
      "2  ndcg@10.  1 0.20068666377598746\n",
      "2  trec-dl  1 0.28169934667141894\n",
      "2  superv  1 0.28169934667141894\n",
      "2  sign  1 0.13264666955734586\n",
      "2  listw  1 0.28169934667141894\n",
      "2  175b  1 0.28169934667141894\n",
      "2  approach  1 0.13264666955734586\n",
      "2  (llms)  1 0.20068666377598746\n",
      "2  av  1 0.28169934667141894\n",
      "2  reduc  1 0.20068666377598746\n",
      "2  pointw  1 0.28169934667141894\n",
      "2  understand  1 0.20068666377598746\n",
      "2  4.2%  1 0.28169934667141894\n",
      "2  llm-based  1 0.15904041823988746\n",
      "2  cal  1 0.28169934667141894\n",
      "2  perform  2 0.4013733275519749\n",
      "2  fav  1 0.28169934667141894\n",
      "2  tasks,  1 0.15904041823988746\n",
      "2  research  1 0.20068666377598746\n",
      "2  vary  1 0.15904041823988746\n",
      "2  larg  1 0.10034333188799373\n",
      "2  off-the-shelf  1 0.28169934667141894\n",
      "2  docu  1 0.28169934667141894\n",
      "2  analys  1 0.20068666377598746\n",
      "2  ful  1 0.28169934667141894\n",
      "2  commerc  1 0.28169934667141894\n",
      "2  benchmark  2 0.3180808364797749\n",
      "2  paper,  1 0.13264666955734586\n",
      "2  bas  1 0.15904041823988746\n",
      "2  model  2 0.2282817872148042\n",
      "2  burd  1 0.28169934667141894\n",
      "2  show  1 0.20068666377598746\n",
      "2  paramet  1 0.28169934667141894\n",
      "2  literature,  1 0.28169934667141894\n",
      "2  12-10%  1 0.28169934667141894\n",
      "2  prevy  1 0.15904041823988746\n",
      "2  2019  1 0.28169934667141894\n",
      "2  2020,  1 0.28169934667141894\n",
      "2  ex  1 0.28169934667141894\n",
      "2  metrics.  1 0.20068666377598746\n",
      "2  beir  1 0.20068666377598746\n",
      "2  parameters,  1 0.28169934667141894\n",
      "2  (estimated)  1 0.28169934667141894\n",
      "2  size,  1 0.28169934667141894\n",
      "2  achiev  1 0.15904041823988746\n",
      "2  solv  2 0.5633986933428379\n",
      "2  datasets.  1 0.28169934667141894\n",
      "2  blackbox  1 0.28169934667141894\n",
      "2  templ  1 0.20068666377598746\n",
      "2  pairw  1 0.28169934667141894\n",
      "2  sev  2 0.5633986933428379\n",
      "2  difficult  1 0.28169934667141894\n",
      "2  prp  1 0.28169934667141894\n",
      "2  direct  1 0.20068666377598746\n",
      "2  argu  1 0.28169934667141894\n",
      "2  best  1 0.28169934667141894\n",
      "2  llms.  1 0.20068666377598746\n",
      "2  techn  1 0.15904041823988746\n",
      "2  competit  1 0.28169934667141894\n",
      "2  lit  1 0.28169934667141894\n",
      "2  poss  1 0.28169934667141894\n",
      "2  solutions,  1 0.28169934667141894\n",
      "2  however,  1 0.28169934667141894\n",
      "2  instructgpt  1 0.28169934667141894\n",
      "2  50x  1 0.28169934667141894\n",
      "2  linear  1 0.28169934667141894\n",
      "2  first  1 0.15904041823988746\n",
      "2  candid  1 0.28169934667141894\n",
      "2  langu  1 0.10034333188799373\n",
      "2  new  1 0.28169934667141894\n",
      "2  result  1 0.13264666955734586\n",
      "2  fine-tuned  1 0.28169934667141894\n",
      "2  fee  1 0.28169934667141894\n",
      "3  train  1 0.4225490200071284\n",
      "3  distil  2 0.8450980400142568\n",
      "3  process,  1 0.3010299956639812\n",
      "3  improv  2 0.3979400086720376\n",
      "3  efficy  2 0.6020599913279624\n",
      "3  strategy  1 0.4225490200071284\n",
      "3  design  1 0.4225490200071284\n",
      "3  attempt  1 0.4225490200071284\n",
      "3  tim  1 0.4225490200071284\n",
      "3  tak  1 0.23856062735983122\n",
      "3  item  1 0.3010299956639812\n",
      "3  may  1 0.4225490200071284\n",
      "3  inf  1 0.4225490200071284\n",
      "3  extend  1 0.4225490200071284\n",
      "3  although  1 0.4225490200071284\n",
      "3  tasks.  1 0.3010299956639812\n",
      "3  most  1 0.4225490200071284\n",
      "3  (i.e.,  1 0.4225490200071284\n",
      "3  limit  1 0.3010299956639812\n",
      "3  word  1 0.4225490200071284\n",
      "3  plain  1 0.4225490200071284\n",
      "3  immedy  1 0.4225490200071284\n",
      "3  bridg  1 0.3010299956639812\n",
      "3  vect  1 0.4225490200071284\n",
      "3  propos  1 0.17121134041110314\n",
      "3  id  1 0.4225490200071284\n",
      "3  us  2 0.3010299956639812\n",
      "3  prompt  2 0.3979400086720376\n",
      "3  manifest  1 0.4225490200071284\n",
      "3  enough  1 0.4225490200071284\n",
      "3  limited.  1 0.4225490200071284\n",
      "3  user/item  1 0.4225490200071284\n",
      "3  sign  1 0.1989700043360188\n",
      "3  long  2 0.8450980400142568\n",
      "3  fil  1 0.4225490200071284\n",
      "3  approach  1 0.1989700043360188\n",
      "3  reduc  1 0.3010299956639812\n",
      "3  contain  1 0.4225490200071284\n",
      "3  understand  1 0.3010299956639812\n",
      "3  multi-step  1 0.4225490200071284\n",
      "3  time.  1 0.3010299956639812\n",
      "3  requir  1 0.4225490200071284\n",
      "3  llm-based  1 0.23856062735983122\n",
      "3  dataset  1 0.3010299956639812\n",
      "3  noisy  1 0.4225490200071284\n",
      "3  (pod)  1 0.4225490200071284\n",
      "3  discret  1 0.4225490200071284\n",
      "3  unparallel  1 0.4225490200071284\n",
      "3  tasks,  1 0.23856062735983122\n",
      "3  research  1 0.3010299956639812\n",
      "3  llm  1 0.4225490200071284\n",
      "3  input  1 0.23856062735983122\n",
      "3  vary  1 0.23856062735983122\n",
      "3  larg  1 0.1505149978319906\n",
      "3  fine-tuning  1 0.4225490200071284\n",
      "3  thu  1 0.4225490200071284\n",
      "3  models,  1 0.4225490200071284\n",
      "3  (llm)  1 0.4225490200071284\n",
      "3  find  1 0.3010299956639812\n",
      "3  three  1 0.4225490200071284\n",
      "3  also  1 0.3010299956639812\n",
      "3  set  1 0.23856062735983122\n",
      "3  pow  1 0.23856062735983122\n",
      "3  continu  1 0.4225490200071284\n",
      "3  model  2 0.3424226808222063\n",
      "3  information.  1 0.4225490200071284\n",
      "3  response.  1 0.4225490200071284\n",
      "3  task  1 0.3010299956639812\n",
      "3  effect  1 0.23856062735983122\n",
      "3  allow  1 0.3010299956639812\n",
      "3  expery  1 0.23856062735983122\n",
      "3  prompt)  1 0.4225490200071284\n",
      "3  recommendation.  1 0.4225490200071284\n",
      "3  problems,  1 0.4225490200071284\n",
      "3  giv  1 0.3010299956639812\n",
      "3  templ  1 0.3010299956639812\n",
      "3  could  1 0.4225490200071284\n",
      "3  text  1 0.23856062735983122\n",
      "3  address  1 0.4225490200071284\n",
      "3  real-world  1 0.4225490200071284\n",
      "3  commun  1 0.4225490200071284\n",
      "3  unleash  1 0.4225490200071284\n",
      "3  e.g.,  1 0.4225490200071284\n",
      "3  task,  1 0.3010299956639812\n",
      "3  top-n  1 0.4225490200071284\n",
      "3  cap  1 0.4225490200071284\n",
      "3  reasoning,  1 0.4225490200071284\n",
      "3  recommend  2 0.6020599913279624\n",
      "3  improved,  1 0.4225490200071284\n",
      "3  spec  1 0.4225490200071284\n",
      "3  sequ  1 0.3010299956639812\n",
      "3  langu  1 0.1505149978319906\n",
      "3  models.  1 0.3010299956639812\n",
      "3  result  1 0.1989700043360188\n",
      "3  system  1 0.4225490200071284\n",
      "3  demonst  1 0.23856062735983122\n",
      "3  text,  1 0.4225490200071284\n",
      "3  nee  1 0.4225490200071284\n",
      "3  inspir  1 0.3010299956639812\n",
      "4  lev  2 0.3180808364797749\n",
      "4  innov  1 0.28169934667141894\n",
      "4  phas  1 0.28169934667141894\n",
      "4  improv  1 0.13264666955734586\n",
      "4  gencrf:  1 0.28169934667141894\n",
      "4  evalu  1 0.15904041823988746\n",
      "4  mod  1 0.28169934667141894\n",
      "4  adapt  2 0.5633986933428379\n",
      "4  aggreg  1 0.28169934667141894\n",
      "4  empir  1 0.28169934667141894\n",
      "4  inform  1 0.15904041823988746\n",
      "4  boost  1 0.28169934667141894\n",
      "4  combin  1 0.20068666377598746\n",
      "4  aim  1 0.20068666377598746\n",
      "4  autom  1 0.28169934667141894\n",
      "4  retriev  3 0.6020599913279624\n",
      "4  furthermore,  1 0.20068666377598746\n",
      "4  (qerm)  1 0.28169934667141894\n",
      "4  limit  1 0.20068666377598746\n",
      "4  problem  1 0.28169934667141894\n",
      "4  query  3 0.3979400086720376\n",
      "4  llms  1 0.13264666955734586\n",
      "4  state-of-the-art  1 0.20068666377598746\n",
      "4  propos  1 0.1141408936074021\n",
      "4  us  1 0.10034333188799373\n",
      "4  strategies  1 0.15904041823988746\n",
      "4  group  1 0.28169934667141894\n",
      "4  ndcg@10.  1 0.20068666377598746\n",
      "4  method  1 0.20068666377598746\n",
      "4  reward  1 0.28169934667141894\n",
      "4  distinct  1 0.28169934667141894\n",
      "4  sign  1 0.13264666955734586\n",
      "4  (llms)  1 0.20068666377598746\n",
      "4  time.  1 0.20068666377598746\n",
      "4  expansions,  1 0.28169934667141894\n",
      "4  novel  1 0.20068666377598746\n",
      "4  perform  1 0.20068666377598746\n",
      "4  int  2 0.4013733275519749\n",
      "4  query.  1 0.28169934667141894\n",
      "4  retrieval.  1 0.28169934667141894\n",
      "4  input  1 0.15904041823988746\n",
      "4  success  1 0.20068666377598746\n",
      "4  redund  1 0.28169934667141894\n",
      "4  vary  2 0.3180808364797749\n",
      "4  complet  1 0.28169934667141894\n",
      "4  larg  1 0.10034333188799373\n",
      "4  performance,  1 0.28169934667141894\n",
      "4  well-generated  1 0.28169934667141894\n",
      "4  field  1 0.28169934667141894\n",
      "4  intents.  1 0.28169934667141894\n",
      "4  custom  1 0.28169934667141894\n",
      "4  12%  1 0.28169934667141894\n",
      "4  benchmark  1 0.15904041823988746\n",
      "4  oft  1 0.28169934667141894\n",
      "4  optim  1 0.28169934667141894\n",
      "4  repres  1 0.20068666377598746\n",
      "4  paper,  1 0.13264666955734586\n",
      "4  bas  1 0.15904041823988746\n",
      "4  differentiated,  1 0.28169934667141894\n",
      "4  model  2 0.2282817872148042\n",
      "4  cruc  1 0.28169934667141894\n",
      "4  framework  2 0.5633986933428379\n",
      "4  enh  1 0.20068666377598746\n",
      "4  prevy  1 0.15904041823988746\n",
      "4  refin  1 0.28169934667141894\n",
      "4  effect  1 0.15904041823988746\n",
      "4  feedback  1 0.20068666377598746\n",
      "4  beir  1 0.20068666377598746\n",
      "4  expery  1 0.15904041823988746\n",
      "4  adv  1 0.20068666377598746\n",
      "4  achiev  1 0.15904041823988746\n",
      "4  singl  1 0.28169934667141894\n",
      "4  user's  1 0.20068666377598746\n",
      "4  reformulation,  1 0.28169934667141894\n",
      "4  clust  2 0.5633986933428379\n",
      "4  rat  1 0.28169934667141894\n",
      "4  reform  2 0.4013733275519749\n",
      "4  process  1 0.20068666377598746\n",
      "4  weight  1 0.28169934667141894\n",
      "4  pot  1 0.20068666377598746\n",
      "4  constrain  1 0.28169934667141894\n",
      "4  loops.  1 0.28169934667141894\n",
      "4  well-known  1 0.28169934667141894\n",
      "4  techn  1 0.15904041823988746\n",
      "4  init  1 0.28169934667141894\n",
      "4  sota  1 0.28169934667141894\n",
      "4  gencrf  1 0.28169934667141894\n",
      "4  (ir)  1 0.28169934667141894\n",
      "4  first  1 0.15904041823988746\n",
      "4  search  1 0.15904041823988746\n",
      "4  capt  2 0.3180808364797749\n",
      "4  llms,  1 0.28169934667141894\n",
      "4  multipl  1 0.15904041823988746\n",
      "4  surpass  1 0.28169934667141894\n",
      "4  rec  1 0.15904041823988746\n",
      "4  prompts,  1 0.28169934667141894\n",
      "4  divers  1 0.28169934667141894\n",
      "4  langu  1 0.10034333188799373\n",
      "4  demonst  1 0.15904041823988746\n",
      "4  integr  1 0.20068666377598746\n",
      "4  gen  2 0.2652933391146917\n",
      "4  expl  1 0.20068666377598746\n",
      "5  lev  1 0.23856062735983122\n",
      "5  symbol  2 0.8450980400142568\n",
      "5  corpora,  1 0.4225490200071284\n",
      "5  history,  1 0.4225490200071284\n",
      "5  graph-based  1 0.4225490200071284\n",
      "5  process,  1 0.3010299956639812\n",
      "5  rank  1 0.23856062735983122\n",
      "5  complex  1 0.3010299956639812\n",
      "5  sess  2 0.8450980400142568\n",
      "5  structures  1 0.4225490200071284\n",
      "5  neglect  1 0.4225490200071284\n",
      "5  contrast  1 0.4225490200071284\n",
      "5  learn  1 0.4225490200071284\n",
      "5  tak  1 0.23856062735983122\n",
      "5  format.  1 0.4225490200071284\n",
      "5  includ  1 0.4225490200071284\n",
      "5  instruct  1 0.3010299956639812\n",
      "5  (sgr),  1 0.4225490200071284\n",
      "5  inform  1 0.23856062735983122\n",
      "5  modern  1 0.4225490200071284\n",
      "5  aim  1 0.3010299956639812\n",
      "5  en  1 0.4225490200071284\n",
      "5  documents,  1 0.4225490200071284\n",
      "5  interact  2 0.8450980400142568\n",
      "5  query  1 0.1989700043360188\n",
      "5  llms  1 0.1989700043360188\n",
      "5  bridg  1 0.3010299956639812\n",
      "5  propos  1 0.17121134041110314\n",
      "5  us  2 0.3010299956639812\n",
      "5  strategies  1 0.23856062735983122\n",
      "5  (llms).  1 0.4225490200071284\n",
      "5  abl  1 0.3010299956639812\n",
      "5  information,  1 0.4225490200071284\n",
      "5  this,  1 0.4225490200071284\n",
      "5  overlook  1 0.4225490200071284\n",
      "5  structural  1 0.4225490200071284\n",
      "5  graph-to-text  1 0.4225490200071284\n",
      "5  grammar,  1 0.4225490200071284\n",
      "5  datasets,  1 0.4225490200071284\n",
      "5  approach  1 0.1989700043360188\n",
      "5  nat  1 0.3010299956639812\n",
      "5  need.  1 0.4225490200071284\n",
      "5  discrep  1 0.4225490200071284\n",
      "5  pre-trained  1 0.4225490200071284\n",
      "5  concretely,  1 0.4225490200071284\n",
      "5  novel  1 0.3010299956639812\n",
      "5  two  1 0.4225490200071284\n",
      "5  gramm  1 0.4225490200071284\n",
      "5  sem  1 0.4225490200071284\n",
      "5  sery  1 0.4225490200071284\n",
      "5  link  1 0.4225490200071284\n",
      "5  confirm  1 0.4225490200071284\n",
      "5  cur  1 0.4225490200071284\n",
      "5  modeling.  1 0.4225490200071284\n",
      "5  input  1 0.23856062735983122\n",
      "5  learning,  1 0.4225490200071284\n",
      "5  fulfil  1 0.4225490200071284\n",
      "5  larg  1 0.1505149978319906\n",
      "5  tiangong-st,  1 0.4225490200071284\n",
      "5  analys  1 0.3010299956639812\n",
      "5  paradigm  1 0.4225490200071284\n",
      "5  nod  1 0.4225490200071284\n",
      "5  topolog  1 0.4225490200071284\n",
      "5  tradit  1 0.4225490200071284\n",
      "5  self-supervised  1 0.4225490200071284\n",
      "5  prediction,  1 0.4225490200071284\n",
      "5  benchmark  1 0.23856062735983122\n",
      "5  methodolog  1 0.4225490200071284\n",
      "5  produc  1 0.4225490200071284\n",
      "5  llms'  1 0.4225490200071284\n",
      "5  graph  2 0.8450980400142568\n",
      "5  repres  1 0.3010299956639812\n",
      "5  also  1 0.3010299956639812\n",
      "5  set  1 0.23856062735983122\n",
      "5  pow  1 0.23856062735983122\n",
      "5  paper,  1 0.1989700043360188\n",
      "5  model  2 0.3424226808222063\n",
      "5  convert  1 0.4225490200071284\n",
      "5  rul  1 0.4225490200071284\n",
      "5  task  2 0.6020599913279624\n",
      "5  enh  1 0.3010299956639812\n",
      "5  supery  1 0.4225490200071284\n",
      "5  interactions.  1 0.4225490200071284\n",
      "5  off  1 0.4225490200071284\n",
      "5  effect  1 0.23856062735983122\n",
      "5  allow  1 0.3010299956639812\n",
      "5  introduc  1 0.3010299956639812\n",
      "5  expery  1 0.23856062735983122\n",
      "5  structure  1 0.4225490200071284\n",
      "5  act  1 0.4225490200071284\n",
      "5  adv  1 0.3010299956639812\n",
      "5  achiev  1 0.23856062735983122\n",
      "5  typ  1 0.4225490200071284\n",
      "5  object  1 0.4225490200071284\n",
      "5  giv  1 0.3010299956639812\n",
      "5  user's  1 0.3010299956639812\n",
      "5  coarse-grained  1 0.4225490200071284\n",
      "5  text  1 0.23856062735983122\n",
      "5  understanding,  1 0.4225490200071284\n",
      "5  foc  1 0.4225490200071284\n",
      "5  moreover,  1 0.4225490200071284\n",
      "5  word-level  1 0.4225490200071284\n",
      "5  generation,  1 0.4225490200071284\n",
      "5  involv  1 0.4225490200071284\n",
      "5  llms.  1 0.3010299956639812\n",
      "5  llm.  1 0.4225490200071284\n",
      "5  fine-grained.  1 0.4225490200071284\n",
      "5  priorit  1 0.4225490200071284\n",
      "5  deep  1 0.4225490200071284\n",
      "5  first  1 0.23856062735983122\n",
      "5  cont  1 0.3010299956639812\n",
      "5  search  1 0.23856062735983122\n",
      "5  text.  1 0.4225490200071284\n",
      "5  capt  2 0.47712125471966244\n",
      "5  rec  1 0.23856062735983122\n",
      "5  within  1 0.4225490200071284\n",
      "5  comprehend  1 0.4225490200071284\n",
      "5  sequ  1 0.3010299956639812\n",
      "5  langu  2 0.3010299956639812\n",
      "5  result  1 0.1989700043360188\n",
      "5  aol  1 0.4225490200071284\n",
      "5  approach.  1 0.4225490200071284\n",
      "5  integr  1 0.3010299956639812\n",
      "5  text-based  1 0.4225490200071284\n",
      "5  gen  2 0.3979400086720376\n",
      "5  gap  1 0.4225490200071284\n",
      "5  seamless  1 0.4225490200071284\n",
      "6  view  1 0.28169934667141894\n",
      "6  play  1 0.28169934667141894\n",
      "6  systems.  1 0.28169934667141894\n",
      "6  open-sourced  1 0.20068666377598746\n",
      "6  moviel  1 0.28169934667141894\n",
      "6  evalu  1 0.15904041823988746\n",
      "6  rol  1 0.28169934667141894\n",
      "6  describ  2 0.5633986933428379\n",
      "6  item  1 0.20068666377598746\n",
      "6  consid  1 0.28169934667141894\n",
      "6  on  1 0.28169934667141894\n",
      "6  inform  1 0.15904041823988746\n",
      "6  obtain  1 0.28169934667141894\n",
      "6  tasks.  1 0.20068666377598746\n",
      "6  combin  1 0.20068666377598746\n",
      "6  web  1 0.28169934667141894\n",
      "6  alpac  1 0.28169934667141894\n",
      "6  llms  1 0.13264666955734586\n",
      "6  alpaca,  1 0.28169934667141894\n",
      "6  us  3 0.3010299956639812\n",
      "6  prompt  2 0.2652933391146917\n",
      "6  hits,  1 0.28169934667141894\n",
      "6  conduc  1 0.28169934667141894\n",
      "6  ndcg  1 0.28169934667141894\n",
      "6  promise,  1 0.28169934667141894\n",
      "6  nam  1 0.28169934667141894\n",
      "6  gpt-3.5,  1 0.28169934667141894\n",
      "6  sign  1 0.13264666955734586\n",
      "6  top  1 0.28169934667141894\n",
      "6  consist  1 0.28169934667141894\n",
      "6  nat  1 0.20068666377598746\n",
      "6  inconsistencies.  1 0.28169934667141894\n",
      "6  emerg  1 0.28169934667141894\n",
      "6  llm-based  1 0.15904041823988746\n",
      "6  1m  1 0.28169934667141894\n",
      "6  titl  1 0.28169934667141894\n",
      "6  descriptions.  1 0.28169934667141894\n",
      "6  subsequently,  1 0.28169934667141894\n",
      "6  dataset  2 0.4013733275519749\n",
      "6  op  1 0.28169934667141894\n",
      "6  book  1 0.28169934667141894\n",
      "6  scraping  1 0.28169934667141894\n",
      "6  cast  1 0.28169934667141894\n",
      "6  auth  1 0.28169934667141894\n",
      "6  larg  1 0.10034333188799373\n",
      "6  web-scraped  1 0.28169934667141894\n",
      "6  traditionally,  1 0.28169934667141894\n",
      "6  sum  1 0.28169934667141894\n",
      "6  man  1 0.28169934667141894\n",
      "6  ess  1 0.28169934667141894\n",
      "6  pow  1 0.15904041823988746\n",
      "6  pivot  1 0.28169934667141894\n",
      "6  paper,  1 0.13264666955734586\n",
      "6  ml  1 0.28169934667141894\n",
      "6  model  1 0.1141408936074021\n",
      "6  study,  1 0.28169934667141894\n",
      "6  metrics.  1 0.20068666377598746\n",
      "6  llm,  1 0.28169934667141894\n",
      "6  lik  1 0.28169934667141894\n",
      "6  provid  1 0.28169934667141894\n",
      "6  goodread  1 0.28169934667141894\n",
      "6  process  1 0.20068666377598746\n",
      "6  items.  1 0.28169934667141894\n",
      "6  pot  1 0.20068666377598746\n",
      "6  suscept  1 0.28169934667141894\n",
      "6  direct  1 0.20068666377598746\n",
      "6  few-shot  1 0.28169934667141894\n",
      "6  comp  2 0.5633986933428379\n",
      "6  techniques,  1 0.28169934667141894\n",
      "6  movy  1 0.28169934667141894\n",
      "6  exhibit  1 0.28169934667141894\n",
      "6  feat  1 0.28169934667141894\n",
      "6  tool  1 0.28169934667141894\n",
      "6  sourc  1 0.28169934667141894\n",
      "6  (llms),  1 0.28169934667141894\n",
      "6  detail  1 0.28169934667141894\n",
      "6  cont  1 0.20068666377598746\n",
      "6  mrr,  1 0.28169934667141894\n",
      "6  recommend  1 0.20068666377598746\n",
      "6  capt  1 0.15904041823988746\n",
      "6  multipl  1 0.15904041823988746\n",
      "6  dataset.  1 0.28169934667141894\n",
      "6  years,  1 0.28169934667141894\n",
      "6  compr  1 0.28169934667141894\n",
      "6  rec  1 0.15904041823988746\n",
      "6  langu  2 0.20068666377598746\n",
      "6  time-consuming  1 0.28169934667141894\n",
      "6  scraped  1 0.28169934667141894\n",
      "6  result  1 0.13264666955734586\n",
      "6  demonst  1 0.15904041823988746\n",
      "6  dat  1 0.28169934667141894\n",
      "6  gen  3 0.3979400086720376\n",
      "6  publ  1 0.28169934667141894\n",
      "6  expl  1 0.20068666377598746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "descripteur_split_lancaster =\"\"\n",
    "\n",
    "for i in range(len(termes_split_lancaster)):\n",
    "    for j in range(len(termes_split_lancaster[i])):\n",
    "               \n",
    "        term = termes_split_lancaster[i][j]\n",
    "        frequency_term = frequency_dict_split_lancaster_documents[i][term]\n",
    "        max_frequancy = max_frequency_dict_split_lancaster_documents[i]\n",
    "        frequency_in_collection = document_frequency_dict_split_lancaster[term]\n",
    "\n",
    "        poids_term = poids(frequency_term,max_frequancy,frequency_in_collection,n_split)\n",
    "\n",
    "        descripteur_split_lancaster = descripteur_split_lancaster + (str(i+1)+ \"  \" +termes_split_lancaster[i][j]+ \"  \" +str(frequency_term)+\" \"+ str(poids_term)+\"\\n\")\n",
    "\n",
    "\n",
    "print(descripteur_split_lancaster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  lev  1 0.11928031367991561\n",
      "1  rank  1 0.11928031367991561\n",
      "1  relev  1 0.2112745100035642\n",
      "1  improv  4 0.3979400086720376\n",
      "1  18%  1 0.2112745100035642\n",
      "1  evalu  1 0.11928031367991561\n",
      "1  tak  1 0.11928031367991561\n",
      "1  state-of-art  1 0.2112745100035642\n",
      "1  msmarco  1 0.2112745100035642\n",
      "1  knowledg  1 0.2112745100035642\n",
      "1  instruct  1 0.1505149978319906\n",
      "1  investig  1 0.2112745100035642\n",
      "1  rel  1 0.2112745100035642\n",
      "1  5%  1 0.2112745100035642\n",
      "1  retriev  1 0.1505149978319906\n",
      "1  query  2 0.1989700043360188\n",
      "1  shown  1 0.2112745100035642\n",
      "1  pseudo  1 0.2112745100035642\n",
      "1  propos  1 0.08560567020555157\n",
      "1  us  3 0.22577249674798588\n",
      "1  strategies  1 0.11928031367991561\n",
      "1  prompt  1 0.08560567020555157\n",
      "1  abl  1 0.1505149978319906\n",
      "1  context  1 0.2112745100035642\n",
      "1  incorp  1 0.2112745100035642\n",
      "1  approach  1 0.0994850021680094\n",
      "1  perform  1 0.11928031367991561\n",
      "1  post-retrieval  1 0.2112745100035642\n",
      "1  four  1 0.2112745100035642\n",
      "1  int  1 0.1505149978319906\n",
      "1  success  1 0.1505149978319906\n",
      "1  vary  1 0.0994850021680094\n",
      "1  larg  1 0.0752574989159953\n",
      "1  24%  1 0.2112745100035642\n",
      "1  transform  1 0.2112745100035642\n",
      "1  docu  1 0.11928031367991561\n",
      "1  ultim  1 0.2112745100035642\n",
      "1  ndcg@10  1 0.11928031367991561\n",
      "1  benchmark  1 0.0994850021680094\n",
      "1  find  1 0.1505149978319906\n",
      "1  inh  1 0.2112745100035642\n",
      "1  set  2 0.23856062735983122\n",
      "1  prom  1 0.1505149978319906\n",
      "1  qr  1 0.2112745100035642\n",
      "1  bas  1 0.11928031367991561\n",
      "1  model  1 0.0752574989159953\n",
      "1  ir  1 0.1505149978319906\n",
      "1  show  1 0.1505149978319906\n",
      "1  task  2 0.17121134041110314\n",
      "1  prevy  1 0.11928031367991561\n",
      "1  9%  1 0.2112745100035642\n",
      "1  genqrensemblerf  1 0.2112745100035642\n",
      "1  benefit  1 0.2112745100035642\n",
      "1  ensembl  1 0.2112745100035642\n",
      "1  feedback  1 0.1505149978319906\n",
      "1  introduc  1 0.1505149978319906\n",
      "1  expery  1 0.0994850021680094\n",
      "1  pseudo-relevance  1 0.2112745100035642\n",
      "1  due  1 0.2112745100035642\n",
      "1  paraphras  1 0.2112745100035642\n",
      "1  exploit  1 0.2112745100035642\n",
      "1  reform  3 0.45154499349597177\n",
      "1  mrr  1 0.1505149978319906\n",
      "1  origin  1 0.2112745100035642\n",
      "1  text  1 0.11928031367991561\n",
      "1  techn  2 0.1989700043360188\n",
      "1  upto  1 0.2112745100035642\n",
      "1  align  1 0.2112745100035642\n",
      "1  keyword  1 0.2112745100035642\n",
      "1  many  1 0.2112745100035642\n",
      "1  pass  1 0.2112745100035642\n",
      "1  genqrensembl  1 0.2112745100035642\n",
      "1  search  1 0.11928031367991561\n",
      "1  multipl  1 0.11928031367991561\n",
      "1  rec  1 0.0994850021680094\n",
      "1  langu  1 0.0752574989159953\n",
      "1  zero-shot  1 0.2112745100035642\n",
      "1  bet  1 0.2112745100035642\n",
      "1  gain  1 0.2112745100035642\n",
      "1  gen  2 0.1989700043360188\n",
      "1  map  1 0.2112745100035642\n",
      "1  inspir  1 0.1505149978319906\n",
      "1  help  1 0.2112745100035642\n",
      "2  rank  3 0.47712125471966244\n",
      "2  complex  1 0.20068666377598746\n",
      "2  improv  1 0.13264666955734586\n",
      "2  ev  1 0.28169934667141894\n",
      "2  efficy  1 0.20068666377598746\n",
      "2  furtherm  1 0.20068666377598746\n",
      "2  open-sourced  1 0.20068666377598746\n",
      "2  howev  1 0.28169934667141894\n",
      "2  gpt-4  1 0.28169934667141894\n",
      "2  estim  1 0.28169934667141894\n",
      "2  baselin  2 0.5633986933428379\n",
      "2  standard  1 0.28169934667141894\n",
      "2  form  1 0.20068666377598746\n",
      "2  flan-ul2  1 0.28169934667141894\n",
      "2  moderate-sized  1 0.28169934667141894\n",
      "2  challeng  1 0.28169934667141894\n",
      "2  outperform  3 0.8450980400142568\n",
      "2  problem  1 0.15904041823988746\n",
      "2  query  1 0.13264666955734586\n",
      "2  llms  1 0.13264666955734586\n",
      "2  2020  1 0.28169934667141894\n",
      "2  10%  1 0.28169934667141894\n",
      "2  state-of-the-art  1 0.20068666377598746\n",
      "2  propos  1 0.1141408936074021\n",
      "2  20b  1 0.28169934667141894\n",
      "2  us  2 0.20068666377598746\n",
      "2  found  1 0.28169934667141894\n",
      "2  interest  1 0.28169934667141894\n",
      "2  pract  1 0.28169934667141894\n",
      "2  prompt  3 0.3424226808222063\n",
      "2  chatgpt  1 0.28169934667141894\n",
      "2  method  1 0.20068666377598746\n",
      "2  trec-dl  1 0.28169934667141894\n",
      "2  superv  1 0.28169934667141894\n",
      "2  sign  1 0.13264666955734586\n",
      "2  listw  1 0.28169934667141894\n",
      "2  175b  1 0.28169934667141894\n",
      "2  approach  1 0.13264666955734586\n",
      "2  av  1 0.28169934667141894\n",
      "2  reduc  1 0.20068666377598746\n",
      "2  pointw  1 0.28169934667141894\n",
      "2  understand  1 0.15904041823988746\n",
      "2  4.2%  1 0.28169934667141894\n",
      "2  llm-based  1 0.15904041823988746\n",
      "2  cal  1 0.28169934667141894\n",
      "2  perform  2 0.3180808364797749\n",
      "2  dataset  1 0.13264666955734586\n",
      "2  fav  1 0.28169934667141894\n",
      "2  research  1 0.20068666377598746\n",
      "2  vary  1 0.13264666955734586\n",
      "2  larg  1 0.10034333188799373\n",
      "2  off-the-shelf  1 0.28169934667141894\n",
      "2  pap  1 0.13264666955734586\n",
      "2  docu  1 0.15904041823988746\n",
      "2  analys  1 0.20068666377598746\n",
      "2  ndcg@10  1 0.15904041823988746\n",
      "2  ful  1 0.28169934667141894\n",
      "2  commerc  1 0.28169934667141894\n",
      "2  benchmark  2 0.2652933391146917\n",
      "2  bas  1 0.15904041823988746\n",
      "2  model  2 0.20068666377598746\n",
      "2  burd  1 0.28169934667141894\n",
      "2  show  1 0.20068666377598746\n",
      "2  paramet  1 0.28169934667141894\n",
      "2  task  1 0.1141408936074021\n",
      "2  12-10%  1 0.28169934667141894\n",
      "2  prevy  1 0.15904041823988746\n",
      "2  2019  1 0.28169934667141894\n",
      "2  ex  1 0.28169934667141894\n",
      "2  beir  1 0.20068666377598746\n",
      "2  siz  1 0.28169934667141894\n",
      "2  achiev  1 0.15904041823988746\n",
      "2  solv  2 0.5633986933428379\n",
      "2  met  1 0.20068666377598746\n",
      "2  blackbox  1 0.28169934667141894\n",
      "2  templ  1 0.20068666377598746\n",
      "2  pairw  1 0.28169934667141894\n",
      "2  sev  2 0.5633986933428379\n",
      "2  difficult  1 0.28169934667141894\n",
      "2  prp  1 0.28169934667141894\n",
      "2  direct  1 0.20068666377598746\n",
      "2  argu  1 0.28169934667141894\n",
      "2  best  1 0.28169934667141894\n",
      "2  techn  1 0.13264666955734586\n",
      "2  competit  1 0.28169934667141894\n",
      "2  lit  1 0.28169934667141894\n",
      "2  poss  1 0.28169934667141894\n",
      "2  instructgpt  1 0.28169934667141894\n",
      "2  50x  1 0.28169934667141894\n",
      "2  linear  1 0.28169934667141894\n",
      "2  first  1 0.15904041823988746\n",
      "2  candid  1 0.28169934667141894\n",
      "2  langu  1 0.10034333188799373\n",
      "2  new  1 0.28169934667141894\n",
      "2  result  1 0.13264666955734586\n",
      "2  fine-tuned  1 0.28169934667141894\n",
      "2  fee  1 0.28169934667141894\n",
      "3  train  1 0.28169934667141894\n",
      "3  distil  2 0.5633986933428379\n",
      "3  improv  3 0.3979400086720376\n",
      "3  efficy  2 0.4013733275519749\n",
      "3  strategy  1 0.28169934667141894\n",
      "3  design  1 0.28169934667141894\n",
      "3  attempt  1 0.28169934667141894\n",
      "3  tim  1 0.20068666377598746\n",
      "3  tak  1 0.15904041823988746\n",
      "3  item  1 0.20068666377598746\n",
      "3  may  1 0.28169934667141894\n",
      "3  inf  1 0.28169934667141894\n",
      "3  extend  1 0.28169934667141894\n",
      "3  e.g.  1 0.28169934667141894\n",
      "3  although  1 0.28169934667141894\n",
      "3  inform  1 0.13264666955734586\n",
      "3  most  1 0.28169934667141894\n",
      "3  limit  1 0.20068666377598746\n",
      "3  word  1 0.28169934667141894\n",
      "3  plain  1 0.28169934667141894\n",
      "3  problem  1 0.15904041823988746\n",
      "3  immedy  1 0.28169934667141894\n",
      "3  bridg  1 0.20068666377598746\n",
      "3  vect  1 0.28169934667141894\n",
      "3  propos  1 0.1141408936074021\n",
      "3  id  1 0.28169934667141894\n",
      "3  us  2 0.20068666377598746\n",
      "3  prompt  2 0.2282817872148042\n",
      "3  manifest  1 0.28169934667141894\n",
      "3  enough  1 0.28169934667141894\n",
      "3  user/item  1 0.28169934667141894\n",
      "3  sign  1 0.13264666955734586\n",
      "3  long  2 0.5633986933428379\n",
      "3  fil  1 0.28169934667141894\n",
      "3  approach  1 0.13264666955734586\n",
      "3  reduc  1 0.20068666377598746\n",
      "3  contain  1 0.28169934667141894\n",
      "3  understand  1 0.15904041823988746\n",
      "3  multi-step  1 0.28169934667141894\n",
      "3  requir  1 0.28169934667141894\n",
      "3  llm-based  1 0.15904041823988746\n",
      "3  dataset  1 0.13264666955734586\n",
      "3  noisy  1 0.28169934667141894\n",
      "3  i.e.  1 0.28169934667141894\n",
      "3  discret  1 0.28169934667141894\n",
      "3  unparallel  1 0.28169934667141894\n",
      "3  research  1 0.20068666377598746\n",
      "3  llm  1 0.15904041823988746\n",
      "3  input  1 0.15904041823988746\n",
      "3  vary  1 0.13264666955734586\n",
      "3  larg  1 0.10034333188799373\n",
      "3  fine-tuning  1 0.28169934667141894\n",
      "3  thu  1 0.28169934667141894\n",
      "3  find  1 0.20068666377598746\n",
      "3  three  1 0.28169934667141894\n",
      "3  also  1 0.20068666377598746\n",
      "3  set  1 0.15904041823988746\n",
      "3  pow  1 0.15904041823988746\n",
      "3  reason  1 0.28169934667141894\n",
      "3  continu  1 0.28169934667141894\n",
      "3  model  2 0.20068666377598746\n",
      "3  task  2 0.2282817872148042\n",
      "3  effect  1 0.15904041823988746\n",
      "3  allow  1 0.20068666377598746\n",
      "3  expery  1 0.13264666955734586\n",
      "3  giv  1 0.20068666377598746\n",
      "3  templ  1 0.20068666377598746\n",
      "3  process  1 0.13264666955734586\n",
      "3  could  1 0.28169934667141894\n",
      "3  text  1 0.15904041823988746\n",
      "3  address  1 0.28169934667141894\n",
      "3  real-world  1 0.28169934667141894\n",
      "3  respons  1 0.28169934667141894\n",
      "3  commun  1 0.28169934667141894\n",
      "3  unleash  1 0.28169934667141894\n",
      "3  pod  1 0.28169934667141894\n",
      "3  top-n  1 0.28169934667141894\n",
      "3  cap  1 0.28169934667141894\n",
      "3  recommend  2 0.4013733275519749\n",
      "3  langu  1 0.10034333188799373\n",
      "3  spec  1 0.28169934667141894\n",
      "3  sequ  1 0.20068666377598746\n",
      "3  result  1 0.13264666955734586\n",
      "3  system  1 0.20068666377598746\n",
      "3  demonst  1 0.15904041823988746\n",
      "3  nee  1 0.20068666377598746\n",
      "3  inspir  1 0.20068666377598746\n",
      "4  lev  2 0.3180808364797749\n",
      "4  innov  1 0.28169934667141894\n",
      "4  phas  1 0.28169934667141894\n",
      "4  improv  1 0.13264666955734586\n",
      "4  furtherm  1 0.20068666377598746\n",
      "4  evalu  1 0.15904041823988746\n",
      "4  mod  1 0.28169934667141894\n",
      "4  tim  1 0.20068666377598746\n",
      "4  adapt  2 0.5633986933428379\n",
      "4  aggreg  1 0.28169934667141894\n",
      "4  empir  1 0.28169934667141894\n",
      "4  inform  1 0.13264666955734586\n",
      "4  boost  1 0.28169934667141894\n",
      "4  combin  1 0.20068666377598746\n",
      "4  aim  1 0.20068666377598746\n",
      "4  autom  1 0.28169934667141894\n",
      "4  retriev  3 0.6020599913279624\n",
      "4  limit  1 0.20068666377598746\n",
      "4  problem  1 0.15904041823988746\n",
      "4  query  3 0.3979400086720376\n",
      "4  llms  1 0.13264666955734586\n",
      "4  state-of-the-art  1 0.20068666377598746\n",
      "4  propos  1 0.1141408936074021\n",
      "4  us  2 0.20068666377598746\n",
      "4  strategies  1 0.15904041823988746\n",
      "4  prompt  1 0.1141408936074021\n",
      "4  group  1 0.28169934667141894\n",
      "4  method  1 0.20068666377598746\n",
      "4  reward  1 0.28169934667141894\n",
      "4  distinct  1 0.28169934667141894\n",
      "4  sign  1 0.13264666955734586\n",
      "4  qerm  1 0.28169934667141894\n",
      "4  novel  1 0.20068666377598746\n",
      "4  perform  1 0.15904041823988746\n",
      "4  int  2 0.4013733275519749\n",
      "4  input  1 0.15904041823988746\n",
      "4  success  1 0.20068666377598746\n",
      "4  redund  1 0.28169934667141894\n",
      "4  vary  2 0.2652933391146917\n",
      "4  complet  1 0.28169934667141894\n",
      "4  larg  1 0.10034333188799373\n",
      "4  well-generated  1 0.28169934667141894\n",
      "4  pap  1 0.13264666955734586\n",
      "4  expand  1 0.28169934667141894\n",
      "4  field  1 0.28169934667141894\n",
      "4  ndcg@10  1 0.15904041823988746\n",
      "4  custom  1 0.28169934667141894\n",
      "4  12%  1 0.28169934667141894\n",
      "4  benchmark  1 0.13264666955734586\n",
      "4  oft  1 0.28169934667141894\n",
      "4  optim  1 0.28169934667141894\n",
      "4  repres  1 0.20068666377598746\n",
      "4  bas  1 0.15904041823988746\n",
      "4  model  2 0.20068666377598746\n",
      "4  cruc  1 0.28169934667141894\n",
      "4  ir  1 0.20068666377598746\n",
      "4  framework  2 0.5633986933428379\n",
      "4  enh  1 0.20068666377598746\n",
      "4  prevy  1 0.15904041823988746\n",
      "4  refin  1 0.28169934667141894\n",
      "4  effect  1 0.15904041823988746\n",
      "4  feedback  1 0.20068666377598746\n",
      "4  beir  1 0.20068666377598746\n",
      "4  expery  1 0.13264666955734586\n",
      "4  loop  1 0.28169934667141894\n",
      "4  adv  1 0.20068666377598746\n",
      "4  achiev  1 0.15904041823988746\n",
      "4  singl  1 0.28169934667141894\n",
      "4  clust  2 0.5633986933428379\n",
      "4  rat  1 0.28169934667141894\n",
      "4  reform  2 0.4013733275519749\n",
      "4  process  1 0.13264666955734586\n",
      "4  weight  1 0.28169934667141894\n",
      "4  pot  1 0.20068666377598746\n",
      "4  constrain  1 0.28169934667141894\n",
      "4  well-known  1 0.28169934667141894\n",
      "4  techn  1 0.13264666955734586\n",
      "4  init  1 0.28169934667141894\n",
      "4  sota  1 0.28169934667141894\n",
      "4  gencrf  1 0.28169934667141894\n",
      "4  first  1 0.15904041823988746\n",
      "4  search  1 0.15904041823988746\n",
      "4  capt  2 0.3180808364797749\n",
      "4  multipl  1 0.15904041823988746\n",
      "4  differenty  1 0.28169934667141894\n",
      "4  surpass  1 0.28169934667141894\n",
      "4  rec  1 0.13264666955734586\n",
      "4  divers  1 0.28169934667141894\n",
      "4  langu  1 0.10034333188799373\n",
      "4  demonst  1 0.15904041823988746\n",
      "4  integr  1 0.20068666377598746\n",
      "4  gen  2 0.2652933391146917\n",
      "4  expl  1 0.20068666377598746\n",
      "5  lev  1 0.15904041823988746\n",
      "5  symbol  2 0.5633986933428379\n",
      "5  graph-based  1 0.28169934667141894\n",
      "5  rank  1 0.15904041823988746\n",
      "5  complex  1 0.20068666377598746\n",
      "5  sess  2 0.5633986933428379\n",
      "5  structures  1 0.28169934667141894\n",
      "5  neglect  1 0.28169934667141894\n",
      "5  contrast  1 0.28169934667141894\n",
      "5  learn  1 0.28169934667141894\n",
      "5  tak  1 0.15904041823988746\n",
      "5  includ  1 0.28169934667141894\n",
      "5  instruct  1 0.20068666377598746\n",
      "5  inform  1 0.13264666955734586\n",
      "5  form  1 0.20068666377598746\n",
      "5  modern  1 0.28169934667141894\n",
      "5  predict  1 0.28169934667141894\n",
      "5  aim  1 0.20068666377598746\n",
      "5  en  1 0.28169934667141894\n",
      "5  interact  3 0.8450980400142568\n",
      "5  query  1 0.13264666955734586\n",
      "5  llms  1 0.13264666955734586\n",
      "5  bridg  1 0.20068666377598746\n",
      "5  propos  1 0.1141408936074021\n",
      "5  us  3 0.3010299956639812\n",
      "5  corpor  1 0.28169934667141894\n",
      "5  strategies  1 0.15904041823988746\n",
      "5  hist  1 0.28169934667141894\n",
      "5  abl  1 0.20068666377598746\n",
      "5  overlook  1 0.28169934667141894\n",
      "5  structural  1 0.28169934667141894\n",
      "5  graph-to-text  1 0.28169934667141894\n",
      "5  approach  2 0.2652933391146917\n",
      "5  nat  1 0.20068666377598746\n",
      "5  understand  1 0.15904041823988746\n",
      "5  discrep  1 0.28169934667141894\n",
      "5  pre-trained  1 0.28169934667141894\n",
      "5  tiangong-st  1 0.28169934667141894\n",
      "5  novel  1 0.20068666377598746\n",
      "5  two  1 0.28169934667141894\n",
      "5  gramm  1 0.28169934667141894\n",
      "5  sem  1 0.28169934667141894\n",
      "5  dataset  1 0.13264666955734586\n",
      "5  sery  1 0.28169934667141894\n",
      "5  link  1 0.28169934667141894\n",
      "5  confirm  1 0.28169934667141894\n",
      "5  cur  1 0.28169934667141894\n",
      "5  llm  1 0.15904041823988746\n",
      "5  input  1 0.15904041823988746\n",
      "5  fulfil  1 0.28169934667141894\n",
      "5  moreov  1 0.28169934667141894\n",
      "5  larg  1 0.10034333188799373\n",
      "5  pap  1 0.13264666955734586\n",
      "5  docu  1 0.15904041823988746\n",
      "5  analys  1 0.20068666377598746\n",
      "5  paradigm  1 0.28169934667141894\n",
      "5  nod  1 0.28169934667141894\n",
      "5  topolog  1 0.28169934667141894\n",
      "5  tradit  1 0.20068666377598746\n",
      "5  self-supervised  1 0.28169934667141894\n",
      "5  benchmark  1 0.13264666955734586\n",
      "5  methodolog  1 0.28169934667141894\n",
      "5  produc  1 0.28169934667141894\n",
      "5  graph  2 0.5633986933428379\n",
      "5  repres  1 0.20068666377598746\n",
      "5  also  1 0.20068666377598746\n",
      "5  set  1 0.15904041823988746\n",
      "5  pow  1 0.15904041823988746\n",
      "5  model  2 0.20068666377598746\n",
      "5  convert  1 0.28169934667141894\n",
      "5  rul  1 0.28169934667141894\n",
      "5  task  2 0.2282817872148042\n",
      "5  enh  1 0.20068666377598746\n",
      "5  supery  1 0.28169934667141894\n",
      "5  off  1 0.28169934667141894\n",
      "5  effect  1 0.15904041823988746\n",
      "5  allow  1 0.20068666377598746\n",
      "5  introduc  1 0.20068666377598746\n",
      "5  expery  1 0.13264666955734586\n",
      "5  structure  1 0.28169934667141894\n",
      "5  act  1 0.28169934667141894\n",
      "5  adv  1 0.20068666377598746\n",
      "5  achiev  1 0.15904041823988746\n",
      "5  typ  1 0.28169934667141894\n",
      "5  object  1 0.28169934667141894\n",
      "5  giv  1 0.20068666377598746\n",
      "5  sgr  1 0.28169934667141894\n",
      "5  coarse-grained  1 0.28169934667141894\n",
      "5  process  1 0.13264666955734586\n",
      "5  text  2 0.3180808364797749\n",
      "5  foc  1 0.28169934667141894\n",
      "5  word-level  1 0.28169934667141894\n",
      "5  fine-grained  1 0.28169934667141894\n",
      "5  involv  1 0.28169934667141894\n",
      "5  priorit  1 0.28169934667141894\n",
      "5  deep  1 0.28169934667141894\n",
      "5  first  1 0.15904041823988746\n",
      "5  cont  1 0.20068666377598746\n",
      "5  search  1 0.15904041823988746\n",
      "5  capt  2 0.3180808364797749\n",
      "5  rec  1 0.13264666955734586\n",
      "5  within  1 0.28169934667141894\n",
      "5  comprehend  1 0.28169934667141894\n",
      "5  sequ  1 0.20068666377598746\n",
      "5  langu  2 0.20068666377598746\n",
      "5  result  1 0.13264666955734586\n",
      "5  aol  1 0.28169934667141894\n",
      "5  integr  1 0.20068666377598746\n",
      "5  text-based  1 0.28169934667141894\n",
      "5  concret  1 0.28169934667141894\n",
      "5  gen  3 0.3979400086720376\n",
      "5  gap  1 0.28169934667141894\n",
      "5  seamless  1 0.28169934667141894\n",
      "5  nee  1 0.20068666377598746\n",
      "6  view  1 0.28169934667141894\n",
      "6  subsequ  1 0.28169934667141894\n",
      "6  play  1 0.28169934667141894\n",
      "6  open-sourced  1 0.20068666377598746\n",
      "6  moviel  1 0.28169934667141894\n",
      "6  evalu  1 0.15904041823988746\n",
      "6  rol  1 0.28169934667141894\n",
      "6  describ  2 0.5633986933428379\n",
      "6  item  2 0.4013733275519749\n",
      "6  consid  1 0.28169934667141894\n",
      "6  on  1 0.28169934667141894\n",
      "6  inform  1 0.13264666955734586\n",
      "6  obtain  1 0.28169934667141894\n",
      "6  combin  1 0.20068666377598746\n",
      "6  web  1 0.28169934667141894\n",
      "6  alpac  1 0.28169934667141894\n",
      "6  llms  1 0.13264666955734586\n",
      "6  us  3 0.3010299956639812\n",
      "6  prompt  2 0.2282817872148042\n",
      "6  conduc  1 0.28169934667141894\n",
      "6  ndcg  1 0.28169934667141894\n",
      "6  nam  1 0.28169934667141894\n",
      "6  hit  1 0.28169934667141894\n",
      "6  sign  1 0.13264666955734586\n",
      "6  top  1 0.28169934667141894\n",
      "6  consist  1 0.28169934667141894\n",
      "6  nat  1 0.20068666377598746\n",
      "6  emerg  1 0.28169934667141894\n",
      "6  llm-based  1 0.15904041823988746\n",
      "6  1m  1 0.28169934667141894\n",
      "6  titl  1 0.28169934667141894\n",
      "6  dataset  2 0.2652933391146917\n",
      "6  op  1 0.28169934667141894\n",
      "6  book  1 0.28169934667141894\n",
      "6  scraping  1 0.28169934667141894\n",
      "6  cast  1 0.28169934667141894\n",
      "6  llm  1 0.15904041823988746\n",
      "6  auth  1 0.28169934667141894\n",
      "6  larg  1 0.10034333188799373\n",
      "6  web-scraped  1 0.28169934667141894\n",
      "6  pap  1 0.13264666955734586\n",
      "6  year  1 0.28169934667141894\n",
      "6  tradit  1 0.20068666377598746\n",
      "6  inconsist  1 0.28169934667141894\n",
      "6  sum  1 0.28169934667141894\n",
      "6  man  1 0.28169934667141894\n",
      "6  ess  1 0.28169934667141894\n",
      "6  prom  1 0.20068666377598746\n",
      "6  pow  1 0.15904041823988746\n",
      "6  pivot  1 0.28169934667141894\n",
      "6  ml  1 0.28169934667141894\n",
      "6  model  1 0.10034333188799373\n",
      "6  task  1 0.1141408936074021\n",
      "6  lik  1 0.28169934667141894\n",
      "6  provid  1 0.28169934667141894\n",
      "6  met  1 0.20068666377598746\n",
      "6  goodread  1 0.28169934667141894\n",
      "6  process  1 0.13264666955734586\n",
      "6  pot  1 0.20068666377598746\n",
      "6  mrr  1 0.20068666377598746\n",
      "6  suscept  1 0.28169934667141894\n",
      "6  direct  1 0.20068666377598746\n",
      "6  few-shot  1 0.28169934667141894\n",
      "6  comp  2 0.5633986933428379\n",
      "6  techn  1 0.13264666955734586\n",
      "6  movy  1 0.28169934667141894\n",
      "6  exhibit  1 0.28169934667141894\n",
      "6  feat  1 0.28169934667141894\n",
      "6  tool  1 0.28169934667141894\n",
      "6  sourc  1 0.28169934667141894\n",
      "6  detail  1 0.28169934667141894\n",
      "6  cont  1 0.20068666377598746\n",
      "6  recommend  1 0.20068666377598746\n",
      "6  study  1 0.28169934667141894\n",
      "6  capt  1 0.15904041823988746\n",
      "6  gpt-3.5  1 0.28169934667141894\n",
      "6  multipl  1 0.15904041823988746\n",
      "6  compr  1 0.28169934667141894\n",
      "6  rec  1 0.13264666955734586\n",
      "6  langu  2 0.20068666377598746\n",
      "6  time-consuming  1 0.28169934667141894\n",
      "6  scraped  1 0.28169934667141894\n",
      "6  result  1 0.13264666955734586\n",
      "6  system  1 0.20068666377598746\n",
      "6  demonst  1 0.15904041823988746\n",
      "6  dat  1 0.28169934667141894\n",
      "6  gen  3 0.3979400086720376\n",
      "6  publ  1 0.28169934667141894\n",
      "6  expl  1 0.20068666377598746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "descripteur_reg_lancaster =\"\"\n",
    "\n",
    "for i in range(len(termes_reg_lancaster)):\n",
    "    for j in range(len(termes_reg_lancaster[i])):\n",
    "\n",
    "        term = termes_reg_lancaster[i][j]\n",
    "        frequency_term = frequency_dict_reg_lancaster_documents[i][term]\n",
    "        max_frequancy = max_frequency_dict_reg_lancaster_documents[i]\n",
    "        frequency_in_collection = document_frequency_dict_reg_lancaster[term]\n",
    "\n",
    "        poids_term = poids(frequency_term,max_frequancy,frequency_in_collection,n_reg)\n",
    "        descripteur_reg_lancaster= descripteur_reg_lancaster + (str(i+1)+ \"  \" +termes_reg_lancaster[i][j]+ \"  \" +str(frequency_term)+\" \"+ str(poids_term)+\"\\n\")\n",
    "\n",
    "\n",
    "print(descripteur_reg_lancaster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inverse file creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  inspiration  1  1  0.28169934667141894\n",
      "1  Passage  1  1  0.28169934667141894\n",
      "1  18%  1  1  0.28169934667141894\n",
      "1  taking  1  1  0.28169934667141894\n",
      "1  sets  1  1  0.28169934667141894\n",
      "1  intent  1  1  0.28169934667141894\n",
      "1  improvements  1  2  0.5633986933428379\n",
      "1  retrieval  1  1  0.20068666377598746\n",
      "2  retrieval  4  2  0.3010299956639812\n",
      "1  QR  1  1  0.28169934667141894\n",
      "1  Ranking  1  1  0.20068666377598746\n",
      "2  Ranking  2  2  0.3010299956639812\n",
      "1  used  1  1  0.15904041823988746\n",
      "2  used  2  1  0.11928031367991561\n",
      "3  used  6  1  0.11928031367991561\n",
      "1  leverages  1  1  0.20068666377598746\n",
      "2  leverages  4  1  0.1505149978319906\n",
      "1  incorporate  1  1  0.28169934667141894\n",
      "1  technique,  1  1  0.28169934667141894\n",
      "1  5%  1  1  0.28169934667141894\n",
      "1  MRR  1  1  0.28169934667141894\n",
      "1  paraphrases  1  1  0.28169934667141894\n",
      "1  prompting  1  2  0.4013733275519749\n",
      "2  prompting  6  1  0.1505149978319906\n",
      "1  nDCG@10  1  2  0.5633986933428379\n",
      "1  query  1  2  0.3180808364797749\n",
      "2  query  2  1  0.11928031367991561\n",
      "3  query  4  4  0.47712125471966244\n",
      "1  pseudo  1  1  0.28169934667141894\n",
      "1  shown  1  1  0.28169934667141894\n",
      "1  introduce  1  1  0.20068666377598746\n",
      "2  introduce  5  2  0.4013733275519749\n",
      "1  shows  1  1  0.28169934667141894\n",
      "1  strategies  1  1  0.15904041823988746\n",
      "2  strategies  4  1  0.11928031367991561\n",
      "3  strategies  5  2  0.3180808364797749\n",
      "1  GenQREnsembleRF  1  2  0.5633986933428379\n",
      "1  evaluations  1  1  0.28169934667141894\n",
      "1  approach  1  1  0.15904041823988746\n",
      "2  approach  2  1  0.11928031367991561\n",
      "3  approach  3  1  0.11928031367991561\n",
      "1  generate  1  1  0.15904041823988746\n",
      "2  generate  4  2  0.23856062735983122\n",
      "3  generate  6  2  0.23856062735983122\n",
      "1  based  1  1  0.15904041823988746\n",
      "2  based  2  2  0.23856062735983122\n",
      "3  based  4  1  0.11928031367991561\n",
      "1  inherent  1  1  0.28169934667141894\n",
      "1  GenQREnsemble  1  2  0.5633986933428379\n",
      "1  user’s  1  2  0.5633986933428379\n",
      "1  post-retrieval  1  1  0.28169934667141894\n",
      "1  performance.  1  1  0.28169934667141894\n",
      "1  state-of-art.  1  1  0.28169934667141894\n",
      "1  large  1  1  0.28169934667141894\n",
      "1  four  1  1  0.28169934667141894\n",
      "1  tasks,  1  1  0.15904041823988746\n",
      "2  tasks,  2  1  0.11928031367991561\n",
      "3  tasks,  3  1  0.11928031367991561\n",
      "1  success  1  1  0.28169934667141894\n",
      "1  aligns  1  1  0.28169934667141894\n",
      "1  improving  1  1  0.28169934667141894\n",
      "1  24%  1  1  0.28169934667141894\n",
      "1  transform  1  1  0.28169934667141894\n",
      "1  documents.  1  1  0.28169934667141894\n",
      "1  relative  1  2  0.5633986933428379\n",
      "1  benchmarks,  1  1  0.28169934667141894\n",
      "1  previous  1  1  0.15904041823988746\n",
      "2  previous  2  1  0.11928031367991561\n",
      "3  previous  4  1  0.11928031367991561\n",
      "1  experience.  1  1  0.28169934667141894\n",
      "1  find  1  1  0.28169934667141894\n",
      "1  feedback,  1  1  0.28169934667141894\n",
      "1  multiple  1  1  0.15904041823988746\n",
      "2  multiple  4  1  0.11928031367991561\n",
      "3  multiple  6  1  0.11928031367991561\n",
      "1  Query  1  1  0.20068666377598746\n",
      "2  Query  4  2  0.3010299956639812\n",
      "1  set  1  1  0.15904041823988746\n",
      "2  set  3  1  0.11928031367991561\n",
      "3  set  5  2  0.3180808364797749\n",
      "1  reformulation.  1  1  0.28169934667141894\n",
      "1  propose  1  1  0.1141408936074021\n",
      "2  propose  2  2  0.17121134041110314\n",
      "3  propose  3  1  0.08560567020555157\n",
      "4  propose  4  1  0.08560567020555157\n",
      "5  propose  5  1  0.1141408936074021\n",
      "1  ensemble  1  2  0.5633986933428379\n",
      "1  9%  1  1  0.28169934667141894\n",
      "1  MSMarco  1  1  0.28169934667141894\n",
      "1  feedback  1  1  0.20068666377598746\n",
      "2  feedback  4  1  0.1505149978319906\n",
      "1  using  1  2  0.2282817872148042\n",
      "2  using  2  4  0.3424226808222063\n",
      "3  using  4  1  0.08560567020555157\n",
      "4  using  5  1  0.1141408936074021\n",
      "5  using  6  1  0.08560567020555157\n",
      "1  pseudo-relevance  1  1  0.28169934667141894\n",
      "1  due  1  1  0.28169934667141894\n",
      "1  context,  1  1  0.28169934667141894\n",
      "1  gains  1  1  0.28169934667141894\n",
      "1  ability  1  1  0.20068666377598746\n",
      "2  ability  5  1  0.20068666377598746\n",
      "1  original  1  1  0.28169934667141894\n",
      "1  reformulations  1  1  0.28169934667141894\n",
      "1  exploit  1  1  0.28169934667141894\n",
      "1  relevant  1  2  0.5633986933428379\n",
      "1  benefited  1  1  0.28169934667141894\n",
      "1  improve  1  1  0.13264666955734586\n",
      "2  improve  2  1  0.0994850021680094\n",
      "3  improve  3  2  0.1989700043360188\n",
      "4  improve  4  1  0.0994850021680094\n",
      "1  text  1  1  0.20068666377598746\n",
      "2  text  3  1  0.1505149978319906\n",
      "1  Recently,  1  1  0.28169934667141894\n",
      "1  knowledge  1  1  0.28169934667141894\n",
      "1  MAP  1  1  0.28169934667141894\n",
      "1  investigate  1  1  0.28169934667141894\n",
      "1  feedback.  1  1  0.28169934667141894\n",
      "1  generates  1  1  0.28169934667141894\n",
      "1  upto  1  1  0.28169934667141894\n",
      "1  promising  1  1  0.28169934667141894\n",
      "1  Reformulation(QR)  1  1  0.28169934667141894\n",
      "1  task,  1  1  0.20068666377598746\n",
      "2  task,  3  1  0.1505149978319906\n",
      "1  ultimately  1  1  0.28169934667141894\n",
      "1  many  1  1  0.28169934667141894\n",
      "1  search  1  2  0.3180808364797749\n",
      "2  search  4  1  0.11928031367991561\n",
      "3  search  5  2  0.3180808364797749\n",
      "1  variant,  1  1  0.28169934667141894\n",
      "1  improves  1  1  0.28169934667141894\n",
      "1  zero-shot  1  3  0.8450980400142568\n",
      "1  models.  1  1  0.20068666377598746\n",
      "2  models.  3  2  0.3010299956639812\n",
      "1  better  1  2  0.5633986933428379\n",
      "1  techniques  1  1  0.20068666377598746\n",
      "2  techniques  4  1  0.1505149978319906\n",
      "1  instruction  1  1  0.20068666377598746\n",
      "2  instruction  5  1  0.20068666377598746\n",
      "1  language  1  1  0.13264666955734586\n",
      "2  language  3  1  0.0994850021680094\n",
      "3  language  5  1  0.13264666955734586\n",
      "4  language  6  1  0.0994850021680094\n",
      "1  IR  1  1  0.28169934667141894\n",
      "1  help  1  1  0.28169934667141894\n",
      "1  keywords  1  1  0.28169934667141894\n",
      "1  possible  2  1  0.2112745100035642\n",
      "1  open-sourced  2  1  0.1505149978319906\n",
      "2  open-sourced  6  1  0.1505149978319906\n",
      "1  GPT-4  2  1  0.2112745100035642\n",
      "1  complexity  2  1  0.2112745100035642\n",
      "1  analyze  2  1  0.2112745100035642\n",
      "1  template  2  1  0.1505149978319906\n",
      "2  template  3  2  0.3010299956639812\n",
      "1  rankers  2  1  0.2112745100035642\n",
      "1  called  2  1  0.2112745100035642\n",
      "1  standard  2  1  0.2112745100035642\n",
      "1  Models  2  1  0.0994850021680094\n",
      "2  Models  4  1  0.0994850021680094\n",
      "3  Models  5  1  0.13264666955734586\n",
      "4  Models  6  1  0.0994850021680094\n",
      "1  moderate-sized  2  1  0.2112745100035642\n",
      "1  performs  2  1  0.2112745100035642\n",
      "1  formulations.  2  1  0.2112745100035642\n",
      "1  outperform  2  1  0.2112745100035642\n",
      "1  literature  2  1  0.2112745100035642\n",
      "1  even  2  1  0.2112745100035642\n",
      "1  documents  2  2  0.4225490200071284\n",
      "1  technique  2  1  0.2112745100035642\n",
      "1  baselines  2  1  0.2112745100035642\n",
      "1  10%  2  1  0.2112745100035642\n",
      "1  Flan-UL2  2  1  0.2112745100035642\n",
      "1  state-of-the-art  2  1  0.1505149978319906\n",
      "2  state-of-the-art  4  1  0.1505149978319906\n",
      "1  solution  2  1  0.2112745100035642\n",
      "1  found  2  1  0.2112745100035642\n",
      "1  prompt  2  2  0.3010299956639812\n",
      "2  prompt  3  2  0.3010299956639812\n",
      "1  outperforming  2  1  0.2112745100035642\n",
      "1  problem.  2  1  0.2112745100035642\n",
      "1  existing  2  1  0.2112745100035642\n",
      "1  favorably  2  1  0.2112745100035642\n",
      "1  directly  2  1  0.2112745100035642\n",
      "1  several  2  1  0.2112745100035642\n",
      "1  argue  2  1  0.2112745100035642\n",
      "1  supervised  2  1  0.2112745100035642\n",
      "1  average  2  1  0.2112745100035642\n",
      "1  commercial  2  2  0.4225490200071284\n",
      "1  ChatGPT  2  1  0.2112745100035642\n",
      "1  reduce  2  1  0.1505149978319906\n",
      "2  reduce  3  1  0.1505149978319906\n",
      "1  researchers  2  1  0.1505149978319906\n",
      "2  researchers  3  1  0.1505149978319906\n",
      "1  understand  2  1  0.1505149978319906\n",
      "2  understand  3  1  0.1505149978319906\n",
      "1  4.2%  2  1  0.2112745100035642\n",
      "1  variants  2  1  0.2112745100035642\n",
      "1  results  2  2  0.1989700043360188\n",
      "2  results  3  1  0.0994850021680094\n",
      "3  results  5  1  0.13264666955734586\n",
      "4  results  6  2  0.1989700043360188\n",
      "1  performance  2  1  0.1505149978319906\n",
      "2  performance  4  2  0.3010299956639812\n",
      "1  burden  2  1  0.2112745100035642\n",
      "1  TREC-DL  2  1  0.2112745100035642\n",
      "1  achieve  2  2  0.3010299956639812\n",
      "2  achieve  5  1  0.20068666377598746\n",
      "1  Furthermore,  2  1  0.1505149978319906\n",
      "2  Furthermore,  4  1  0.1505149978319906\n",
      "1  20B  2  1  0.2112745100035642\n",
      "1  Large  2  1  0.08560567020555157\n",
      "2  Large  3  1  0.08560567020555157\n",
      "3  Large  4  1  0.08560567020555157\n",
      "4  Large  5  1  0.1141408936074021\n",
      "5  Large  6  1  0.08560567020555157\n",
      "1  efficiency  2  1  0.1505149978319906\n",
      "2  efficiency  3  4  0.6020599913279624\n",
      "1  off-the-shelf  2  1  0.2112745100035642\n",
      "1  benchmarks  2  1  0.2112745100035642\n",
      "1  LLM-based  2  2  0.23856062735983122\n",
      "2  LLM-based  3  2  0.23856062735983122\n",
      "3  LLM-based  6  1  0.11928031367991561\n",
      "1  (LLMs)  2  1  0.1505149978319906\n",
      "2  (LLMs)  4  1  0.1505149978319906\n",
      "1  significantly  2  1  0.11928031367991561\n",
      "2  significantly  3  1  0.11928031367991561\n",
      "3  significantly  4  1  0.11928031367991561\n",
      "1  feeding  2  1  0.2112745100035642\n",
      "1  LLMs.  2  1  0.1505149978319906\n",
      "2  LLMs.  5  1  0.20068666377598746\n",
      "1  benchmark  2  1  0.11928031367991561\n",
      "2  benchmark  4  1  0.11928031367991561\n",
      "3  benchmark  5  1  0.15904041823988746\n",
      "1  parameters  2  1  0.2112745100035642\n",
      "1  paper,  2  1  0.0994850021680094\n",
      "2  paper,  4  1  0.0994850021680094\n",
      "3  paper,  5  1  0.13264666955734586\n",
      "4  paper,  6  1  0.0994850021680094\n",
      "1  model  2  2  0.4225490200071284\n",
      "1  Pairwise  2  1  0.2112745100035642\n",
      "1  baseline  2  1  0.2112745100035642\n",
      "1  methods  2  1  0.1505149978319906\n",
      "2  methods  4  1  0.1505149978319906\n",
      "1  show  2  1  0.2112745100035642\n",
      "1  literature,  2  1  0.2112745100035642\n",
      "1  fully  2  1  0.2112745100035642\n",
      "1  12-10%  2  1  0.2112745100035642\n",
      "1  (PRP).  2  1  0.2112745100035642\n",
      "1  2019  2  1  0.2112745100035642\n",
      "1  2020,  2  1  0.2112745100035642\n",
      "1  metrics.  2  1  0.1505149978319906\n",
      "2  metrics.  6  1  0.1505149978319906\n",
      "1  175B  2  1  0.2112745100035642\n",
      "1  parameters,  2  1  0.2112745100035642\n",
      "1  Prompting  2  1  0.2112745100035642\n",
      "1  (estimated)  2  1  0.2112745100035642\n",
      "1  size,  2  1  0.2112745100035642\n",
      "1  datasets.  2  1  0.2112745100035642\n",
      "1  listwise  2  1  0.2112745100035642\n",
      "1  interesting  2  1  0.2112745100035642\n",
      "1  blackbox  2  2  0.4225490200071284\n",
      "1  InstructGPT  2  1  0.2112745100035642\n",
      "1  solutions  2  1  0.2112745100035642\n",
      "1  difficult  2  1  0.2112745100035642\n",
      "1  prompts  2  1  0.2112745100035642\n",
      "1  outperforms  2  2  0.4225490200071284\n",
      "1  best  2  1  0.2112745100035642\n",
      "1  ranking  2  4  0.8450980400142568\n",
      "1  pointwise  2  2  0.4225490200071284\n",
      "1  challenging  2  1  0.2112745100035642\n",
      "1  competitive  2  1  0.2112745100035642\n",
      "1  candidate  2  1  0.2112745100035642\n",
      "1  BEIR  2  1  0.1505149978319906\n",
      "2  BEIR  4  1  0.1505149978319906\n",
      "1  NDCG@10.  2  1  0.2112745100035642\n",
      "1  solutions,  2  1  0.2112745100035642\n",
      "1  However,  2  1  0.2112745100035642\n",
      "1  50x  2  1  0.2112745100035642\n",
      "1  PRP  2  3  0.6338235300106926\n",
      "1  linear  2  1  0.2112745100035642\n",
      "1  first  2  1  0.11928031367991561\n",
      "2  first  4  1  0.11928031367991561\n",
      "3  first  5  1  0.15904041823988746\n",
      "1  practical  2  1  0.2112745100035642\n",
      "1  seven  2  1  0.2112745100035642\n",
      "1  new  2  1  0.2112745100035642\n",
      "1  LLMs  2  2  0.1989700043360188\n",
      "2  LLMs  4  1  0.0994850021680094\n",
      "3  LLMs  5  2  0.2652933391146917\n",
      "4  LLMs  6  2  0.1989700043360188\n",
      "1  fine-tuned  2  1  0.2112745100035642\n",
      "1  Language  2  1  0.0994850021680094\n",
      "2  Language  4  1  0.0994850021680094\n",
      "3  Language  5  1  0.13264666955734586\n",
      "4  Language  6  1  0.0994850021680094\n",
      "1  datasets  3  1  0.2112745100035642\n",
      "1  process,  3  1  0.1505149978319906\n",
      "2  process,  5  1  0.20068666377598746\n",
      "1  usually  3  2  0.4225490200071284\n",
      "1  models  3  4  0.8450980400142568\n",
      "1  design  3  1  0.2112745100035642\n",
      "1  thus  3  1  0.2112745100035642\n",
      "1  strategy  3  1  0.2112745100035642\n",
      "1  attempt  3  1  0.2112745100035642\n",
      "1  PrOmpt  3  1  0.2112745100035642\n",
      "1  community  3  1  0.2112745100035642\n",
      "1  demonstrate  3  1  0.1505149978319906\n",
      "2  demonstrate  4  1  0.1505149978319906\n",
      "1  extensive  3  1  0.2112745100035642\n",
      "1  item  3  1  0.1505149978319906\n",
      "2  item  6  1  0.1505149978319906\n",
      "1  may  3  2  0.4225490200071284\n",
      "1  require  3  1  0.2112745100035642\n",
      "1  Experimental  3  1  0.2112745100035642\n",
      "1  specific  3  1  0.2112745100035642\n",
      "1  limited  3  1  0.1505149978319906\n",
      "2  limited  4  1  0.1505149978319906\n",
      "1  tasks.  3  1  0.1505149978319906\n",
      "2  tasks.  6  1  0.1505149978319906\n",
      "1  (i.e.,  3  1  0.2112745100035642\n",
      "1  recommender  3  1  0.2112745100035642\n",
      "1  plain  3  1  0.2112745100035642\n",
      "1  distill  3  1  0.2112745100035642\n",
      "1  take  3  1  0.1505149978319906\n",
      "2  take  5  1  0.20068666377598746\n",
      "1  enough  3  1  0.2112745100035642\n",
      "1  limited.  3  1  0.2112745100035642\n",
      "1  user/item  3  1  0.2112745100035642\n",
      "1  long  3  2  0.4225490200071284\n",
      "1  manifested  3  1  0.2112745100035642\n",
      "1  effectiveness  3  1  0.1505149978319906\n",
      "2  effectiveness  4  1  0.1505149978319906\n",
      "1  finding  3  1  0.2112745100035642\n",
      "1  systems  3  1  0.2112745100035642\n",
      "1  contain  3  1  0.2112745100035642\n",
      "1  (POD)  3  1  0.2112745100035642\n",
      "1  multi-step  3  1  0.2112745100035642\n",
      "1  time.  3  1  0.1505149978319906\n",
      "2  time.  4  1  0.1505149978319906\n",
      "1  Although  3  1  0.2112745100035642\n",
      "1  various  3  1  0.1505149978319906\n",
      "2  various  4  1  0.1505149978319906\n",
      "1  Long  3  1  0.2112745100035642\n",
      "1  noisy  3  1  0.2112745100035642\n",
      "1  Distillation  3  1  0.2112745100035642\n",
      "1  input  3  1  0.1505149978319906\n",
      "2  input  4  1  0.1505149978319906\n",
      "1  power  3  1  0.1505149978319906\n",
      "2  power  5  1  0.20068666377598746\n",
      "1  improvement  3  1  0.2112745100035642\n",
      "1  sequential  3  1  0.1505149978319906\n",
      "2  sequential  5  1  0.20068666377598746\n",
      "1  fine-tuning  3  1  0.2112745100035642\n",
      "1  discrete  3  2  0.4225490200071284\n",
      "1  inspire  3  1  0.2112745100035642\n",
      "1  models,  3  1  0.2112745100035642\n",
      "1  need  3  1  0.2112745100035642\n",
      "1  three  3  1  0.2112745100035642\n",
      "1  training  3  3  0.6338235300106926\n",
      "1  LLM  3  1  0.2112745100035642\n",
      "1  also  3  1  0.1505149978319906\n",
      "2  also  5  1  0.20068666377598746\n",
      "1  time  3  1  0.2112745100035642\n",
      "1  unparalleled  3  1  0.2112745100035642\n",
      "1  information.  3  1  0.2112745100035642\n",
      "1  filled  3  1  0.2112745100035642\n",
      "1  given  3  1  0.1505149978319906\n",
      "2  given  5  1  0.20068666377598746\n",
      "1  response.  3  1  0.2112745100035642\n",
      "1  task  3  1  0.1505149978319906\n",
      "2  task  5  1  0.20068666377598746\n",
      "1  user  3  1  0.2112745100035642\n",
      "1  allow  3  1  0.2112745100035642\n",
      "1  IDs  3  3  0.6338235300106926\n",
      "1  prompt)  3  1  0.2112745100035642\n",
      "1  recommendation.  3  1  0.2112745100035642\n",
      "1  problems,  3  1  0.2112745100035642\n",
      "1  top-N  3  1  0.2112745100035642\n",
      "1  words  3  2  0.4225490200071284\n",
      "1  vectors  3  1  0.2112745100035642\n",
      "1  could  3  2  0.4225490200071284\n",
      "1  address  3  1  0.2112745100035642\n",
      "1  real-world  3  1  0.2112745100035642\n",
      "1  continuous  3  1  0.2112745100035642\n",
      "1  recommendation  3  4  0.6020599913279624\n",
      "2  recommendation  6  1  0.1505149978319906\n",
      "1  bridge  3  2  0.4225490200071284\n",
      "1  unleash  3  1  0.2112745100035642\n",
      "1  e.g.,  3  1  0.2112745100035642\n",
      "1  mostly  3  1  0.2112745100035642\n",
      "1  reasoning,  3  1  0.2112745100035642\n",
      "1  efficient  3  1  0.2112745100035642\n",
      "1  modeling  3  1  0.1505149978319906\n",
      "2  modeling  5  1  0.20068666377598746\n",
      "1  improved,  3  1  0.2112745100035642\n",
      "1  capability  3  1  0.2112745100035642\n",
      "1  text,  3  1  0.2112745100035642\n",
      "1  (LLM)  3  1  0.2112745100035642\n",
      "1  inference  3  3  0.6338235300106926\n",
      "1  immediate  3  1  0.2112745100035642\n",
      "1  explores  4  1  0.2112745100035642\n",
      "1  retriever  4  1  0.2112745100035642\n",
      "1  initial  4  1  0.2112745100035642\n",
      "1  completion  4  1  0.2112745100035642\n",
      "1  SOTAs  4  1  0.2112745100035642\n",
      "1  nDCG@10.  4  1  0.2112745100035642\n",
      "1  Clustering  4  1  0.2112745100035642\n",
      "1  Model  4  1  0.2112745100035642\n",
      "1  represent  4  1  0.2112745100035642\n",
      "1  rate  4  1  0.2112745100035642\n",
      "1  Generative  4  1  0.2112745100035642\n",
      "1  problem  4  1  0.2112745100035642\n",
      "1  experiments  4  1  0.2112745100035642\n",
      "1  automatically  4  1  0.2112745100035642\n",
      "1  customized  4  1  0.2112745100035642\n",
      "1  combine  4  1  0.2112745100035642\n",
      "1  Reformulation  4  1  0.2112745100035642\n",
      "1  distinctly  4  1  0.2112745100035642\n",
      "1  boosting  4  1  0.2112745100035642\n",
      "1  leverage  4  1  0.2112745100035642\n",
      "1  capturing  4  1  0.1505149978319906\n",
      "2  capturing  5  1  0.20068666377598746\n",
      "1  capture  4  1  0.1505149978319906\n",
      "2  capture  5  2  0.4013733275519749\n",
      "1  surpassing  4  1  0.2112745100035642\n",
      "1  expansions,  4  1  0.2112745100035642\n",
      "1  novel  4  1  0.1505149978319906\n",
      "2  novel  5  1  0.20068666377598746\n",
      "1  reformulation  4  2  0.4225490200071284\n",
      "1  advancing  4  1  0.2112745100035642\n",
      "1  (QERM)  4  1  0.2112745100035642\n",
      "1  query.  4  1  0.2112745100035642\n",
      "1  Empirical  4  1  0.2112745100035642\n",
      "1  successful  4  1  0.2112745100035642\n",
      "1  crucially  4  1  0.2112745100035642\n",
      "1  performance,  4  1  0.2112745100035642\n",
      "1  refine  4  1  0.2112745100035642\n",
      "1  well-generated  4  1  0.2112745100035642\n",
      "1  adaptively  4  1  0.2112745100035642\n",
      "1  Framework  4  1  0.2112745100035642\n",
      "1  field  4  1  0.2112745100035642\n",
      "1  LLMs,  4  1  0.2112745100035642\n",
      "1  Retrieval.  4  1  0.2112745100035642\n",
      "1  intents.  4  2  0.4225490200071284\n",
      "1  single  4  1  0.2112745100035642\n",
      "1  variable  4  1  0.2112745100035642\n",
      "1  Evaluation  4  1  0.2112745100035642\n",
      "1  12%  4  1  0.2112745100035642\n",
      "1  Information  4  2  0.4225490200071284\n",
      "1  adapted  4  1  0.2112745100035642\n",
      "1  queries  4  2  0.3010299956639812\n",
      "2  queries  5  1  0.20068666377598746\n",
      "1  weighted  4  1  0.2112745100035642\n",
      "1  groups  4  1  0.2112745100035642\n",
      "1  differentiated,  4  1  0.2112745100035642\n",
      "1  phase  4  1  0.2112745100035642\n",
      "1  framework  4  1  0.2112745100035642\n",
      "1  constraining  4  1  0.2112745100035642\n",
      "1  enhancing  4  1  0.2112745100035642\n",
      "1  Rewarding  4  1  0.2112745100035642\n",
      "1  aggregation  4  1  0.2112745100035642\n",
      "1  intentions  4  1  0.2112745100035642\n",
      "1  user's  4  1  0.1505149978319906\n",
      "2  user's  5  1  0.20068666377598746\n",
      "1  achieves  4  1  0.2112745100035642\n",
      "1  GenCRF  4  2  0.4225490200071284\n",
      "1  reformulation,  4  1  0.2112745100035642\n",
      "1  process  4  1  0.2112745100035642\n",
      "1  aimed  4  1  0.2112745100035642\n",
      "1  integrates  4  1  0.2112745100035642\n",
      "1  intents  4  1  0.2112745100035642\n",
      "1  (IR)  4  1  0.2112745100035642\n",
      "1  loops.  4  1  0.2112745100035642\n",
      "1  well-known  4  1  0.2112745100035642\n",
      "1  potentially  4  1  0.2112745100035642\n",
      "1  often  4  1  0.2112745100035642\n",
      "1  Recent  4  1  0.2112745100035642\n",
      "1  GenCRF:  4  1  0.2112745100035642\n",
      "1  Retrieval  4  1  0.2112745100035642\n",
      "1  diverse  4  4  0.8450980400142568\n",
      "1  prompts,  4  1  0.2112745100035642\n",
      "1  redundant  4  1  0.2112745100035642\n",
      "1  modifying  4  1  0.2112745100035642\n",
      "1  clusters  4  1  0.2112745100035642\n",
      "1  optimize  4  1  0.2112745100035642\n",
      "1  innovative  4  1  0.2112745100035642\n",
      "1  Ranker  5  1  0.28169934667141894\n",
      "1  history,  5  1  0.28169934667141894\n",
      "1  corpora,  5  1  0.28169934667141894\n",
      "1  graph-based  5  1  0.28169934667141894\n",
      "1  complex  5  1  0.28169934667141894\n",
      "1  structures  5  1  0.28169934667141894\n",
      "1  bridges  5  1  0.28169934667141894\n",
      "1  interactive  5  1  0.28169934667141894\n",
      "1  (SGR),  5  1  0.28169934667141894\n",
      "1  interaction  5  1  0.28169934667141894\n",
      "1  format.  5  1  0.28169934667141894\n",
      "1  contrastive  5  1  0.28169934667141894\n",
      "1  inputs  5  1  0.28169934667141894\n",
      "1  actions  5  1  0.28169934667141894\n",
      "1  LLMs'  5  1  0.28169934667141894\n",
      "1  modern  5  1  0.28169934667141894\n",
      "1  documents,  5  1  0.28169934667141894\n",
      "1  Moreover,  5  1  0.28169934667141894\n",
      "1  objective  5  1  0.28169934667141894\n",
      "1  prioritize  5  1  0.28169934667141894\n",
      "1  generative  5  1  0.28169934667141894\n",
      "1  Current  5  1  0.28169934667141894\n",
      "1  natural  5  1  0.20068666377598746\n",
      "2  natural  6  1  0.1505149978319906\n",
      "1  information,  5  1  0.28169934667141894\n",
      "1  effective  5  1  0.28169934667141894\n",
      "1  this,  5  1  0.28169934667141894\n",
      "1  approaches  5  2  0.5633986933428379\n",
      "1  structural  5  1  0.28169934667141894\n",
      "1  generalized  5  1  0.28169934667141894\n",
      "1  graph-to-text  5  1  0.28169934667141894\n",
      "1  focus  5  1  0.28169934667141894\n",
      "1  aims  5  1  0.28169934667141894\n",
      "1  grammar,  5  1  0.28169934667141894\n",
      "1  datasets,  5  1  0.28169934667141894\n",
      "1  AOL  5  1  0.28169934667141894\n",
      "1  need.  5  1  0.28169934667141894\n",
      "1  produce  5  1  0.28169934667141894\n",
      "1  pre-trained  5  1  0.28169934667141894\n",
      "1  allows  5  1  0.28169934667141894\n",
      "1  recent  5  1  0.20068666377598746\n",
      "2  recent  6  1  0.1505149978319906\n",
      "1  two  5  1  0.28169934667141894\n",
      "1  (LLMs).  5  1  0.28169934667141894\n",
      "1  link  5  1  0.28169934667141894\n",
      "1  confirm  5  1  0.28169934667141894\n",
      "1  use  5  1  0.20068666377598746\n",
      "2  use  6  1  0.1505149978319906\n",
      "1  modeling.  5  1  0.28169934667141894\n",
      "1  discrepancy  5  1  0.28169934667141894\n",
      "1  learning,  5  1  0.28169934667141894\n",
      "1  leveraging  5  1  0.28169934667141894\n",
      "1  paradigm  5  1  0.28169934667141894\n",
      "1  self-supervised  5  1  0.28169934667141894\n",
      "1  prediction,  5  1  0.28169934667141894\n",
      "1  representation  5  1  0.28169934667141894\n",
      "1  advantage  5  1  0.28169934667141894\n",
      "1  graph  5  3  0.8450980400142568\n",
      "1  grammar  5  1  0.28169934667141894\n",
      "1  neglecting  5  1  0.28169934667141894\n",
      "1  including  5  1  0.28169934667141894\n",
      "1  Tiangong-ST,  5  1  0.28169934667141894\n",
      "1  typically  5  1  0.28169934667141894\n",
      "1  convert  5  1  0.28169934667141894\n",
      "1  comprehensive  5  1  0.28169934667141894\n",
      "1  interactions.  5  1  0.28169934667141894\n",
      "1  structure  5  1  0.28169934667141894\n",
      "1  fulfill  5  1  0.28169934667141894\n",
      "1  offers  5  1  0.28169934667141894\n",
      "1  information  5  2  0.5633986933428379\n",
      "1  rules  5  1  0.28169934667141894\n",
      "1  analysis  5  1  0.28169934667141894\n",
      "1  integrating  5  1  0.28169934667141894\n",
      "1  coarse-grained  5  1  0.28169934667141894\n",
      "1  traditional  5  1  0.28169934667141894\n",
      "1  understanding,  5  1  0.28169934667141894\n",
      "1  word-level  5  1  0.28169934667141894\n",
      "1  learning  5  1  0.28169934667141894\n",
      "1  generation,  5  1  0.28169934667141894\n",
      "1  symbolic  5  3  0.8450980400142568\n",
      "1  textual  5  2  0.5633986933428379\n",
      "1  content  5  1  0.28169934667141894\n",
      "1  enable  5  1  0.28169934667141894\n",
      "1  fine-grained.  5  1  0.28169934667141894\n",
      "1  node  5  1  0.28169934667141894\n",
      "1  enhance  5  1  0.28169934667141894\n",
      "1  deep  5  1  0.28169934667141894\n",
      "1  semantic  5  2  0.5633986933428379\n",
      "1  Symbolic  5  1  0.28169934667141894\n",
      "1  Concretely,  5  1  0.28169934667141894\n",
      "1  Session  5  1  0.28169934667141894\n",
      "1  methodology  5  1  0.28169934667141894\n",
      "1  topological  5  1  0.28169934667141894\n",
      "1  text.  5  1  0.28169934667141894\n",
      "1  Graph  5  1  0.28169934667141894\n",
      "1  seamlessly  5  1  0.28169934667141894\n",
      "1  involves  5  1  0.28169934667141894\n",
      "1  within  5  1  0.28169934667141894\n",
      "1  approach.  5  1  0.28169934667141894\n",
      "1  session  5  2  0.5633986933428379\n",
      "1  text-based  5  1  0.28169934667141894\n",
      "1  series  5  1  0.28169934667141894\n",
      "1  gap  5  1  0.28169934667141894\n",
      "1  tasks  5  1  0.28169934667141894\n",
      "1  Experiment  5  1  0.28169934667141894\n",
      "1  overlooking  5  1  0.28169934667141894\n",
      "1  superiority  5  1  0.28169934667141894\n",
      "1  LLM.  5  1  0.28169934667141894\n",
      "1  providing  6  1  0.2112745100035642\n",
      "1  GPT-3.5,  6  1  0.2112745100035642\n",
      "1  directors  6  1  0.2112745100035642\n",
      "1  Hits,  6  1  0.2112745100035642\n",
      "1  systems.  6  1  0.2112745100035642\n",
      "1  consisting  6  1  0.2112745100035642\n",
      "1  source  6  1  0.2112745100035642\n",
      "1  descriptions  6  4  0.8450980400142568\n",
      "1  emerged  6  1  0.2112745100035642\n",
      "1  features  6  1  0.2112745100035642\n",
      "1  summaries  6  1  0.2112745100035642\n",
      "1  considering  6  1  0.2112745100035642\n",
      "1  web  6  1  0.2112745100035642\n",
      "1  captivate  6  1  0.2112745100035642\n",
      "1  processing  6  1  0.2112745100035642\n",
      "1  comprising  6  1  0.2112745100035642\n",
      "1  essential  6  1  0.2112745100035642\n",
      "1  exhibits  6  1  0.2112745100035642\n",
      "1  Alpaca,  6  1  0.2112745100035642\n",
      "1  (LLMs),  6  1  0.2112745100035642\n",
      "1  promise,  6  1  0.2112745100035642\n",
      "1  publisher  6  1  0.2112745100035642\n",
      "1  ones  6  1  0.2112745100035642\n",
      "1  Goodreads  6  2  0.4225490200071284\n",
      "1  1M  6  1  0.2112745100035642\n",
      "1  viewers  6  1  0.2112745100035642\n",
      "1  data  6  1  0.2112745100035642\n",
      "1  inconsistencies.  6  1  0.2112745100035642\n",
      "1  informative  6  1  0.2112745100035642\n",
      "1  evaluation  6  1  0.2112745100035642\n",
      "1  generation  6  1  0.2112745100035642\n",
      "1  powerful  6  1  0.2112745100035642\n",
      "1  descriptions.  6  1  0.2112745100035642\n",
      "1  subsequently,  6  1  0.2112745100035642\n",
      "1  dataset  6  3  0.6338235300106926\n",
      "1  scraping  6  1  0.2112745100035642\n",
      "1  cast  6  1  0.2112745100035642\n",
      "1  MRR,  6  1  0.2112745100035642\n",
      "1  author  6  1  0.2112745100035642\n",
      "1  compared  6  1  0.2112745100035642\n",
      "1  prompted  6  1  0.2112745100035642\n",
      "1  web-scraped  6  1  0.2112745100035642\n",
      "1  obtained  6  2  0.4225490200071284\n",
      "1  Traditionally,  6  1  0.2112745100035642\n",
      "1  manual  6  1  0.2112745100035642\n",
      "1  demonstrated  6  1  0.2112745100035642\n",
      "1  description  6  3  0.6338235300106926\n",
      "1  potential  6  1  0.2112745100035642\n",
      "1  open  6  1  0.2112745100035642\n",
      "1  significant  6  1  0.2112745100035642\n",
      "1  Top  6  1  0.2112745100035642\n",
      "1  study,  6  1  0.2112745100035642\n",
      "1  books  6  1  0.2112745100035642\n",
      "1  comparable  6  1  0.2112745100035642\n",
      "1  LLM,  6  1  0.2112745100035642\n",
      "1  explored  6  1  0.2112745100035642\n",
      "1  NDCG  6  1  0.2112745100035642\n",
      "1  items.  6  1  0.2112745100035642\n",
      "1  few-shot  6  1  0.2112745100035642\n",
      "1  generated  6  1  0.2112745100035642\n",
      "1  techniques,  6  1  0.2112745100035642\n",
      "1  Dataset  6  1  0.2112745100035642\n",
      "1  like  6  2  0.4225490200071284\n",
      "1  combination  6  1  0.2112745100035642\n",
      "1  MovieLens  6  1  0.2112745100035642\n",
      "1  ML  6  1  0.2112745100035642\n",
      "1  plays  6  1  0.2112745100035642\n",
      "1  pivotal  6  1  0.2112745100035642\n",
      "1  susceptible  6  1  0.2112745100035642\n",
      "1  names  6  3  0.6338235300106926\n",
      "1  dataset.  6  1  0.2112745100035642\n",
      "1  concise  6  1  0.2112745100035642\n",
      "1  years,  6  1  0.2112745100035642\n",
      "1  Alpaca  6  1  0.2112745100035642\n",
      "1  tools  6  1  0.2112745100035642\n",
      "1  titles  6  1  0.2112745100035642\n",
      "1  conduct  6  1  0.2112745100035642\n",
      "1  time-consuming  6  1  0.2112745100035642\n",
      "1  scraped  6  1  0.2112745100035642\n",
      "1  detailed  6  2  0.4225490200071284\n",
      "1  movie  6  3  0.6338235300106926\n",
      "1  role  6  1  0.2112745100035642\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inverse_split = {}\n",
    "\n",
    "# Loop over each document's terms\n",
    "for i in range(len(termes_split)):\n",
    "    seen_terms = set()  # Track terms already processed for the current document\n",
    "    \n",
    "    for term in termes_split[i]:\n",
    "        # Ensure we only process each term once per document\n",
    "        if (term, i) not in seen_terms:\n",
    "            seen_terms.add((term, i))  # Mark term as processed for this document\n",
    "            \n",
    "            if term not in inverse_split:\n",
    "                inverse_split[term] = []  # Initialize list for storing details\n",
    "            \n",
    "            # Calculate frequency and weight for the term in the current document\n",
    "            frequency_term = frequency_dict_split_documents[i][term]\n",
    "            poids_term = poids(frequency_term, max_frequency_dict_split_documents[i], document_frequency_dict_split[term], n_split)\n",
    "            \n",
    "            # Store the document number, frequency, and weight\n",
    "            inverse_split[term].append((i + 1, frequency_term, poids_term))\n",
    "\n",
    "# Prepare output for the inverse split\n",
    "inverse_split_output = \"\"\n",
    "for term, docs in inverse_split.items():\n",
    "    for idx, doc_info in enumerate(docs, 1):\n",
    "        doc_num, frequency_term, poids_term = doc_info\n",
    "        inverse_split_output += f\"{idx}  {term}  {doc_num}  {frequency_term}  {poids_term}\\n\"\n",
    "\n",
    "print(inverse_split_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  inspiration  1  1  0.28169934667141894\n",
      "1  models  1  1  0.20068666377598746\n",
      "2  models  3  7  0.6020599913279624\n",
      "1  Passage  1  1  0.28169934667141894\n",
      "1  18%  1  1  0.28169934667141894\n",
      "1  taking  1  1  0.28169934667141894\n",
      "1  sets  1  1  0.28169934667141894\n",
      "1  intent  1  1  0.28169934667141894\n",
      "1  improvements  1  2  0.5633986933428379\n",
      "1  retrieval  1  1  0.20068666377598746\n",
      "2  retrieval  4  2  0.24082399653118497\n",
      "1  QR  1  2  0.5633986933428379\n",
      "1  Ranking  1  1  0.20068666377598746\n",
      "2  Ranking  2  2  0.3010299956639812\n",
      "1  used  1  1  0.15904041823988746\n",
      "2  used  2  1  0.11928031367991561\n",
      "3  used  6  1  0.09542425094393249\n",
      "1  leverages  1  1  0.20068666377598746\n",
      "2  leverages  4  1  0.12041199826559248\n",
      "1  state-of-art  1  1  0.28169934667141894\n",
      "1  incorporate  1  1  0.28169934667141894\n",
      "1  Recently  1  1  0.28169934667141894\n",
      "1  5%  1  1  0.28169934667141894\n",
      "1  MRR  1  1  0.20068666377598746\n",
      "2  MRR  6  1  0.12041199826559248\n",
      "1  paraphrases  1  1  0.28169934667141894\n",
      "1  prompting  1  2  0.4013733275519749\n",
      "2  prompting  6  1  0.12041199826559248\n",
      "1  nDCG@10  1  2  0.4013733275519749\n",
      "2  nDCG@10  4  1  0.12041199826559248\n",
      "1  documents  1  1  0.15904041823988746\n",
      "2  documents  2  2  0.23856062735983122\n",
      "3  documents  5  1  0.09542425094393249\n",
      "1  query  1  2  0.3180808364797749\n",
      "2  query  2  1  0.11928031367991561\n",
      "3  query  4  5  0.47712125471966244\n",
      "1  pseudo  1  1  0.28169934667141894\n",
      "1  technique  1  1  0.20068666377598746\n",
      "2  technique  2  1  0.1505149978319906\n",
      "1  shown  1  1  0.28169934667141894\n",
      "1  introduce  1  1  0.20068666377598746\n",
      "2  introduce  5  2  0.24082399653118497\n",
      "1  shows  1  1  0.28169934667141894\n",
      "1  strategies  1  1  0.15904041823988746\n",
      "2  strategies  4  1  0.09542425094393249\n",
      "3  strategies  5  2  0.19084850188786498\n",
      "1  Reformulation  1  1  0.20068666377598746\n",
      "2  Reformulation  4  1  0.12041199826559248\n",
      "1  GenQREnsembleRF  1  2  0.5633986933428379\n",
      "1  evaluations  1  1  0.28169934667141894\n",
      "1  context  1  1  0.28169934667141894\n",
      "1  approach  1  1  0.13264666955734586\n",
      "2  approach  2  1  0.0994850021680094\n",
      "3  approach  3  1  0.05684857266743394\n",
      "4  approach  5  1  0.07958800173440753\n",
      "1  generate  1  1  0.15904041823988746\n",
      "2  generate  4  2  0.19084850188786498\n",
      "3  generate  6  2  0.19084850188786498\n",
      "1  based  1  1  0.15904041823988746\n",
      "2  based  2  2  0.23856062735983122\n",
      "3  based  4  1  0.09542425094393249\n",
      "1  inherent  1  1  0.28169934667141894\n",
      "1  GenQREnsemble  1  2  0.5633986933428379\n",
      "1  variant  1  1  0.28169934667141894\n",
      "1  performance  1  1  0.15904041823988746\n",
      "2  performance  2  1  0.11928031367991561\n",
      "3  performance  4  3  0.28627275283179743\n",
      "1  reformulation  1  1  0.20068666377598746\n",
      "2  reformulation  4  3  0.3612359947967774\n",
      "1  post-retrieval  1  1  0.28169934667141894\n",
      "1  large  1  1  0.28169934667141894\n",
      "1  four  1  1  0.28169934667141894\n",
      "1  success  1  1  0.28169934667141894\n",
      "1  aligns  1  1  0.28169934667141894\n",
      "1  improving  1  1  0.28169934667141894\n",
      "1  benchmarks  1  1  0.20068666377598746\n",
      "2  benchmarks  2  1  0.1505149978319906\n",
      "1  24%  1  1  0.28169934667141894\n",
      "1  transform  1  1  0.28169934667141894\n",
      "1  relative  1  2  0.5633986933428379\n",
      "1  previous  1  1  0.15904041823988746\n",
      "2  previous  2  1  0.11928031367991561\n",
      "3  previous  4  1  0.09542425094393249\n",
      "1  find  1  1  0.28169934667141894\n",
      "1  multiple  1  1  0.15904041823988746\n",
      "2  multiple  4  1  0.09542425094393249\n",
      "3  multiple  6  1  0.09542425094393249\n",
      "1  Query  1  1  0.20068666377598746\n",
      "2  Query  4  2  0.24082399653118497\n",
      "1  set  1  1  0.15904041823988746\n",
      "2  set  3  1  0.06816017924566606\n",
      "3  set  5  2  0.19084850188786498\n",
      "1  experience  1  1  0.28169934667141894\n",
      "1  propose  1  1  0.1141408936074021\n",
      "2  propose  2  2  0.17121134041110314\n",
      "3  propose  3  1  0.048917525831743754\n",
      "4  propose  4  1  0.06848453616444126\n",
      "5  propose  5  1  0.06848453616444126\n",
      "1  task  1  1  0.15904041823988746\n",
      "2  task  3  2  0.13632035849133212\n",
      "3  task  5  1  0.09542425094393249\n",
      "1  ensemble  1  2  0.5633986933428379\n",
      "1  9%  1  1  0.28169934667141894\n",
      "1  user  1  2  0.2652933391146917\n",
      "2  user  3  1  0.05684857266743394\n",
      "3  user  4  1  0.07958800173440753\n",
      "4  user  5  1  0.07958800173440753\n",
      "1  MSMarco  1  1  0.28169934667141894\n",
      "1  feedback  1  3  0.6020599913279624\n",
      "2  feedback  4  1  0.12041199826559248\n",
      "1  using  1  2  0.2282817872148042\n",
      "2  using  2  4  0.3424226808222063\n",
      "3  using  4  1  0.06848453616444126\n",
      "4  using  5  1  0.06848453616444126\n",
      "5  using  6  1  0.06848453616444126\n",
      "1  pseudo-relevance  1  1  0.28169934667141894\n",
      "1  due  1  1  0.28169934667141894\n",
      "1  gains  1  1  0.28169934667141894\n",
      "1  ability  1  1  0.20068666377598746\n",
      "2  ability  5  1  0.12041199826559248\n",
      "1  original  1  1  0.28169934667141894\n",
      "1  reformulations  1  1  0.28169934667141894\n",
      "1  exploit  1  1  0.28169934667141894\n",
      "1  relevant  1  2  0.5633986933428379\n",
      "1  benefited  1  1  0.28169934667141894\n",
      "1  improve  1  1  0.13264666955734586\n",
      "2  improve  2  1  0.0994850021680094\n",
      "3  improve  3  2  0.11369714533486788\n",
      "4  improve  4  1  0.07958800173440753\n",
      "1  text  1  1  0.15904041823988746\n",
      "2  text  3  2  0.13632035849133212\n",
      "3  text  5  1  0.09542425094393249\n",
      "1  knowledge  1  1  0.28169934667141894\n",
      "1  MAP  1  1  0.28169934667141894\n",
      "1  investigate  1  1  0.28169934667141894\n",
      "1  generates  1  1  0.28169934667141894\n",
      "1  upto  1  1  0.28169934667141894\n",
      "1  promising  1  1  0.28169934667141894\n",
      "1  ultimately  1  1  0.28169934667141894\n",
      "1  many  1  1  0.28169934667141894\n",
      "1  search  1  2  0.3180808364797749\n",
      "2  search  4  1  0.09542425094393249\n",
      "3  search  5  2  0.19084850188786498\n",
      "1  improves  1  1  0.28169934667141894\n",
      "1  zero-shot  1  3  0.8450980400142568\n",
      "1  better  1  2  0.5633986933428379\n",
      "1  techniques  1  1  0.15904041823988746\n",
      "2  techniques  4  1  0.09542425094393249\n",
      "3  techniques  6  1  0.09542425094393249\n",
      "1  instruction  1  1  0.20068666377598746\n",
      "2  instruction  5  1  0.12041199826559248\n",
      "1  language  1  1  0.13264666955734586\n",
      "2  language  3  1  0.05684857266743394\n",
      "3  language  5  1  0.07958800173440753\n",
      "4  language  6  1  0.07958800173440753\n",
      "1  IR  1  1  0.20068666377598746\n",
      "2  IR  4  1  0.12041199826559248\n",
      "1  tasks  1  1  0.1141408936074021\n",
      "2  tasks  2  1  0.08560567020555157\n",
      "3  tasks  3  2  0.09783505166348751\n",
      "4  tasks  5  1  0.06848453616444126\n",
      "5  tasks  6  1  0.06848453616444126\n",
      "1  help  1  1  0.28169934667141894\n",
      "1  keywords  1  1  0.28169934667141894\n",
      "1  datasets  2  1  0.11928031367991561\n",
      "2  datasets  3  1  0.06816017924566606\n",
      "3  datasets  5  1  0.09542425094393249\n",
      "1  possible  2  1  0.2112745100035642\n",
      "1  estimated  2  1  0.2112745100035642\n",
      "1  open-sourced  2  1  0.1505149978319906\n",
      "2  open-sourced  6  1  0.12041199826559248\n",
      "1  GPT-4  2  1  0.2112745100035642\n",
      "1  complexity  2  1  0.2112745100035642\n",
      "1  analyze  2  1  0.2112745100035642\n",
      "1  template  2  1  0.1505149978319906\n",
      "2  template  3  2  0.17201714037941782\n",
      "1  Furthermore  2  1  0.1505149978319906\n",
      "2  Furthermore  4  1  0.12041199826559248\n",
      "1  rankers  2  1  0.2112745100035642\n",
      "1  called  2  1  0.2112745100035642\n",
      "1  metrics  2  1  0.1505149978319906\n",
      "2  metrics  6  1  0.12041199826559248\n",
      "1  standard  2  1  0.2112745100035642\n",
      "1  paper  2  1  0.0994850021680094\n",
      "2  paper  4  1  0.07958800173440753\n",
      "3  paper  5  1  0.07958800173440753\n",
      "4  paper  6  1  0.07958800173440753\n",
      "1  Models  2  1  0.0994850021680094\n",
      "2  Models  4  1  0.07958800173440753\n",
      "3  Models  5  1  0.07958800173440753\n",
      "4  Models  6  1  0.07958800173440753\n",
      "1  moderate-sized  2  1  0.2112745100035642\n",
      "1  performs  2  1  0.2112745100035642\n",
      "1  outperform  2  1  0.2112745100035642\n",
      "1  literature  2  2  0.4225490200071284\n",
      "1  even  2  1  0.2112745100035642\n",
      "1  problem  2  1  0.1505149978319906\n",
      "2  problem  4  1  0.12041199826559248\n",
      "1  baselines  2  1  0.2112745100035642\n",
      "1  2020  2  1  0.2112745100035642\n",
      "1  Flan-UL2  2  1  0.2112745100035642\n",
      "1  state-of-the-art  2  1  0.1505149978319906\n",
      "2  state-of-the-art  4  1  0.12041199826559248\n",
      "1  10%  2  1  0.2112745100035642\n",
      "1  solution  2  1  0.2112745100035642\n",
      "1  found  2  1  0.2112745100035642\n",
      "1  prompt  2  2  0.3010299956639812\n",
      "2  prompt  3  3  0.2580257105691267\n",
      "1  outperforming  2  1  0.2112745100035642\n",
      "1  existing  2  1  0.2112745100035642\n",
      "1  favorably  2  1  0.2112745100035642\n",
      "1  directly  2  1  0.2112745100035642\n",
      "1  several  2  1  0.2112745100035642\n",
      "1  argue  2  1  0.2112745100035642\n",
      "1  supervised  2  1  0.2112745100035642\n",
      "1  average  2  1  0.2112745100035642\n",
      "1  commercial  2  2  0.4225490200071284\n",
      "1  ChatGPT  2  1  0.2112745100035642\n",
      "1  reduce  2  1  0.1505149978319906\n",
      "2  reduce  3  1  0.08600857018970891\n",
      "1  researchers  2  1  0.1505149978319906\n",
      "2  researchers  3  1  0.08600857018970891\n",
      "1  understand  2  1  0.1505149978319906\n",
      "2  understand  3  1  0.08600857018970891\n",
      "1  4.2%  2  1  0.2112745100035642\n",
      "1  variants  2  1  0.2112745100035642\n",
      "1  results  2  2  0.1989700043360188\n",
      "2  results  3  1  0.05684857266743394\n",
      "3  results  5  1  0.07958800173440753\n",
      "4  results  6  2  0.15917600346881505\n",
      "1  burden  2  1  0.2112745100035642\n",
      "1  TREC-DL  2  1  0.2112745100035642\n",
      "1  achieve  2  2  0.3010299956639812\n",
      "2  achieve  5  1  0.12041199826559248\n",
      "1  formulations  2  1  0.2112745100035642\n",
      "1  20B  2  1  0.2112745100035642\n",
      "1  Large  2  1  0.08560567020555157\n",
      "2  Large  3  1  0.048917525831743754\n",
      "3  Large  4  1  0.06848453616444126\n",
      "4  Large  5  1  0.06848453616444126\n",
      "5  Large  6  1  0.06848453616444126\n",
      "1  efficiency  2  1  0.1505149978319906\n",
      "2  efficiency  3  4  0.34403428075883563\n",
      "1  off-the-shelf  2  1  0.2112745100035642\n",
      "1  LLM-based  2  2  0.23856062735983122\n",
      "2  LLM-based  3  2  0.13632035849133212\n",
      "3  LLM-based  6  1  0.09542425094393249\n",
      "1  significantly  2  1  0.11928031367991561\n",
      "2  significantly  3  1  0.06816017924566606\n",
      "3  significantly  4  1  0.09542425094393249\n",
      "1  However  2  1  0.2112745100035642\n",
      "1  feeding  2  1  0.2112745100035642\n",
      "1  benchmark  2  1  0.11928031367991561\n",
      "2  benchmark  4  1  0.09542425094393249\n",
      "3  benchmark  5  1  0.09542425094393249\n",
      "1  parameters  2  2  0.4225490200071284\n",
      "1  model  2  2  0.4225490200071284\n",
      "1  Pairwise  2  1  0.2112745100035642\n",
      "1  baseline  2  1  0.2112745100035642\n",
      "1  methods  2  1  0.1505149978319906\n",
      "2  methods  4  1  0.12041199826559248\n",
      "1  show  2  1  0.2112745100035642\n",
      "1  fully  2  1  0.2112745100035642\n",
      "1  12-10%  2  1  0.2112745100035642\n",
      "1  2019  2  1  0.2112745100035642\n",
      "1  175B  2  1  0.2112745100035642\n",
      "1  Prompting  2  1  0.2112745100035642\n",
      "1  listwise  2  1  0.2112745100035642\n",
      "1  interesting  2  1  0.2112745100035642\n",
      "1  blackbox  2  2  0.4225490200071284\n",
      "1  InstructGPT  2  1  0.2112745100035642\n",
      "1  solutions  2  2  0.4225490200071284\n",
      "1  NDCG@10  2  1  0.2112745100035642\n",
      "1  difficult  2  1  0.2112745100035642\n",
      "1  prompts  2  1  0.1505149978319906\n",
      "2  prompts  4  1  0.12041199826559248\n",
      "1  outperforms  2  2  0.4225490200071284\n",
      "1  best  2  1  0.2112745100035642\n",
      "1  ranking  2  4  0.8450980400142568\n",
      "1  pointwise  2  2  0.4225490200071284\n",
      "1  challenging  2  1  0.2112745100035642\n",
      "1  competitive  2  1  0.2112745100035642\n",
      "1  candidate  2  1  0.2112745100035642\n",
      "1  BEIR  2  1  0.1505149978319906\n",
      "2  BEIR  4  1  0.12041199826559248\n",
      "1  50x  2  1  0.2112745100035642\n",
      "1  PRP  2  4  0.8450980400142568\n",
      "1  linear  2  1  0.2112745100035642\n",
      "1  first  2  1  0.11928031367991561\n",
      "2  first  4  1  0.09542425094393249\n",
      "3  first  5  1  0.09542425094393249\n",
      "1  size  2  1  0.2112745100035642\n",
      "1  practical  2  1  0.2112745100035642\n",
      "1  seven  2  1  0.2112745100035642\n",
      "1  new  2  1  0.2112745100035642\n",
      "1  LLMs  2  4  0.3979400086720376\n",
      "2  LLMs  4  3  0.23876400520322255\n",
      "3  LLMs  5  5  0.3979400086720376\n",
      "4  LLMs  6  3  0.23876400520322255\n",
      "1  fine-tuned  2  1  0.2112745100035642\n",
      "1  Language  2  1  0.0994850021680094\n",
      "2  Language  4  1  0.07958800173440753\n",
      "3  Language  5  1  0.07958800173440753\n",
      "4  Language  6  1  0.07958800173440753\n",
      "1  usually  3  2  0.2414565828612162\n",
      "1  POD  3  1  0.1207282914306081\n",
      "1  design  3  1  0.1207282914306081\n",
      "1  thus  3  1  0.1207282914306081\n",
      "1  strategy  3  1  0.1207282914306081\n",
      "1  attempt  3  1  0.1207282914306081\n",
      "1  PrOmpt  3  1  0.1207282914306081\n",
      "1  community  3  1  0.1207282914306081\n",
      "1  demonstrate  3  1  0.08600857018970891\n",
      "2  demonstrate  4  1  0.12041199826559248\n",
      "1  extensive  3  1  0.1207282914306081\n",
      "1  item  3  1  0.08600857018970891\n",
      "2  item  6  1  0.12041199826559248\n",
      "1  may  3  2  0.2414565828612162\n",
      "1  e.g.  3  1  0.1207282914306081\n",
      "1  require  3  1  0.1207282914306081\n",
      "1  Experimental  3  1  0.1207282914306081\n",
      "1  specific  3  1  0.1207282914306081\n",
      "1  limited  3  2  0.17201714037941782\n",
      "2  limited  4  1  0.12041199826559248\n",
      "1  recommender  3  1  0.1207282914306081\n",
      "1  plain  3  1  0.1207282914306081\n",
      "1  distill  3  1  0.1207282914306081\n",
      "1  take  3  1  0.08600857018970891\n",
      "2  take  5  1  0.12041199826559248\n",
      "1  enough  3  1  0.1207282914306081\n",
      "1  user/item  3  1  0.1207282914306081\n",
      "1  long  3  2  0.2414565828612162\n",
      "1  manifested  3  1  0.1207282914306081\n",
      "1  effectiveness  3  1  0.08600857018970891\n",
      "2  effectiveness  4  1  0.12041199826559248\n",
      "1  finding  3  1  0.1207282914306081\n",
      "1  systems  3  1  0.08600857018970891\n",
      "2  systems  6  1  0.12041199826559248\n",
      "1  contain  3  1  0.1207282914306081\n",
      "1  multi-step  3  1  0.1207282914306081\n",
      "1  Although  3  1  0.1207282914306081\n",
      "1  various  3  1  0.08600857018970891\n",
      "2  various  4  1  0.12041199826559248\n",
      "1  problems  3  1  0.1207282914306081\n",
      "1  Long  3  1  0.1207282914306081\n",
      "1  noisy  3  1  0.1207282914306081\n",
      "1  i.e.  3  1  0.1207282914306081\n",
      "1  Distillation  3  1  0.1207282914306081\n",
      "1  input  3  1  0.08600857018970891\n",
      "2  input  4  1  0.12041199826559248\n",
      "1  power  3  1  0.08600857018970891\n",
      "2  power  5  1  0.12041199826559248\n",
      "1  improvement  3  1  0.1207282914306081\n",
      "1  sequential  3  1  0.08600857018970891\n",
      "2  sequential  5  1  0.12041199826559248\n",
      "1  fine-tuning  3  1  0.1207282914306081\n",
      "1  discrete  3  2  0.2414565828612162\n",
      "1  inspire  3  1  0.1207282914306081\n",
      "1  need  3  1  0.08600857018970891\n",
      "2  need  5  1  0.12041199826559248\n",
      "1  three  3  1  0.1207282914306081\n",
      "1  training  3  3  0.36218487429182433\n",
      "1  LLM  3  2  0.13632035849133212\n",
      "2  LLM  5  1  0.09542425094393249\n",
      "3  LLM  6  1  0.09542425094393249\n",
      "1  also  3  1  0.08600857018970891\n",
      "2  also  5  1  0.12041199826559248\n",
      "1  time  3  2  0.17201714037941782\n",
      "2  time  4  1  0.12041199826559248\n",
      "1  unparalleled  3  1  0.1207282914306081\n",
      "1  filled  3  1  0.1207282914306081\n",
      "1  given  3  1  0.08600857018970891\n",
      "2  given  5  1  0.12041199826559248\n",
      "1  response  3  1  0.1207282914306081\n",
      "1  improved  3  1  0.1207282914306081\n",
      "1  allow  3  1  0.1207282914306081\n",
      "1  IDs  3  3  0.36218487429182433\n",
      "1  top-N  3  1  0.1207282914306081\n",
      "1  information  3  1  0.08600857018970891\n",
      "2  information  5  3  0.3612359947967774\n",
      "1  words  3  2  0.2414565828612162\n",
      "1  vectors  3  1  0.1207282914306081\n",
      "1  process  3  1  0.06816017924566606\n",
      "2  process  4  1  0.09542425094393249\n",
      "3  process  5  1  0.09542425094393249\n",
      "1  could  3  2  0.2414565828612162\n",
      "1  address  3  1  0.1207282914306081\n",
      "1  real-world  3  1  0.1207282914306081\n",
      "1  continuous  3  1  0.1207282914306081\n",
      "1  recommendation  3  5  0.43004285094854455\n",
      "2  recommendation  6  1  0.12041199826559248\n",
      "1  bridge  3  2  0.2414565828612162\n",
      "1  unleash  3  1  0.1207282914306081\n",
      "1  mostly  3  1  0.1207282914306081\n",
      "1  reasoning  3  1  0.1207282914306081\n",
      "1  efficient  3  1  0.1207282914306081\n",
      "1  modeling  3  1  0.08600857018970891\n",
      "2  modeling  5  2  0.24082399653118497\n",
      "1  capability  3  1  0.1207282914306081\n",
      "1  inference  3  3  0.36218487429182433\n",
      "1  immediate  3  1  0.1207282914306081\n",
      "1  explores  4  1  0.16901960800285137\n",
      "1  retriever  4  1  0.16901960800285137\n",
      "1  initial  4  1  0.16901960800285137\n",
      "1  expansions  4  1  0.16901960800285137\n",
      "1  completion  4  1  0.16901960800285137\n",
      "1  SOTAs  4  1  0.16901960800285137\n",
      "1  Clustering  4  1  0.16901960800285137\n",
      "1  Model  4  1  0.16901960800285137\n",
      "1  represent  4  1  0.16901960800285137\n",
      "1  rate  4  1  0.16901960800285137\n",
      "1  Generative  4  1  0.16901960800285137\n",
      "1  QERM  4  1  0.16901960800285137\n",
      "1  experiments  4  1  0.16901960800285137\n",
      "1  automatically  4  1  0.16901960800285137\n",
      "1  customized  4  1  0.16901960800285137\n",
      "1  combine  4  1  0.16901960800285137\n",
      "1  distinctly  4  1  0.16901960800285137\n",
      "1  boosting  4  1  0.16901960800285137\n",
      "1  leverage  4  1  0.16901960800285137\n",
      "1  capturing  4  1  0.12041199826559248\n",
      "2  capturing  5  1  0.12041199826559248\n",
      "1  capture  4  1  0.12041199826559248\n",
      "2  capture  5  2  0.24082399653118497\n",
      "1  surpassing  4  1  0.16901960800285137\n",
      "1  novel  4  1  0.12041199826559248\n",
      "2  novel  5  1  0.12041199826559248\n",
      "1  loops  4  1  0.16901960800285137\n",
      "1  advancing  4  1  0.16901960800285137\n",
      "1  Empirical  4  1  0.16901960800285137\n",
      "1  successful  4  1  0.16901960800285137\n",
      "1  crucially  4  1  0.16901960800285137\n",
      "1  refine  4  1  0.16901960800285137\n",
      "1  well-generated  4  1  0.16901960800285137\n",
      "1  adaptively  4  1  0.16901960800285137\n",
      "1  Framework  4  1  0.16901960800285137\n",
      "1  field  4  1  0.16901960800285137\n",
      "1  single  4  1  0.16901960800285137\n",
      "1  variable  4  1  0.16901960800285137\n",
      "1  Evaluation  4  1  0.16901960800285137\n",
      "1  12%  4  1  0.16901960800285137\n",
      "1  Information  4  2  0.33803921600570275\n",
      "1  adapted  4  1  0.16901960800285137\n",
      "1  queries  4  2  0.24082399653118497\n",
      "2  queries  5  1  0.12041199826559248\n",
      "1  weighted  4  1  0.16901960800285137\n",
      "1  groups  4  1  0.16901960800285137\n",
      "1  phase  4  1  0.16901960800285137\n",
      "1  framework  4  1  0.16901960800285137\n",
      "1  constraining  4  1  0.16901960800285137\n",
      "1  enhancing  4  1  0.16901960800285137\n",
      "1  Rewarding  4  1  0.16901960800285137\n",
      "1  aggregation  4  1  0.16901960800285137\n",
      "1  intentions  4  1  0.16901960800285137\n",
      "1  achieves  4  1  0.16901960800285137\n",
      "1  GenCRF  4  3  0.5070588240085541\n",
      "1  aimed  4  1  0.16901960800285137\n",
      "1  integrates  4  1  0.16901960800285137\n",
      "1  intents  4  3  0.5070588240085541\n",
      "1  well-known  4  1  0.16901960800285137\n",
      "1  potentially  4  1  0.16901960800285137\n",
      "1  often  4  1  0.16901960800285137\n",
      "1  Recent  4  1  0.16901960800285137\n",
      "1  Retrieval  4  2  0.33803921600570275\n",
      "1  diverse  4  4  0.6760784320114055\n",
      "1  redundant  4  1  0.16901960800285137\n",
      "1  modifying  4  1  0.16901960800285137\n",
      "1  differentiated  4  1  0.16901960800285137\n",
      "1  clusters  4  1  0.16901960800285137\n",
      "1  optimize  4  1  0.16901960800285137\n",
      "1  innovative  4  1  0.16901960800285137\n",
      "1  Ranker  5  1  0.16901960800285137\n",
      "1  graph-based  5  1  0.16901960800285137\n",
      "1  complex  5  1  0.16901960800285137\n",
      "1  structures  5  1  0.16901960800285137\n",
      "1  bridges  5  1  0.16901960800285137\n",
      "1  interactive  5  1  0.16901960800285137\n",
      "1  interaction  5  1  0.16901960800285137\n",
      "1  Tiangong-ST  5  1  0.16901960800285137\n",
      "1  contrastive  5  1  0.16901960800285137\n",
      "1  inputs  5  1  0.16901960800285137\n",
      "1  actions  5  1  0.16901960800285137\n",
      "1  Concretely  5  1  0.16901960800285137\n",
      "1  modern  5  1  0.16901960800285137\n",
      "1  objective  5  1  0.16901960800285137\n",
      "1  prioritize  5  1  0.16901960800285137\n",
      "1  generative  5  1  0.16901960800285137\n",
      "1  Current  5  1  0.16901960800285137\n",
      "1  understanding  5  1  0.16901960800285137\n",
      "1  natural  5  1  0.12041199826559248\n",
      "2  natural  6  1  0.12041199826559248\n",
      "1  effective  5  1  0.16901960800285137\n",
      "1  approaches  5  2  0.33803921600570275\n",
      "1  structural  5  1  0.16901960800285137\n",
      "1  generalized  5  1  0.16901960800285137\n",
      "1  graph-to-text  5  1  0.16901960800285137\n",
      "1  focus  5  1  0.16901960800285137\n",
      "1  aims  5  1  0.16901960800285137\n",
      "1  AOL  5  1  0.16901960800285137\n",
      "1  produce  5  1  0.16901960800285137\n",
      "1  generation  5  1  0.12041199826559248\n",
      "2  generation  6  1  0.12041199826559248\n",
      "1  pre-trained  5  1  0.16901960800285137\n",
      "1  allows  5  1  0.16901960800285137\n",
      "1  recent  5  1  0.12041199826559248\n",
      "2  recent  6  1  0.12041199826559248\n",
      "1  two  5  1  0.16901960800285137\n",
      "1  link  5  1  0.16901960800285137\n",
      "1  confirm  5  1  0.16901960800285137\n",
      "1  use  5  1  0.12041199826559248\n",
      "2  use  6  1  0.12041199826559248\n",
      "1  discrepancy  5  1  0.16901960800285137\n",
      "1  leveraging  5  1  0.16901960800285137\n",
      "1  paradigm  5  1  0.16901960800285137\n",
      "1  self-supervised  5  1  0.16901960800285137\n",
      "1  corpora  5  1  0.16901960800285137\n",
      "1  representation  5  1  0.16901960800285137\n",
      "1  advantage  5  1  0.16901960800285137\n",
      "1  graph  5  3  0.5070588240085541\n",
      "1  grammar  5  2  0.33803921600570275\n",
      "1  neglecting  5  1  0.16901960800285137\n",
      "1  including  5  1  0.16901960800285137\n",
      "1  typically  5  1  0.16901960800285137\n",
      "1  convert  5  1  0.16901960800285137\n",
      "1  comprehensive  5  1  0.16901960800285137\n",
      "1  Moreover  5  1  0.16901960800285137\n",
      "1  prediction  5  1  0.16901960800285137\n",
      "1  structure  5  1  0.16901960800285137\n",
      "1  fulfill  5  1  0.16901960800285137\n",
      "1  offers  5  1  0.16901960800285137\n",
      "1  rules  5  1  0.16901960800285137\n",
      "1  analysis  5  1  0.16901960800285137\n",
      "1  SGR  5  1  0.16901960800285137\n",
      "1  integrating  5  1  0.16901960800285137\n",
      "1  coarse-grained  5  1  0.16901960800285137\n",
      "1  traditional  5  1  0.16901960800285137\n",
      "1  word-level  5  1  0.16901960800285137\n",
      "1  fine-grained  5  1  0.16901960800285137\n",
      "1  learning  5  2  0.33803921600570275\n",
      "1  interactions  5  1  0.16901960800285137\n",
      "1  symbolic  5  3  0.5070588240085541\n",
      "1  textual  5  2  0.33803921600570275\n",
      "1  content  5  1  0.16901960800285137\n",
      "1  enable  5  1  0.16901960800285137\n",
      "1  history  5  1  0.16901960800285137\n",
      "1  format  5  1  0.16901960800285137\n",
      "1  node  5  1  0.16901960800285137\n",
      "1  enhance  5  1  0.16901960800285137\n",
      "1  deep  5  1  0.16901960800285137\n",
      "1  semantic  5  2  0.33803921600570275\n",
      "1  Symbolic  5  1  0.16901960800285137\n",
      "1  Session  5  1  0.16901960800285137\n",
      "1  methodology  5  1  0.16901960800285137\n",
      "1  topological  5  1  0.16901960800285137\n",
      "1  Graph  5  1  0.16901960800285137\n",
      "1  seamlessly  5  1  0.16901960800285137\n",
      "1  involves  5  1  0.16901960800285137\n",
      "1  within  5  1  0.16901960800285137\n",
      "1  session  5  2  0.33803921600570275\n",
      "1  text-based  5  1  0.16901960800285137\n",
      "1  series  5  1  0.16901960800285137\n",
      "1  gap  5  1  0.16901960800285137\n",
      "1  Experiment  5  1  0.16901960800285137\n",
      "1  overlooking  5  1  0.16901960800285137\n",
      "1  superiority  5  1  0.16901960800285137\n",
      "1  providing  6  1  0.16901960800285137\n",
      "1  directors  6  1  0.16901960800285137\n",
      "1  consisting  6  1  0.16901960800285137\n",
      "1  source  6  1  0.16901960800285137\n",
      "1  promise  6  1  0.16901960800285137\n",
      "1  descriptions  6  5  0.8450980400142568\n",
      "1  emerged  6  1  0.16901960800285137\n",
      "1  features  6  1  0.16901960800285137\n",
      "1  summaries  6  1  0.16901960800285137\n",
      "1  considering  6  1  0.16901960800285137\n",
      "1  years  6  1  0.16901960800285137\n",
      "1  web  6  1  0.16901960800285137\n",
      "1  captivate  6  1  0.16901960800285137\n",
      "1  processing  6  1  0.16901960800285137\n",
      "1  comprising  6  1  0.16901960800285137\n",
      "1  GPT-3.5  6  1  0.16901960800285137\n",
      "1  essential  6  1  0.16901960800285137\n",
      "1  exhibits  6  1  0.16901960800285137\n",
      "1  items  6  1  0.16901960800285137\n",
      "1  publisher  6  1  0.16901960800285137\n",
      "1  ones  6  1  0.16901960800285137\n",
      "1  Goodreads  6  2  0.33803921600570275\n",
      "1  1M  6  1  0.16901960800285137\n",
      "1  viewers  6  1  0.16901960800285137\n",
      "1  data  6  1  0.16901960800285137\n",
      "1  informative  6  1  0.16901960800285137\n",
      "1  evaluation  6  1  0.16901960800285137\n",
      "1  powerful  6  1  0.16901960800285137\n",
      "1  dataset  6  4  0.6760784320114055\n",
      "1  scraping  6  1  0.16901960800285137\n",
      "1  cast  6  1  0.16901960800285137\n",
      "1  author  6  1  0.16901960800285137\n",
      "1  compared  6  1  0.16901960800285137\n",
      "1  prompted  6  1  0.16901960800285137\n",
      "1  web-scraped  6  1  0.16901960800285137\n",
      "1  obtained  6  2  0.33803921600570275\n",
      "1  manual  6  1  0.16901960800285137\n",
      "1  demonstrated  6  1  0.16901960800285137\n",
      "1  description  6  3  0.5070588240085541\n",
      "1  potential  6  1  0.16901960800285137\n",
      "1  open  6  1  0.16901960800285137\n",
      "1  Traditionally  6  1  0.16901960800285137\n",
      "1  significant  6  1  0.16901960800285137\n",
      "1  Top  6  1  0.16901960800285137\n",
      "1  books  6  1  0.16901960800285137\n",
      "1  comparable  6  1  0.16901960800285137\n",
      "1  inconsistencies  6  1  0.16901960800285137\n",
      "1  explored  6  1  0.16901960800285137\n",
      "1  NDCG  6  1  0.16901960800285137\n",
      "1  few-shot  6  1  0.16901960800285137\n",
      "1  generated  6  1  0.16901960800285137\n",
      "1  Dataset  6  1  0.16901960800285137\n",
      "1  like  6  2  0.33803921600570275\n",
      "1  combination  6  1  0.16901960800285137\n",
      "1  MovieLens  6  1  0.16901960800285137\n",
      "1  ML  6  1  0.16901960800285137\n",
      "1  plays  6  1  0.16901960800285137\n",
      "1  pivotal  6  1  0.16901960800285137\n",
      "1  susceptible  6  1  0.16901960800285137\n",
      "1  names  6  3  0.5070588240085541\n",
      "1  study  6  1  0.16901960800285137\n",
      "1  concise  6  1  0.16901960800285137\n",
      "1  Alpaca  6  2  0.33803921600570275\n",
      "1  tools  6  1  0.16901960800285137\n",
      "1  titles  6  1  0.16901960800285137\n",
      "1  conduct  6  1  0.16901960800285137\n",
      "1  subsequently  6  1  0.16901960800285137\n",
      "1  time-consuming  6  1  0.16901960800285137\n",
      "1  scraped  6  1  0.16901960800285137\n",
      "1  detailed  6  2  0.33803921600570275\n",
      "1  Hits  6  1  0.16901960800285137\n",
      "1  movie  6  3  0.5070588240085541\n",
      "1  role  6  1  0.16901960800285137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inverse_reg = {}\n",
    "\n",
    "for i in range(len(termes_reg)):\n",
    "    seen_terms = set()  # Track terms processed in the current document\n",
    "\n",
    "    for term in termes_reg[i]:\n",
    "        # Ensure each term-doc pair is processed once\n",
    "        if (term, i) not in seen_terms:\n",
    "            seen_terms.add((term, i))\n",
    "\n",
    "            if term not in inverse_reg:\n",
    "                inverse_reg[term] = []  # Initialize list for storing details\n",
    "            \n",
    "            frequency_term = frequency_dict_reg_documents[i][term]\n",
    "            poids_term = poids(frequency_term, max_frequency_dict_reg_documents[i], document_frequency_dict_reg[term], n_reg)\n",
    "            \n",
    "            inverse_reg[term].append((i + 1, frequency_term, poids_term))\n",
    "\n",
    "# Prepare output for the inverse split\n",
    "inverse_reg_output = \"\"\n",
    "for term, docs in inverse_reg.items():\n",
    "    for idx, doc_info in enumerate(docs, 1):\n",
    "        doc_num, frequency_term, poids_term = doc_info\n",
    "        inverse_reg_output += f\"{idx}  {term}  {doc_num}  {frequency_term}  {poids_term}\\n\"\n",
    "\n",
    "print(inverse_reg_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  rank  1  1  0.1505149978319906\n",
      "2  rank  2  2  0.4013733275519749\n",
      "1  relev  1  1  0.2112745100035642\n",
      "1  improv  1  4  0.3979400086720376\n",
      "2  improv  2  1  0.13264666955734586\n",
      "3  improv  3  2  0.3979400086720376\n",
      "4  improv  4  1  0.13264666955734586\n",
      "1  18%  1  1  0.2112745100035642\n",
      "1  evalu  1  1  0.11928031367991561\n",
      "2  evalu  4  1  0.15904041823988746\n",
      "3  evalu  6  1  0.15904041823988746\n",
      "1  intent  1  1  0.1505149978319906\n",
      "2  intent  4  2  0.4013733275519749\n",
      "1  msmarco  1  1  0.2112745100035642\n",
      "1  knowledg  1  1  0.2112745100035642\n",
      "1  instruct  1  1  0.1505149978319906\n",
      "2  instruct  5  1  0.20068666377598746\n",
      "1  technique,  1  1  0.2112745100035642\n",
      "1  investig  1  1  0.2112745100035642\n",
      "1  rel  1  1  0.2112745100035642\n",
      "1  recently,  1  1  0.2112745100035642\n",
      "1  promis  1  1  0.2112745100035642\n",
      "1  5%  1  1  0.2112745100035642\n",
      "1  retriev  1  1  0.1505149978319906\n",
      "2  retriev  4  3  0.6020599913279624\n",
      "1  shown  1  1  0.2112745100035642\n",
      "1  pseudo  1  1  0.2112745100035642\n",
      "1  mani  1  1  0.2112745100035642\n",
      "1  propos  1  1  0.08560567020555157\n",
      "2  propos  2  1  0.1141408936074021\n",
      "3  propos  3  1  0.17121134041110314\n",
      "4  propos  4  1  0.1141408936074021\n",
      "5  propos  5  1  0.1141408936074021\n",
      "1  take  1  1  0.11928031367991561\n",
      "2  take  3  1  0.23856062735983122\n",
      "3  take  5  1  0.15904041823988746\n",
      "1  leverag  1  1  0.11928031367991561\n",
      "2  leverag  4  2  0.3180808364797749\n",
      "3  leverag  5  1  0.15904041823988746\n",
      "1  prompt  1  1  0.0994850021680094\n",
      "2  prompt  2  3  0.3979400086720376\n",
      "3  prompt  3  2  0.3979400086720376\n",
      "4  prompt  6  2  0.2652933391146917\n",
      "1  approach  1  1  0.0994850021680094\n",
      "2  approach  2  1  0.13264666955734586\n",
      "3  approach  3  1  0.1989700043360188\n",
      "4  approach  5  1  0.13264666955734586\n",
      "1  performance.  1  1  0.2112745100035642\n",
      "1  state-of-art.  1  1  0.2112745100035642\n",
      "1  four  1  1  0.2112745100035642\n",
      "1  use  1  2  0.17121134041110314\n",
      "2  use  2  2  0.2282817872148042\n",
      "3  use  4  1  0.1141408936074021\n",
      "4  use  5  2  0.2282817872148042\n",
      "5  use  6  3  0.3424226808222063\n",
      "1  tasks,  1  1  0.11928031367991561\n",
      "2  tasks,  2  1  0.15904041823988746\n",
      "3  tasks,  3  1  0.23856062735983122\n",
      "1  success  1  1  0.1505149978319906\n",
      "2  success  4  1  0.20068666377598746\n",
      "1  larg  1  1  0.0752574989159953\n",
      "2  larg  2  1  0.10034333188799373\n",
      "3  larg  3  1  0.1505149978319906\n",
      "4  larg  4  1  0.10034333188799373\n",
      "5  larg  5  1  0.10034333188799373\n",
      "6  larg  6  1  0.10034333188799373\n",
      "1  24%  1  1  0.2112745100035642\n",
      "1  transform  1  1  0.2112745100035642\n",
      "1  reformulation(qr)  1  1  0.2112745100035642\n",
      "1  ultim  1  1  0.2112745100035642\n",
      "1  ndcg@10  1  1  0.2112745100035642\n",
      "1  pseudo-relev  1  1  0.2112745100035642\n",
      "1  documents.  1  1  0.2112745100035642\n",
      "1  benchmarks,  1  1  0.2112745100035642\n",
      "1  experience.  1  1  0.2112745100035642\n",
      "1  find  1  1  0.1505149978319906\n",
      "2  find  3  1  0.3010299956639812\n",
      "1  base  1  1  0.11928031367991561\n",
      "2  base  2  1  0.15904041823988746\n",
      "3  base  4  1  0.15904041823988746\n",
      "1  feedback,  1  1  0.2112745100035642\n",
      "1  set  1  2  0.23856062735983122\n",
      "2  set  3  1  0.23856062735983122\n",
      "3  set  5  1  0.15904041823988746\n",
      "1  qr  1  1  0.2112745100035642\n",
      "1  reformulation.  1  1  0.2112745100035642\n",
      "1  ir  1  1  0.2112745100035642\n",
      "1  show  1  1  0.1505149978319906\n",
      "2  show  2  1  0.20068666377598746\n",
      "1  9%  1  1  0.2112745100035642\n",
      "1  genqrensemblerf  1  1  0.2112745100035642\n",
      "1  benefit  1  1  0.2112745100035642\n",
      "1  ensembl  1  1  0.2112745100035642\n",
      "1  feedback  1  1  0.1505149978319906\n",
      "2  feedback  4  1  0.20068666377598746\n",
      "1  introduc  1  1  0.1505149978319906\n",
      "2  introduc  5  1  0.20068666377598746\n",
      "1  user’  1  1  0.2112745100035642\n",
      "1  due  1  1  0.2112745100035642\n",
      "1  context,  1  1  0.2112745100035642\n",
      "1  paraphras  1  1  0.2112745100035642\n",
      "1  exploit  1  1  0.2112745100035642\n",
      "1  inher  1  1  0.2112745100035642\n",
      "1  mrr  1  1  0.2112745100035642\n",
      "1  origin  1  1  0.2112745100035642\n",
      "1  text  1  1  0.1505149978319906\n",
      "2  text  3  1  0.3010299956639812\n",
      "1  post-retriev  1  1  0.2112745100035642\n",
      "1  languag  1  1  0.0752574989159953\n",
      "2  languag  2  1  0.10034333188799373\n",
      "3  languag  3  1  0.1505149978319906\n",
      "4  languag  4  1  0.10034333188799373\n",
      "5  languag  5  2  0.20068666377598746\n",
      "6  languag  6  2  0.20068666377598746\n",
      "1  strategi  1  1  0.0994850021680094\n",
      "2  strategi  3  1  0.1989700043360188\n",
      "3  strategi  4  1  0.13264666955734586\n",
      "4  strategi  5  1  0.13264666955734586\n",
      "1  previou  1  1  0.11928031367991561\n",
      "2  previou  2  1  0.15904041823988746\n",
      "3  previou  4  1  0.15904041823988746\n",
      "1  feedback.  1  1  0.2112745100035642\n",
      "1  upto  1  1  0.2112745100035642\n",
      "1  align  1  1  0.2112745100035642\n",
      "1  keyword  1  1  0.2112745100035642\n",
      "1  task,  1  1  0.1505149978319906\n",
      "2  task,  3  1  0.3010299956639812\n",
      "1  abil  1  1  0.1505149978319906\n",
      "2  abil  5  1  0.20068666377598746\n",
      "1  genqrensembl  1  1  0.2112745100035642\n",
      "1  search  1  1  0.11928031367991561\n",
      "2  search  4  1  0.15904041823988746\n",
      "3  search  5  1  0.15904041823988746\n",
      "1  variant,  1  1  0.2112745100035642\n",
      "1  multipl  1  1  0.11928031367991561\n",
      "2  multipl  4  1  0.15904041823988746\n",
      "3  multipl  6  1  0.15904041823988746\n",
      "1  techniqu  1  1  0.11928031367991561\n",
      "2  techniqu  2  1  0.15904041823988746\n",
      "3  techniqu  4  1  0.15904041823988746\n",
      "1  incorpor  1  1  0.2112745100035642\n",
      "1  queri  1  2  0.1989700043360188\n",
      "2  queri  2  1  0.13264666955734586\n",
      "3  queri  4  3  0.3979400086720376\n",
      "4  queri  5  1  0.13264666955734586\n",
      "1  gener  1  2  0.1989700043360188\n",
      "2  gener  4  2  0.2652933391146917\n",
      "3  gener  5  2  0.2652933391146917\n",
      "4  gener  6  3  0.3979400086720376\n",
      "1  zero-shot  1  1  0.2112745100035642\n",
      "1  models.  1  1  0.1505149978319906\n",
      "2  models.  3  1  0.3010299956639812\n",
      "1  reformul  1  1  0.1505149978319906\n",
      "2  reformul  4  2  0.4013733275519749\n",
      "1  better  1  1  0.2112745100035642\n",
      "1  gain  1  1  0.2112745100035642\n",
      "1  passag  1  1  0.2112745100035642\n",
      "1  map  1  1  0.2112745100035642\n",
      "1  inspir  1  1  0.1505149978319906\n",
      "2  inspir  3  1  0.3010299956639812\n",
      "1  help  1  1  0.2112745100035642\n",
      "1  complex  2  1  0.20068666377598746\n",
      "2  complex  5  1  0.20068666377598746\n",
      "1  (prp).  2  1  0.28169934667141894\n",
      "1  analyz  2  1  0.28169934667141894\n",
      "1  moderate-s  2  1  0.28169934667141894\n",
      "1  gpt-4  2  1  0.28169934667141894\n",
      "1  averag  2  1  0.28169934667141894\n",
      "1  baselin  2  2  0.5633986933428379\n",
      "1  standard  2  1  0.28169934667141894\n",
      "1  open-sourc  2  1  0.20068666377598746\n",
      "2  open-sourc  6  1  0.20068666377598746\n",
      "1  flan-ul2  2  1  0.28169934667141894\n",
      "1  challeng  2  1  0.28169934667141894\n",
      "1  pairwis  2  1  0.28169934667141894\n",
      "1  furthermore,  2  1  0.20068666377598746\n",
      "2  furthermore,  4  1  0.20068666377598746\n",
      "1  formulations.  2  1  0.28169934667141894\n",
      "1  outperform  2  3  0.8450980400142568\n",
      "1  listwis  2  1  0.28169934667141894\n",
      "1  even  2  1  0.28169934667141894\n",
      "1  fine-tun  2  1  0.20068666377598746\n",
      "2  fine-tun  3  1  0.3010299956639812\n",
      "1  pointwis  2  1  0.28169934667141894\n",
      "1  10%  2  1  0.28169934667141894\n",
      "1  state-of-the-art  2  1  0.20068666377598746\n",
      "2  state-of-the-art  4  1  0.20068666377598746\n",
      "1  directli  2  1  0.28169934667141894\n",
      "1  20b  2  1  0.28169934667141894\n",
      "1  found  2  1  0.28169934667141894\n",
      "1  interest  2  1  0.28169934667141894\n",
      "1  chatgpt  2  1  0.28169934667141894\n",
      "1  feed  2  1  0.28169934667141894\n",
      "1  problem.  2  1  0.28169934667141894\n",
      "1  method  2  1  0.20068666377598746\n",
      "2  method  4  1  0.20068666377598746\n",
      "1  ndcg@10.  2  1  0.20068666377598746\n",
      "2  ndcg@10.  4  1  0.20068666377598746\n",
      "1  trec-dl  2  1  0.28169934667141894\n",
      "1  175b  2  1  0.28169934667141894\n",
      "1  (llms)  2  1  0.20068666377598746\n",
      "2  (llms)  4  1  0.20068666377598746\n",
      "1  llm-base  2  1  0.15904041823988746\n",
      "2  llm-base  3  1  0.23856062735983122\n",
      "3  llm-base  6  1  0.15904041823988746\n",
      "1  reduc  2  1  0.20068666377598746\n",
      "2  reduc  3  1  0.3010299956639812\n",
      "1  variant  2  1  0.28169934667141894\n",
      "1  understand  2  1  0.20068666377598746\n",
      "2  understand  3  1  0.3010299956639812\n",
      "1  4.2%  2  1  0.28169934667141894\n",
      "1  literatur  2  1  0.28169934667141894\n",
      "1  burden  2  1  0.28169934667141894\n",
      "1  exist  2  1  0.28169934667141894\n",
      "1  perform  2  2  0.4013733275519749\n",
      "2  perform  4  1  0.20068666377598746\n",
      "1  research  2  1  0.20068666377598746\n",
      "2  research  3  1  0.3010299956639812\n",
      "1  llm  2  1  0.1141408936074021\n",
      "2  llm  3  1  0.17121134041110314\n",
      "3  llm  4  1  0.1141408936074021\n",
      "4  llm  5  1  0.1141408936074021\n",
      "5  llm  6  1  0.1141408936074021\n",
      "1  sever  2  1  0.28169934667141894\n",
      "1  significantli  2  1  0.15904041823988746\n",
      "2  significantli  3  1  0.23856062735983122\n",
      "3  significantli  4  1  0.15904041823988746\n",
      "1  off-the-shelf  2  1  0.28169934667141894\n",
      "1  practic  2  1  0.28169934667141894\n",
      "1  favor  2  1  0.28169934667141894\n",
      "1  document  2  1  0.28169934667141894\n",
      "1  fulli  2  1  0.28169934667141894\n",
      "1  ranker  2  1  0.20068666377598746\n",
      "2  ranker  5  1  0.20068666377598746\n",
      "1  benchmark  2  2  0.3180808364797749\n",
      "2  benchmark  4  1  0.15904041823988746\n",
      "3  benchmark  5  1  0.15904041823988746\n",
      "1  paper,  2  1  0.13264666955734586\n",
      "2  paper,  4  1  0.13264666955734586\n",
      "3  paper,  5  1  0.13264666955734586\n",
      "4  paper,  6  1  0.13264666955734586\n",
      "1  model  2  2  0.2282817872148042\n",
      "2  model  3  2  0.3424226808222063\n",
      "3  model  4  2  0.2282817872148042\n",
      "4  model  5  2  0.2282817872148042\n",
      "5  model  6  1  0.1141408936074021\n",
      "1  paramet  2  1  0.28169934667141894\n",
      "1  literature,  2  1  0.28169934667141894\n",
      "1  12-10%  2  1  0.28169934667141894\n",
      "1  2019  2  1  0.28169934667141894\n",
      "1  2020,  2  1  0.28169934667141894\n",
      "1  metrics.  2  1  0.20068666377598746\n",
      "2  metrics.  6  1  0.20068666377598746\n",
      "1  beir  2  1  0.20068666377598746\n",
      "2  beir  4  1  0.20068666377598746\n",
      "1  parameters,  2  1  0.28169934667141894\n",
      "1  (estimated)  2  1  0.28169934667141894\n",
      "1  templat  2  1  0.20068666377598746\n",
      "2  templat  3  1  0.3010299956639812\n",
      "1  achiev  2  1  0.15904041823988746\n",
      "2  achiev  4  1  0.15904041823988746\n",
      "3  achiev  5  1  0.15904041823988746\n",
      "1  size,  2  1  0.28169934667141894\n",
      "1  datasets.  2  1  0.28169934667141894\n",
      "1  blackbox  2  1  0.28169934667141894\n",
      "1  difficult  2  1  0.28169934667141894\n",
      "1  prp  2  1  0.28169934667141894\n",
      "1  argu  2  1  0.28169934667141894\n",
      "1  best  2  1  0.28169934667141894\n",
      "1  llms.  2  1  0.20068666377598746\n",
      "2  llms.  5  1  0.20068666377598746\n",
      "1  competit  2  1  0.28169934667141894\n",
      "1  solutions,  2  1  0.28169934667141894\n",
      "1  however,  2  1  0.28169934667141894\n",
      "1  instructgpt  2  1  0.28169934667141894\n",
      "1  supervis  2  1  0.28169934667141894\n",
      "1  50x  2  1  0.28169934667141894\n",
      "1  linear  2  1  0.28169934667141894\n",
      "1  first  2  1  0.15904041823988746\n",
      "2  first  4  1  0.15904041823988746\n",
      "3  first  5  1  0.15904041823988746\n",
      "1  candid  2  1  0.28169934667141894\n",
      "1  effici  2  1  0.20068666377598746\n",
      "2  effici  3  2  0.6020599913279624\n",
      "1  seven  2  1  0.28169934667141894\n",
      "1  new  2  1  0.28169934667141894\n",
      "1  result  2  1  0.13264666955734586\n",
      "2  result  3  1  0.1989700043360188\n",
      "3  result  5  1  0.13264666955734586\n",
      "4  result  6  1  0.13264666955734586\n",
      "1  commerci  2  1  0.28169934667141894\n",
      "1  call  2  1  0.28169934667141894\n",
      "1  possibl  2  1  0.28169934667141894\n",
      "1  solut  2  2  0.5633986933428379\n",
      "1  train  3  1  0.4225490200071284\n",
      "1  distil  3  2  0.8450980400142568\n",
      "1  process,  3  1  0.3010299956639812\n",
      "2  process,  5  1  0.20068666377598746\n",
      "1  design  3  1  0.4225490200071284\n",
      "1  attempt  3  1  0.4225490200071284\n",
      "1  experiment  3  1  0.4225490200071284\n",
      "1  item  3  1  0.3010299956639812\n",
      "2  item  6  1  0.20068666377598746\n",
      "1  may  3  1  0.4225490200071284\n",
      "1  although  3  1  0.4225490200071284\n",
      "1  extens  3  1  0.4225490200071284\n",
      "1  mostli  3  1  0.4225490200071284\n",
      "1  tasks.  3  1  0.3010299956639812\n",
      "2  tasks.  6  1  0.20068666377598746\n",
      "1  demonstr  3  1  0.23856062735983122\n",
      "2  demonstr  4  1  0.15904041823988746\n",
      "3  demonstr  6  1  0.15904041823988746\n",
      "1  (i.e.,  3  1  0.4225490200071284\n",
      "1  limit  3  1  0.3010299956639812\n",
      "2  limit  4  1  0.20068666377598746\n",
      "1  word  3  1  0.4225490200071284\n",
      "1  plain  3  1  0.4225490200071284\n",
      "1  bridg  3  1  0.3010299956639812\n",
      "2  bridg  5  1  0.20068666377598746\n",
      "1  id  3  1  0.4225490200071284\n",
      "1  capabl  3  1  0.4225490200071284\n",
      "1  manifest  3  1  0.4225490200071284\n",
      "1  enough  3  1  0.4225490200071284\n",
      "1  variou  3  1  0.3010299956639812\n",
      "2  variou  4  1  0.20068666377598746\n",
      "1  limited.  3  1  0.4225490200071284\n",
      "1  user/item  3  1  0.4225490200071284\n",
      "1  long  3  2  0.8450980400142568\n",
      "1  contain  3  1  0.4225490200071284\n",
      "1  multi-step  3  1  0.4225490200071284\n",
      "1  time.  3  1  0.3010299956639812\n",
      "2  time.  4  1  0.20068666377598746\n",
      "1  requir  3  1  0.4225490200071284\n",
      "1  usual  3  1  0.4225490200071284\n",
      "1  dataset  3  1  0.3010299956639812\n",
      "2  dataset  6  2  0.4013733275519749\n",
      "1  (pod)  3  1  0.4225490200071284\n",
      "1  discret  3  1  0.4225490200071284\n",
      "1  unparallel  3  1  0.4225490200071284\n",
      "1  input  3  1  0.23856062735983122\n",
      "2  input  4  1  0.15904041823988746\n",
      "3  input  5  1  0.15904041823988746\n",
      "1  power  3  1  0.23856062735983122\n",
      "2  power  5  1  0.15904041823988746\n",
      "3  power  6  1  0.15904041823988746\n",
      "1  vector  3  1  0.4225490200071284\n",
      "1  specif  3  1  0.4225490200071284\n",
      "1  fill  3  1  0.4225490200071284\n",
      "1  infer  3  1  0.4225490200071284\n",
      "1  thu  3  1  0.4225490200071284\n",
      "1  models,  3  1  0.4225490200071284\n",
      "1  (llm)  3  1  0.4225490200071284\n",
      "1  need  3  1  0.4225490200071284\n",
      "1  three  3  1  0.4225490200071284\n",
      "1  also  3  1  0.3010299956639812\n",
      "2  also  5  1  0.20068666377598746\n",
      "1  time  3  1  0.4225490200071284\n",
      "1  continu  3  1  0.4225490200071284\n",
      "1  information.  3  1  0.4225490200071284\n",
      "1  given  3  1  0.3010299956639812\n",
      "2  given  5  1  0.20068666377598746\n",
      "1  response.  3  1  0.4225490200071284\n",
      "1  task  3  1  0.3010299956639812\n",
      "2  task  5  2  0.4013733275519749\n",
      "1  user  3  1  0.4225490200071284\n",
      "1  effect  3  1  0.23856062735983122\n",
      "2  effect  4  1  0.15904041823988746\n",
      "3  effect  5  1  0.15904041823988746\n",
      "1  allow  3  1  0.3010299956639812\n",
      "2  allow  5  1  0.20068666377598746\n",
      "1  prompt)  3  1  0.4225490200071284\n",
      "1  recommendation.  3  1  0.4225490200071284\n",
      "1  problems,  3  1  0.4225490200071284\n",
      "1  could  3  1  0.4225490200071284\n",
      "1  address  3  1  0.4225490200071284\n",
      "1  real-world  3  1  0.4225490200071284\n",
      "1  commun  3  1  0.4225490200071284\n",
      "1  unleash  3  1  0.4225490200071284\n",
      "1  e.g.,  3  1  0.4225490200071284\n",
      "1  top-n  3  1  0.4225490200071284\n",
      "1  reasoning,  3  1  0.4225490200071284\n",
      "1  sequenti  3  1  0.3010299956639812\n",
      "2  sequenti  5  1  0.20068666377598746\n",
      "1  recommend  3  2  0.6020599913279624\n",
      "2  recommend  6  1  0.20068666377598746\n",
      "1  noisi  3  1  0.4225490200071284\n",
      "1  improved,  3  1  0.4225490200071284\n",
      "1  immedi  3  1  0.4225490200071284\n",
      "1  system  3  1  0.4225490200071284\n",
      "1  text,  3  1  0.4225490200071284\n",
      "1  innov  4  1  0.28169934667141894\n",
      "1  gencrf:  4  1  0.28169934667141894\n",
      "1  adapt  4  2  0.5633986933428379\n",
      "1  modifi  4  1  0.28169934667141894\n",
      "1  aggreg  4  1  0.28169934667141894\n",
      "1  empir  4  1  0.28169934667141894\n",
      "1  inform  4  1  0.15904041823988746\n",
      "2  inform  5  1  0.15904041823988746\n",
      "3  inform  6  1  0.15904041823988746\n",
      "1  boost  4  1  0.28169934667141894\n",
      "1  experi  4  1  0.20068666377598746\n",
      "2  experi  5  1  0.20068666377598746\n",
      "1  combin  4  1  0.20068666377598746\n",
      "2  combin  6  1  0.20068666377598746\n",
      "1  aim  4  1  0.20068666377598746\n",
      "2  aim  5  1  0.20068666377598746\n",
      "1  rate  4  1  0.28169934667141894\n",
      "1  (qerm)  4  1  0.28169934667141894\n",
      "1  problem  4  1  0.28169934667141894\n",
      "1  enhanc  4  1  0.20068666377598746\n",
      "2  enhanc  5  1  0.20068666377598746\n",
      "1  group  4  1  0.28169934667141894\n",
      "1  cluster  4  2  0.5633986933428379\n",
      "1  advanc  4  1  0.28169934667141894\n",
      "1  reward  4  1  0.28169934667141894\n",
      "1  variabl  4  1  0.28169934667141894\n",
      "1  expansions,  4  1  0.28169934667141894\n",
      "1  recent  4  1  0.15904041823988746\n",
      "2  recent  5  1  0.15904041823988746\n",
      "3  recent  6  1  0.15904041823988746\n",
      "1  novel  4  1  0.20068666377598746\n",
      "2  novel  5  1  0.20068666377598746\n",
      "1  crucial  4  1  0.28169934667141894\n",
      "1  query.  4  1  0.28169934667141894\n",
      "1  retrieval.  4  1  0.28169934667141894\n",
      "1  redund  4  1  0.28169934667141894\n",
      "1  complet  4  1  0.28169934667141894\n",
      "1  performance,  4  1  0.28169934667141894\n",
      "1  field  4  1  0.28169934667141894\n",
      "1  intents.  4  1  0.28169934667141894\n",
      "1  custom  4  1  0.28169934667141894\n",
      "1  12%  4  1  0.28169934667141894\n",
      "1  optim  4  1  0.28169934667141894\n",
      "1  repres  4  1  0.28169934667141894\n",
      "1  differentiated,  4  1  0.28169934667141894\n",
      "1  phase  4  1  0.28169934667141894\n",
      "1  framework  4  2  0.5633986933428379\n",
      "1  distinctli  4  1  0.28169934667141894\n",
      "1  refin  4  1  0.28169934667141894\n",
      "1  initi  4  1  0.28169934667141894\n",
      "1  singl  4  1  0.28169934667141894\n",
      "1  reformulation,  4  1  0.28169934667141894\n",
      "1  explor  4  1  0.20068666377598746\n",
      "2  explor  6  1  0.20068666377598746\n",
      "1  process  4  1  0.20068666377598746\n",
      "2  process  6  1  0.20068666377598746\n",
      "1  user'  4  1  0.20068666377598746\n",
      "2  user'  5  1  0.20068666377598746\n",
      "1  weight  4  1  0.28169934667141894\n",
      "1  constrain  4  1  0.28169934667141894\n",
      "1  loops.  4  1  0.28169934667141894\n",
      "1  well-known  4  1  0.28169934667141894\n",
      "1  potenti  4  1  0.20068666377598746\n",
      "2  potenti  6  1  0.20068666377598746\n",
      "1  often  4  1  0.28169934667141894\n",
      "1  well-gener  4  1  0.28169934667141894\n",
      "1  sota  4  1  0.28169934667141894\n",
      "1  gencrf  4  1  0.28169934667141894\n",
      "1  captur  4  2  0.4013733275519749\n",
      "2  captur  5  2  0.4013733275519749\n",
      "1  (ir)  4  1  0.28169934667141894\n",
      "1  llms,  4  1  0.28169934667141894\n",
      "1  surpass  4  1  0.28169934667141894\n",
      "1  prompts,  4  1  0.28169934667141894\n",
      "1  divers  4  1  0.28169934667141894\n",
      "1  automat  4  1  0.28169934667141894\n",
      "1  integr  4  1  0.20068666377598746\n",
      "2  integr  5  1  0.20068666377598746\n",
      "1  symbol  5  2  0.5633986933428379\n",
      "1  corpora,  5  1  0.28169934667141894\n",
      "1  history,  5  1  0.28169934667141894\n",
      "1  pre-train  5  1  0.28169934667141894\n",
      "1  neglect  5  1  0.28169934667141894\n",
      "1  contrast  5  1  0.28169934667141894\n",
      "1  learn  5  1  0.28169934667141894\n",
      "1  format.  5  1  0.28169934667141894\n",
      "1  action  5  1  0.28169934667141894\n",
      "1  represent  5  1  0.28169934667141894\n",
      "1  includ  5  1  0.28169934667141894\n",
      "1  text-bas  5  1  0.28169934667141894\n",
      "1  (sgr),  5  1  0.28169934667141894\n",
      "1  modern  5  1  0.28169934667141894\n",
      "1  documents,  5  1  0.28169934667141894\n",
      "1  interact  5  2  0.5633986933428379\n",
      "1  analysi  5  1  0.28169934667141894\n",
      "1  typic  5  1  0.28169934667141894\n",
      "1  (llms).  5  1  0.28169934667141894\n",
      "1  information,  5  1  0.28169934667141894\n",
      "1  this,  5  1  0.28169934667141894\n",
      "1  overlook  5  1  0.28169934667141894\n",
      "1  graph-bas  5  1  0.28169934667141894\n",
      "1  graph-to-text  5  1  0.28169934667141894\n",
      "1  grammar,  5  1  0.28169934667141894\n",
      "1  datasets,  5  1  0.28169934667141894\n",
      "1  superior  5  1  0.28169934667141894\n",
      "1  need.  5  1  0.28169934667141894\n",
      "1  natur  5  1  0.20068666377598746\n",
      "2  natur  6  1  0.20068666377598746\n",
      "1  discrep  5  1  0.28169934667141894\n",
      "1  concretely,  5  1  0.28169934667141894\n",
      "1  two  5  1  0.28169934667141894\n",
      "1  link  5  1  0.28169934667141894\n",
      "1  confirm  5  1  0.28169934667141894\n",
      "1  modeling.  5  1  0.28169934667141894\n",
      "1  learning,  5  1  0.28169934667141894\n",
      "1  fulfil  5  1  0.28169934667141894\n",
      "1  tiangong-st,  5  1  0.28169934667141894\n",
      "1  paradigm  5  1  0.28169934667141894\n",
      "1  topolog  5  1  0.28169934667141894\n",
      "1  tradit  5  1  0.28169934667141894\n",
      "1  advantag  5  1  0.28169934667141894\n",
      "1  prediction,  5  1  0.28169934667141894\n",
      "1  semant  5  1  0.28169934667141894\n",
      "1  methodolog  5  1  0.28169934667141894\n",
      "1  offer  5  1  0.28169934667141894\n",
      "1  produc  5  1  0.28169934667141894\n",
      "1  llms'  5  1  0.28169934667141894\n",
      "1  graph  5  2  0.5633986933428379\n",
      "1  grammar  5  1  0.28169934667141894\n",
      "1  self-supervis  5  1  0.28169934667141894\n",
      "1  convert  5  1  0.28169934667141894\n",
      "1  seamlessli  5  1  0.28169934667141894\n",
      "1  interactions.  5  1  0.28169934667141894\n",
      "1  object  5  1  0.28169934667141894\n",
      "1  understanding,  5  1  0.28169934667141894\n",
      "1  moreover,  5  1  0.28169934667141894\n",
      "1  word-level  5  1  0.28169934667141894\n",
      "1  structur  5  3  0.8450980400142568\n",
      "1  generation,  5  1  0.28169934667141894\n",
      "1  involv  5  1  0.28169934667141894\n",
      "1  textual  5  1  0.28169934667141894\n",
      "1  content  5  1  0.28169934667141894\n",
      "1  llm.  5  1  0.28169934667141894\n",
      "1  fine-grained.  5  1  0.28169934667141894\n",
      "1  priorit  5  1  0.28169934667141894\n",
      "1  node  5  1  0.28169934667141894\n",
      "1  rule  5  1  0.28169934667141894\n",
      "1  deep  5  1  0.28169934667141894\n",
      "1  enabl  5  1  0.28169934667141894\n",
      "1  focu  5  1  0.28169934667141894\n",
      "1  text.  5  1  0.28169934667141894\n",
      "1  coarse-grain  5  1  0.28169934667141894\n",
      "1  seri  5  1  0.28169934667141894\n",
      "1  within  5  1  0.28169934667141894\n",
      "1  aol  5  1  0.28169934667141894\n",
      "1  approach.  5  1  0.28169934667141894\n",
      "1  session  5  2  0.5633986933428379\n",
      "1  comprehens  5  1  0.28169934667141894\n",
      "1  current  5  1  0.28169934667141894\n",
      "1  gap  5  1  0.28169934667141894\n",
      "1  play  6  1  0.28169934667141894\n",
      "1  systems.  6  1  0.28169934667141894\n",
      "1  viewer  6  1  0.28169934667141894\n",
      "1  compar  6  2  0.5633986933428379\n",
      "1  alpaca  6  1  0.28169934667141894\n",
      "1  consid  6  1  0.28169934667141894\n",
      "1  obtain  6  1  0.28169934667141894\n",
      "1  publish  6  1  0.28169934667141894\n",
      "1  web  6  1  0.28169934667141894\n",
      "1  alpaca,  6  1  0.28169934667141894\n",
      "1  director  6  1  0.28169934667141894\n",
      "1  hits,  6  1  0.28169934667141894\n",
      "1  one  6  1  0.28169934667141894\n",
      "1  ndcg  6  1  0.28169934667141894\n",
      "1  featur  6  1  0.28169934667141894\n",
      "1  promise,  6  1  0.28169934667141894\n",
      "1  gpt-3.5,  6  1  0.28169934667141894\n",
      "1  top  6  1  0.28169934667141894\n",
      "1  consist  6  1  0.28169934667141894\n",
      "1  movielen  6  1  0.28169934667141894\n",
      "1  data  6  1  0.28169934667141894\n",
      "1  inconsistencies.  6  1  0.28169934667141894\n",
      "1  emerg  6  1  0.28169934667141894\n",
      "1  signific  6  1  0.28169934667141894\n",
      "1  1m  6  1  0.28169934667141894\n",
      "1  titl  6  1  0.28169934667141894\n",
      "1  descriptions.  6  1  0.28169934667141894\n",
      "1  subsequently,  6  1  0.28169934667141894\n",
      "1  book  6  1  0.28169934667141894\n",
      "1  compris  6  1  0.28169934667141894\n",
      "1  cast  6  1  0.28169934667141894\n",
      "1  summari  6  1  0.28169934667141894\n",
      "1  author  6  1  0.28169934667141894\n",
      "1  web-scrap  6  1  0.28169934667141894\n",
      "1  traditionally,  6  1  0.28169934667141894\n",
      "1  manual  6  1  0.28169934667141894\n",
      "1  descript  6  2  0.5633986933428379\n",
      "1  open  6  1  0.28169934667141894\n",
      "1  pivot  6  1  0.28169934667141894\n",
      "1  ml  6  1  0.28169934667141894\n",
      "1  name  6  1  0.28169934667141894\n",
      "1  study,  6  1  0.28169934667141894\n",
      "1  llm,  6  1  0.28169934667141894\n",
      "1  provid  6  1  0.28169934667141894\n",
      "1  time-consum  6  1  0.28169934667141894\n",
      "1  goodread  6  1  0.28169934667141894\n",
      "1  items.  6  1  0.28169934667141894\n",
      "1  suscept  6  1  0.28169934667141894\n",
      "1  movi  6  1  0.28169934667141894\n",
      "1  few-shot  6  1  0.28169934667141894\n",
      "1  concis  6  1  0.28169934667141894\n",
      "1  techniques,  6  1  0.28169934667141894\n",
      "1  exhibit  6  1  0.28169934667141894\n",
      "1  like  6  1  0.28169934667141894\n",
      "1  tool  6  1  0.28169934667141894\n",
      "1  essenti  6  1  0.28169934667141894\n",
      "1  sourc  6  1  0.28169934667141894\n",
      "1  captiv  6  1  0.28169934667141894\n",
      "1  (llms),  6  1  0.28169934667141894\n",
      "1  detail  6  1  0.28169934667141894\n",
      "1  mrr,  6  1  0.28169934667141894\n",
      "1  dataset.  6  1  0.28169934667141894\n",
      "1  years,  6  1  0.28169934667141894\n",
      "1  conduct  6  1  0.28169934667141894\n",
      "1  scrape  6  2  0.5633986933428379\n",
      "1  role  6  1  0.28169934667141894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inverse_split_porter = {}\n",
    "\n",
    "for i in range(len(termes_split_porter)):\n",
    "    seen_terms = set()  # Track terms processed in the current document\n",
    "\n",
    "    for j in range(len(termes_split_porter[i])):\n",
    "        term = termes_split_porter[i][j]\n",
    "\n",
    "        if (term, i) not in seen_terms:\n",
    "            seen_terms.add((term, i))\n",
    "\n",
    "            if term not in inverse_split_porter:\n",
    "                inverse_split_porter[term] = []\n",
    "            \n",
    "            frequency_term = frequency_dict_split_porter_documents[i][termes_split_porter[i][j]]\n",
    "            poids_term = poids(frequency_term, max_frequency_dict_split_porter_documents[i], document_frequency_dict_split_porter[termes_split_porter[i][j]], n_split)\n",
    "            \n",
    "            inverse_split_porter[term].append((i + 1, frequency_term, poids_term))\n",
    "\n",
    "inverse_split_porter_output = \"\"\n",
    "for term, docs in inverse_split_porter.items():\n",
    "    for idx, doc_info in enumerate(docs, 1):\n",
    "        doc_num, frequency_term, poids_term = doc_info\n",
    "        inverse_split_porter_output += f\"{idx}  {term}  {doc_num}  {frequency_term}  {poids_term}\\n\"\n",
    "\n",
    "print(inverse_split_porter_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  rank  1  1  0.1505149978319906\n",
      "2  rank  2  2  0.4013733275519749\n",
      "1  relev  1  1  0.2112745100035642\n",
      "1  improv  1  4  0.3979400086720376\n",
      "2  improv  2  1  0.13264666955734586\n",
      "3  improv  3  3  0.3979400086720376\n",
      "4  improv  4  1  0.13264666955734586\n",
      "1  18%  1  1  0.2112745100035642\n",
      "1  evalu  1  1  0.11928031367991561\n",
      "2  evalu  4  1  0.15904041823988746\n",
      "3  evalu  6  1  0.15904041823988746\n",
      "1  intent  1  1  0.1505149978319906\n",
      "2  intent  4  2  0.4013733275519749\n",
      "1  state-of-art  1  1  0.2112745100035642\n",
      "1  msmarco  1  1  0.2112745100035642\n",
      "1  knowledg  1  1  0.2112745100035642\n",
      "1  instruct  1  1  0.1505149978319906\n",
      "2  instruct  5  1  0.20068666377598746\n",
      "1  investig  1  1  0.2112745100035642\n",
      "1  rel  1  1  0.2112745100035642\n",
      "1  experi  1  1  0.11928031367991561\n",
      "2  experi  4  1  0.15904041823988746\n",
      "3  experi  5  1  0.15904041823988746\n",
      "1  promis  1  1  0.1505149978319906\n",
      "2  promis  6  1  0.20068666377598746\n",
      "1  5%  1  1  0.2112745100035642\n",
      "1  retriev  1  1  0.1505149978319906\n",
      "2  retriev  4  3  0.6020599913279624\n",
      "1  mani  1  1  0.2112745100035642\n",
      "1  shown  1  1  0.2112745100035642\n",
      "1  pseudo  1  1  0.2112745100035642\n",
      "1  propos  1  1  0.08560567020555157\n",
      "2  propos  2  1  0.1141408936074021\n",
      "3  propos  3  1  0.1141408936074021\n",
      "4  propos  4  1  0.1141408936074021\n",
      "5  propos  5  1  0.1141408936074021\n",
      "1  take  1  1  0.11928031367991561\n",
      "2  take  3  1  0.15904041823988746\n",
      "3  take  5  1  0.15904041823988746\n",
      "1  leverag  1  1  0.11928031367991561\n",
      "2  leverag  4  2  0.3180808364797749\n",
      "3  leverag  5  1  0.15904041823988746\n",
      "1  prompt  1  1  0.08560567020555157\n",
      "2  prompt  2  3  0.3424226808222063\n",
      "3  prompt  3  2  0.2282817872148042\n",
      "4  prompt  4  1  0.1141408936074021\n",
      "5  prompt  6  2  0.2282817872148042\n",
      "1  context  1  1  0.2112745100035642\n",
      "1  approach  1  1  0.0994850021680094\n",
      "2  approach  2  1  0.13264666955734586\n",
      "3  approach  3  1  0.13264666955734586\n",
      "4  approach  5  2  0.2652933391146917\n",
      "1  variant  1  1  0.1505149978319906\n",
      "2  variant  2  1  0.20068666377598746\n",
      "1  recent  1  1  0.0994850021680094\n",
      "2  recent  4  1  0.13264666955734586\n",
      "3  recent  5  1  0.13264666955734586\n",
      "4  recent  6  1  0.13264666955734586\n",
      "1  perform  1  1  0.11928031367991561\n",
      "2  perform  2  2  0.3180808364797749\n",
      "3  perform  4  1  0.15904041823988746\n",
      "1  four  1  1  0.2112745100035642\n",
      "1  use  1  2  0.17121134041110314\n",
      "2  use  2  2  0.2282817872148042\n",
      "3  use  4  1  0.1141408936074021\n",
      "4  use  5  2  0.2282817872148042\n",
      "5  use  6  3  0.3424226808222063\n",
      "1  success  1  1  0.1505149978319906\n",
      "2  success  4  1  0.20068666377598746\n",
      "1  larg  1  1  0.0752574989159953\n",
      "2  larg  2  1  0.10034333188799373\n",
      "3  larg  3  1  0.10034333188799373\n",
      "4  larg  4  1  0.10034333188799373\n",
      "5  larg  5  1  0.10034333188799373\n",
      "6  larg  6  1  0.10034333188799373\n",
      "1  24%  1  1  0.2112745100035642\n",
      "1  transform  1  1  0.2112745100035642\n",
      "1  ultim  1  1  0.2112745100035642\n",
      "1  document  1  1  0.11928031367991561\n",
      "2  document  2  1  0.15904041823988746\n",
      "3  document  5  1  0.15904041823988746\n",
      "1  ndcg@10  1  1  0.11928031367991561\n",
      "2  ndcg@10  2  1  0.15904041823988746\n",
      "3  ndcg@10  4  1  0.15904041823988746\n",
      "1  pseudo-relev  1  1  0.2112745100035642\n",
      "1  benchmark  1  1  0.0994850021680094\n",
      "2  benchmark  2  2  0.2652933391146917\n",
      "3  benchmark  4  1  0.13264666955734586\n",
      "4  benchmark  5  1  0.13264666955734586\n",
      "1  find  1  1  0.1505149978319906\n",
      "2  find  3  1  0.20068666377598746\n",
      "1  base  1  1  0.11928031367991561\n",
      "2  base  2  1  0.15904041823988746\n",
      "3  base  4  1  0.15904041823988746\n",
      "1  set  1  2  0.23856062735983122\n",
      "2  set  3  1  0.15904041823988746\n",
      "3  set  5  1  0.15904041823988746\n",
      "1  qr  1  1  0.2112745100035642\n",
      "1  model  1  1  0.0752574989159953\n",
      "2  model  2  2  0.20068666377598746\n",
      "3  model  3  2  0.20068666377598746\n",
      "4  model  4  2  0.20068666377598746\n",
      "5  model  5  2  0.20068666377598746\n",
      "6  model  6  1  0.10034333188799373\n",
      "1  ir  1  1  0.1505149978319906\n",
      "2  ir  4  1  0.20068666377598746\n",
      "1  show  1  1  0.1505149978319906\n",
      "2  show  2  1  0.20068666377598746\n",
      "1  task  1  2  0.17121134041110314\n",
      "2  task  2  1  0.1141408936074021\n",
      "3  task  3  2  0.2282817872148042\n",
      "4  task  5  2  0.2282817872148042\n",
      "5  task  6  1  0.1141408936074021\n",
      "1  9%  1  1  0.2112745100035642\n",
      "1  user  1  1  0.0994850021680094\n",
      "2  user  3  1  0.13264666955734586\n",
      "3  user  4  1  0.13264666955734586\n",
      "4  user  5  1  0.13264666955734586\n",
      "1  genqrensemblerf  1  1  0.2112745100035642\n",
      "1  benefit  1  1  0.2112745100035642\n",
      "1  ensembl  1  1  0.2112745100035642\n",
      "1  feedback  1  1  0.1505149978319906\n",
      "2  feedback  4  1  0.20068666377598746\n",
      "1  introduc  1  1  0.1505149978319906\n",
      "2  introduc  5  1  0.20068666377598746\n",
      "1  due  1  1  0.2112745100035642\n",
      "1  paraphras  1  1  0.2112745100035642\n",
      "1  exploit  1  1  0.2112745100035642\n",
      "1  inher  1  1  0.2112745100035642\n",
      "1  mrr  1  1  0.1505149978319906\n",
      "2  mrr  6  1  0.20068666377598746\n",
      "1  origin  1  1  0.2112745100035642\n",
      "1  text  1  1  0.11928031367991561\n",
      "2  text  3  1  0.15904041823988746\n",
      "3  text  5  1  0.15904041823988746\n",
      "1  post-retriev  1  1  0.2112745100035642\n",
      "1  languag  1  1  0.0752574989159953\n",
      "2  languag  2  1  0.10034333188799373\n",
      "3  languag  3  1  0.10034333188799373\n",
      "4  languag  4  1  0.10034333188799373\n",
      "5  languag  5  2  0.20068666377598746\n",
      "6  languag  6  2  0.20068666377598746\n",
      "1  strategi  1  1  0.0994850021680094\n",
      "2  strategi  3  1  0.13264666955734586\n",
      "3  strategi  4  1  0.13264666955734586\n",
      "4  strategi  5  1  0.13264666955734586\n",
      "1  previou  1  1  0.11928031367991561\n",
      "2  previou  2  1  0.15904041823988746\n",
      "3  previou  4  1  0.15904041823988746\n",
      "1  upto  1  1  0.2112745100035642\n",
      "1  align  1  1  0.2112745100035642\n",
      "1  keyword  1  1  0.2112745100035642\n",
      "1  abil  1  1  0.1505149978319906\n",
      "2  abil  5  1  0.20068666377598746\n",
      "1  genqrensembl  1  1  0.2112745100035642\n",
      "1  search  1  1  0.11928031367991561\n",
      "2  search  4  1  0.15904041823988746\n",
      "3  search  5  1  0.15904041823988746\n",
      "1  multipl  1  1  0.11928031367991561\n",
      "2  multipl  4  1  0.15904041823988746\n",
      "3  multipl  6  1  0.15904041823988746\n",
      "1  techniqu  1  2  0.1989700043360188\n",
      "2  techniqu  2  1  0.13264666955734586\n",
      "3  techniqu  4  1  0.13264666955734586\n",
      "4  techniqu  6  1  0.13264666955734586\n",
      "1  incorpor  1  1  0.2112745100035642\n",
      "1  queri  1  2  0.1989700043360188\n",
      "2  queri  2  1  0.13264666955734586\n",
      "3  queri  4  3  0.3979400086720376\n",
      "4  queri  5  1  0.13264666955734586\n",
      "1  gener  1  2  0.1989700043360188\n",
      "2  gener  4  2  0.2652933391146917\n",
      "3  gener  5  3  0.3979400086720376\n",
      "4  gener  6  3  0.3979400086720376\n",
      "1  zero-shot  1  1  0.2112745100035642\n",
      "1  reformul  1  3  0.45154499349597177\n",
      "2  reformul  4  2  0.4013733275519749\n",
      "1  better  1  1  0.2112745100035642\n",
      "1  gain  1  1  0.2112745100035642\n",
      "1  passag  1  1  0.2112745100035642\n",
      "1  map  1  1  0.2112745100035642\n",
      "1  inspir  1  1  0.1505149978319906\n",
      "2  inspir  3  1  0.20068666377598746\n",
      "1  help  1  1  0.2112745100035642\n",
      "1  complex  2  1  0.20068666377598746\n",
      "2  complex  5  1  0.20068666377598746\n",
      "1  analyz  2  1  0.28169934667141894\n",
      "1  moderate-s  2  1  0.28169934667141894\n",
      "1  howev  2  1  0.28169934667141894\n",
      "1  gpt-4  2  1  0.28169934667141894\n",
      "1  estim  2  1  0.28169934667141894\n",
      "1  averag  2  1  0.28169934667141894\n",
      "1  baselin  2  2  0.5633986933428379\n",
      "1  standard  2  1  0.28169934667141894\n",
      "1  paper  2  1  0.13264666955734586\n",
      "2  paper  4  1  0.13264666955734586\n",
      "3  paper  5  1  0.13264666955734586\n",
      "4  paper  6  1  0.13264666955734586\n",
      "1  open-sourc  2  1  0.20068666377598746\n",
      "2  open-sourc  6  1  0.20068666377598746\n",
      "1  flan-ul2  2  1  0.28169934667141894\n",
      "1  challeng  2  1  0.28169934667141894\n",
      "1  pairwis  2  1  0.28169934667141894\n",
      "1  listwis  2  1  0.28169934667141894\n",
      "1  outperform  2  3  0.8450980400142568\n",
      "1  even  2  1  0.28169934667141894\n",
      "1  fine-tun  2  1  0.20068666377598746\n",
      "2  fine-tun  3  1  0.20068666377598746\n",
      "1  problem  2  1  0.15904041823988746\n",
      "2  problem  3  1  0.15904041823988746\n",
      "3  problem  4  1  0.15904041823988746\n",
      "1  pointwis  2  1  0.28169934667141894\n",
      "1  10%  2  1  0.28169934667141894\n",
      "1  2020  2  1  0.28169934667141894\n",
      "1  state-of-the-art  2  1  0.20068666377598746\n",
      "2  state-of-the-art  4  1  0.20068666377598746\n",
      "1  directli  2  1  0.28169934667141894\n",
      "1  20b  2  1  0.28169934667141894\n",
      "1  found  2  1  0.28169934667141894\n",
      "1  interest  2  1  0.28169934667141894\n",
      "1  chatgpt  2  1  0.28169934667141894\n",
      "1  feed  2  1  0.28169934667141894\n",
      "1  method  2  1  0.20068666377598746\n",
      "2  method  4  1  0.20068666377598746\n",
      "1  trec-dl  2  1  0.28169934667141894\n",
      "1  furthermor  2  1  0.20068666377598746\n",
      "2  furthermor  4  1  0.20068666377598746\n",
      "1  175b  2  1  0.28169934667141894\n",
      "1  llm-base  2  1  0.15904041823988746\n",
      "2  llm-base  3  1  0.15904041823988746\n",
      "3  llm-base  6  1  0.15904041823988746\n",
      "1  reduc  2  1  0.20068666377598746\n",
      "2  reduc  3  1  0.20068666377598746\n",
      "1  understand  2  1  0.15904041823988746\n",
      "2  understand  3  1  0.15904041823988746\n",
      "3  understand  5  1  0.15904041823988746\n",
      "1  4.2%  2  1  0.28169934667141894\n",
      "1  literatur  2  1  0.28169934667141894\n",
      "1  burden  2  1  0.28169934667141894\n",
      "1  exist  2  1  0.28169934667141894\n",
      "1  dataset  2  1  0.13264666955734586\n",
      "2  dataset  3  1  0.13264666955734586\n",
      "3  dataset  5  1  0.13264666955734586\n",
      "4  dataset  6  2  0.2652933391146917\n",
      "1  research  2  1  0.20068666377598746\n",
      "2  research  3  1  0.20068666377598746\n",
      "1  llm  2  1  0.1141408936074021\n",
      "2  llm  3  1  0.1141408936074021\n",
      "3  llm  4  1  0.1141408936074021\n",
      "4  llm  5  2  0.2282817872148042\n",
      "5  llm  6  2  0.2282817872148042\n",
      "1  sever  2  1  0.28169934667141894\n",
      "1  significantli  2  1  0.15904041823988746\n",
      "2  significantli  3  1  0.15904041823988746\n",
      "3  significantli  4  1  0.15904041823988746\n",
      "1  off-the-shelf  2  1  0.28169934667141894\n",
      "1  practic  2  1  0.28169934667141894\n",
      "1  favor  2  1  0.28169934667141894\n",
      "1  fulli  2  1  0.28169934667141894\n",
      "1  ranker  2  1  0.20068666377598746\n",
      "2  ranker  5  1  0.20068666377598746\n",
      "1  paramet  2  1  0.28169934667141894\n",
      "1  12-10%  2  1  0.28169934667141894\n",
      "1  2019  2  1  0.28169934667141894\n",
      "1  beir  2  1  0.20068666377598746\n",
      "2  beir  4  1  0.20068666377598746\n",
      "1  templat  2  1  0.20068666377598746\n",
      "2  templat  3  1  0.20068666377598746\n",
      "1  achiev  2  1  0.15904041823988746\n",
      "2  achiev  4  1  0.15904041823988746\n",
      "3  achiev  5  1  0.15904041823988746\n",
      "1  blackbox  2  1  0.28169934667141894\n",
      "1  difficult  2  1  0.28169934667141894\n",
      "1  prp  2  1  0.28169934667141894\n",
      "1  argu  2  1  0.28169934667141894\n",
      "1  best  2  1  0.28169934667141894\n",
      "1  competit  2  1  0.28169934667141894\n",
      "1  instructgpt  2  1  0.28169934667141894\n",
      "1  supervis  2  1  0.28169934667141894\n",
      "1  50x  2  1  0.28169934667141894\n",
      "1  linear  2  1  0.28169934667141894\n",
      "1  first  2  1  0.15904041823988746\n",
      "2  first  4  1  0.15904041823988746\n",
      "3  first  5  1  0.15904041823988746\n",
      "1  candid  2  1  0.28169934667141894\n",
      "1  size  2  1  0.28169934667141894\n",
      "1  metric  2  1  0.20068666377598746\n",
      "2  metric  6  1  0.20068666377598746\n",
      "1  effici  2  1  0.20068666377598746\n",
      "2  effici  3  2  0.4013733275519749\n",
      "1  seven  2  1  0.28169934667141894\n",
      "1  new  2  1  0.28169934667141894\n",
      "1  result  2  1  0.13264666955734586\n",
      "2  result  3  1  0.13264666955734586\n",
      "3  result  5  1  0.13264666955734586\n",
      "4  result  6  1  0.13264666955734586\n",
      "1  commerci  2  1  0.28169934667141894\n",
      "1  call  2  1  0.28169934667141894\n",
      "1  possibl  2  1  0.28169934667141894\n",
      "1  formul  2  1  0.28169934667141894\n",
      "1  solut  2  2  0.5633986933428379\n",
      "1  train  3  1  0.28169934667141894\n",
      "1  distil  3  2  0.5633986933428379\n",
      "1  design  3  1  0.28169934667141894\n",
      "1  attempt  3  1  0.28169934667141894\n",
      "1  experiment  3  1  0.28169934667141894\n",
      "1  item  3  1  0.20068666377598746\n",
      "2  item  6  2  0.4013733275519749\n",
      "1  may  3  1  0.28169934667141894\n",
      "1  e.g.  3  1  0.28169934667141894\n",
      "1  although  3  1  0.28169934667141894\n",
      "1  inform  3  1  0.13264666955734586\n",
      "2  inform  4  1  0.13264666955734586\n",
      "3  inform  5  1  0.13264666955734586\n",
      "4  inform  6  1  0.13264666955734586\n",
      "1  extens  3  1  0.28169934667141894\n",
      "1  mostli  3  1  0.28169934667141894\n",
      "1  demonstr  3  1  0.15904041823988746\n",
      "2  demonstr  4  1  0.15904041823988746\n",
      "3  demonstr  6  1  0.15904041823988746\n",
      "1  limit  3  1  0.20068666377598746\n",
      "2  limit  4  1  0.20068666377598746\n",
      "1  word  3  1  0.28169934667141894\n",
      "1  plain  3  1  0.28169934667141894\n",
      "1  bridg  3  1  0.20068666377598746\n",
      "2  bridg  5  1  0.20068666377598746\n",
      "1  id  3  1  0.28169934667141894\n",
      "1  capabl  3  1  0.28169934667141894\n",
      "1  manifest  3  1  0.28169934667141894\n",
      "1  enough  3  1  0.28169934667141894\n",
      "1  variou  3  1  0.20068666377598746\n",
      "2  variou  4  1  0.20068666377598746\n",
      "1  user/item  3  1  0.28169934667141894\n",
      "1  long  3  2  0.5633986933428379\n",
      "1  contain  3  1  0.28169934667141894\n",
      "1  multi-step  3  1  0.28169934667141894\n",
      "1  requir  3  1  0.28169934667141894\n",
      "1  usual  3  1  0.28169934667141894\n",
      "1  i.e.  3  1  0.28169934667141894\n",
      "1  discret  3  1  0.28169934667141894\n",
      "1  unparallel  3  1  0.28169934667141894\n",
      "1  input  3  1  0.15904041823988746\n",
      "2  input  4  1  0.15904041823988746\n",
      "3  input  5  1  0.15904041823988746\n",
      "1  power  3  1  0.15904041823988746\n",
      "2  power  5  1  0.15904041823988746\n",
      "3  power  6  1  0.15904041823988746\n",
      "1  vector  3  1  0.28169934667141894\n",
      "1  specif  3  1  0.28169934667141894\n",
      "1  fill  3  1  0.28169934667141894\n",
      "1  infer  3  1  0.28169934667141894\n",
      "1  thu  3  1  0.28169934667141894\n",
      "1  need  3  1  0.20068666377598746\n",
      "2  need  5  1  0.20068666377598746\n",
      "1  three  3  1  0.28169934667141894\n",
      "1  also  3  1  0.20068666377598746\n",
      "2  also  5  1  0.20068666377598746\n",
      "1  time  3  1  0.20068666377598746\n",
      "2  time  4  1  0.20068666377598746\n",
      "1  reason  3  1  0.28169934667141894\n",
      "1  continu  3  1  0.28169934667141894\n",
      "1  given  3  1  0.20068666377598746\n",
      "2  given  5  1  0.20068666377598746\n",
      "1  effect  3  1  0.15904041823988746\n",
      "2  effect  4  1  0.15904041823988746\n",
      "3  effect  5  1  0.15904041823988746\n",
      "1  allow  3  1  0.20068666377598746\n",
      "2  allow  5  1  0.20068666377598746\n",
      "1  process  3  1  0.13264666955734586\n",
      "2  process  4  1  0.13264666955734586\n",
      "3  process  5  1  0.13264666955734586\n",
      "4  process  6  1  0.13264666955734586\n",
      "1  could  3  1  0.28169934667141894\n",
      "1  address  3  1  0.28169934667141894\n",
      "1  real-world  3  1  0.28169934667141894\n",
      "1  respons  3  1  0.28169934667141894\n",
      "1  commun  3  1  0.28169934667141894\n",
      "1  unleash  3  1  0.28169934667141894\n",
      "1  pod  3  1  0.28169934667141894\n",
      "1  top-n  3  1  0.28169934667141894\n",
      "1  sequenti  3  1  0.20068666377598746\n",
      "2  sequenti  5  1  0.20068666377598746\n",
      "1  recommend  3  2  0.4013733275519749\n",
      "2  recommend  6  1  0.20068666377598746\n",
      "1  noisi  3  1  0.28169934667141894\n",
      "1  immedi  3  1  0.28169934667141894\n",
      "1  system  3  1  0.20068666377598746\n",
      "2  system  6  1  0.20068666377598746\n",
      "1  innov  4  1  0.28169934667141894\n",
      "1  differenti  4  1  0.28169934667141894\n",
      "1  adapt  4  2  0.5633986933428379\n",
      "1  modifi  4  1  0.28169934667141894\n",
      "1  aggreg  4  1  0.28169934667141894\n",
      "1  empir  4  1  0.28169934667141894\n",
      "1  boost  4  1  0.28169934667141894\n",
      "1  combin  4  1  0.20068666377598746\n",
      "2  combin  6  1  0.20068666377598746\n",
      "1  aim  4  1  0.20068666377598746\n",
      "2  aim  5  1  0.20068666377598746\n",
      "1  rate  4  1  0.28169934667141894\n",
      "1  enhanc  4  1  0.20068666377598746\n",
      "2  enhanc  5  1  0.20068666377598746\n",
      "1  group  4  1  0.28169934667141894\n",
      "1  cluster  4  2  0.5633986933428379\n",
      "1  advanc  4  1  0.28169934667141894\n",
      "1  reward  4  1  0.28169934667141894\n",
      "1  variabl  4  1  0.28169934667141894\n",
      "1  qerm  4  1  0.28169934667141894\n",
      "1  novel  4  1  0.20068666377598746\n",
      "2  novel  5  1  0.20068666377598746\n",
      "1  crucial  4  1  0.28169934667141894\n",
      "1  redund  4  1  0.28169934667141894\n",
      "1  complet  4  1  0.28169934667141894\n",
      "1  field  4  1  0.28169934667141894\n",
      "1  custom  4  1  0.28169934667141894\n",
      "1  12%  4  1  0.28169934667141894\n",
      "1  optim  4  1  0.28169934667141894\n",
      "1  repres  4  1  0.28169934667141894\n",
      "1  phase  4  1  0.28169934667141894\n",
      "1  framework  4  2  0.5633986933428379\n",
      "1  distinctli  4  1  0.28169934667141894\n",
      "1  refin  4  1  0.28169934667141894\n",
      "1  initi  4  1  0.28169934667141894\n",
      "1  loop  4  1  0.28169934667141894\n",
      "1  singl  4  1  0.28169934667141894\n",
      "1  explor  4  1  0.20068666377598746\n",
      "2  explor  6  1  0.20068666377598746\n",
      "1  weight  4  1  0.28169934667141894\n",
      "1  expans  4  1  0.28169934667141894\n",
      "1  constrain  4  1  0.28169934667141894\n",
      "1  well-known  4  1  0.28169934667141894\n",
      "1  potenti  4  1  0.20068666377598746\n",
      "2  potenti  6  1  0.20068666377598746\n",
      "1  often  4  1  0.28169934667141894\n",
      "1  well-gener  4  1  0.28169934667141894\n",
      "1  sota  4  1  0.28169934667141894\n",
      "1  gencrf  4  1  0.28169934667141894\n",
      "1  captur  4  2  0.4013733275519749\n",
      "2  captur  5  2  0.4013733275519749\n",
      "1  surpass  4  1  0.28169934667141894\n",
      "1  divers  4  1  0.28169934667141894\n",
      "1  automat  4  1  0.28169934667141894\n",
      "1  integr  4  1  0.20068666377598746\n",
      "2  integr  5  1  0.20068666377598746\n",
      "1  symbol  5  2  0.5633986933428379\n",
      "1  pre-train  5  1  0.28169934667141894\n",
      "1  neglect  5  1  0.28169934667141894\n",
      "1  contrast  5  1  0.28169934667141894\n",
      "1  learn  5  1  0.28169934667141894\n",
      "1  action  5  1  0.28169934667141894\n",
      "1  represent  5  1  0.28169934667141894\n",
      "1  includ  5  1  0.28169934667141894\n",
      "1  text-bas  5  1  0.28169934667141894\n",
      "1  modern  5  1  0.28169934667141894\n",
      "1  predict  5  1  0.28169934667141894\n",
      "1  interact  5  3  0.8450980400142568\n",
      "1  analysi  5  1  0.28169934667141894\n",
      "1  typic  5  1  0.28169934667141894\n",
      "1  overlook  5  1  0.28169934667141894\n",
      "1  graph-bas  5  1  0.28169934667141894\n",
      "1  graph-to-text  5  1  0.28169934667141894\n",
      "1  superior  5  1  0.28169934667141894\n",
      "1  natur  5  1  0.20068666377598746\n",
      "2  natur  6  1  0.20068666377598746\n",
      "1  discrep  5  1  0.28169934667141894\n",
      "1  tiangong-st  5  1  0.28169934667141894\n",
      "1  two  5  1  0.28169934667141894\n",
      "1  link  5  1  0.28169934667141894\n",
      "1  confirm  5  1  0.28169934667141894\n",
      "1  fulfil  5  1  0.28169934667141894\n",
      "1  moreov  5  1  0.28169934667141894\n",
      "1  paradigm  5  1  0.28169934667141894\n",
      "1  topolog  5  1  0.28169934667141894\n",
      "1  tradit  5  1  0.20068666377598746\n",
      "2  tradit  6  1  0.20068666377598746\n",
      "1  corpora  5  1  0.28169934667141894\n",
      "1  advantag  5  1  0.28169934667141894\n",
      "1  semant  5  1  0.28169934667141894\n",
      "1  methodolog  5  1  0.28169934667141894\n",
      "1  offer  5  1  0.28169934667141894\n",
      "1  produc  5  1  0.28169934667141894\n",
      "1  graph  5  2  0.5633986933428379\n",
      "1  grammar  5  1  0.28169934667141894\n",
      "1  self-supervis  5  1  0.28169934667141894\n",
      "1  convert  5  1  0.28169934667141894\n",
      "1  seamlessli  5  1  0.28169934667141894\n",
      "1  fine-grain  5  1  0.28169934667141894\n",
      "1  object  5  1  0.28169934667141894\n",
      "1  sgr  5  1  0.28169934667141894\n",
      "1  word-level  5  1  0.28169934667141894\n",
      "1  structur  5  3  0.8450980400142568\n",
      "1  involv  5  1  0.28169934667141894\n",
      "1  textual  5  1  0.28169934667141894\n",
      "1  content  5  1  0.28169934667141894\n",
      "1  priorit  5  1  0.28169934667141894\n",
      "1  format  5  1  0.28169934667141894\n",
      "1  node  5  1  0.28169934667141894\n",
      "1  rule  5  1  0.28169934667141894\n",
      "1  deep  5  1  0.28169934667141894\n",
      "1  enabl  5  1  0.28169934667141894\n",
      "1  focu  5  1  0.28169934667141894\n",
      "1  coarse-grain  5  1  0.28169934667141894\n",
      "1  seri  5  1  0.28169934667141894\n",
      "1  within  5  1  0.28169934667141894\n",
      "1  aol  5  1  0.28169934667141894\n",
      "1  histori  5  1  0.28169934667141894\n",
      "1  session  5  2  0.5633986933428379\n",
      "1  comprehens  5  1  0.28169934667141894\n",
      "1  concret  5  1  0.28169934667141894\n",
      "1  current  5  1  0.28169934667141894\n",
      "1  gap  5  1  0.28169934667141894\n",
      "1  subsequ  6  1  0.28169934667141894\n",
      "1  play  6  1  0.28169934667141894\n",
      "1  viewer  6  1  0.28169934667141894\n",
      "1  compar  6  2  0.5633986933428379\n",
      "1  alpaca  6  1  0.28169934667141894\n",
      "1  consid  6  1  0.28169934667141894\n",
      "1  obtain  6  1  0.28169934667141894\n",
      "1  publish  6  1  0.28169934667141894\n",
      "1  studi  6  1  0.28169934667141894\n",
      "1  web  6  1  0.28169934667141894\n",
      "1  director  6  1  0.28169934667141894\n",
      "1  one  6  1  0.28169934667141894\n",
      "1  ndcg  6  1  0.28169934667141894\n",
      "1  featur  6  1  0.28169934667141894\n",
      "1  hit  6  1  0.28169934667141894\n",
      "1  top  6  1  0.28169934667141894\n",
      "1  consist  6  1  0.28169934667141894\n",
      "1  movielen  6  1  0.28169934667141894\n",
      "1  data  6  1  0.28169934667141894\n",
      "1  emerg  6  1  0.28169934667141894\n",
      "1  signific  6  1  0.28169934667141894\n",
      "1  1m  6  1  0.28169934667141894\n",
      "1  titl  6  1  0.28169934667141894\n",
      "1  book  6  1  0.28169934667141894\n",
      "1  compris  6  1  0.28169934667141894\n",
      "1  cast  6  1  0.28169934667141894\n",
      "1  summari  6  1  0.28169934667141894\n",
      "1  author  6  1  0.28169934667141894\n",
      "1  web-scrap  6  1  0.28169934667141894\n",
      "1  year  6  1  0.28169934667141894\n",
      "1  inconsist  6  1  0.28169934667141894\n",
      "1  manual  6  1  0.28169934667141894\n",
      "1  descript  6  2  0.5633986933428379\n",
      "1  open  6  1  0.28169934667141894\n",
      "1  pivot  6  1  0.28169934667141894\n",
      "1  ml  6  1  0.28169934667141894\n",
      "1  name  6  1  0.28169934667141894\n",
      "1  provid  6  1  0.28169934667141894\n",
      "1  time-consum  6  1  0.28169934667141894\n",
      "1  goodread  6  1  0.28169934667141894\n",
      "1  suscept  6  1  0.28169934667141894\n",
      "1  movi  6  1  0.28169934667141894\n",
      "1  few-shot  6  1  0.28169934667141894\n",
      "1  concis  6  1  0.28169934667141894\n",
      "1  exhibit  6  1  0.28169934667141894\n",
      "1  like  6  1  0.28169934667141894\n",
      "1  tool  6  1  0.28169934667141894\n",
      "1  essenti  6  1  0.28169934667141894\n",
      "1  sourc  6  1  0.28169934667141894\n",
      "1  captiv  6  1  0.28169934667141894\n",
      "1  detail  6  1  0.28169934667141894\n",
      "1  gpt-3.5  6  1  0.28169934667141894\n",
      "1  conduct  6  1  0.28169934667141894\n",
      "1  scrape  6  2  0.5633986933428379\n",
      "1  role  6  1  0.28169934667141894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inverse_reg_porter = {}\n",
    "\n",
    "for i in range(len(termes_reg_porter)):\n",
    "    seen_terms = set()  # Track terms processed in the current document\n",
    "\n",
    "    for j in range(len(termes_reg_porter[i])):\n",
    "        term = termes_reg_porter[i][j]\n",
    "\n",
    "        if (term, i) not in seen_terms:\n",
    "            seen_terms.add((term, i))\n",
    "\n",
    "            if term not in inverse_reg_porter:\n",
    "                inverse_reg_porter[term] = []\n",
    "            \n",
    "            frequency_term = frequency_dict_reg_porter_documents[i][termes_reg_porter[i][j]]\n",
    "            poids_term = poids(frequency_term, max_frequency_dict_reg_porter_documents[i], document_frequency_dict_reg_porter[termes_reg_porter[i][j]], n_reg)\n",
    "            \n",
    "            inverse_reg_porter[term].append((i + 1, frequency_term, poids_term))\n",
    "\n",
    "inverse_reg_porter_output = \"\"\n",
    "for term, docs in inverse_reg_porter.items():\n",
    "    for idx, doc_info in enumerate(docs, 1):\n",
    "        doc_num, frequency_term, poids_term = doc_info\n",
    "        inverse_reg_porter_output += f\"{idx}  {term}  {doc_num}  {frequency_term}  {poids_term}\\n\"\n",
    "\n",
    "print(inverse_reg_porter_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  lev  1  1  0.11928031367991561\n",
      "2  lev  4  2  0.3180808364797749\n",
      "3  lev  5  1  0.15904041823988746\n",
      "1  rank  1  1  0.11928031367991561\n",
      "2  rank  2  3  0.47712125471966244\n",
      "3  rank  5  1  0.15904041823988746\n",
      "1  relev  1  1  0.2112745100035642\n",
      "1  improv  1  4  0.3979400086720376\n",
      "2  improv  2  1  0.13264666955734586\n",
      "3  improv  3  3  0.3979400086720376\n",
      "4  improv  4  1  0.13264666955734586\n",
      "1  18%  1  1  0.2112745100035642\n",
      "1  evalu  1  1  0.11928031367991561\n",
      "2  evalu  4  1  0.15904041823988746\n",
      "3  evalu  6  1  0.15904041823988746\n",
      "1  tak  1  1  0.11928031367991561\n",
      "2  tak  3  1  0.15904041823988746\n",
      "3  tak  5  1  0.15904041823988746\n",
      "1  state-of-art  1  1  0.2112745100035642\n",
      "1  msmarco  1  1  0.2112745100035642\n",
      "1  knowledg  1  1  0.2112745100035642\n",
      "1  instruct  1  1  0.1505149978319906\n",
      "2  instruct  5  1  0.20068666377598746\n",
      "1  investig  1  1  0.2112745100035642\n",
      "1  rel  1  1  0.2112745100035642\n",
      "1  5%  1  1  0.2112745100035642\n",
      "1  retriev  1  1  0.1505149978319906\n",
      "2  retriev  4  3  0.6020599913279624\n",
      "1  query  1  2  0.1989700043360188\n",
      "2  query  2  1  0.13264666955734586\n",
      "3  query  4  3  0.3979400086720376\n",
      "4  query  5  1  0.13264666955734586\n",
      "1  shown  1  1  0.2112745100035642\n",
      "1  pseudo  1  1  0.2112745100035642\n",
      "1  propos  1  1  0.08560567020555157\n",
      "2  propos  2  1  0.1141408936074021\n",
      "3  propos  3  1  0.1141408936074021\n",
      "4  propos  4  1  0.1141408936074021\n",
      "5  propos  5  1  0.1141408936074021\n",
      "1  us  1  3  0.22577249674798588\n",
      "2  us  2  2  0.20068666377598746\n",
      "3  us  3  2  0.20068666377598746\n",
      "4  us  4  2  0.20068666377598746\n",
      "5  us  5  3  0.3010299956639812\n",
      "6  us  6  3  0.3010299956639812\n",
      "1  strategies  1  1  0.11928031367991561\n",
      "2  strategies  4  1  0.15904041823988746\n",
      "3  strategies  5  1  0.15904041823988746\n",
      "1  prompt  1  1  0.08560567020555157\n",
      "2  prompt  2  3  0.3424226808222063\n",
      "3  prompt  3  2  0.2282817872148042\n",
      "4  prompt  4  1  0.1141408936074021\n",
      "5  prompt  6  2  0.2282817872148042\n",
      "1  abl  1  1  0.1505149978319906\n",
      "2  abl  5  1  0.20068666377598746\n",
      "1  context  1  1  0.2112745100035642\n",
      "1  incorp  1  1  0.2112745100035642\n",
      "1  approach  1  1  0.0994850021680094\n",
      "2  approach  2  1  0.13264666955734586\n",
      "3  approach  3  1  0.13264666955734586\n",
      "4  approach  5  2  0.2652933391146917\n",
      "1  perform  1  1  0.11928031367991561\n",
      "2  perform  2  2  0.3180808364797749\n",
      "3  perform  4  1  0.15904041823988746\n",
      "1  post-retrieval  1  1  0.2112745100035642\n",
      "1  four  1  1  0.2112745100035642\n",
      "1  int  1  1  0.1505149978319906\n",
      "2  int  4  2  0.4013733275519749\n",
      "1  success  1  1  0.1505149978319906\n",
      "2  success  4  1  0.20068666377598746\n",
      "1  vary  1  1  0.0994850021680094\n",
      "2  vary  2  1  0.13264666955734586\n",
      "3  vary  3  1  0.13264666955734586\n",
      "4  vary  4  2  0.2652933391146917\n",
      "1  larg  1  1  0.0752574989159953\n",
      "2  larg  2  1  0.10034333188799373\n",
      "3  larg  3  1  0.10034333188799373\n",
      "4  larg  4  1  0.10034333188799373\n",
      "5  larg  5  1  0.10034333188799373\n",
      "6  larg  6  1  0.10034333188799373\n",
      "1  24%  1  1  0.2112745100035642\n",
      "1  transform  1  1  0.2112745100035642\n",
      "1  docu  1  1  0.11928031367991561\n",
      "2  docu  2  1  0.15904041823988746\n",
      "3  docu  5  1  0.15904041823988746\n",
      "1  ultim  1  1  0.2112745100035642\n",
      "1  ndcg@10  1  1  0.11928031367991561\n",
      "2  ndcg@10  2  1  0.15904041823988746\n",
      "3  ndcg@10  4  1  0.15904041823988746\n",
      "1  benchmark  1  1  0.0994850021680094\n",
      "2  benchmark  2  2  0.2652933391146917\n",
      "3  benchmark  4  1  0.13264666955734586\n",
      "4  benchmark  5  1  0.13264666955734586\n",
      "1  find  1  1  0.1505149978319906\n",
      "2  find  3  1  0.20068666377598746\n",
      "1  inh  1  1  0.2112745100035642\n",
      "1  set  1  2  0.23856062735983122\n",
      "2  set  3  1  0.15904041823988746\n",
      "3  set  5  1  0.15904041823988746\n",
      "1  prom  1  1  0.1505149978319906\n",
      "2  prom  6  1  0.20068666377598746\n",
      "1  qr  1  1  0.2112745100035642\n",
      "1  bas  1  1  0.11928031367991561\n",
      "2  bas  2  1  0.15904041823988746\n",
      "3  bas  4  1  0.15904041823988746\n",
      "1  model  1  1  0.0752574989159953\n",
      "2  model  2  2  0.20068666377598746\n",
      "3  model  3  2  0.20068666377598746\n",
      "4  model  4  2  0.20068666377598746\n",
      "5  model  5  2  0.20068666377598746\n",
      "6  model  6  1  0.10034333188799373\n",
      "1  ir  1  1  0.1505149978319906\n",
      "2  ir  4  1  0.20068666377598746\n",
      "1  show  1  1  0.1505149978319906\n",
      "2  show  2  1  0.20068666377598746\n",
      "1  task  1  2  0.17121134041110314\n",
      "2  task  2  1  0.1141408936074021\n",
      "3  task  3  2  0.2282817872148042\n",
      "4  task  5  2  0.2282817872148042\n",
      "5  task  6  1  0.1141408936074021\n",
      "1  prevy  1  1  0.11928031367991561\n",
      "2  prevy  2  1  0.15904041823988746\n",
      "3  prevy  4  1  0.15904041823988746\n",
      "1  9%  1  1  0.2112745100035642\n",
      "1  genqrensemblerf  1  1  0.2112745100035642\n",
      "1  benefit  1  1  0.2112745100035642\n",
      "1  ensembl  1  1  0.2112745100035642\n",
      "1  feedback  1  1  0.1505149978319906\n",
      "2  feedback  4  1  0.20068666377598746\n",
      "1  introduc  1  1  0.1505149978319906\n",
      "2  introduc  5  1  0.20068666377598746\n",
      "1  expery  1  1  0.0994850021680094\n",
      "2  expery  3  1  0.13264666955734586\n",
      "3  expery  4  1  0.13264666955734586\n",
      "4  expery  5  1  0.13264666955734586\n",
      "1  pseudo-relevance  1  1  0.2112745100035642\n",
      "1  due  1  1  0.2112745100035642\n",
      "1  paraphras  1  1  0.2112745100035642\n",
      "1  exploit  1  1  0.2112745100035642\n",
      "1  reform  1  3  0.45154499349597177\n",
      "2  reform  4  2  0.4013733275519749\n",
      "1  mrr  1  1  0.1505149978319906\n",
      "2  mrr  6  1  0.20068666377598746\n",
      "1  origin  1  1  0.2112745100035642\n",
      "1  text  1  1  0.11928031367991561\n",
      "2  text  3  1  0.15904041823988746\n",
      "3  text  5  2  0.3180808364797749\n",
      "1  techn  1  2  0.1989700043360188\n",
      "2  techn  2  1  0.13264666955734586\n",
      "3  techn  4  1  0.13264666955734586\n",
      "4  techn  6  1  0.13264666955734586\n",
      "1  upto  1  1  0.2112745100035642\n",
      "1  align  1  1  0.2112745100035642\n",
      "1  keyword  1  1  0.2112745100035642\n",
      "1  many  1  1  0.2112745100035642\n",
      "1  pass  1  1  0.2112745100035642\n",
      "1  genqrensembl  1  1  0.2112745100035642\n",
      "1  search  1  1  0.11928031367991561\n",
      "2  search  4  1  0.15904041823988746\n",
      "3  search  5  1  0.15904041823988746\n",
      "1  multipl  1  1  0.11928031367991561\n",
      "2  multipl  4  1  0.15904041823988746\n",
      "3  multipl  6  1  0.15904041823988746\n",
      "1  rec  1  1  0.0994850021680094\n",
      "2  rec  4  1  0.13264666955734586\n",
      "3  rec  5  1  0.13264666955734586\n",
      "4  rec  6  1  0.13264666955734586\n",
      "1  langu  1  1  0.0752574989159953\n",
      "2  langu  2  1  0.10034333188799373\n",
      "3  langu  3  1  0.10034333188799373\n",
      "4  langu  4  1  0.10034333188799373\n",
      "5  langu  5  2  0.20068666377598746\n",
      "6  langu  6  2  0.20068666377598746\n",
      "1  zero-shot  1  1  0.2112745100035642\n",
      "1  bet  1  1  0.2112745100035642\n",
      "1  gain  1  1  0.2112745100035642\n",
      "1  gen  1  2  0.1989700043360188\n",
      "2  gen  4  2  0.2652933391146917\n",
      "3  gen  5  3  0.3979400086720376\n",
      "4  gen  6  3  0.3979400086720376\n",
      "1  map  1  1  0.2112745100035642\n",
      "1  inspir  1  1  0.1505149978319906\n",
      "2  inspir  3  1  0.20068666377598746\n",
      "1  help  1  1  0.2112745100035642\n",
      "1  complex  2  1  0.20068666377598746\n",
      "2  complex  5  1  0.20068666377598746\n",
      "1  ev  2  1  0.28169934667141894\n",
      "1  efficy  2  1  0.20068666377598746\n",
      "2  efficy  3  2  0.4013733275519749\n",
      "1  furtherm  2  1  0.20068666377598746\n",
      "2  furtherm  4  1  0.20068666377598746\n",
      "1  open-sourced  2  1  0.20068666377598746\n",
      "2  open-sourced  6  1  0.20068666377598746\n",
      "1  howev  2  1  0.28169934667141894\n",
      "1  gpt-4  2  1  0.28169934667141894\n",
      "1  estim  2  1  0.28169934667141894\n",
      "1  baselin  2  2  0.5633986933428379\n",
      "1  standard  2  1  0.28169934667141894\n",
      "1  form  2  1  0.20068666377598746\n",
      "2  form  5  1  0.20068666377598746\n",
      "1  flan-ul2  2  1  0.28169934667141894\n",
      "1  moderate-sized  2  1  0.28169934667141894\n",
      "1  challeng  2  1  0.28169934667141894\n",
      "1  outperform  2  3  0.8450980400142568\n",
      "1  problem  2  1  0.15904041823988746\n",
      "2  problem  3  1  0.15904041823988746\n",
      "3  problem  4  1  0.15904041823988746\n",
      "1  llms  2  1  0.13264666955734586\n",
      "2  llms  4  1  0.13264666955734586\n",
      "3  llms  5  1  0.13264666955734586\n",
      "4  llms  6  1  0.13264666955734586\n",
      "1  2020  2  1  0.28169934667141894\n",
      "1  10%  2  1  0.28169934667141894\n",
      "1  state-of-the-art  2  1  0.20068666377598746\n",
      "2  state-of-the-art  4  1  0.20068666377598746\n",
      "1  20b  2  1  0.28169934667141894\n",
      "1  found  2  1  0.28169934667141894\n",
      "1  interest  2  1  0.28169934667141894\n",
      "1  pract  2  1  0.28169934667141894\n",
      "1  chatgpt  2  1  0.28169934667141894\n",
      "1  method  2  1  0.20068666377598746\n",
      "2  method  4  1  0.20068666377598746\n",
      "1  trec-dl  2  1  0.28169934667141894\n",
      "1  superv  2  1  0.28169934667141894\n",
      "1  sign  2  1  0.13264666955734586\n",
      "2  sign  3  1  0.13264666955734586\n",
      "3  sign  4  1  0.13264666955734586\n",
      "4  sign  6  1  0.13264666955734586\n",
      "1  listw  2  1  0.28169934667141894\n",
      "1  175b  2  1  0.28169934667141894\n",
      "1  av  2  1  0.28169934667141894\n",
      "1  reduc  2  1  0.20068666377598746\n",
      "2  reduc  3  1  0.20068666377598746\n",
      "1  pointw  2  1  0.28169934667141894\n",
      "1  understand  2  1  0.15904041823988746\n",
      "2  understand  3  1  0.15904041823988746\n",
      "3  understand  5  1  0.15904041823988746\n",
      "1  4.2%  2  1  0.28169934667141894\n",
      "1  llm-based  2  1  0.15904041823988746\n",
      "2  llm-based  3  1  0.15904041823988746\n",
      "3  llm-based  6  1  0.15904041823988746\n",
      "1  cal  2  1  0.28169934667141894\n",
      "1  dataset  2  1  0.13264666955734586\n",
      "2  dataset  3  1  0.13264666955734586\n",
      "3  dataset  5  1  0.13264666955734586\n",
      "4  dataset  6  2  0.2652933391146917\n",
      "1  fav  2  1  0.28169934667141894\n",
      "1  research  2  1  0.20068666377598746\n",
      "2  research  3  1  0.20068666377598746\n",
      "1  off-the-shelf  2  1  0.28169934667141894\n",
      "1  pap  2  1  0.13264666955734586\n",
      "2  pap  4  1  0.13264666955734586\n",
      "3  pap  5  1  0.13264666955734586\n",
      "4  pap  6  1  0.13264666955734586\n",
      "1  analys  2  1  0.20068666377598746\n",
      "2  analys  5  1  0.20068666377598746\n",
      "1  ful  2  1  0.28169934667141894\n",
      "1  commerc  2  1  0.28169934667141894\n",
      "1  burd  2  1  0.28169934667141894\n",
      "1  paramet  2  1  0.28169934667141894\n",
      "1  12-10%  2  1  0.28169934667141894\n",
      "1  2019  2  1  0.28169934667141894\n",
      "1  ex  2  1  0.28169934667141894\n",
      "1  beir  2  1  0.20068666377598746\n",
      "2  beir  4  1  0.20068666377598746\n",
      "1  siz  2  1  0.28169934667141894\n",
      "1  achiev  2  1  0.15904041823988746\n",
      "2  achiev  4  1  0.15904041823988746\n",
      "3  achiev  5  1  0.15904041823988746\n",
      "1  solv  2  2  0.5633986933428379\n",
      "1  met  2  1  0.20068666377598746\n",
      "2  met  6  1  0.20068666377598746\n",
      "1  blackbox  2  1  0.28169934667141894\n",
      "1  templ  2  1  0.20068666377598746\n",
      "2  templ  3  1  0.20068666377598746\n",
      "1  pairw  2  1  0.28169934667141894\n",
      "1  sev  2  2  0.5633986933428379\n",
      "1  difficult  2  1  0.28169934667141894\n",
      "1  prp  2  1  0.28169934667141894\n",
      "1  direct  2  1  0.20068666377598746\n",
      "2  direct  6  1  0.20068666377598746\n",
      "1  argu  2  1  0.28169934667141894\n",
      "1  best  2  1  0.28169934667141894\n",
      "1  competit  2  1  0.28169934667141894\n",
      "1  lit  2  1  0.28169934667141894\n",
      "1  poss  2  1  0.28169934667141894\n",
      "1  instructgpt  2  1  0.28169934667141894\n",
      "1  50x  2  1  0.28169934667141894\n",
      "1  linear  2  1  0.28169934667141894\n",
      "1  first  2  1  0.15904041823988746\n",
      "2  first  4  1  0.15904041823988746\n",
      "3  first  5  1  0.15904041823988746\n",
      "1  candid  2  1  0.28169934667141894\n",
      "1  new  2  1  0.28169934667141894\n",
      "1  result  2  1  0.13264666955734586\n",
      "2  result  3  1  0.13264666955734586\n",
      "3  result  5  1  0.13264666955734586\n",
      "4  result  6  1  0.13264666955734586\n",
      "1  fine-tuned  2  1  0.28169934667141894\n",
      "1  fee  2  1  0.28169934667141894\n",
      "1  train  3  1  0.28169934667141894\n",
      "1  distil  3  2  0.5633986933428379\n",
      "1  strategy  3  1  0.28169934667141894\n",
      "1  design  3  1  0.28169934667141894\n",
      "1  attempt  3  1  0.28169934667141894\n",
      "1  tim  3  1  0.20068666377598746\n",
      "2  tim  4  1  0.20068666377598746\n",
      "1  item  3  1  0.20068666377598746\n",
      "2  item  6  2  0.4013733275519749\n",
      "1  may  3  1  0.28169934667141894\n",
      "1  inf  3  1  0.28169934667141894\n",
      "1  extend  3  1  0.28169934667141894\n",
      "1  e.g.  3  1  0.28169934667141894\n",
      "1  although  3  1  0.28169934667141894\n",
      "1  inform  3  1  0.13264666955734586\n",
      "2  inform  4  1  0.13264666955734586\n",
      "3  inform  5  1  0.13264666955734586\n",
      "4  inform  6  1  0.13264666955734586\n",
      "1  most  3  1  0.28169934667141894\n",
      "1  limit  3  1  0.20068666377598746\n",
      "2  limit  4  1  0.20068666377598746\n",
      "1  word  3  1  0.28169934667141894\n",
      "1  plain  3  1  0.28169934667141894\n",
      "1  immedy  3  1  0.28169934667141894\n",
      "1  bridg  3  1  0.20068666377598746\n",
      "2  bridg  5  1  0.20068666377598746\n",
      "1  vect  3  1  0.28169934667141894\n",
      "1  id  3  1  0.28169934667141894\n",
      "1  manifest  3  1  0.28169934667141894\n",
      "1  enough  3  1  0.28169934667141894\n",
      "1  user/item  3  1  0.28169934667141894\n",
      "1  long  3  2  0.5633986933428379\n",
      "1  fil  3  1  0.28169934667141894\n",
      "1  contain  3  1  0.28169934667141894\n",
      "1  multi-step  3  1  0.28169934667141894\n",
      "1  requir  3  1  0.28169934667141894\n",
      "1  noisy  3  1  0.28169934667141894\n",
      "1  i.e.  3  1  0.28169934667141894\n",
      "1  discret  3  1  0.28169934667141894\n",
      "1  unparallel  3  1  0.28169934667141894\n",
      "1  llm  3  1  0.15904041823988746\n",
      "2  llm  5  1  0.15904041823988746\n",
      "3  llm  6  1  0.15904041823988746\n",
      "1  input  3  1  0.15904041823988746\n",
      "2  input  4  1  0.15904041823988746\n",
      "3  input  5  1  0.15904041823988746\n",
      "1  fine-tuning  3  1  0.28169934667141894\n",
      "1  thu  3  1  0.28169934667141894\n",
      "1  three  3  1  0.28169934667141894\n",
      "1  also  3  1  0.20068666377598746\n",
      "2  also  5  1  0.20068666377598746\n",
      "1  pow  3  1  0.15904041823988746\n",
      "2  pow  5  1  0.15904041823988746\n",
      "3  pow  6  1  0.15904041823988746\n",
      "1  reason  3  1  0.28169934667141894\n",
      "1  continu  3  1  0.28169934667141894\n",
      "1  effect  3  1  0.15904041823988746\n",
      "2  effect  4  1  0.15904041823988746\n",
      "3  effect  5  1  0.15904041823988746\n",
      "1  allow  3  1  0.20068666377598746\n",
      "2  allow  5  1  0.20068666377598746\n",
      "1  giv  3  1  0.20068666377598746\n",
      "2  giv  5  1  0.20068666377598746\n",
      "1  process  3  1  0.13264666955734586\n",
      "2  process  4  1  0.13264666955734586\n",
      "3  process  5  1  0.13264666955734586\n",
      "4  process  6  1  0.13264666955734586\n",
      "1  could  3  1  0.28169934667141894\n",
      "1  address  3  1  0.28169934667141894\n",
      "1  real-world  3  1  0.28169934667141894\n",
      "1  respons  3  1  0.28169934667141894\n",
      "1  commun  3  1  0.28169934667141894\n",
      "1  unleash  3  1  0.28169934667141894\n",
      "1  pod  3  1  0.28169934667141894\n",
      "1  top-n  3  1  0.28169934667141894\n",
      "1  cap  3  1  0.28169934667141894\n",
      "1  recommend  3  2  0.4013733275519749\n",
      "2  recommend  6  1  0.20068666377598746\n",
      "1  spec  3  1  0.28169934667141894\n",
      "1  sequ  3  1  0.20068666377598746\n",
      "2  sequ  5  1  0.20068666377598746\n",
      "1  system  3  1  0.20068666377598746\n",
      "2  system  6  1  0.20068666377598746\n",
      "1  demonst  3  1  0.15904041823988746\n",
      "2  demonst  4  1  0.15904041823988746\n",
      "3  demonst  6  1  0.15904041823988746\n",
      "1  nee  3  1  0.20068666377598746\n",
      "2  nee  5  1  0.20068666377598746\n",
      "1  innov  4  1  0.28169934667141894\n",
      "1  phas  4  1  0.28169934667141894\n",
      "1  mod  4  1  0.28169934667141894\n",
      "1  adapt  4  2  0.5633986933428379\n",
      "1  aggreg  4  1  0.28169934667141894\n",
      "1  empir  4  1  0.28169934667141894\n",
      "1  boost  4  1  0.28169934667141894\n",
      "1  combin  4  1  0.20068666377598746\n",
      "2  combin  6  1  0.20068666377598746\n",
      "1  aim  4  1  0.20068666377598746\n",
      "2  aim  5  1  0.20068666377598746\n",
      "1  autom  4  1  0.28169934667141894\n",
      "1  group  4  1  0.28169934667141894\n",
      "1  reward  4  1  0.28169934667141894\n",
      "1  distinct  4  1  0.28169934667141894\n",
      "1  qerm  4  1  0.28169934667141894\n",
      "1  novel  4  1  0.20068666377598746\n",
      "2  novel  5  1  0.20068666377598746\n",
      "1  redund  4  1  0.28169934667141894\n",
      "1  complet  4  1  0.28169934667141894\n",
      "1  well-generated  4  1  0.28169934667141894\n",
      "1  expand  4  1  0.28169934667141894\n",
      "1  field  4  1  0.28169934667141894\n",
      "1  custom  4  1  0.28169934667141894\n",
      "1  12%  4  1  0.28169934667141894\n",
      "1  oft  4  1  0.28169934667141894\n",
      "1  optim  4  1  0.28169934667141894\n",
      "1  repres  4  1  0.20068666377598746\n",
      "2  repres  5  1  0.20068666377598746\n",
      "1  cruc  4  1  0.28169934667141894\n",
      "1  framework  4  2  0.5633986933428379\n",
      "1  enh  4  1  0.20068666377598746\n",
      "2  enh  5  1  0.20068666377598746\n",
      "1  refin  4  1  0.28169934667141894\n",
      "1  loop  4  1  0.28169934667141894\n",
      "1  adv  4  1  0.20068666377598746\n",
      "2  adv  5  1  0.20068666377598746\n",
      "1  singl  4  1  0.28169934667141894\n",
      "1  clust  4  2  0.5633986933428379\n",
      "1  rat  4  1  0.28169934667141894\n",
      "1  weight  4  1  0.28169934667141894\n",
      "1  pot  4  1  0.20068666377598746\n",
      "2  pot  6  1  0.20068666377598746\n",
      "1  constrain  4  1  0.28169934667141894\n",
      "1  well-known  4  1  0.28169934667141894\n",
      "1  init  4  1  0.28169934667141894\n",
      "1  sota  4  1  0.28169934667141894\n",
      "1  gencrf  4  1  0.28169934667141894\n",
      "1  capt  4  2  0.3180808364797749\n",
      "2  capt  5  2  0.3180808364797749\n",
      "3  capt  6  1  0.15904041823988746\n",
      "1  differenty  4  1  0.28169934667141894\n",
      "1  surpass  4  1  0.28169934667141894\n",
      "1  divers  4  1  0.28169934667141894\n",
      "1  integr  4  1  0.20068666377598746\n",
      "2  integr  5  1  0.20068666377598746\n",
      "1  expl  4  1  0.20068666377598746\n",
      "2  expl  6  1  0.20068666377598746\n",
      "1  symbol  5  2  0.5633986933428379\n",
      "1  graph-based  5  1  0.28169934667141894\n",
      "1  sess  5  2  0.5633986933428379\n",
      "1  structures  5  1  0.28169934667141894\n",
      "1  neglect  5  1  0.28169934667141894\n",
      "1  contrast  5  1  0.28169934667141894\n",
      "1  learn  5  1  0.28169934667141894\n",
      "1  includ  5  1  0.28169934667141894\n",
      "1  modern  5  1  0.28169934667141894\n",
      "1  predict  5  1  0.28169934667141894\n",
      "1  en  5  1  0.28169934667141894\n",
      "1  interact  5  3  0.8450980400142568\n",
      "1  corpor  5  1  0.28169934667141894\n",
      "1  hist  5  1  0.28169934667141894\n",
      "1  overlook  5  1  0.28169934667141894\n",
      "1  structural  5  1  0.28169934667141894\n",
      "1  graph-to-text  5  1  0.28169934667141894\n",
      "1  nat  5  1  0.20068666377598746\n",
      "2  nat  6  1  0.20068666377598746\n",
      "1  discrep  5  1  0.28169934667141894\n",
      "1  pre-trained  5  1  0.28169934667141894\n",
      "1  tiangong-st  5  1  0.28169934667141894\n",
      "1  two  5  1  0.28169934667141894\n",
      "1  gramm  5  1  0.28169934667141894\n",
      "1  sem  5  1  0.28169934667141894\n",
      "1  sery  5  1  0.28169934667141894\n",
      "1  link  5  1  0.28169934667141894\n",
      "1  confirm  5  1  0.28169934667141894\n",
      "1  cur  5  1  0.28169934667141894\n",
      "1  fulfil  5  1  0.28169934667141894\n",
      "1  moreov  5  1  0.28169934667141894\n",
      "1  paradigm  5  1  0.28169934667141894\n",
      "1  nod  5  1  0.28169934667141894\n",
      "1  topolog  5  1  0.28169934667141894\n",
      "1  tradit  5  1  0.20068666377598746\n",
      "2  tradit  6  1  0.20068666377598746\n",
      "1  self-supervised  5  1  0.28169934667141894\n",
      "1  methodolog  5  1  0.28169934667141894\n",
      "1  produc  5  1  0.28169934667141894\n",
      "1  graph  5  2  0.5633986933428379\n",
      "1  convert  5  1  0.28169934667141894\n",
      "1  rul  5  1  0.28169934667141894\n",
      "1  supery  5  1  0.28169934667141894\n",
      "1  off  5  1  0.28169934667141894\n",
      "1  structure  5  1  0.28169934667141894\n",
      "1  act  5  1  0.28169934667141894\n",
      "1  typ  5  1  0.28169934667141894\n",
      "1  object  5  1  0.28169934667141894\n",
      "1  sgr  5  1  0.28169934667141894\n",
      "1  coarse-grained  5  1  0.28169934667141894\n",
      "1  foc  5  1  0.28169934667141894\n",
      "1  word-level  5  1  0.28169934667141894\n",
      "1  fine-grained  5  1  0.28169934667141894\n",
      "1  involv  5  1  0.28169934667141894\n",
      "1  priorit  5  1  0.28169934667141894\n",
      "1  deep  5  1  0.28169934667141894\n",
      "1  cont  5  1  0.20068666377598746\n",
      "2  cont  6  1  0.20068666377598746\n",
      "1  within  5  1  0.28169934667141894\n",
      "1  comprehend  5  1  0.28169934667141894\n",
      "1  aol  5  1  0.28169934667141894\n",
      "1  text-based  5  1  0.28169934667141894\n",
      "1  concret  5  1  0.28169934667141894\n",
      "1  gap  5  1  0.28169934667141894\n",
      "1  seamless  5  1  0.28169934667141894\n",
      "1  view  6  1  0.28169934667141894\n",
      "1  subsequ  6  1  0.28169934667141894\n",
      "1  play  6  1  0.28169934667141894\n",
      "1  moviel  6  1  0.28169934667141894\n",
      "1  rol  6  1  0.28169934667141894\n",
      "1  describ  6  2  0.5633986933428379\n",
      "1  consid  6  1  0.28169934667141894\n",
      "1  on  6  1  0.28169934667141894\n",
      "1  obtain  6  1  0.28169934667141894\n",
      "1  web  6  1  0.28169934667141894\n",
      "1  alpac  6  1  0.28169934667141894\n",
      "1  conduc  6  1  0.28169934667141894\n",
      "1  ndcg  6  1  0.28169934667141894\n",
      "1  nam  6  1  0.28169934667141894\n",
      "1  hit  6  1  0.28169934667141894\n",
      "1  top  6  1  0.28169934667141894\n",
      "1  consist  6  1  0.28169934667141894\n",
      "1  emerg  6  1  0.28169934667141894\n",
      "1  1m  6  1  0.28169934667141894\n",
      "1  titl  6  1  0.28169934667141894\n",
      "1  op  6  1  0.28169934667141894\n",
      "1  book  6  1  0.28169934667141894\n",
      "1  scraping  6  1  0.28169934667141894\n",
      "1  cast  6  1  0.28169934667141894\n",
      "1  auth  6  1  0.28169934667141894\n",
      "1  web-scraped  6  1  0.28169934667141894\n",
      "1  year  6  1  0.28169934667141894\n",
      "1  inconsist  6  1  0.28169934667141894\n",
      "1  sum  6  1  0.28169934667141894\n",
      "1  man  6  1  0.28169934667141894\n",
      "1  ess  6  1  0.28169934667141894\n",
      "1  pivot  6  1  0.28169934667141894\n",
      "1  ml  6  1  0.28169934667141894\n",
      "1  lik  6  1  0.28169934667141894\n",
      "1  provid  6  1  0.28169934667141894\n",
      "1  goodread  6  1  0.28169934667141894\n",
      "1  suscept  6  1  0.28169934667141894\n",
      "1  few-shot  6  1  0.28169934667141894\n",
      "1  comp  6  2  0.5633986933428379\n",
      "1  movy  6  1  0.28169934667141894\n",
      "1  exhibit  6  1  0.28169934667141894\n",
      "1  feat  6  1  0.28169934667141894\n",
      "1  tool  6  1  0.28169934667141894\n",
      "1  sourc  6  1  0.28169934667141894\n",
      "1  detail  6  1  0.28169934667141894\n",
      "1  study  6  1  0.28169934667141894\n",
      "1  gpt-3.5  6  1  0.28169934667141894\n",
      "1  compr  6  1  0.28169934667141894\n",
      "1  time-consuming  6  1  0.28169934667141894\n",
      "1  scraped  6  1  0.28169934667141894\n",
      "1  dat  6  1  0.28169934667141894\n",
      "1  publ  6  1  0.28169934667141894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inverse_reg_lancaster = {}\n",
    "\n",
    "for i in range(len(termes_reg_lancaster)):\n",
    "    seen_terms = set()  # Track terms processed in the current document\n",
    "\n",
    "    for j in range(len(termes_reg_lancaster[i])):\n",
    "        term = termes_reg_lancaster[i][j]\n",
    "\n",
    "        if (term, i) not in seen_terms:\n",
    "            seen_terms.add((term, i))\n",
    "\n",
    "            if term not in inverse_reg_lancaster:\n",
    "                inverse_reg_lancaster[term] = []\n",
    "            \n",
    "            frequency_term = frequency_dict_reg_lancaster_documents[i][termes_reg_lancaster[i][j]]\n",
    "            poids_term = poids(frequency_term, max_frequency_dict_reg_lancaster_documents[i], document_frequency_dict_reg_lancaster[termes_reg_lancaster[i][j]], n_reg)\n",
    "            \n",
    "            inverse_reg_lancaster[term].append((i + 1, frequency_term, poids_term))\n",
    "\n",
    "inverse_reg_lancaster_output = \"\"\n",
    "for term, docs in inverse_reg_lancaster.items():\n",
    "    for idx, doc_info in enumerate(docs, 1):\n",
    "        doc_num, frequency_term, poids_term = doc_info\n",
    "        inverse_reg_lancaster_output += f\"{idx}  {term}  {doc_num}  {frequency_term}  {poids_term}\\n\"\n",
    "\n",
    "print(inverse_reg_lancaster_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  lev  1  1  0.11928031367991561\n",
      "2  lev  4  2  0.3180808364797749\n",
      "3  lev  5  1  0.23856062735983122\n",
      "1  rank  1  1  0.11928031367991561\n",
      "2  rank  2  3  0.47712125471966244\n",
      "3  rank  5  1  0.23856062735983122\n",
      "1  relev  1  1  0.2112745100035642\n",
      "1  improv  1  4  0.3979400086720376\n",
      "2  improv  2  1  0.13264666955734586\n",
      "3  improv  3  2  0.3979400086720376\n",
      "4  improv  4  1  0.13264666955734586\n",
      "1  18%  1  1  0.2112745100035642\n",
      "1  evalu  1  1  0.11928031367991561\n",
      "2  evalu  4  1  0.15904041823988746\n",
      "3  evalu  6  1  0.15904041823988746\n",
      "1  tak  1  1  0.11928031367991561\n",
      "2  tak  3  1  0.23856062735983122\n",
      "3  tak  5  1  0.23856062735983122\n",
      "1  msmarco  1  1  0.2112745100035642\n",
      "1  knowledg  1  1  0.2112745100035642\n",
      "1  instruct  1  1  0.1505149978319906\n",
      "2  instruct  5  1  0.3010299956639812\n",
      "1  technique,  1  1  0.2112745100035642\n",
      "1  investig  1  1  0.2112745100035642\n",
      "1  rel  1  1  0.2112745100035642\n",
      "1  recently,  1  1  0.2112745100035642\n",
      "1  5%  1  1  0.2112745100035642\n",
      "1  retriev  1  1  0.1505149978319906\n",
      "2  retriev  4  3  0.6020599913279624\n",
      "1  query  1  2  0.1989700043360188\n",
      "2  query  2  1  0.13264666955734586\n",
      "3  query  4  3  0.3979400086720376\n",
      "4  query  5  1  0.1989700043360188\n",
      "1  shown  1  1  0.2112745100035642\n",
      "1  pseudo  1  1  0.2112745100035642\n",
      "1  propos  1  1  0.08560567020555157\n",
      "2  propos  2  1  0.1141408936074021\n",
      "3  propos  3  1  0.17121134041110314\n",
      "4  propos  4  1  0.1141408936074021\n",
      "5  propos  5  1  0.17121134041110314\n",
      "1  us  1  2  0.1505149978319906\n",
      "2  us  2  2  0.20068666377598746\n",
      "3  us  3  2  0.3010299956639812\n",
      "4  us  4  1  0.10034333188799373\n",
      "5  us  5  2  0.3010299956639812\n",
      "6  us  6  3  0.3010299956639812\n",
      "1  strategies  1  1  0.11928031367991561\n",
      "2  strategies  4  1  0.15904041823988746\n",
      "3  strategies  5  1  0.23856062735983122\n",
      "1  prompt  1  1  0.0994850021680094\n",
      "2  prompt  2  3  0.3979400086720376\n",
      "3  prompt  3  2  0.3979400086720376\n",
      "4  prompt  6  2  0.2652933391146917\n",
      "1  abl  1  1  0.1505149978319906\n",
      "2  abl  5  1  0.3010299956639812\n",
      "1  incorp  1  1  0.2112745100035642\n",
      "1  approach  1  1  0.0994850021680094\n",
      "2  approach  2  1  0.13264666955734586\n",
      "3  approach  3  1  0.1989700043360188\n",
      "4  approach  5  1  0.1989700043360188\n",
      "1  user’s  1  1  0.2112745100035642\n",
      "1  post-retrieval  1  1  0.2112745100035642\n",
      "1  performance.  1  1  0.2112745100035642\n",
      "1  state-of-art.  1  1  0.2112745100035642\n",
      "1  four  1  1  0.2112745100035642\n",
      "1  int  1  1  0.1505149978319906\n",
      "2  int  4  2  0.4013733275519749\n",
      "1  tasks,  1  1  0.11928031367991561\n",
      "2  tasks,  2  1  0.15904041823988746\n",
      "3  tasks,  3  1  0.23856062735983122\n",
      "1  success  1  1  0.1505149978319906\n",
      "2  success  4  1  0.20068666377598746\n",
      "1  larg  1  1  0.0752574989159953\n",
      "2  larg  2  1  0.10034333188799373\n",
      "3  larg  3  1  0.1505149978319906\n",
      "4  larg  4  1  0.10034333188799373\n",
      "5  larg  5  1  0.1505149978319906\n",
      "6  larg  6  1  0.10034333188799373\n",
      "1  24%  1  1  0.2112745100035642\n",
      "1  transform  1  1  0.2112745100035642\n",
      "1  reformulation(qr)  1  1  0.2112745100035642\n",
      "1  ultim  1  1  0.2112745100035642\n",
      "1  ndcg@10  1  1  0.2112745100035642\n",
      "1  documents.  1  1  0.2112745100035642\n",
      "1  benchmarks,  1  1  0.2112745100035642\n",
      "1  experience.  1  1  0.2112745100035642\n",
      "1  find  1  1  0.1505149978319906\n",
      "2  find  3  1  0.3010299956639812\n",
      "1  feedback,  1  1  0.2112745100035642\n",
      "1  inh  1  1  0.2112745100035642\n",
      "1  set  1  2  0.23856062735983122\n",
      "2  set  3  1  0.23856062735983122\n",
      "3  set  5  1  0.23856062735983122\n",
      "1  prom  1  1  0.2112745100035642\n",
      "1  qr  1  1  0.2112745100035642\n",
      "1  bas  1  1  0.11928031367991561\n",
      "2  bas  2  1  0.15904041823988746\n",
      "3  bas  4  1  0.15904041823988746\n",
      "1  reformulation.  1  1  0.2112745100035642\n",
      "1  ir  1  1  0.2112745100035642\n",
      "1  show  1  1  0.1505149978319906\n",
      "2  show  2  1  0.20068666377598746\n",
      "1  prevy  1  1  0.11928031367991561\n",
      "2  prevy  2  1  0.15904041823988746\n",
      "3  prevy  4  1  0.15904041823988746\n",
      "1  9%  1  1  0.2112745100035642\n",
      "1  genqrensemblerf  1  1  0.2112745100035642\n",
      "1  benefit  1  1  0.2112745100035642\n",
      "1  ensembl  1  1  0.2112745100035642\n",
      "1  feedback  1  1  0.1505149978319906\n",
      "2  feedback  4  1  0.20068666377598746\n",
      "1  introduc  1  1  0.1505149978319906\n",
      "2  introduc  5  1  0.3010299956639812\n",
      "1  pseudo-relevance  1  1  0.2112745100035642\n",
      "1  due  1  1  0.2112745100035642\n",
      "1  context,  1  1  0.2112745100035642\n",
      "1  paraphras  1  1  0.2112745100035642\n",
      "1  exploit  1  1  0.2112745100035642\n",
      "1  reform  1  1  0.1505149978319906\n",
      "2  reform  4  2  0.4013733275519749\n",
      "1  mrr  1  1  0.2112745100035642\n",
      "1  origin  1  1  0.2112745100035642\n",
      "1  text  1  1  0.11928031367991561\n",
      "2  text  3  1  0.23856062735983122\n",
      "3  text  5  1  0.23856062735983122\n",
      "1  techn  1  1  0.11928031367991561\n",
      "2  techn  2  1  0.15904041823988746\n",
      "3  techn  4  1  0.15904041823988746\n",
      "1  feedback.  1  1  0.2112745100035642\n",
      "1  upto  1  1  0.2112745100035642\n",
      "1  align  1  1  0.2112745100035642\n",
      "1  keyword  1  1  0.2112745100035642\n",
      "1  task,  1  1  0.1505149978319906\n",
      "2  task,  3  1  0.3010299956639812\n",
      "1  many  1  1  0.2112745100035642\n",
      "1  pass  1  1  0.2112745100035642\n",
      "1  genqrensembl  1  1  0.2112745100035642\n",
      "1  search  1  1  0.11928031367991561\n",
      "2  search  4  1  0.15904041823988746\n",
      "3  search  5  1  0.23856062735983122\n",
      "1  variant,  1  1  0.2112745100035642\n",
      "1  multipl  1  1  0.11928031367991561\n",
      "2  multipl  4  1  0.15904041823988746\n",
      "3  multipl  6  1  0.15904041823988746\n",
      "1  langu  1  1  0.0752574989159953\n",
      "2  langu  2  1  0.10034333188799373\n",
      "3  langu  3  1  0.1505149978319906\n",
      "4  langu  4  1  0.10034333188799373\n",
      "5  langu  5  2  0.3010299956639812\n",
      "6  langu  6  2  0.20068666377598746\n",
      "1  zero-shot  1  1  0.2112745100035642\n",
      "1  models.  1  1  0.1505149978319906\n",
      "2  models.  3  1  0.3010299956639812\n",
      "1  bet  1  1  0.2112745100035642\n",
      "1  gain  1  1  0.2112745100035642\n",
      "1  gen  1  2  0.1989700043360188\n",
      "2  gen  4  2  0.2652933391146917\n",
      "3  gen  5  2  0.3979400086720376\n",
      "4  gen  6  3  0.3979400086720376\n",
      "1  map  1  1  0.2112745100035642\n",
      "1  inspir  1  1  0.1505149978319906\n",
      "2  inspir  3  1  0.3010299956639812\n",
      "1  help  1  1  0.2112745100035642\n",
      "1  complex  2  1  0.20068666377598746\n",
      "2  complex  5  1  0.3010299956639812\n",
      "1  (prp).  2  1  0.28169934667141894\n",
      "1  ev  2  1  0.28169934667141894\n",
      "1  efficy  2  1  0.20068666377598746\n",
      "2  efficy  3  2  0.6020599913279624\n",
      "1  open-sourced  2  1  0.20068666377598746\n",
      "2  open-sourced  6  1  0.20068666377598746\n",
      "1  gpt-4  2  1  0.28169934667141894\n",
      "1  baselin  2  2  0.5633986933428379\n",
      "1  standard  2  1  0.28169934667141894\n",
      "1  flan-ul2  2  1  0.28169934667141894\n",
      "1  moderate-sized  2  1  0.28169934667141894\n",
      "1  challeng  2  1  0.28169934667141894\n",
      "1  furthermore,  2  1  0.20068666377598746\n",
      "2  furthermore,  4  1  0.20068666377598746\n",
      "1  formulations.  2  1  0.28169934667141894\n",
      "1  outperform  2  3  0.8450980400142568\n",
      "1  llms  2  1  0.13264666955734586\n",
      "2  llms  4  1  0.13264666955734586\n",
      "3  llms  5  1  0.1989700043360188\n",
      "4  llms  6  1  0.13264666955734586\n",
      "1  10%  2  1  0.28169934667141894\n",
      "1  state-of-the-art  2  1  0.20068666377598746\n",
      "2  state-of-the-art  4  1  0.20068666377598746\n",
      "1  20b  2  1  0.28169934667141894\n",
      "1  found  2  1  0.28169934667141894\n",
      "1  interest  2  1  0.28169934667141894\n",
      "1  pract  2  1  0.28169934667141894\n",
      "1  chatgpt  2  1  0.28169934667141894\n",
      "1  problem.  2  1  0.28169934667141894\n",
      "1  method  2  1  0.20068666377598746\n",
      "2  method  4  1  0.20068666377598746\n",
      "1  ndcg@10.  2  1  0.20068666377598746\n",
      "2  ndcg@10.  4  1  0.20068666377598746\n",
      "1  trec-dl  2  1  0.28169934667141894\n",
      "1  superv  2  1  0.28169934667141894\n",
      "1  sign  2  1  0.13264666955734586\n",
      "2  sign  3  1  0.1989700043360188\n",
      "3  sign  4  1  0.13264666955734586\n",
      "4  sign  6  1  0.13264666955734586\n",
      "1  listw  2  1  0.28169934667141894\n",
      "1  175b  2  1  0.28169934667141894\n",
      "1  (llms)  2  1  0.20068666377598746\n",
      "2  (llms)  4  1  0.20068666377598746\n",
      "1  av  2  1  0.28169934667141894\n",
      "1  reduc  2  1  0.20068666377598746\n",
      "2  reduc  3  1  0.3010299956639812\n",
      "1  pointw  2  1  0.28169934667141894\n",
      "1  understand  2  1  0.20068666377598746\n",
      "2  understand  3  1  0.3010299956639812\n",
      "1  4.2%  2  1  0.28169934667141894\n",
      "1  llm-based  2  1  0.15904041823988746\n",
      "2  llm-based  3  1  0.23856062735983122\n",
      "3  llm-based  6  1  0.15904041823988746\n",
      "1  cal  2  1  0.28169934667141894\n",
      "1  perform  2  2  0.4013733275519749\n",
      "2  perform  4  1  0.20068666377598746\n",
      "1  fav  2  1  0.28169934667141894\n",
      "1  research  2  1  0.20068666377598746\n",
      "2  research  3  1  0.3010299956639812\n",
      "1  vary  2  1  0.15904041823988746\n",
      "2  vary  3  1  0.23856062735983122\n",
      "3  vary  4  2  0.3180808364797749\n",
      "1  off-the-shelf  2  1  0.28169934667141894\n",
      "1  docu  2  1  0.28169934667141894\n",
      "1  analys  2  1  0.20068666377598746\n",
      "2  analys  5  1  0.3010299956639812\n",
      "1  ful  2  1  0.28169934667141894\n",
      "1  commerc  2  1  0.28169934667141894\n",
      "1  benchmark  2  2  0.3180808364797749\n",
      "2  benchmark  4  1  0.15904041823988746\n",
      "3  benchmark  5  1  0.23856062735983122\n",
      "1  paper,  2  1  0.13264666955734586\n",
      "2  paper,  4  1  0.13264666955734586\n",
      "3  paper,  5  1  0.1989700043360188\n",
      "4  paper,  6  1  0.13264666955734586\n",
      "1  model  2  2  0.2282817872148042\n",
      "2  model  3  2  0.3424226808222063\n",
      "3  model  4  2  0.2282817872148042\n",
      "4  model  5  2  0.3424226808222063\n",
      "5  model  6  1  0.1141408936074021\n",
      "1  burd  2  1  0.28169934667141894\n",
      "1  paramet  2  1  0.28169934667141894\n",
      "1  literature,  2  1  0.28169934667141894\n",
      "1  12-10%  2  1  0.28169934667141894\n",
      "1  2019  2  1  0.28169934667141894\n",
      "1  2020,  2  1  0.28169934667141894\n",
      "1  ex  2  1  0.28169934667141894\n",
      "1  metrics.  2  1  0.20068666377598746\n",
      "2  metrics.  6  1  0.20068666377598746\n",
      "1  beir  2  1  0.20068666377598746\n",
      "2  beir  4  1  0.20068666377598746\n",
      "1  parameters,  2  1  0.28169934667141894\n",
      "1  (estimated)  2  1  0.28169934667141894\n",
      "1  size,  2  1  0.28169934667141894\n",
      "1  achiev  2  1  0.15904041823988746\n",
      "2  achiev  4  1  0.15904041823988746\n",
      "3  achiev  5  1  0.23856062735983122\n",
      "1  solv  2  2  0.5633986933428379\n",
      "1  datasets.  2  1  0.28169934667141894\n",
      "1  blackbox  2  1  0.28169934667141894\n",
      "1  templ  2  1  0.20068666377598746\n",
      "2  templ  3  1  0.3010299956639812\n",
      "1  pairw  2  1  0.28169934667141894\n",
      "1  sev  2  2  0.5633986933428379\n",
      "1  difficult  2  1  0.28169934667141894\n",
      "1  prp  2  1  0.28169934667141894\n",
      "1  direct  2  1  0.20068666377598746\n",
      "2  direct  6  1  0.20068666377598746\n",
      "1  argu  2  1  0.28169934667141894\n",
      "1  best  2  1  0.28169934667141894\n",
      "1  llms.  2  1  0.20068666377598746\n",
      "2  llms.  5  1  0.3010299956639812\n",
      "1  competit  2  1  0.28169934667141894\n",
      "1  lit  2  1  0.28169934667141894\n",
      "1  poss  2  1  0.28169934667141894\n",
      "1  solutions,  2  1  0.28169934667141894\n",
      "1  however,  2  1  0.28169934667141894\n",
      "1  instructgpt  2  1  0.28169934667141894\n",
      "1  50x  2  1  0.28169934667141894\n",
      "1  linear  2  1  0.28169934667141894\n",
      "1  first  2  1  0.15904041823988746\n",
      "2  first  4  1  0.15904041823988746\n",
      "3  first  5  1  0.23856062735983122\n",
      "1  candid  2  1  0.28169934667141894\n",
      "1  new  2  1  0.28169934667141894\n",
      "1  result  2  1  0.13264666955734586\n",
      "2  result  3  1  0.1989700043360188\n",
      "3  result  5  1  0.1989700043360188\n",
      "4  result  6  1  0.13264666955734586\n",
      "1  fine-tuned  2  1  0.28169934667141894\n",
      "1  fee  2  1  0.28169934667141894\n",
      "1  train  3  1  0.4225490200071284\n",
      "1  distil  3  2  0.8450980400142568\n",
      "1  process,  3  1  0.3010299956639812\n",
      "2  process,  5  1  0.3010299956639812\n",
      "1  strategy  3  1  0.4225490200071284\n",
      "1  design  3  1  0.4225490200071284\n",
      "1  attempt  3  1  0.4225490200071284\n",
      "1  tim  3  1  0.4225490200071284\n",
      "1  item  3  1  0.3010299956639812\n",
      "2  item  6  1  0.20068666377598746\n",
      "1  may  3  1  0.4225490200071284\n",
      "1  inf  3  1  0.4225490200071284\n",
      "1  extend  3  1  0.4225490200071284\n",
      "1  although  3  1  0.4225490200071284\n",
      "1  tasks.  3  1  0.3010299956639812\n",
      "2  tasks.  6  1  0.20068666377598746\n",
      "1  most  3  1  0.4225490200071284\n",
      "1  (i.e.,  3  1  0.4225490200071284\n",
      "1  limit  3  1  0.3010299956639812\n",
      "2  limit  4  1  0.20068666377598746\n",
      "1  word  3  1  0.4225490200071284\n",
      "1  plain  3  1  0.4225490200071284\n",
      "1  immedy  3  1  0.4225490200071284\n",
      "1  bridg  3  1  0.3010299956639812\n",
      "2  bridg  5  1  0.3010299956639812\n",
      "1  vect  3  1  0.4225490200071284\n",
      "1  id  3  1  0.4225490200071284\n",
      "1  manifest  3  1  0.4225490200071284\n",
      "1  enough  3  1  0.4225490200071284\n",
      "1  limited.  3  1  0.4225490200071284\n",
      "1  user/item  3  1  0.4225490200071284\n",
      "1  long  3  2  0.8450980400142568\n",
      "1  fil  3  1  0.4225490200071284\n",
      "1  contain  3  1  0.4225490200071284\n",
      "1  multi-step  3  1  0.4225490200071284\n",
      "1  time.  3  1  0.3010299956639812\n",
      "2  time.  4  1  0.20068666377598746\n",
      "1  requir  3  1  0.4225490200071284\n",
      "1  dataset  3  1  0.3010299956639812\n",
      "2  dataset  6  2  0.4013733275519749\n",
      "1  noisy  3  1  0.4225490200071284\n",
      "1  (pod)  3  1  0.4225490200071284\n",
      "1  discret  3  1  0.4225490200071284\n",
      "1  unparallel  3  1  0.4225490200071284\n",
      "1  llm  3  1  0.4225490200071284\n",
      "1  input  3  1  0.23856062735983122\n",
      "2  input  4  1  0.15904041823988746\n",
      "3  input  5  1  0.23856062735983122\n",
      "1  fine-tuning  3  1  0.4225490200071284\n",
      "1  thu  3  1  0.4225490200071284\n",
      "1  models,  3  1  0.4225490200071284\n",
      "1  (llm)  3  1  0.4225490200071284\n",
      "1  three  3  1  0.4225490200071284\n",
      "1  also  3  1  0.3010299956639812\n",
      "2  also  5  1  0.3010299956639812\n",
      "1  pow  3  1  0.23856062735983122\n",
      "2  pow  5  1  0.23856062735983122\n",
      "3  pow  6  1  0.15904041823988746\n",
      "1  continu  3  1  0.4225490200071284\n",
      "1  information.  3  1  0.4225490200071284\n",
      "1  response.  3  1  0.4225490200071284\n",
      "1  task  3  1  0.3010299956639812\n",
      "2  task  5  2  0.6020599913279624\n",
      "1  effect  3  1  0.23856062735983122\n",
      "2  effect  4  1  0.15904041823988746\n",
      "3  effect  5  1  0.23856062735983122\n",
      "1  allow  3  1  0.3010299956639812\n",
      "2  allow  5  1  0.3010299956639812\n",
      "1  expery  3  1  0.23856062735983122\n",
      "2  expery  4  1  0.15904041823988746\n",
      "3  expery  5  1  0.23856062735983122\n",
      "1  prompt)  3  1  0.4225490200071284\n",
      "1  recommendation.  3  1  0.4225490200071284\n",
      "1  problems,  3  1  0.4225490200071284\n",
      "1  giv  3  1  0.3010299956639812\n",
      "2  giv  5  1  0.3010299956639812\n",
      "1  could  3  1  0.4225490200071284\n",
      "1  address  3  1  0.4225490200071284\n",
      "1  real-world  3  1  0.4225490200071284\n",
      "1  commun  3  1  0.4225490200071284\n",
      "1  unleash  3  1  0.4225490200071284\n",
      "1  e.g.,  3  1  0.4225490200071284\n",
      "1  top-n  3  1  0.4225490200071284\n",
      "1  cap  3  1  0.4225490200071284\n",
      "1  reasoning,  3  1  0.4225490200071284\n",
      "1  recommend  3  2  0.6020599913279624\n",
      "2  recommend  6  1  0.20068666377598746\n",
      "1  improved,  3  1  0.4225490200071284\n",
      "1  spec  3  1  0.4225490200071284\n",
      "1  sequ  3  1  0.3010299956639812\n",
      "2  sequ  5  1  0.3010299956639812\n",
      "1  system  3  1  0.4225490200071284\n",
      "1  demonst  3  1  0.23856062735983122\n",
      "2  demonst  4  1  0.15904041823988746\n",
      "3  demonst  6  1  0.15904041823988746\n",
      "1  text,  3  1  0.4225490200071284\n",
      "1  nee  3  1  0.4225490200071284\n",
      "1  innov  4  1  0.28169934667141894\n",
      "1  phas  4  1  0.28169934667141894\n",
      "1  gencrf:  4  1  0.28169934667141894\n",
      "1  mod  4  1  0.28169934667141894\n",
      "1  adapt  4  2  0.5633986933428379\n",
      "1  aggreg  4  1  0.28169934667141894\n",
      "1  empir  4  1  0.28169934667141894\n",
      "1  inform  4  1  0.15904041823988746\n",
      "2  inform  5  1  0.23856062735983122\n",
      "3  inform  6  1  0.15904041823988746\n",
      "1  boost  4  1  0.28169934667141894\n",
      "1  combin  4  1  0.20068666377598746\n",
      "2  combin  6  1  0.20068666377598746\n",
      "1  aim  4  1  0.20068666377598746\n",
      "2  aim  5  1  0.3010299956639812\n",
      "1  autom  4  1  0.28169934667141894\n",
      "1  (qerm)  4  1  0.28169934667141894\n",
      "1  problem  4  1  0.28169934667141894\n",
      "1  group  4  1  0.28169934667141894\n",
      "1  reward  4  1  0.28169934667141894\n",
      "1  distinct  4  1  0.28169934667141894\n",
      "1  expansions,  4  1  0.28169934667141894\n",
      "1  novel  4  1  0.20068666377598746\n",
      "2  novel  5  1  0.3010299956639812\n",
      "1  query.  4  1  0.28169934667141894\n",
      "1  retrieval.  4  1  0.28169934667141894\n",
      "1  redund  4  1  0.28169934667141894\n",
      "1  complet  4  1  0.28169934667141894\n",
      "1  performance,  4  1  0.28169934667141894\n",
      "1  well-generated  4  1  0.28169934667141894\n",
      "1  field  4  1  0.28169934667141894\n",
      "1  intents.  4  1  0.28169934667141894\n",
      "1  custom  4  1  0.28169934667141894\n",
      "1  12%  4  1  0.28169934667141894\n",
      "1  oft  4  1  0.28169934667141894\n",
      "1  optim  4  1  0.28169934667141894\n",
      "1  repres  4  1  0.20068666377598746\n",
      "2  repres  5  1  0.3010299956639812\n",
      "1  differentiated,  4  1  0.28169934667141894\n",
      "1  cruc  4  1  0.28169934667141894\n",
      "1  framework  4  2  0.5633986933428379\n",
      "1  enh  4  1  0.20068666377598746\n",
      "2  enh  5  1  0.3010299956639812\n",
      "1  refin  4  1  0.28169934667141894\n",
      "1  adv  4  1  0.20068666377598746\n",
      "2  adv  5  1  0.3010299956639812\n",
      "1  singl  4  1  0.28169934667141894\n",
      "1  user's  4  1  0.20068666377598746\n",
      "2  user's  5  1  0.3010299956639812\n",
      "1  reformulation,  4  1  0.28169934667141894\n",
      "1  clust  4  2  0.5633986933428379\n",
      "1  rat  4  1  0.28169934667141894\n",
      "1  process  4  1  0.20068666377598746\n",
      "2  process  6  1  0.20068666377598746\n",
      "1  weight  4  1  0.28169934667141894\n",
      "1  pot  4  1  0.20068666377598746\n",
      "2  pot  6  1  0.20068666377598746\n",
      "1  constrain  4  1  0.28169934667141894\n",
      "1  loops.  4  1  0.28169934667141894\n",
      "1  well-known  4  1  0.28169934667141894\n",
      "1  init  4  1  0.28169934667141894\n",
      "1  sota  4  1  0.28169934667141894\n",
      "1  gencrf  4  1  0.28169934667141894\n",
      "1  (ir)  4  1  0.28169934667141894\n",
      "1  capt  4  2  0.3180808364797749\n",
      "2  capt  5  2  0.47712125471966244\n",
      "3  capt  6  1  0.15904041823988746\n",
      "1  llms,  4  1  0.28169934667141894\n",
      "1  surpass  4  1  0.28169934667141894\n",
      "1  rec  4  1  0.15904041823988746\n",
      "2  rec  5  1  0.23856062735983122\n",
      "3  rec  6  1  0.15904041823988746\n",
      "1  prompts,  4  1  0.28169934667141894\n",
      "1  divers  4  1  0.28169934667141894\n",
      "1  integr  4  1  0.20068666377598746\n",
      "2  integr  5  1  0.3010299956639812\n",
      "1  expl  4  1  0.20068666377598746\n",
      "2  expl  6  1  0.20068666377598746\n",
      "1  symbol  5  2  0.8450980400142568\n",
      "1  corpora,  5  1  0.4225490200071284\n",
      "1  history,  5  1  0.4225490200071284\n",
      "1  graph-based  5  1  0.4225490200071284\n",
      "1  sess  5  2  0.8450980400142568\n",
      "1  structures  5  1  0.4225490200071284\n",
      "1  neglect  5  1  0.4225490200071284\n",
      "1  contrast  5  1  0.4225490200071284\n",
      "1  learn  5  1  0.4225490200071284\n",
      "1  format.  5  1  0.4225490200071284\n",
      "1  includ  5  1  0.4225490200071284\n",
      "1  (sgr),  5  1  0.4225490200071284\n",
      "1  modern  5  1  0.4225490200071284\n",
      "1  en  5  1  0.4225490200071284\n",
      "1  documents,  5  1  0.4225490200071284\n",
      "1  interact  5  2  0.8450980400142568\n",
      "1  (llms).  5  1  0.4225490200071284\n",
      "1  information,  5  1  0.4225490200071284\n",
      "1  this,  5  1  0.4225490200071284\n",
      "1  overlook  5  1  0.4225490200071284\n",
      "1  structural  5  1  0.4225490200071284\n",
      "1  graph-to-text  5  1  0.4225490200071284\n",
      "1  grammar,  5  1  0.4225490200071284\n",
      "1  datasets,  5  1  0.4225490200071284\n",
      "1  nat  5  1  0.3010299956639812\n",
      "2  nat  6  1  0.20068666377598746\n",
      "1  need.  5  1  0.4225490200071284\n",
      "1  discrep  5  1  0.4225490200071284\n",
      "1  pre-trained  5  1  0.4225490200071284\n",
      "1  concretely,  5  1  0.4225490200071284\n",
      "1  two  5  1  0.4225490200071284\n",
      "1  gramm  5  1  0.4225490200071284\n",
      "1  sem  5  1  0.4225490200071284\n",
      "1  sery  5  1  0.4225490200071284\n",
      "1  link  5  1  0.4225490200071284\n",
      "1  confirm  5  1  0.4225490200071284\n",
      "1  cur  5  1  0.4225490200071284\n",
      "1  modeling.  5  1  0.4225490200071284\n",
      "1  learning,  5  1  0.4225490200071284\n",
      "1  fulfil  5  1  0.4225490200071284\n",
      "1  tiangong-st,  5  1  0.4225490200071284\n",
      "1  paradigm  5  1  0.4225490200071284\n",
      "1  nod  5  1  0.4225490200071284\n",
      "1  topolog  5  1  0.4225490200071284\n",
      "1  tradit  5  1  0.4225490200071284\n",
      "1  self-supervised  5  1  0.4225490200071284\n",
      "1  prediction,  5  1  0.4225490200071284\n",
      "1  methodolog  5  1  0.4225490200071284\n",
      "1  produc  5  1  0.4225490200071284\n",
      "1  llms'  5  1  0.4225490200071284\n",
      "1  graph  5  2  0.8450980400142568\n",
      "1  convert  5  1  0.4225490200071284\n",
      "1  rul  5  1  0.4225490200071284\n",
      "1  supery  5  1  0.4225490200071284\n",
      "1  interactions.  5  1  0.4225490200071284\n",
      "1  off  5  1  0.4225490200071284\n",
      "1  structure  5  1  0.4225490200071284\n",
      "1  act  5  1  0.4225490200071284\n",
      "1  typ  5  1  0.4225490200071284\n",
      "1  object  5  1  0.4225490200071284\n",
      "1  coarse-grained  5  1  0.4225490200071284\n",
      "1  understanding,  5  1  0.4225490200071284\n",
      "1  foc  5  1  0.4225490200071284\n",
      "1  moreover,  5  1  0.4225490200071284\n",
      "1  word-level  5  1  0.4225490200071284\n",
      "1  generation,  5  1  0.4225490200071284\n",
      "1  involv  5  1  0.4225490200071284\n",
      "1  llm.  5  1  0.4225490200071284\n",
      "1  fine-grained.  5  1  0.4225490200071284\n",
      "1  priorit  5  1  0.4225490200071284\n",
      "1  deep  5  1  0.4225490200071284\n",
      "1  cont  5  1  0.3010299956639812\n",
      "2  cont  6  1  0.20068666377598746\n",
      "1  text.  5  1  0.4225490200071284\n",
      "1  within  5  1  0.4225490200071284\n",
      "1  comprehend  5  1  0.4225490200071284\n",
      "1  aol  5  1  0.4225490200071284\n",
      "1  approach.  5  1  0.4225490200071284\n",
      "1  text-based  5  1  0.4225490200071284\n",
      "1  gap  5  1  0.4225490200071284\n",
      "1  seamless  5  1  0.4225490200071284\n",
      "1  view  6  1  0.28169934667141894\n",
      "1  play  6  1  0.28169934667141894\n",
      "1  systems.  6  1  0.28169934667141894\n",
      "1  moviel  6  1  0.28169934667141894\n",
      "1  rol  6  1  0.28169934667141894\n",
      "1  describ  6  2  0.5633986933428379\n",
      "1  consid  6  1  0.28169934667141894\n",
      "1  on  6  1  0.28169934667141894\n",
      "1  obtain  6  1  0.28169934667141894\n",
      "1  web  6  1  0.28169934667141894\n",
      "1  alpac  6  1  0.28169934667141894\n",
      "1  alpaca,  6  1  0.28169934667141894\n",
      "1  hits,  6  1  0.28169934667141894\n",
      "1  conduc  6  1  0.28169934667141894\n",
      "1  ndcg  6  1  0.28169934667141894\n",
      "1  promise,  6  1  0.28169934667141894\n",
      "1  nam  6  1  0.28169934667141894\n",
      "1  gpt-3.5,  6  1  0.28169934667141894\n",
      "1  top  6  1  0.28169934667141894\n",
      "1  consist  6  1  0.28169934667141894\n",
      "1  inconsistencies.  6  1  0.28169934667141894\n",
      "1  emerg  6  1  0.28169934667141894\n",
      "1  1m  6  1  0.28169934667141894\n",
      "1  titl  6  1  0.28169934667141894\n",
      "1  descriptions.  6  1  0.28169934667141894\n",
      "1  subsequently,  6  1  0.28169934667141894\n",
      "1  op  6  1  0.28169934667141894\n",
      "1  book  6  1  0.28169934667141894\n",
      "1  scraping  6  1  0.28169934667141894\n",
      "1  cast  6  1  0.28169934667141894\n",
      "1  auth  6  1  0.28169934667141894\n",
      "1  web-scraped  6  1  0.28169934667141894\n",
      "1  traditionally,  6  1  0.28169934667141894\n",
      "1  sum  6  1  0.28169934667141894\n",
      "1  man  6  1  0.28169934667141894\n",
      "1  ess  6  1  0.28169934667141894\n",
      "1  pivot  6  1  0.28169934667141894\n",
      "1  ml  6  1  0.28169934667141894\n",
      "1  study,  6  1  0.28169934667141894\n",
      "1  llm,  6  1  0.28169934667141894\n",
      "1  lik  6  1  0.28169934667141894\n",
      "1  provid  6  1  0.28169934667141894\n",
      "1  goodread  6  1  0.28169934667141894\n",
      "1  items.  6  1  0.28169934667141894\n",
      "1  suscept  6  1  0.28169934667141894\n",
      "1  few-shot  6  1  0.28169934667141894\n",
      "1  comp  6  2  0.5633986933428379\n",
      "1  techniques,  6  1  0.28169934667141894\n",
      "1  movy  6  1  0.28169934667141894\n",
      "1  exhibit  6  1  0.28169934667141894\n",
      "1  feat  6  1  0.28169934667141894\n",
      "1  tool  6  1  0.28169934667141894\n",
      "1  sourc  6  1  0.28169934667141894\n",
      "1  (llms),  6  1  0.28169934667141894\n",
      "1  detail  6  1  0.28169934667141894\n",
      "1  mrr,  6  1  0.28169934667141894\n",
      "1  dataset.  6  1  0.28169934667141894\n",
      "1  years,  6  1  0.28169934667141894\n",
      "1  compr  6  1  0.28169934667141894\n",
      "1  time-consuming  6  1  0.28169934667141894\n",
      "1  scraped  6  1  0.28169934667141894\n",
      "1  dat  6  1  0.28169934667141894\n",
      "1  publ  6  1  0.28169934667141894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inverse_split_lancaster = {}\n",
    "\n",
    "for i in range(len(termes_split_lancaster)):\n",
    "    seen_terms = set()  # Track terms processed in the current document\n",
    "\n",
    "    for j in range(len(termes_split_lancaster[i])):\n",
    "        term = termes_split_lancaster[i][j]\n",
    "\n",
    "        if (term, i) not in seen_terms:\n",
    "            seen_terms.add((term, i))\n",
    "\n",
    "            if term not in inverse_split_lancaster:\n",
    "                inverse_split_lancaster[term] = []\n",
    "            \n",
    "            frequency_term = frequency_dict_split_lancaster_documents[i][termes_split_lancaster[i][j]]\n",
    "            poids_term = poids(frequency_term, max_frequency_dict_split_lancaster_documents[i], document_frequency_dict_split_lancaster[termes_split_lancaster[i][j]], n_split)\n",
    "            \n",
    "            inverse_split_lancaster[term].append((i + 1, frequency_term, poids_term))\n",
    "\n",
    "inverse_split_lancaster_output = \"\"\n",
    "for term, docs in inverse_split_lancaster.items():\n",
    "    for idx, doc_info in enumerate(docs, 1):\n",
    "        doc_num, frequency_term, poids_term = doc_info\n",
    "        inverse_split_lancaster_output += f\"{idx}  {term}  {doc_num}  {frequency_term}  {poids_term}\\n\"\n",
    "\n",
    "print(inverse_split_lancaster_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving Files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved to descripteur_split.txt\n"
     ]
    }
   ],
   "source": [
    "output_file_path = 'descripteur_split.txt'\n",
    "\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(descripteur_split)\n",
    "\n",
    "print(f'file saved to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved to descripteur_reg.txt\n"
     ]
    }
   ],
   "source": [
    "output_file_path = 'descripteur_reg.txt'\n",
    "\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(descripteur_reg)\n",
    "\n",
    "print(f'file saved to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved to descripteur_split_porter.txt\n"
     ]
    }
   ],
   "source": [
    "output_file_path = 'descripteur_split_porter.txt'\n",
    "\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(descripteur_split_porter)\n",
    "\n",
    "print(f'file saved to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved to descripteur_reg_porter.txt\n"
     ]
    }
   ],
   "source": [
    "output_file_path = 'descripteur_reg_porter.txt'\n",
    "\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(descripteur_reg_porter)\n",
    "\n",
    "print(f'file saved to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved to descripteur_split_lancaster.txt\n"
     ]
    }
   ],
   "source": [
    "output_file_path = 'descripteur_split_lancaster.txt'\n",
    "\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(descripteur_split_lancaster)\n",
    "\n",
    "print(f'file saved to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved to descripteur_reg_lancaster.txt\n"
     ]
    }
   ],
   "source": [
    "output_file_path = 'descripteur_reg_lancaster.txt'\n",
    "\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(descripteur_reg_lancaster)\n",
    "\n",
    "print(f'file saved to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved to inverse_split.txt\n"
     ]
    }
   ],
   "source": [
    "output_file_path = 'inverse_split.txt'\n",
    "\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(inverse_split_output)\n",
    "\n",
    "print(f'file saved to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved to inverse_reg.txt\n"
     ]
    }
   ],
   "source": [
    "output_file_path = 'inverse_reg.txt'\n",
    "\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(inverse_reg_output)\n",
    "\n",
    "print(f'file saved to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved to inverse_split_porter.txt\n"
     ]
    }
   ],
   "source": [
    "output_file_path = 'inverse_split_porter.txt'\n",
    "\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(inverse_split_porter_output)\n",
    "\n",
    "print(f'file saved to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved to inverse_reg_porter.txt\n"
     ]
    }
   ],
   "source": [
    "output_file_path = 'inverse_reg_porter.txt'\n",
    "\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(inverse_reg_porter_output)\n",
    "\n",
    "print(f'file saved to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved to inverse_split_lancaster.txt\n"
     ]
    }
   ],
   "source": [
    "output_file_path = 'inverse_split_lancaster.txt'\n",
    "\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(inverse_split_lancaster_output)\n",
    "\n",
    "print(f'file saved to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved to inverse_reg_lancaster.txt\n"
     ]
    }
   ],
   "source": [
    "output_file_path = 'inverse_reg_lancaster.txt'\n",
    "\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(inverse_reg_lancaster_output)\n",
    "\n",
    "print(f'file saved to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c98606bbe0e5451780f537c70198d539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Text(value='', description='Query:', layout=Layout(width='60%'), placeholder='Enter your query …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d6ccee375d4757bec51b5aa50b4040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HBox(children=(Dropdown(description='Preprocessing:', layout=Layout(width='45%'), options=('Spl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb0a6cf4a8b94703a07c0e24fab5d592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', description='Results:', layout=Layout(height='300px', width='100%'), placeholder='Results w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Colors\n",
    "border_color = 'lightgray'\n",
    "background_color = 'lightblue'  # Light blue\n",
    "container_background_color = 'lightgray'  # Slightly darker blue\n",
    "\n",
    "# Create the text input for the query\n",
    "query_input = widgets.Text(\n",
    "    description='Query:',\n",
    "    placeholder='Enter your query here',\n",
    "    layout=widgets.Layout(width='60%')\n",
    ")\n",
    "\n",
    "# Create a button to submit the query\n",
    "submit_button = widgets.Button(\n",
    "    description='Search',\n",
    "    layout=widgets.Layout(width='20%')\n",
    ")\n",
    "\n",
    "# Combine query input and submit button in a single line with styling\n",
    "query_container = widgets.HBox(\n",
    "    [query_input, submit_button],\n",
    "    layout=widgets.Layout(\n",
    "        border=f'2px solid {border_color}',\n",
    "        border_radius='10px',\n",
    "        padding='10px',\n",
    "        background_color=border_color\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create dropdowns for preprocessing parameters\n",
    "preprocessing_options = ['Split', 'Reg']\n",
    "stemming_options = ['Porter', 'Lancaster', 'No Stemming']\n",
    "\n",
    "preprocessing_dropdown = widgets.Dropdown(\n",
    "    options=preprocessing_options,\n",
    "    description='Preprocessing:',\n",
    "    layout=widgets.Layout(width='45%')\n",
    ")\n",
    "\n",
    "stemming_dropdown = widgets.Dropdown(\n",
    "    options=stemming_options,\n",
    "    description='Stemming:',\n",
    "    layout=widgets.Layout(width='45%')\n",
    ")\n",
    "\n",
    "# Group preprocessing and stemming dropdowns in a container\n",
    "preprocessing_container = widgets.HBox(\n",
    "    [preprocessing_dropdown, stemming_dropdown],\n",
    "    layout=widgets.Layout(\n",
    "        border=f'2px solid {border_color}',\n",
    "        border_radius='10px',\n",
    "        padding='10px',\n",
    "        background_color=container_background_color,\n",
    "        justify_content='space-between',\n",
    "        width='50%'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create checkboxes for file selection\n",
    "file_options = ['DOCS per Term', 'Terms per Doc']\n",
    "file_selection = widgets.RadioButtons(\n",
    "    options=file_options,\n",
    "    description='File Type:',\n",
    "    layout=widgets.Layout(width='40%')\n",
    ")\n",
    "\n",
    "# Group preprocessing_container and file_selection in a single line container\n",
    "dropdowns_container = widgets.HBox(\n",
    "    [preprocessing_container, file_selection],\n",
    "    layout=widgets.Layout(\n",
    "        border=f'2px solid {border_color}',\n",
    "        border_radius='10px',\n",
    "        padding='10px',\n",
    "        background_color=background_color,\n",
    "        justify_content='space-between'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create a text area to display results\n",
    "result_area = widgets.Textarea(\n",
    "    description='Results:',\n",
    "    placeholder='Results will be displayed here',\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(\n",
    "        width='100%',\n",
    "        height='300px',\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Function to handle button click\n",
    "def on_submit(b):\n",
    "    query = query_input.value\n",
    "    preprocessing = preprocessing_dropdown.value\n",
    "    stemming = stemming_dropdown.value\n",
    "    selected_file = file_selection.value\n",
    "\n",
    "    # Determine file path based on selection\n",
    "    file_path = \"\"\n",
    "    if selected_file == \"Terms per Doc\":  # descriptive file\n",
    "        if preprocessing == \"Split\":\n",
    "            match stemming:\n",
    "                case 'No Stemming':\n",
    "                    file_path = 'descripteur_split.txt'\n",
    "                case 'Porter':\n",
    "                    file_path = 'descripteur_split_porter.txt'\n",
    "                case 'Lancaster':\n",
    "                    file_path = 'descripteur_split_lancaster.txt'\n",
    "        else:\n",
    "            match stemming:\n",
    "                case 'No Stemming':\n",
    "                    file_path = 'descripteur_reg.txt'\n",
    "                case 'Porter':\n",
    "                    file_path = 'descripteur_reg_porter.txt'\n",
    "                case 'Lancaster':\n",
    "                    file_path = 'descripteur_reg_lancaster.txt'\n",
    "    else:  # inverse file\n",
    "        if preprocessing == \"Split\":\n",
    "            match stemming:\n",
    "                case 'No Stemming':\n",
    "                    file_path = 'inverse_split.txt'\n",
    "                case 'Porter':\n",
    "                    file_path = 'inverse_split_porter.txt'\n",
    "                case 'Lancaster':\n",
    "                    file_path = 'inverse_split_lancaster.txt'\n",
    "        else:\n",
    "            match stemming:\n",
    "                case 'No Stemming':\n",
    "                    file_path = 'inverse_reg.txt'\n",
    "                case 'Porter':\n",
    "                    file_path = 'inverse_reg_porter.txt'\n",
    "                case 'Lancaster':\n",
    "                    file_path = 'inverse_reg_lancaster.txt'\n",
    "\n",
    "    # Initialize result content with the correct header and numbered lines\n",
    "    line_counter = 1\n",
    "    if selected_file == \"Terms per Doc\":\n",
    "        result_content = \"N  Ndoc   Term           Freq   Weight\\n\"\n",
    "        \n",
    "        # Track terms and frequencies for the selected document\n",
    "        term_count = 0\n",
    "        \n",
    "        \n",
    "        # Filter the file content based on query and file type\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                parts = line.split()\n",
    "                \n",
    "                # Check if the document number matches the query\n",
    "                if parts[0] == query:\n",
    "                    # Format and add the numbered line to result_content\n",
    "                    formatted_line = f\"{line_counter:<3} {parts[0]:<5} {parts[1]:<15} {parts[2]:<5} {parts[3]:<10}\\n\"\n",
    "                    result_content += formatted_line\n",
    "                    line_counter += 1\n",
    "                    term_count += int(parts[2])  # Increment by term frequency\n",
    "                \n",
    "        # Append document vocabulary and size\n",
    "        result_content += f\"-------------------------------------------------------------------\"\n",
    "        result_content += f\"\\n# Doc vocabulary: {line_counter-1}               \"\n",
    "        result_content += f\"# Doc size: {term_count}\\n\"\n",
    "    \n",
    "    else:\n",
    "        result_content = \"N   Term            Ndoc   Freq   Weight\\n\"\n",
    "        \n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                parts = line.split()\n",
    "                \n",
    "                \n",
    "                if parts[1] == query:\n",
    "                   \n",
    "                    formatted_line = f\"{parts[0]:<3} {parts[1]:<15} {parts[2]:<5} {parts[3]:<5} {parts[4]:<10}\\n\"\n",
    "                    result_content += formatted_line\n",
    "                    line_counter += 1\n",
    "\n",
    "  \n",
    "    if line_counter == 1:  # Only header is present\n",
    "        result_content += \"No matching results found.\"\n",
    "    \n",
    "    \n",
    "    result_area.value = result_content\n",
    "\n",
    "submit_button.on_click(on_submit)\n",
    "\n",
    "# Display all widgets\n",
    "display(query_container, dropdowns_container, result_area)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
